
Title:
Quantum machine learning
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Interdisciplinary research area at the intersection of quantum physics and machine learning
 A major contributor to this article appears to have a close connection with its subject. It may require cleanup to comply with Wikipedia's content policies, particularly neutral point of view. Please discuss further on the talk page.  (September 2018) (Learn how and when to remove this template message)
.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Part of a series of articles aboutQuantum mechanics
  
    
      
        i
        â
        
          
            â
            
              â
              t
            
          
        
        
          |
        
        Ï
        (
        t
        )
        â©
        =
        
          
            
              H
              ^
            
          
        
        
          |
        
        Ï
        (
        t
        )
        â©
      
    
    {\displaystyle i\hbar {\frac {\partial }{\partial t}}|\psi (t)\rangle ={\hat {H}}|\psi (t)\rangle }
  
SchrÃ¶dinger equation
Introduction
Glossary
History
showBackground
Classical mechanics
Old quantum theory
Braâket notation

Hamiltonian
Interference


showFundamentals
Complementarity
Decoherence
Entanglement
Energy level
Measurement
Nonlocality
Quantum number
State
Superposition
Symmetry
Tunnelling
Uncertainty
Wave function
Collapse


showExperiments
Bell's inequality
DavissonâGermer
Double-slit
ElitzurâVaidman
FranckâHertz
LeggettâGarg inequality
MachâZehnder
Popper

Quantum eraser
Delayed-choice

SchrÃ¶dinger's cat
SternâGerlach
Wheeler's delayed-choice


showFormulations
Overview

Heisenberg
Interaction
Matrix
Phase-space
SchrÃ¶dinger
Sum-over-histories (path integral)


showEquations
Dirac
KleinâGordon
Pauli
Rydberg
SchrÃ¶dinger


showInterpretations
Overview

Bayesian
Consistent histories
Copenhagen
de BroglieâBohm
Ensemble
Hidden-variable
Local
Many-worlds
Objective collapse
Quantum logic
Relational
Transactional


showAdvanced topics
Relativistic quantum mechanics
Quantum field theory
Quantum information science
Quantum computing
Quantum chaos
Density matrix
Scattering theory
Quantum statistical mechanics
Quantum machine learning

showScientists
Aharonov
Bell
Bethe
Blackett
Bloch
Bohm
Bohr
Born
Bose
de Broglie
Compton
Dirac
Davisson
Debye
Ehrenfest
Einstein
Everett
Fock
Fermi
Feynman
Glauber
Gutzwiller
Heisenberg
Hilbert
Jordan
Kramers
Pauli
Lamb
Landau
Laue
Moseley
Millikan
Onnes
Planck
Rabi
Raman
Rydberg
SchrÃ¶dinger
Simmons
Sommerfeld
von Neumann
Weyl
Wien
Wigner
Zeeman
Zeilinger

.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
Quantum machine learning is the integration of quantum algorithms within machine learning programs.[1][2][3] The most common use of the term refers to machine learning algorithms for the analysis of classical data executed on a quantum computer, i.e. quantum-enhanced machine learning.[4][5][6] While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program.[7] This includes hybrid methods that involve both classical and quantum processing, where computationally difficult subroutines are outsourced to a quantum device.[8][9][10] These routines can be more complex in nature and executed faster on a quantum computer.[2] Furthermore, quantum algorithms can be used to analyze quantum states instead of classical data.[11][12] Beyond quantum computing, the term "quantum machine learning" is also associated with classical machine learning methods applied to data generated from quantum experiments (i.e. machine learning of quantum systems), such as learning the phase transitions of a quantum system[13][14] or creating new quantum experiments.[15][16][17] Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks. For example, some mathematical and numerical techniques from quantum physics are applicable to classical deep learning and vice versa.[18][19][20] Furthermore, researchers investigate more abstract notions of learning theory with respect to quantum information, sometimes referred to as "quantum learning theory".[21][22]

  Four different approaches to combine the disciplines of quantum computing and machine learning.[23][24] The first letter refers to whether the system under study is classical or quantum, while the second letter defines whether a classical or quantum information processing device is used.
Contents

1 Machine learning with quantum computers

1.1 Linear algebra simulation with quantum amplitudes
1.2 Quantum machine learning algorithms based on Grover search
1.3 Quantum-enhanced reinforcement learning
1.4 Quantum annealing
1.5 Quantum sampling techniques
1.6 Quantum neural networks
1.7 Hidden Quantum Markov Models
1.8 Fully quantum machine learning


2 Classical learning applied to quantum problems
3 Quantum learning theory
4 Implementations and experiments
5 Skepticism
6 See also
7 References



Machine learning with quantum computers[edit]
Quantum-enhanced machine learning refers to quantum algorithms that solve tasks in machine learning, thereby improving and often expediting classical machine learning techniques. Such algorithms typically require one to encode the given classical data set into a quantum computer to make it accessible for quantum information processing. Subsequently, quantum information processing routines are applied and the result of the quantum computation is read out by measuring the quantum system. For example, the outcome of the measurement of a qubit reveals the result of a binary classification task. While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices.

Linear algebra simulation with quantum amplitudes[edit]
A number of quantum algorithms for machine learning are based on the idea of amplitude encoding, that is, to associate the amplitudes of a quantum state with the inputs and outputs of computations.[25][26][27] Since a state of 
  
    
      
        n
      
    
    {\displaystyle n}
  
 qubits is described by 
  
    
      
        
          2
          
            n
          
        
      
    
    {\displaystyle 2^{n}}
  
 complex amplitudes, this information encoding can allow for an exponentially compact representation. Intuitively, this corresponds to associating a discrete probability distribution over binary random variables with a classical vector. The goal of algorithms based on amplitude encoding is to formulate quantum algorithms whose resources grow polynomially in the number of qubits 
  
    
      
        n
      
    
    {\displaystyle n}
  
, which amounts to a logarithmic growth in the number of amplitudes and thereby the dimension of the input.
Many quantum machine learning algorithms in this category are based on variations of the quantum algorithm for linear systems of equations[28] (colloquially called HHL, after the paper's authors) which, under specific conditions, performs a matrix inversion using an amount of physical resources growing only logarithmically in the dimensions of the matrix. One of these conditions is that a Hamiltonian which entrywise corresponds to the matrix can be simulated efficiently, which is known to be possible if the matrix is sparse[29] or low rank.[30] For reference, any known classical algorithm for matrix inversion requires a number of operations that grows at least quadratically in the dimension of the matrix, but they are not restricted to sparse matrices.
Quantum matrix inversion can be applied to machine learning methods in which the training reduces to solving a linear system of equations, for example in least-squares linear regression,[26][27] the least-squares version of support vector machines,[25] and Gaussian processes. [31]
A crucial bottleneck of methods that simulate linear algebra computations with the amplitudes of quantum states is state preparation, which often requires one to initialise a quantum system in a state whose amplitudes reflect the features of the entire dataset. Although efficient methods for state preparation are known for specific cases,[32][33] this step easily hides the complexity of the task.[34][35]

Quantum machine learning algorithms based on Grover search[edit]
Another approach to improving classical machine learning with quantum information processing uses amplitude amplification methods based on Grover's search algorithm, which has been shown to solve unstructured search problems with a quadratic speedup compared to classical algorithms. These quantum routines can be employed for learning algorithms that translate into an unstructured search task, as can be done, for instance, in the case of the k-medians[36] and the k-nearest neighbors algorithms.[4] Another application is a quadratic speedup in the training of perceptron.[37]
An example of amplitude amplification being used in a machine learning algorithm is Grover's search algorithm minimization. In which a subroutine uses Grover's search algorithm to find an element less than some previously defined element. This can be done with an oracle that determines whether or not a state with a corresponding element is less than the predefined one. Grover's algorithm can then find an element such that our condition is met. The minimization is initialized by some random element in our data set, and iteratively does this subroutine to find the minimum element in the data set. This minimization is notably used in quantum k-medians, and it has a speed up of at least 
  
    
      
        O
        (
        
          
            n
            
              /
            
            k
          
        
        )
      
    
    {\displaystyle O({\sqrt {n/k}})}
  
 compared to classical versions of k-medians, where 
  
    
      
        n
      
    
    {\displaystyle n}
  
 is the number of data points and 
  
    
      
        k
      
    
    {\displaystyle k}
  
 is the number of clusters.[36]
Amplitude amplification is often combined with quantum walks to achieve the same quadratic speedup. Quantum walks have been proposed to enhance Google's PageRank algorithm[38] as well as the performance of reinforcement learning agents in the projective simulation framework.[39]

Quantum-enhanced reinforcement learning[edit]
Reinforcement learning is a branch of machine learning distinct from supervised and unsupervised learning, which also admits quantum enhancements.[40][39][41] In quantum-enhanced reinforcement learning, a quantum agent interacts with a classical or quantum environment and occasionally receives rewards for its actions, which allows the agent to adapt its behaviorâin other words, to learn what to do in order to gain more rewards. In some situations, either because of the quantum processing capability of the agent,[39] or due to the possibility to probe the environment in superpositions,[24] a quantum speedup may be achieved. Implementations of these kinds of protocols have been proposed for systems of trapped ions[42] and superconducting circuits.[43] A quantum speedup of the agent's internal decision-making time[39] has been experimentally demonstrated in trapped ions,[44] while a quantum speedup of the learning time in a fully coherent (`quantum') interaction between agent and environment has been experimentally realized in a photonic setup.[45]

Quantum annealing[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Quantum annealing
Quantum annealing is an optimization technique used to determine the local minima and maxima of a function over a given set of candidate functions. This is a method of discretizing a function with many local minima or maxima in order to determine the observables of the function. The process can be distinguished from Simulated annealing by the Quantum tunneling process, by which particles tunnel through kinetic or potential barriers from a high state to a low state. Quantum annealing starts from a superposition of all possible states of a system, weighted equally. Then the time-dependent SchrÃ¶dinger equation guides the time evolution of the system, serving to affect the amplitude of each state as time increases. Eventually, the ground state can be reached to yield the instantaneous Hamiltonian of the system. .

Quantum sampling techniques[edit]
Sampling from high-dimensional probability distributions is at the core of a wide spectrum of computational techniques with important applications across science, engineering, and society. Examples include deep learning, probabilistic programming, and other machine learning and artificial intelligence applications.
A computationally hard problem, which is key for some relevant machine learning tasks, is the estimation of averages over probabilistic models defined in terms of a Boltzmann distribution. Sampling from generic probabilistic models is hard: algorithms relying heavily on sampling are expected to remain intractable no matter how large and powerful classical computing resources become. Even though quantum annealers, like those produced by D-Wave Systems, were designed for challenging combinatorial optimization problems, it has been recently recognized as a potential candidate to speed up computations that rely on sampling by exploiting quantum effects.[46]
Some research groups have recently explored the use of quantum annealing hardware for training Boltzmann machines and deep neural networks.[47][48][49] The standard approach to training Boltzmann machines relies on the computation of certain averages that can be estimated by standard sampling techniques, such as Markov chain Monte Carlo algorithms. Another possibility is to rely on a physical process, like quantum annealing, that naturally generates samples from a Boltzmann distribution. The objective is to find the optimal control parameters that best represent the empirical distribution of a given dataset.
The D-Wave 2X system hosted at NASA Ames Research Center has been recently used for the learning of a special class of restricted Boltzmann machines that can serve as a building block for deep learning architectures.[48] Complementary work that appeared roughly simultaneously showed that quantum annealing can be used for supervised learning in classification tasks.[47] The same device was later used to train a fully connected Boltzmann machine to generate, reconstruct, and classify down-scaled, low-resolution handwritten digits, among other synthetic datasets.[50] In both cases, the models trained by quantum annealing had a similar or better performance in terms of quality. The ultimate question that drives this endeavour is whether there is quantum speedup in sampling applications. Experience with the use of quantum annealers for combinatorial optimization suggests the answer is not straightforward. Reverse annealing has been used as well to solve a fully connected quantum restricted Boltzmann machine.[51]
Inspired by the success of Boltzmann machines based on classical Boltzmann distribution, a new machine learning approach based on quantum Boltzmann distribution of a transverse-field Ising Hamiltonian was recently proposed.[52] Due to the non-commutative nature of quantum mechanics, the training process of the quantum Boltzmann machine can become nontrivial. This problem was, to some extent, circumvented by introducing bounds on the quantum probabilities, allowing the authors to train the model efficiently by sampling. It is possible that a specific type of quantum Boltzmann machine has been trained in the D-Wave 2X by using a learning rule analogous to that of classical Boltzmann machines.[50] [49][53]
Quantum annealing is not the only technology for sampling. In a prepare-and-measure scenario, a universal quantum computer prepares a thermal state, which is then sampled by measurements. This can reduce the time required to train a deep restricted Boltzmann machine, and provide a richer and more comprehensive framework for deep learning than classical computing.[54] The same quantum methods also permit efficient training of full Boltzmann machines and multi-layer, fully connected models and do not have well-known classical counterparts. Relying on an efficient thermal state preparation protocol starting from an arbitrary state, quantum-enhanced Markov logic networks exploit the symmetries and the locality structure of the probabilistic graphical model generated by a first-order logic template.[55] This provides an exponential reduction in computational complexity in probabilistic inference, and, while the protocol relies on a universal quantum computer, under mild assumptions it can be embedded on contemporary quantum annealing hardware.

Quantum neural networks[edit]
Main article: Quantum neural network
Quantum analogues or generalizations of classical neural nets are often referred to as quantum neural networks. The term is claimed by a wide range of approaches, including the implementation and extension of neural networks using photons, layered variational circuits or quantum Ising-type models. Quantum neural networks are often defined as an expansion on Deutsch's model of a quantum computational network.[56] Within this model, nonlinear and irreversible gates, dissimilar to the Hamiltonian operator, are deployed to speculate the given data set.[56] Such gates make certain phases unable to be observed and generate specific oscillations.[56] Quantum neural networks apply the principals quantum information and quantum computation to classical neurocomputing.[57] Current research shows that QNN can exponentially increase the amount of computing power and the degrees of freedom for a computer, which is limited for a classical computer to its size.[57] A quantum neural network has computational capabilities to decrease the number of steps, qubits used, and computation time.[56] The wave function to quantum mechanics is the neuron for Neural networks. To test quantum applications in a neural network, quantum dot molecules are deposited on a substrate of GaAs or similar to record how they communicate with one another. Each quantum dot can be referred as an island of electric activity, and when such dots are close enough (approximately 10Â±20Â nm)[58] electrons can tunnel underneath the islands. An even distribution across the substrate in sets of two create dipoles and ultimately two spin states, up or down. These states are commonly known as qubits with corresponding states of 
  
    
      
        
          |
        
        0
        â©
      
    
    {\displaystyle |0\rangle }
  
  and 
  
    
      
        
          |
        
        1
        â©
      
    
    {\displaystyle |1\rangle }
  
 in Dirac notation.[58]

Hidden Quantum Markov Models[edit]
Hidden Quantum Markov Models[59] (HQMMs) are a quantum-enhanced version of classical Hidden Markov Models (HMMs), which are typically used to model sequential data in various fields like robotics and natural language processing. Unlike the approach taken by other quantum-enhanced machine learning algorithms, HQMMs can be viewed as models inspired by quantum mechanics that can be run on classical computers as well.[60] Where classical HMMs use probability vectors to represent hidden 'belief' states, HQMMs use the quantum analogue: density matrices. Recent work has shown that these models can be successfully learned by maximizing the log-likelihood of the given data via classical optimization, and there is some empirical evidence that these models can better model sequential data compared to classical HMMs in practice, although further work is needed to determine exactly when and how these benefits are derived.[60] Additionally, since classical HMMs are a particular kind of Bayes net, an exciting aspect of HQMMs is that the techniques used show how we can perform quantum-analogous Bayesian inference, which should allow for the general construction of the quantum versions of probabilistic graphical models.[60]

Fully quantum machine learning[edit]
In the most general case of quantum machine learning, both the learning device and the system under study, as well as their interaction, are fully quantum. This section gives a few examples of results on this topic.
One class of problem that can benefit from the fully quantum approach is that of 'learning' unknown quantum states, processes or measurements, in the sense that one can subsequently reproduce them on another quantum system. For example, one may wish to learn a measurement that discriminates between two coherent states, given not a classical description of the states to be discriminated, but instead a set of example quantum systems prepared in these states. The naive approach would be to first extract a classical description of the states and then implement an ideal discriminating measurement based on this information. This would only require classical learning. However, one can show that a fully quantum approach is strictly superior in this case.[61] (This also relates to work on quantum pattern matching.[62]) The problem of learning unitary transformations can be approached in a similar way.[63]
Going beyond the specific problem of learning states and transformations, the task of clustering also admits a fully quantum version, wherein both the oracle which returns the distance between data-points and the information processing device which runs the algorithm are quantum.[64] Finally, a general framework spanning supervised, unsupervised and reinforcement learning in the fully quantum setting was introduced in,[24] where it was also shown that the possibility of probing the environment in superpositions permits a quantum speedup in reinforcement learning. Such a speedup in the reinforcement-learning paradigm has been experimentally demonstrated in a photonic setup.[45]

Classical learning applied to quantum problems[edit]
Further information: Machine learning in physics
The term "quantum machine learning" sometimes refers to classical machine learning performed on data from quantum systems. A basic example of this is quantum state tomography, where a quantum state is learned from measurement. Other applications include learning Hamiltonians[65] and automatically generating quantum experiments.[15]

Quantum learning theory[edit]
Quantum learning theory pursues a mathematical analysis of the quantum generalizations of classical learning models and of the possible speed-ups or other improvements that they may provide. The framework is very similar to that of classical computational learning theory, but the learner in this case is a quantum information processing device, while the data may be either classical or quantum. Quantum learning theory should be contrasted with the quantum-enhanced machine learning discussed above, where the goal was to consider specific problems and to use quantum protocols to improve the time complexity of classical algorithms for these problems. Although quantum learning theory is still under development, partial results in this direction have been obtained.[66]
The starting point in learning theory is typically a concept class, a set of possible concepts. Usually a concept is a function on some domain, such as 
  
    
      
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle \{0,1\}^{n}}
  
. For example, the concept class could be the set of disjunctive normal form (DNF) formulas on n bits or the set of Boolean circuits of some constant depth. The goal for the learner is to learn (exactly or approximately) an unknown target concept from this concept class. The learner may be actively interacting with the target concept, or passively receiving samples from it.
In active learning, a learner can make membership queries to the target concept c, asking for its value c(x) on inputs x chosen by the learner. The learner then has to reconstruct the exact target concept, with high probability. In the model of quantum exact learning, the learner can make membership queries in quantum superposition. If the complexity of the learner is measured by the number of membership queries it makes, then quantum exact learners can be polynomially more efficient than classical learners for some concept classes, but not more.[67] If complexity is measured by the amount of time the learner uses, then there are concept classes that can be learned efficiently by quantum learners but not by classical learners (under plausible complexity-theoretic assumptions).[67]
A natural model of passive learning is Valiant's probably approximately correct (PAC) learning. Here the learner receives random examples (x,c(x)), where x is distributed according to some unknown distribution D. The learner's goal is to output a hypothesis function h such that h(x)=c(x) with high probability when x is drawn according to D. The learner has to be able to produce such an 'approximately correct' h for every D and every target concept c in its concept class. We can consider replacing the random examples by potentially more powerful quantum examples 
  
    
      
        
          â
          
            x
          
        
        
          
            D
            (
            x
            )
          
        
        
          |
        
        x
        ,
        c
        (
        x
        )
        â©
      
    
    {\displaystyle \sum _{x}{\sqrt {D(x)}}|x,c(x)\rangle }
  
. In the PAC model (and the related agnostic model), this doesn't significantly reduce the number of examples needed: for every concept class, classical and quantum sample complexity are the same up to constant factors.[68] However, for learning under some fixed distribution D, quantum examples can be very helpful, for example for learning DNF under the uniform distribution.[69] When considering time complexity, there exist concept classes that can be PAC-learned efficiently by quantum learners, even from classical examples, but not by classical learners (again, under plausible complexity-theoretic assumptions).[67]
This passive learning type is also the most common scheme in supervised learning: a learning algorithm typically takes the training examples fixed, without the ability to query the label of unlabelled examples. Outputting a hypothesis h is a step of induction. Classically, an inductive model splits into a training and an application phase: the model parameters are estimated in the training phase, and the learned model is applied an arbitrary many times in the application phase. In the asymptotic limit of the number of applications, this splitting of phases is also present with quantum resources.[70]

Implementations and experiments[edit]
The earliest experiments were conducted using the adiabatic D-Wave quantum computer, for instance, to detect cars in digital images using regularized boosting with a nonconvex objective function in a demonstration in 2009.[71] Many experiments followed on the same architecture, and leading tech companies have shown interest in the potential of quantum machine learning for future technological implementations. In 2013, Google Research, NASA, and the Universities Space Research Association launched the Quantum Artificial Intelligence Lab which explores the use of the adiabatic D-Wave quantum computer.[72][73] A more recent example trained a probabilistic generative models with arbitrary pairwise connectivity, showing that their model is capable of generating handwritten digits as well as reconstructing noisy images of bars and stripes and handwritten digits.[50]
Using a different annealing technology based on nuclear magnetic resonance (NMR), a quantum Hopfield network was implemented in 2009 that mapped the input data and memorized data to Hamiltonians, allowing the use of adiabatic quantum computation.[74] NMR technology also enables universal quantum computing,[citation needed] and it was used for the first experimental implementation of a quantum support vector machine to distinguish hand written number â6â and â9â on a liquid-state  quantum computer in 2015.[75] The training data involved the pre-processing of the image which maps them to normalized 2-dimensional vectors to represent the images as the states of a qubit. The two entries of the vector are the vertical and horizontal ratio of the pixel intensity of the image. Once the vectors are defined on the feature space, the quantum support vector machine was implemented to classify the unknown input vector. The readout avoids costly quantum tomography by reading out the final state in terms of direction (up/down) of the NMR signal.
Photonic implementations are attracting more attention,[76] not the least because they do not require extensive cooling. Simultaneous spoken digit and speaker recognition and chaotic time-series prediction were demonstrated at data rates beyond 1 gigabyte per second in 2013.[77] Using non-linear photonics to implement an all-optical linear classifier, a perceptron model was capable of learning the classification boundary iteratively from training data through a feedback rule.[78] A core building block in many learning algorithms is to calculate the distance between two vectors: this was first experimentally demonstrated for up to eight dimensions using entangled qubits in a photonic quantum computer in 2015.[79]
Recently, based on a neuromimetic approach, a novel ingredient has been added to the field of quantum machine learning, in the form of a so-called quantum memristor, a quantized model of the standard classical memristor.[80] This device can be constructed by means of a tunable resistor, weak measurements on the system, and a classical feed-forward mechanism. An implementation of a quantum memristor in superconducting circuits has been proposed,[81] and an experiment with quantum dots performed.[82] A quantum memristor would implement nonlinear interactions in the quantum dynamics which would aid the search for a fully functional quantum neural network.
Since 2016, IBM has launched an online cloud-based platform for quantum software developers, called the IBM Q Experience. This platform consists of several fully operational quantum processors accessible via the IBM Web API. In doing so, the company is encouraging software developers to pursue new algorithms through a development environment with quantum capabilities. New architectures are being explored on an experimental basis, up to 32 qbits, utilizing both trapped-ion and superconductive quantum computing methods.
In October 2019, it was noted that the introduction of Quantum Random Number Generators (QRNGs) to machine learning models including Neural Networks and Convolutional Neural Networks for random initial weight distribution and Random Forests for splitting processes had a profound effect on their ability when compared to the classical method of Pseudorandom Number Generators (PRNGs).[83] However, in a more recent publication from 2021, these claims could not be reproduced for Neural Network weight initialization and no significant advantage of using QRNGs over PRNGs was found.[84] The work also demonstrated that the generation of fair random numbers with a gate quantum computer is a non-trivial task on NISQ devices, and QRNGs are therefore typically much more difficult to utilize in practice than PRNGs.
A paper published in December 2018 reported on an experiment using a trapped-ion system demonstrating a quantum speedup of the deliberation time of reinforcement learning agents employing internal quantum hardware.[44] 
In March 2021, a team of researchers from Austria, The Netherlands, the USA and Germany reported the experimental demonstration of a quantum speedup of the learning time of reinforcement learning agents interacting fully quantumly with the environment.[85][45] The relevant degrees of freedom of both agent and environment were realized on a compact and fully tunable integrated nanophotonic processor.

Skepticism[edit]
While machine learning itself is now not only a research field but an economically significant and fast growing industry and quantum computing is a well established field of both theoretical and experimental research, quantum machine learning remains a purely theoretical field of studies. Attempts to experimentally demonstrate concepts of quantum machine learning remain insufficient.[citation needed]
Many of the leading scientists that extensively publish in the field of quantum machine learning warn about the extensive hype around the topic and are very restrained if asked about its practical uses in the foreseeable future. Sophia Chen[86] collected some of the statements made by well known scientists in the field:

"I think we haven't done our homework yet. This is an extremely new scientific field," - physicist Maria Schuld of Canada-based quantum computing startup Xanadu.
"There is a lot more work that needs to be done before claiming quantum machine learning will actually work," - computer scientist Iordanis Kerenidis, the head of quantum algorithms at the Silicon Valley-based quantum computing startup QC Ware.
"I have not seen a single piece of evidence that there exists a meaningful [machine learning] task for which it would make sense to use a quantum computer and not a classical computer," - physicist Ryan Sweke of the Free University of Berlin in Germany.
âDon't fall for the hype!â -  Frank Zickert,[87] who is the author of probably the most practical book related to the subject beware that âquantum computers are far away from advancing machine learning for their representation abilityâ, and even speaking about evaluation and optimization for any kind of useful task quantum supremacy is not yet achieved. Furthermore, nobody among the active researchers in the field make any forecasts about when it could possibly become practical.[citation needed]

See also[edit]
Differentiable programming
Quantum computing
Quantum algorithm for linear systems of equations
Quantum annealing
Quantum neural network
Quantum image
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Schuld, Maria; Petruccione, Francesco (2018). Supervised Learning with Quantum Computers. Quantum Science and Technology. doi:10.1007/978-3-319-96424-9. ISBNÂ 978-3-319-96423-2.

^ Jump up to: a b Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco (2014). "An introduction to quantum machine learning". Contemporary Physics. 56 (2): 172â185. arXiv:1409.3097. Bibcode:2015ConPh..56..172S. CiteSeerXÂ 10.1.1.740.5622. doi:10.1080/00107514.2014.964942. S2CIDÂ 119263556.

^ Wittek, Peter (2014). Quantum Machine Learning: What Quantum Computing Means to Data Mining. Academic Press. ISBNÂ 978-0-12-800953-6.

^ Jump up to: a b Wiebe, Nathan; Kapoor, Ashish; Svore, Krysta (2014). "Quantum Algorithms for Nearest-Neighbor Methods for Supervised and Unsupervised Learning". Quantum Information & Computation. 15 (3): 0318â0358. arXiv:1401.2142. Bibcode:2014arXiv1401.2142W.

^ Lloyd, Seth; Mohseni, Masoud; Rebentrost, Patrick (2013). "Quantum algorithms for supervised and unsupervised machine learning". arXiv:1307.0411 [quant-ph].

^ Yoo, Seokwon; Bang, Jeongho; Lee, Changhyoup; Lee, Jinhyoung (2014). "A quantum speedup in machine learning: Finding a N-bit Boolean function for a classification". New Journal of Physics. 16 (10): 103014. arXiv:1303.6055. Bibcode:2014NJPh...16j3014Y. doi:10.1088/1367-2630/16/10/103014. S2CIDÂ 4956424.

^ Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco (2014-10-15). "An introduction to quantum machine learning". Contemporary Physics. 56 (2): 172â185. arXiv:1409.3097. Bibcode:2015ConPh..56..172S. CiteSeerXÂ 10.1.1.740.5622. doi:10.1080/00107514.2014.964942. ISSNÂ 0010-7514. S2CIDÂ 119263556.

^ Benedetti, Marcello; Realpe-GÃ³mez, John; Biswas, Rupak; Perdomo-Ortiz, Alejandro (2017-11-30). "Quantum-Assisted Learning of Hardware-Embedded Probabilistic Graphical Models". Physical Review X. 7 (4): 041052. arXiv:1609.02542. Bibcode:2017PhRvX...7d1052B. doi:10.1103/PhysRevX.7.041052. ISSNÂ 2160-3308. S2CIDÂ 55331519.

^ Farhi, Edward; Neven, Hartmut (2018-02-16). "Classification with Quantum Neural Networks on Near Term Processors". arXiv:1802.06002 [quant-ph].

^ Schuld, Maria; Bocharov, Alex; Svore, Krysta; Wiebe, Nathan (2020). "Circuit-centric quantum classifiers". Physical Review A. 101 (3): 032308. arXiv:1804.00633. Bibcode:2020PhRvA.101c2308S. doi:10.1103/PhysRevA.101.032308. S2CIDÂ 49577148.

^ Yu, Shang; Albarran-Arriagada, F.; Retamal, J. C.; Wang, Yi-Tao; Liu, Wei; Ke, Zhi-Jin; Meng, Yu; Li, Zhi-Peng; Tang, Jian-Shun (2018-08-28). "Reconstruction of a Photonic Qubit State with Quantum Reinforcement Learning". Advanced Quantum Technologies. 2 (7â8): 1800074. arXiv:1808.09241. doi:10.1002/qute.201800074. S2CIDÂ 85529734.

^ Ghosh, Sanjib; Opala, A.; Matuszewski, M.; Paterek, T.; Liew, Timothy C. H. (2019). "Quantum reservoir processing". NPJ Quantum Information. 5 (35): 35. arXiv:1811.10335. Bibcode:2019npjQI...5...35G. doi:10.1038/s41534-019-0149-8. S2CIDÂ 119197635.

^ Broecker, Peter; Assaad, Fakher F.; Trebst, Simon (2017-07-03). "Quantum phase recognition via unsupervised machine learning". arXiv:1707.00663 [cond-mat.str-el].

^ Huembeli, Patrick; Dauphin, Alexandre; Wittek, Peter (2018). "Identifying Quantum Phase Transitions with Adversarial Neural Networks". Physical Review B. 97 (13): 134109. arXiv:1710.08382. Bibcode:2018PhRvB..97m4109H. doi:10.1103/PhysRevB.97.134109. ISSNÂ 2469-9950.

^ Jump up to: a b Krenn, Mario (2016-01-01). "Automated Search for new Quantum Experiments". Physical Review Letters. 116 (9): 090405. arXiv:1509.02749. Bibcode:2016PhRvL.116i0405K. doi:10.1103/PhysRevLett.116.090405. PMIDÂ 26991161. S2CIDÂ 20182586.

^ Knott, Paul (2016-03-22). "A search algorithm for quantum state engineering and metrology". New Journal of Physics. 18 (7): 073033. arXiv:1511.05327. Bibcode:2016NJPh...18g3033K. doi:10.1088/1367-2630/18/7/073033. S2CIDÂ 2721958.

^ Dunjko, Vedran; Briegel, Hans J (2018-06-19). "Machine learning & artificial intelligence in the quantum domain: a review of recent progress". Reports on Progress in Physics. 81 (7): 074001. arXiv:1709.02779. Bibcode:2018RPPh...81g4001D. doi:10.1088/1361-6633/aab406. hdl:1887/71084. ISSNÂ 0034-4885. PMIDÂ 29504942. S2CIDÂ 3681629.

^ Huggins, William; Patel, Piyush; Whaley, K. Birgitta; Stoudenmire, E. Miles (2018-03-30). "Towards Quantum Machine Learning with Tensor Networks". Quantum Science and Technology. 4 (2): 024001. arXiv:1803.11537. doi:10.1088/2058-9565/aaea94. S2CIDÂ 4531946.

^ Carleo, Giuseppe; Nomura, Yusuke; Imada, Masatoshi (2018-02-26). "Constructing exact representations of quantum many-body systems with deep neural networks". Nature Communications. 9 (1): 5322. arXiv:1802.09558. Bibcode:2018NatCo...9.5322C. doi:10.1038/s41467-018-07520-3. PMCÂ 6294148. PMIDÂ 30552316.

^ BÃ©ny, CÃ©dric (2013-01-14). "Deep learning and the renormalization group". arXiv:1301.3124 [quant-ph].

^ Arunachalam, Srinivasan; de Wolf, Ronald (2017-01-24). "A Survey of Quantum Learning Theory". arXiv:1701.06806 [quant-ph].

^ Sergioli, Giuseppe; Giuntini, Roberto; Freytes, Hector (2019-05-09). "A new Quantum approach to binary classification". PLOS ONE. 14 (5): e0216224. Bibcode:2019PLoSO..1416224S. doi:10.1371/journal.pone.0216224. PMCÂ 6508868. PMIDÂ 31071129.

^ AÃ¯meur, Esma; Brassard, Gilles; Gambs, SÃ©bastien (2006-06-07). Machine Learning in a Quantum World. Advances in Artificial Intelligence. Lecture Notes in Computer Science. Vol.Â 4013. pp.Â 431â442. doi:10.1007/11766247_37. ISBNÂ 978-3-540-34628-9.

^ Jump up to: a b c Dunjko, Vedran; Taylor, Jacob M.; Briegel, Hans J. (2016-09-20). "Quantum-Enhanced Machine Learning". Physical Review Letters. 117 (13): 130501. arXiv:1610.08251. Bibcode:2016PhRvL.117m0501D. doi:10.1103/PhysRevLett.117.130501. PMIDÂ 27715099. S2CIDÂ 12698722.

^ Jump up to: a b Rebentrost, Patrick; Mohseni, Masoud; Lloyd, Seth (2014). "Quantum Support Vector Machine for Big Data Classification". Physical Review Letters. 113 (13): 130503. arXiv:1307.0471. Bibcode:2014PhRvL.113m0503R. doi:10.1103/PhysRevLett.113.130503. hdl:1721.1/90391. PMIDÂ 25302877. S2CIDÂ 5503025.

^ Jump up to: a b Wiebe, Nathan; Braun, Daniel; Lloyd, Seth (2012). "Quantum Algorithm for Data Fitting". Physical Review Letters. 109 (5): 050505. arXiv:1204.5242. Bibcode:2012PhRvL.109e0505W. doi:10.1103/PhysRevLett.109.050505. PMIDÂ 23006156.

^ Jump up to: a b Schuld, Maria; Sinayskiy, Ilya; Petruccione, Francesco (2016). "Prediction by linear regression on a quantum computer". Physical Review A. 94 (2): 022342. arXiv:1601.07823. Bibcode:2016PhRvA..94b2342S. doi:10.1103/PhysRevA.94.022342. S2CIDÂ 118459345.

^ Harrow, Aram W.; Hassidim, Avinatan; Lloyd, Seth (2008). "Quantum algorithm for solving linear systems of equations". Physical Review Letters. 103 (15): 150502. arXiv:0811.3171. Bibcode:2009PhRvL.103o0502H. doi:10.1103/PhysRevLett.103.150502. PMIDÂ 19905613. S2CIDÂ 5187993.

^ Berry, Dominic W.; Childs, Andrew M.; Kothari, Robin (2015). Hamiltonian simulation with nearly optimal dependence on all parameters. 56th Annual Symposium on Foundations of Computer Science. IEEE. pp.Â 792â809. arXiv:1501.01715. doi:10.1109/FOCS.2015.54.

^ Lloyd, Seth; Mohseni, Masoud; Rebentrost, Patrick (2014). "Quantum principal component analysis". Nature Physics. 10 (9): 631. arXiv:1307.0401. Bibcode:2014NatPh..10..631L. CiteSeerXÂ 10.1.1.746.480. doi:10.1038/nphys3029. S2CIDÂ 11553314.

^ Zhao, Zhikuan; Fitzsimons, Jack K.; Fitzsimons, Joseph F. (2019). "Quantum assisted Gaussian process regression". Physical Review A. 99 (5): 052331. arXiv:1512.03929. Bibcode:2019PhRvA..99e2331Z. doi:10.1103/PhysRevA.99.052331. S2CIDÂ 18303333.

^ Soklakov, Andrei N.; Schack, RÃ¼diger (2006). "Efficient state preparation for a register of quantum bits". Physical Review A. 73 (1): 012307. arXiv:quant-ph/0408045. Bibcode:2006PhRvA..73a2307S. doi:10.1103/PhysRevA.73.012307. S2CIDÂ 17318769.

^ Giovannetti, Vittorio; Lloyd, Seth; MacCone, Lorenzo (2008). "Quantum Random Access Memory". Physical Review Letters. 100 (16): 160501. arXiv:0708.1879. Bibcode:2008PhRvL.100p0501G. doi:10.1103/PhysRevLett.100.160501. PMIDÂ 18518173. S2CIDÂ 570390.

^ Aaronson, Scott (2015). "Read the fine print". Nature Physics. 11 (4): 291â293. Bibcode:2015NatPh..11..291A. doi:10.1038/nphys3272.

^ Bang, Jeongho; Dutta, Arijit; Lee, Seung-Woo; Kim, Jaewan (2019). "Optimal usage of quantum random access memory in quantum machine learning". Physical Review A. 99 (1): 012326. arXiv:1809.04814. Bibcode:2019PhRvA..99a2326B. doi:10.1103/PhysRevA.99.012326. S2CIDÂ 62841090.

^ Jump up to: a b AÃ¯meur, Esma; Brassard, Gilles; Gambs, SÃ©bastien (2013-02-01). "Quantum speed-up for unsupervised learning". Machine Learning. 90 (2): 261â287. doi:10.1007/s10994-012-5316-5. ISSNÂ 0885-6125.

^ Wiebe, Nathan; Kapoor, Ashish; Svore, Krysta M. (2016). Quantum Perceptron Models. Advances in Neural Information Processing Systems. Vol.Â 29. pp.Â 3999â4007. arXiv:1602.04799. Bibcode:2016arXiv160204799W.

^ Paparo, Giuseppe Davide; Martin-Delgado, Miguel Angel (2012). "Google in a Quantum Network". Scientific Reports. 2 (444): 444. arXiv:1112.2079. Bibcode:2012NatSR...2E.444P. doi:10.1038/srep00444. PMCÂ 3370332. PMIDÂ 22685626.

^ Jump up to: a b c d Paparo, Giuseppe Davide; Dunjko, Vedran; Makmal, Adi; Martin-Delgado, Miguel Angel; Briegel, Hans J. (2014). "Quantum Speedup for Active Learning Agents". Physical Review X. 4 (3): 031002. arXiv:1401.4997. Bibcode:2014PhRvX...4c1002P. doi:10.1103/PhysRevX.4.031002. S2CIDÂ 54652978.

^ Dong, Daoyi; Chen, Chunlin; Li, Hanxiong; Tarn, Tzyh-Jong (2008). "Quantum Reinforcement Learning". IEEE Transactions on Systems, Man, and Cybernetics â Part B: Cybernetics. 38 (5): 1207â1220. arXiv:0810.3828. CiteSeerXÂ 10.1.1.243.5369. doi:10.1109/TSMCB.2008.925743. PMIDÂ 18784007.

^ Crawford, Daniel; Levit, Anna; Ghadermarzy, Navid; Oberoi, Jaspreet S.; Ronagh, Pooya (2018). "Reinforcement Learning Using Quantum Boltzmann Machines". arXiv:1612.05695 [quant-ph].

^ Dunjko, Vedran; Friis, Nicolai; Briegel, Hans J. (2015-01-01). "Quantum-enhanced deliberation of learning agents using trapped ions". New Journal of Physics. 17 (2): 023006. arXiv:1407.2830. Bibcode:2015NJPh...17b3006D. doi:10.1088/1367-2630/17/2/023006. ISSNÂ 1367-2630. S2CIDÂ 119292539.

^ Lamata, Lucas (2017). "Basic protocols in quantum reinforcement learning with superconducting circuits". Scientific Reports. 7 (1): 1609. arXiv:1701.05131. Bibcode:2017NatSR...7.1609L. doi:10.1038/s41598-017-01711-6. PMCÂ 5431677. PMIDÂ 28487535.

^ Jump up to: a b Sriarunothai, Theeraphot; WÃ¶lk, Sabine; Giri, Gouri Shankar; Friis, Nicolai; Dunjko, Vedran; Briegel, Hans J.; Wunderlich, Christof (2019). "Speeding-up the decision making of a learning agent using an ion trap quantum processor". Quantum Science and Technology. 4 (1): 015014. arXiv:1709.01366. Bibcode:2019QS&T....4a5014S. doi:10.1088/2058-9565/aaef5e. ISSNÂ 2058-9565. S2CIDÂ 2429346.

^ Jump up to: a b c Saggio, Valeria; Asenbeck, Beate; Hamann, Arne; StrÃ¶mberg, Teodor; Schiansky, Peter; Dunjko, Vedran; Friis, Nicolai; Harris, Nicholas C.; Hochberg, Michael; Englund, Dirk; WÃ¶lk, Sabine; Briegel, Hans J.; Walther, Philip (10 March 2021). "Experimental quantum speed-up in reinforcement learning agents". Nature. 591 (7849): 229â233. arXiv:2103.06294. Bibcode:2021Natur.591..229S. doi:10.1038/s41586-021-03242-7. ISSNÂ 1476-4687. PMCÂ 7612051. PMIDÂ 33692560. S2CIDÂ 232185235.

^ Biswas, Rupak; Jiang, Zhang; Kechezi, Kostya; Knysh, Sergey; MandrÃ , Salvatore; OâGorman, Bryan; Perdomo-Ortiz, Alejando; Pethukov, Andre; Realpe-GÃ³mez, John; Rieffel, Eleanor; Venturelli, Davide; Vasko, Fedir; Wang, Zhihui (2016). "A NASA perspective on quantum computing: Opportunities and challenges". Parallel Computing. 64: 81â98. arXiv:1704.04836. doi:10.1016/j.parco.2016.11.002. S2CIDÂ 27547901.

^ Jump up to: a b Adachi, Steven H.; Henderson, Maxwell P. (2015). "Application of quantum annealing to training of deep neural networks". arXiv:1510.06356 [quant-ph].

^ Jump up to: a b Benedetti, Marcello; Realpe-GÃ³mez, John; Biswas, Rupak; Perdomo-Ortiz, Alejandro (2016). "Estimation of effective temperatures in quantum annealers for sampling applications: A case study with possible applications in deep learning". Physical Review A. 94 (2): 022308. arXiv:1510.07611. Bibcode:2016PhRvA..94b2308B. doi:10.1103/PhysRevA.94.022308. S2CIDÂ 118602077.

^ Jump up to: a b Korenkevych, Dmytro; Xue, Yanbo; Bian, Zhengbing; Chudak, Fabian; Macready, William G.; Rolfe, Jason; Andriyash, Evgeny (2016). "Benchmarking quantum hardware for training of fully visible Boltzmann machines". arXiv:1611.04528 [quant-ph].

^ Jump up to: a b c Benedetti, Marcello; Realpe-GÃ³mez, John; Biswas, Rupak; Perdomo-Ortiz, Alejandro (2017). "Quantum-assisted learning of graphical models with arbitrary pairwise connectivity". Physical Review X. 7 (4): 041052. arXiv:1609.02542. Bibcode:2017PhRvX...7d1052B. doi:10.1103/PhysRevX.7.041052. S2CIDÂ 55331519.

^ Rocutto, Lorenzo; Destri, Claudio; Prati, Enrico (2021). "Quantum Semantic Learning by Reverse Annealing of an Adiabatic Quantum Computer". Advanced Quantum Technologies. 4 (2): 2000133. arXiv:2003.11945. doi:10.1002/qute.202000133. ISSNÂ 2511-9044. S2CIDÂ 214667224.

^ Amin, Mohammad H.; Andriyash, Evgeny; Rolfe, Jason; Kulchytskyy, Bohdan; Melko, Roger (2018). "Quantum Boltzmann machines". Phys. Rev. X. 8 (21050): 021050. arXiv:1601.02036. Bibcode:2018PhRvX...8b1050A. doi:10.1103/PhysRevX.8.021050. S2CIDÂ 119198869.

^ "Phys. Rev. E 72, 026701 (2005): Quantum annealing in a kinetically coâ¦". archive.is. 2014-01-13. Archived from the original on 2014-01-13. Retrieved 2018-12-07.

^ Wiebe, Nathan; Kapoor, Ashish; Svore, Krysta M. (2014). "Quantum deep learning". arXiv:1412.3489 [quant-ph].

^ Wittek, Peter; Gogolin, Christian (2017). "Quantum Enhanced Inference in Markov Logic Networks". Scientific Reports. 7 (45672): 45672. arXiv:1611.08104. Bibcode:2017NatSR...745672W. doi:10.1038/srep45672. PMCÂ 5395824. PMIDÂ 28422093.

^ Jump up to: a b c d Gupta, Sanjay; Zia, R.K.P. (2001-11-01). "Quantum Neural Networks". Journal of Computer and System Sciences. 63 (3): 355â383. arXiv:quant-ph/0201144. doi:10.1006/jcss.2001.1769. ISSNÂ 0022-0000. S2CIDÂ 206569020.

^ Jump up to: a b Ezhov, Alexandr A.; Ventura, Dan (2000), "Quantum Neural Networks", Future Directions for Intelligent Systems and Information Sciences, Physica-Verlag HD, pp.Â 213â235, CiteSeerXÂ 10.1.1.683.5972, doi:10.1007/978-3-7908-1856-7_11, ISBNÂ 978-3-7908-2470-4, S2CIDÂ 9099722

^ Jump up to: a b Behrman, E.C.; Nash, L.R.; Steck, J.E.; Chandrashekar, V.G.; Skinner, S.R. (2000-10-01). "Simulations of quantum neural networks". Information Sciences. 128 (3â4): 257â269. doi:10.1016/S0020-0255(00)00056-6. ISSNÂ 0020-0255.

^ Clark, Lewis A.; Huang W., Wei; Barlow, Thomas H.; Beige, Almut (2015). "Hidden Quantum Markov Models and Open Quantum Systems with Instantaneous Feedback".  In Sanayei, Ali; RÃ¶ssler, Otto E.; Zelinka, Ivan (eds.). ISCS 2014: Interdisciplinary Symposium on Complex Systems. Emergence, Complexity and Computation. Iscs, P. 143, Springer (2015). Emergence, Complexity and Computation. Vol.Â 14. pp.Â 131â151. arXiv:1406.5847. CiteSeerXÂ 10.1.1.749.3332. doi:10.1007/978-3-319-10759-2_16. ISBNÂ 978-3-319-10759-2. S2CIDÂ 119226526.

^ Jump up to: a b c Srinivasan, Siddarth; Gordon, Geoff; Boots, Byron (2018). "Learning Hidden Quantum Markov Models" (PDF). Aistats.

^ SentÃ­s, Gael; GuÅ£Ä, MÄdÄlin; Adesso, Gerardo (9 July 2015). "Quantum learning of coherent states". EPJ Quantum Technology. 2 (1). doi:10.1140/epjqt/s40507-015-0030-4.

^ Sasaki, Masahide; Carlini, Alberto (6 August 2002). "Quantum learning and universal quantum matching machine". Physical Review A. 66 (2): 022303. arXiv:quant-ph/0202173. Bibcode:2002PhRvA..66b2303S. doi:10.1103/PhysRevA.66.022303. S2CIDÂ 119383508.

^ Bisio, Alessandro; Chiribella, Giulio; DâAriano, Giacomo Mauro; Facchini, Stefano; Perinotti, Paolo (25 March 2010). "Optimal quantum learning of a unitary transformation". Physical Review A. 81 (3): 032324. arXiv:0903.0543. Bibcode:2010PhRvA..81c2324B. doi:10.1103/PhysRevA.81.032324. S2CIDÂ 119289138.

^ AÃ¯meur, Esma; Brassard, Gilles; Gambs, SÃ©bastien (1 January 2007). Quantum Clustering Algorithms. Proceedings of the 24th International Conference on Machine Learning. pp.Â 1â8. CiteSeerXÂ 10.1.1.80.9513. doi:10.1145/1273496.1273497. ISBNÂ 978-1-59593-793-3. S2CIDÂ 4357684.

^ Cory, D. G.; Wiebe, Nathan; Ferrie, Christopher; Granade, Christopher E. (2012-07-06). "Robust Online Hamiltonian Learning". New Journal of Physics. 14 (10): 103013. arXiv:1207.1655. Bibcode:2012NJPh...14j3013G. doi:10.1088/1367-2630/14/10/103013. S2CIDÂ 9928389.

^ Arunachalam, Srinivasan; de Wolf, Ronald (2017). "A Survey of Quantum Learning Theory". arXiv:1701.06806 [quant-ph].

^ Jump up to: a b c Servedio, Rocco A.; Gortler, Steven J. (2004). "Equivalences and Separations Between Quantum and Classical Learnability". SIAM Journal on Computing. 33 (5): 1067â1092. CiteSeerXÂ 10.1.1.69.6555. doi:10.1137/S0097539704412910.

^ Arunachalam, Srinivasan; de Wolf, Ronald (2016). "Optimal Quantum Sample Complexity of Learning Algorithms". arXiv:1607.00932 [quant-ph].

^ Nader, Bshouty H.; Jeffrey, Jackson C. (1999). "Learning DNF over the Uniform Distribution Using a Quantum Example Oracle". SIAM Journal on Computing. 28 (3): 1136â1153. CiteSeerXÂ 10.1.1.23.5709. doi:10.1137/S0097539795293123.

^ MonrÃ s, Alex; SentÃ­s, Gael; Wittek, Peter (2017). "Inductive supervised quantum learning". Physical Review Letters. 118 (19): 190503. arXiv:1605.07541. Bibcode:2017PhRvL.118s0503M. doi:10.1103/PhysRevLett.118.190503. PMIDÂ 28548536. S2CIDÂ 6521971.

^ "NIPS 2009 Demonstration: Binary Classification using Hardware Implementation of Quantum Annealing" (PDF). Static.googleusercontent.com. Retrieved 26 November 2014.

^ "Google Quantum A.I. Lab Team". Google Plus. 31 January 2017. Retrieved 31 January 2017.

^ "NASA Quantum Artificial Intelligence Laboratory". NASA. NASA. 31 January 2017. Archived from the original on 1 February 2017. Retrieved 31 January 2017.

^ Neigovzen, Rodion; Neves, Jorge L.; Sollacher, Rudolf; Glaser, Steffen J. (2009). "Quantum pattern recognition with liquid-state nuclear magnetic resonance". Physical Review A. 79 (4): 042321. arXiv:0802.1592. Bibcode:2009PhRvA..79d2321N. doi:10.1103/PhysRevA.79.042321. S2CIDÂ 119115625.

^ Li, Zhaokai; Liu, Xiaomei; Xu, Nanyang; Du, Jiangfeng (2015). "Experimental Realization of a Quantum Support Vector Machine". Physical Review Letters. 114 (14): 140504. arXiv:1410.1054. Bibcode:2015PhRvL.114n0504L. doi:10.1103/PhysRevLett.114.140504. PMIDÂ 25910101.

^ Wan, Kwok-Ho; Dahlsten, Oscar; Kristjansson, Hler; Gardner, Robert; Kim, Myungshik (2017). "Quantum generalisation of feedforward neural networks". NPJ Quantum Information. 3 (36): 36. arXiv:1612.01045. Bibcode:2017npjQI...3...36W. doi:10.1038/s41534-017-0032-4. S2CIDÂ 51685660.

^ Brunner, Daniel; Soriano, Miguel C.; Mirasso, Claudio R.; Fischer, Ingo (2013). "Parallel photonic information processing at gigabyte per second data rates using transient states". Nature Communications. 4: 1364. Bibcode:2013NatCo...4.1364B. doi:10.1038/ncomms2368. PMCÂ 3562454. PMIDÂ 23322052.

^ Tezak, Nikolas; Mabuchi, Hideo (2015). "A coherent perceptron for all-optical learning". EPJ Quantum Technology. 2. arXiv:1501.01608. Bibcode:2015arXiv150101608T. doi:10.1140/epjqt/s40507-015-0023-3. S2CIDÂ 28568346.

^ Cai, X.-D.; Wu, D.; Su, Z.-E.; Chen, M.-C.; Wang, X.-L.; Li, Li; Liu, N.-L.; Lu, C.-Y.; Pan, J.-W. (2015). "Entanglement-Based Machine Learning on a Quantum Computer". Physical Review Letters. 114 (11): 110504. arXiv:1409.7770. Bibcode:2015PhRvL.114k0504C. doi:10.1103/PhysRevLett.114.110504. PMIDÂ 25839250. S2CIDÂ 44769024.

^ Pfeiffer, P.; Egusquiza, I. L.; Di Ventra, M.; Sanz, M.; Solano, E. (2016). "Quantum memristors". Scientific Reports. 6 (2016): 29507. arXiv:1511.02192. Bibcode:2016NatSR...629507P. doi:10.1038/srep29507. PMCÂ 4933948. PMIDÂ 27381511.

^ Salmilehto, J.; Deppe, F.; Di Ventra, M.; Sanz, M.; Solano, E. (2017). "Quantum Memristors with Superconducting Circuits". Scientific Reports. 7 (42044): 42044. arXiv:1603.04487. Bibcode:2017NatSR...742044S. doi:10.1038/srep42044. PMCÂ 5307327. PMIDÂ 28195193.

^ Li, Ying; Holloway, Gregory W.; Benjamin, Simon C.; Briggs, G. Andrew D.; Baugh, Jonathan; Mol, Jan A. (2017). "A simple and robust quantum memristor". Physical Review B. 96 (7): 075446. arXiv:1612.08409. Bibcode:2017PhRvB..96g5446L. doi:10.1103/PhysRevB.96.075446. S2CIDÂ 119454549.

^ Bird, Jordan J.; EkÃ¡rt, AnikÃ³; Faria, Diego R. (2019-10-28). "On the effects of pseudorandom and quantum-random number generators in soft computing". Soft Computing. Springer Science and Business Media LLC. 24 (12): 9243â9256. doi:10.1007/s00500-019-04450-0. ISSNÂ 1432-7643.

^ Heese, Raoul; Wolter, Moritz; MÃ¼cke, Sascha; Franken, Lukas; Piatkowski, Nico (2021). "On the effects of biased quantum random numbers on the initialization of artificial neural networks". arXiv:2108.13329 [quant-ph].

^ "A quantum trick with photons gives machine learning a speed boost". New Scientist. Retrieved 31 August 2021.

^ "Can quantum machine learning move beyond its own hype?". Protocol. 2020-05-04. Retrieved 2020-10-27.

^ Zickert, Frank (2020-09-23). "Quantum Machine Learning". Medium. Retrieved 2020-10-27.


.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}showvteQuantum information scienceGeneral
DiVincenzo's criteria
NISQ era
Quantum computing
Timeline
Cloud-based
Quantum information
Quantum programming
Qubit
physical vs. logical
Quantum processors
Theorems
Bell's
Gleason's
GottesmanâKnill
Holevo's
MargolusâLevitin
No-broadcast
No-cloning
No-communication
No-deleting
No-hiding
No-teleportation
PBR
Quantum threshold
SolovayâKitaev
Quantumcommunication
Classical capacity
entanglement-assisted
Quantum capacity
Entanglement distillation
LOCC
Quantum channel
Quantum network
Quantum cryptography
Quantum key distribution
BB84
SARG04
Three-stage quantum cryptography protocol
Quantum Secret Sharing
Quantum teleportation
Superdense coding
Quantum algorithms
BernsteinâVazirani
DeutschâJozsa
Grover's
Quantum counting
Quantum phase estimation
Shor's
Simon's
Amplitude amplification
Linear systems of equations
Quantum annealing
Quantum Fourier transform
Quantum neural network
Universal quantum simulator
Quantumcomplexity theory
BQP
EQP
QIP
QMA
PostBQP
Quantumcomputing models
Adiabatic quantum computation
Differentiable quantum computing
One-way quantum computer
cluster state
Quantum circuit
Quantum logic gate
Quantum Turing machine
Topological quantum computer
Quantumerror correction
Codes
CSS
Quantum convolutional
stabilizer
Shor
Steane
Toric
gnu
Entanglement-assisted quantum error correction
PhysicalimplementationsQuantum optics
Boson sampling
Cavity QED
Circuit QED
Linear optical quantum computing
KLM protocol
Ultracold atoms
Optical lattice
Trapped ion quantum computer
Spin-based
Kane QC
Spin qubit QC
Nitrogen-vacancy center
Nuclear magnetic resonance QC
Superconductingquantum computing
Charge qubit
Flux qubit
Phase qubit
Transmon
Quantumprogramming
OpenQASM-Qiskit-IBM QX
Quil-Forest/Rigetti QCS
Cirq
Q#
libquantum
many others...
 Quantum mechanics topics
showvteDifferentiable computingGeneral
Differentiable programming
Neural Turing machine
Differentiable neural computer
Automatic differentiation
Neuromorphic engineering
Cable theory
Pattern recognition
Computational learning theory
Tensor calculus
Concepts
Gradient descent
SGD
Clustering
Regression
Overfitting
Adversary
Attention
Convolution
Loss functions
Backpropagation
Normalization
Activation
Softmax
Sigmoid
Rectifier
Regularization
Datasets
Augmentation
Programming languages
Python
Julia
Application
Machine learning
Artificial neural network
Deep learning
Scientific computing
Artificial Intelligence
Hardware
IPU
TPU
VPU
Memristor
SpiNNaker
Software library
TensorFlow
PyTorch
Keras
Theano
ImplementationAudio-visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
Speech recognition
Facial recognition
AlphaFold
DALL-E
Verbal
Word2vec
Transformer
BERT
NMT
Project Debater
Watson
GPT-2
GPT-3
Decisional
AlphaGo
AlphaZero
Q-learning
SARSA
OpenAI Five
Self-driving car
MuZero
Action selection
Robot control
People
Alex Graves
Ian Goodfellow
Yoshua Bengio
Geoffrey Hinton
Yann LeCun
Andrew Ng
Demis Hassabis
David Silver
Fei-Fei Li
Organizations
DeepMind
OpenAI
MIT CSAIL
Mila
Google Brain
FAIR

 Portals
Computer programming
Technology
 Category
Artificial neural networks
Machine learning

showvteEmerging technologiesFieldsQuantum
algorithms
amplifier
bus
cellular automata
channel
circuit
complexity theory
computing
clock
cryptography
post-quantum
dynamics
electronics
error correction
finite automata
image processing
imaging
information
key distribution
logic
logic gates
machine
machine learning
metamaterial
network
neural network
optics
programming
sensing
simulator
teleportation
Other
Anti-gravity
Acoustic levitation
Cloak of invisibility
Digital scent technology
Force field
Plasma window
Immersive virtual reality
Magnetic refrigeration
Phased-array optics
Thermoacoustic heat engine

 Category
 List





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Quantum_machine_learning&oldid=1068873419"
		Categories: Machine learningQuantum information scienceTheoretical computer scienceEmerging technologiesQuantum programmingHidden categories: Articles with short descriptionShort description matches WikidataWikipedia articles with possible conflicts of interest from September 2018All articles with unsourced statementsArticles with unsourced statements from February 2017Articles with unsourced statements from December 2020
	
