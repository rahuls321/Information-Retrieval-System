
Title:
BellmanâFord algorithm
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Algorithm for finding the shortest paths in graphs
.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}BellmanâFord algorithmClassSingle-source shortest path problem (for weighted directed graphs)Data structureGraphWorst-case performance
  
    
      
        Î
        (
        
          |
        
        V
        
          |
        
        
          |
        
        E
        
          |
        
        )
      
    
    {\displaystyle \Theta (|V||E|)}
  
Best-case performance
  
    
      
        Î
        (
        
          |
        
        E
        
          |
        
        )
      
    
    {\displaystyle \Theta (|E|)}
  
Worst-case space complexity
  
    
      
        Î
        (
        
          |
        
        V
        
          |
        
        )
      
    
    {\displaystyle \Theta (|V|)}
  

.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Graph and treesearch algorithms
Î±âÎ²
A*
B*
Backtracking
Beam
BellmanâFord
Best-first
Bidirectional
BorÅ¯vka
Branch & bound
BFS
British Museum
D*
DFS
Dijkstra
Edmonds
FloydâWarshall
Fringe search
Hill climbing
IDA*
Iterative deepening
Johnson
Jump point
Kruskal
Lexicographic BFS
LPA*
Prim
SMA*

Listings
Graph algorithms
Search algorithms
List of graph algorithms

Related topics
Dynamic programming
Graph traversal
Tree traversal
Search games
Graph coloring
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
The BellmanâFord algorithm is an algorithm that computes shortest paths from a single source vertex to all of the other vertices in a weighted digraph.[1]
It is slower than Dijkstra's algorithm for the same problem, but more versatile, as it is capable of handling graphs in which some of the edge weights are negative numbers.
The algorithm was first proposed by Alfonso ShimbelÂ (1955), but is instead named after Richard Bellman and Lester Ford Jr., who published it in 1958 and 1956, respectively.[2] Edward F. Moore also published a variation of the algorithm in 1959, and for this reason it is also sometimes called the BellmanâFordâMoore algorithm.[1]
Negative edge weights are found in various applications of graphs, hence the usefulness of this algorithm.[3]
If a graph contains a "negative cycle" (i.e. a cycle whose edges sum to a negative value) that is reachable from the source, then there is no cheapest path: any path that has a point on the negative cycle can be made cheaper by one more walk around the negative cycle. In such a case, the BellmanâFord algorithm can detect and report the negative cycle.[1][4]

Contents

1 Algorithm
2 Proof of correctness
3 Finding negative cycles
4 Applications in routing
5 Improvements
6 Notes
7 References

7.1 Original sources
7.2 Secondary sources





Algorithm[edit]
This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.  (December 2021) (Learn how and when to remove this template message)
  In this example graph, assuming that A is the source and edges are processed in the worst order, from right to left, it requires the full |V|â1 or 4 iterations for the distance estimates to converge. Conversely, if the edges are processed in the best order, from left to right, the algorithm converges in a single iteration.
Like Dijkstra's algorithm, BellmanâFord proceeds by relaxation, in which approximations to the correct distance are replaced by better ones until they eventually reach the solution. In both algorithms, the approximate distance to each vertex is always an overestimate of the true distance, and is replaced by the minimum of its old value and the length of a newly found path.
However, Dijkstra's algorithm uses a priority queue to greedily select the closest vertex that has not yet been processed, and performs this relaxation process on all of its outgoing edges; by contrast, the BellmanâFord algorithm simply relaxes all the edges, and does this 
  
    
      
        
          |
        
        V
        
          |
        
        â
        1
      
    
    {\displaystyle |V|-1}
  
 times, where 
  
    
      
        
          |
        
        V
        
          |
        
      
    
    {\displaystyle |V|}
  
 is the number of vertices in the graph. In each of these repetitions, the number of vertices with correctly calculated distances grows, from which it follows that eventually all vertices will have their correct distances. This method allows the BellmanâFord algorithm to be applied to a wider class of inputs than Dijkstra. The intermediate answers depend on the order of edges relaxed, but the final answer remains the same.
BellmanâFord runs in 
  
    
      
        O
        (
        
          |
        
        V
        
          |
        
        â
        
          |
        
        E
        
          |
        
        )
      
    
    {\displaystyle O(|V|\cdot |E|)}
  
 time, where 
  
    
      
        
          |
        
        V
        
          |
        
      
    
    {\displaystyle |V|}
  
 and 
  
    
      
        
          |
        
        E
        
          |
        
      
    
    {\displaystyle |E|}
  
 are the number of vertices and edges respectively.

function BellmanFord(list vertices, list edges, vertex source) is

    // This implementation takes in a graph, represented as
    // lists of vertices (represented as integers [0..n-1]) and edges,
    // and fills two arrays (distance and predecessor) holding
    // the shortest path from the source to each vertex

    distanceÂ := list of size n
    predecessorÂ := list of size n

    // Step 1: initialize graph
    for each vertex v in vertices do

        distance[v]Â := inf             // Initialize the distance to all vertices to infinity
        predecessor[v]Â := null         // And having a null predecessor
    
    distance[source]Â := 0              // The distance from the source to itself is, of course, zero

    // Step 2: relax edges repeatedly
    
    repeat |V|â1 times:
         for each edge (u, v) with weight w in edges do
             if distance[u] + w < distance[v] then
                 distance[v]Â := distance[u] + w
                 predecessor[v]Â := u

    // Step 3: check for negative-weight cycles
    for each edge (u, v) with weight w in edges do
        if distance[u] + w < distance[v] then
            error "Graph contains a negative-weight cycle"

    return distance, predecessor

Simply put, the algorithm initializes the distance to the source to 0 and all other nodes to infinity. Then for all edges, if the distance to the destination can be shortened by taking the edge, the distance is updated to the new lower value. At each iteration i that the edges are scanned, the algorithm finds all shortest paths of at most length i edges (and possibly some paths longer than i edges). Since the longest possible path without a cycle can be 
  
    
      
        
          |
        
        V
        
          |
        
        â
        1
      
    
    {\displaystyle |V|-1}
  
 edges, the edges must be scanned 
  
    
      
        
          |
        
        V
        
          |
        
        â
        1
      
    
    {\displaystyle |V|-1}
  
 times to ensure the shortest path has been found for all nodes. A final scan of all the edges is performed and if any distance is updated, then a path of length 
  
    
      
        
          |
        
        V
        
          |
        
      
    
    {\displaystyle |V|}
  
 edges has been found which can only occur if at least one negative cycle exists in the graph.

Proof of correctness[edit]
This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.  (March 2019) (Learn how and when to remove this template message)
The correctness of the algorithm can be shown by induction:
Lemma. After i repetitions of for loop,

if Distance(u) is not infinity, it is equal to the length of some path from s to u; and
if there is a path from s to u with at most i edges, then Distance(u) is at most the length of the shortest path from s to u with at most i edges.
Proof. For the base case of induction, consider i=0 and the moment before for loop is executed for the first time. Then, for the source vertex, source.distance = 0, which is correct. For other vertices u, u.distance = infinity, which is also correct because there is no path from source to u with 0 edges.
For the inductive case, we first prove the first part. Consider a moment when a vertex's distance is updated by
v.distanceÂ := u.distance + uv.weight. By inductive assumption, u.distance is the length of some path from source to u. Then u.distance + uv.weight is the length of the path from source to v that follows the path from  source to u and then goes to v.
For the second part, consider a shortest path P (there may be more than one) from source to v with at most i edges. Let u be the last vertex before v on this path. Then, the part of the path from source to u is a shortest path from source to u with at most i-1 edges, since if it were not, then there must be some strictly shorter path from source to u with at most i-1 edges, and we could then append the edge uv to this path to obtain a path with at most i edges that is strictly shorter than Pâa contradiction. By inductive assumption, u.distance after iâ1 iterations is at most the length of this path from source to u. Therefore, uv.weight + u.distance is at most the length of P. In the ith iteration, v.distance gets compared with uv.weight + u.distance, and is set equal to it if uv.weight + u.distance is smaller. Therefore, after i iterations, v.distance is at most the length of P, i.e., the length of the shortest path from source to v that uses at most i edges.
If there are no negative-weight cycles, then every shortest path visits each vertex at most once, so at step 3 no further improvements can be made. Conversely, suppose no improvement can be made. Then for any cycle with vertices v[0], ..., v[kâ1],
v[i].distance <= v[i-1 (mod k)].distance + v[i-1 (mod k)]v[i].weight
Summing around the cycle, the v[i].distance and v[iâ1 (mod k)].distance terms cancel, leaving
0 <= sum from 1 to k of v[i-1 (mod k)]v[i].weight
I.e., every cycle has nonnegative weight.

Finding negative cycles[edit]
When the algorithm is used to find shortest paths, the existence of negative cycles is a problem, preventing the algorithm from finding a correct answer. However, since it terminates upon finding a negative cycle, the BellmanâFord algorithm can be used for applications in which this is the target to be sought â for example in cycle-cancelling techniques in network flow analysis.[1]

Applications in routing[edit]
A distributed variant of the BellmanâFord algorithm is used in distance-vector routing protocols, for example the Routing Information Protocol (RIP). The algorithm is distributed because it involves a number of nodes (routers) within an Autonomous system (AS), a collection of IP networks typically owned by an ISP.
It consists of the following steps:

Each node calculates the distances between itself and all other nodes within the AS and stores this information as a table.
Each node sends its table to all neighboring nodes.
When a node receives distance tables from its neighbors, it calculates the shortest routes to all other nodes and updates its own table to reflect any changes.
The main disadvantages of the BellmanâFord algorithm in this setting are as follows:

It does not scale well.
Changes in network topology are not reflected quickly since updates are spread node-by-node.
Count to infinity if link or node failures render a node unreachable from some set of other nodes, those nodes may spend forever gradually increasing their estimates of the distance to it, and in the meantime there may be routing loops.
Improvements[edit]
The BellmanâFord algorithm may be improved in practice (although not in the worst case) by the observation that, if an iteration of the main loop of the algorithm terminates without making any changes, the algorithm can be immediately terminated, as subsequent iterations will not make any more changes. With this early termination condition, the main loop may in some cases use many fewer than |V|Â âÂ 1 iterations, even though the worst case of the algorithm remains unchanged. The following improvements all maintain the 
  
    
      
        O
        (
        
          |
        
        V
        
          |
        
        â
        
          |
        
        E
        
          |
        
        )
      
    
    {\displaystyle O(|V|\cdot |E|)}
  
 worst-case time complexity.
A variation of the Bellman-Ford algorithm known as Shortest Path Faster Algorithm, first described by Moore (1959), reduces the number of relaxation steps that need to be performed within each iteration of the algorithm. If a vertex v has a distance value that has not changed since the last time the edges out of v were relaxed, then there is no need to relax the edges out of v a second time. In this way, as the number of vertices with correct distance values grows, the number whose outgoing edges that need to be relaxed in each iteration shrinks, leading to a constant-factor savings in time for dense graphs. 
Yen (1970) described another improvement to the BellmanâFord algorithm. His improvement first assigns some arbitrary linear order on all vertices and then partitions the set of all edges into two subsets. The first subset, Ef, contains all edges (vi, vj) such that i < j; the second, Eb, contains edges (vi, vj) such that i > j. Each vertex is visited in the order v1, v2, ..., v|V|, relaxing each outgoing edge from that vertex in Ef. Each vertex is then visited in the order v|V|, v|V|â1, ..., v1, relaxing each outgoing edge from that vertex in Eb. Each iteration of the main loop of the algorithm, after the first one, adds at least two edges to the set of edges whose relaxed distances match the correct shortest path distances: one from Ef and one from Eb. This modification reduces the worst-case number of iterations of the main loop of the algorithm from |V|Â âÂ 1 to 
  
    
      
        
          |
        
        V
        
          |
        
        
          /
        
        2
      
    
    {\displaystyle |V|/2}
  
.[5][6]
Another improvement, by Bannister & Eppstein (2012), replaces the arbitrary linear order of the vertices used in Yen's second improvement by a random permutation. This change makes the worst case for Yen's improvement (in which the edges of a shortest path strictly alternate between the two subsets Ef and Eb) very unlikely to happen. With a randomly permuted vertex ordering, the expected number of iterations needed in the main loop is at most 
  
    
      
        
          |
        
        V
        
          |
        
        
          /
        
        3
      
    
    {\displaystyle |V|/3}
  
.[6]

Notes[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ a b c d Bang-Jensen & Gutin (2000)

^ Schrijver (2005)

^ Sedgewick (2002).

^ Kleinberg & Tardos (2006).

^ Cormen et al., 2nd ed., Problem 24-1, pp. 614â615.

^ a b See Sedgewick's web exercises for Algorithms, 4th ed., exercises 5 and 12 (retrieved 2013-01-30).


References[edit]
Original sources[edit]
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Shimbel, A. (1955). Structure in communication nets. Proceedings of the Symposium on Information Networks. New York, New York: Polytechnic Press of the Polytechnic Institute of Brooklyn. pp.Â 199â203.
Bellman, Richard (1958). "On a routing problem". Quarterly of Applied Mathematics. 16: 87â90. doi:10.1090/qam/102435. MRÂ 0102435.
Ford, Lester R. Jr. (August 14, 1956). Network Flow Theory. Paper P-923. Santa Monica, California: RAND Corporation.
Moore, Edward F. (1959). The shortest path through a maze. Proc. Internat. Sympos. Switching Theory 1957, Part II. Cambridge, Massachusetts: Harvard Univ. Press. pp.Â 285â292. MRÂ 0114710.
Yen, Jin Y. (1970). "An algorithm for finding shortest routes from all source nodes to a given destination in general networks". Quarterly of Applied Mathematics. 27 (4): 526â530. doi:10.1090/qam/253822. MRÂ 0253822.
Bannister, M. J.; Eppstein, D. (2012). Randomized speedup of the BellmanâFord algorithm. Analytic Algorithmics and Combinatorics (ANALCO12), Kyoto, Japan. pp.Â 41â47. arXiv:1111.5414. doi:10.1137/1.9781611973020.6.
Secondary sources[edit]
Bang-Jensen, JÃ¸rgen; Gutin, Gregory (2000). "Section 2.3.4: The Bellman-Ford-Moore algorithm". Digraphs: Theory, Algorithms and Applications (FirstÂ ed.). ISBNÂ 978-1-84800-997-4.
Schrijver, Alexander (2005). "On the history of combinatorial optimization (till 1960)" (PDF). Handbook of Discrete Optimization. Elsevier: 1â68.
Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L. Introduction to Algorithms. MIT Press and McGraw-Hill., Second Edition. MIT Press and McGraw-Hill, 2001. ISBNÂ 0-262-03293-7. Section 24.1: The BellmanâFord algorithm, pp.Â 588â592. Problem 24-1, pp.Â 614â615. Third Edition. MIT Press, 2009. ISBNÂ 978-0-262-53305-8. Section 24.1: The BellmanâFord algorithm, pp.Â 651â655.
Heineman, George T.; Pollice, Gary; Selkow, Stanley (2008). "Chapter 6: Graph Algorithms". Algorithms in a Nutshell. O'Reilly Media. pp.Â 160â164. ISBNÂ 978-0-596-51624-6.
Kleinberg, Jon; Tardos, Ãva (2006). Algorithm Design. New York: Pearson Education, Inc.
Sedgewick, Robert (2002). "Section 21.7: Negative Edge Weights". Algorithms in Java (3rdÂ ed.). ISBNÂ 0-201-36121-3. Archived from the original on 2008-05-31. Retrieved 2007-05-28.




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=BellmanâFord_algorithm&oldid=1058300389"
		Categories: Graph algorithmsPolynomial-time problemsDynamic programmingGraph distanceHidden categories: Articles with short descriptionShort description is different from WikidataArticles needing additional references from December 2021All articles needing additional referencesArticles needing additional references from March 2019Articles with example C codeArticles with example pseudocode
	
