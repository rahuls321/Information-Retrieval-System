
Title:
Nonlinear programming
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Solution process for some optimization problems
In mathematics, nonlinear programming (NLP) is the process of solving an optimization problem where some of the constraints or the objective function are nonlinear. An optimization problem is one of calculation of the extrema (maxima, minima or stationary points) of an objective function over a set of unknown real variables and conditional to the satisfaction of a system of equalities and inequalities, collectively termed constraints. It is the sub-field of mathematical optimization that deals with problems that are not linear.

Contents

1 Applicability
2 Definition
3 Possible types of constraint set
4 Methods for solving the problem
5 Examples

5.1 2-dimensional example
5.2 3-dimensional example


6 See also
7 References
8 Further reading
9 External links



Applicability[edit]
A typical non-convex problem is that of optimizing transportation costs by selection from a set of transportation methods, one or more of which exhibit economies of scale, with various connectivities and capacity constraints. An example would be petroleum product transport given a selection or combination of pipeline, rail tanker, road tanker, river barge, or coastal tankship. Owing to economic batch size the cost functions may have discontinuities in addition to smooth changes.
In experimental science, some simple data analysis (such as fitting a spectrum with a sum of peaks of known location and shape but unknown magnitude) can be done with linear methods, but in general these problems, also, are nonlinear.  Typically, one has a theoretical model of the system under study with variable parameters in it and a model the experiment or experiments, which may also have unknown parameters.  One tries to find a best fit numerically.  In this case one often wants a measure of the precision of the result, as well as the best fit itself.

Definition[edit]
Let n, m, and p be positive integers. Let X be a subset of Rn, let f, gi, and hj be real-valued functions on X for each i in {1, â¦, m} and each j in {1, â¦, p}, with at least one of f, gi, and hj being nonlinear.
A nonlinear minimization problem is an optimization problem of the form


  
    
      
        
          
            
              
                
                  minimizeÂ 
                
              
              
                f
                (
                x
                )
              
            
            
              
                
                  subject toÂ 
                
              
              
                
                  g
                  
                    i
                  
                
                (
                x
                )
                â¤
                0
                
                  Â for eachÂ 
                
                i
                â
                {
                1
                ,
                â¦
                ,
                m
                }
              
            
            
              
              
                
                  h
                  
                    j
                  
                
                (
                x
                )
                =
                0
                
                  Â for eachÂ 
                
                j
                â
                {
                1
                ,
                â¦
                ,
                p
                }
              
            
            
              
              
                x
                â
                X
                .
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\text{minimize }}&f(x)\\{\text{subject to }}&g_{i}(x)\leq 0{\text{ for each }}i\in \{1,\dotsc ,m\}\\&h_{j}(x)=0{\text{ for each }}j\in \{1,\dotsc ,p\}\\&x\in X.\end{aligned}}}
  

A nonlinear maximization problem is defined in a similar way.

Possible types of constraint set[edit]
There are several possibilities for the nature of the constraint set, also known as the feasible set or feasible region.
An infeasible problem is one for which no set of values for the choice variables satisfies all the constraints. That is, the constraints are mutually contradictory, and no solution exists; the feasible set is the empty set.
A feasible problem is one for which there exists at least one set of values for the choice variables satisfying all the constraints.
An unbounded problem is a feasible problem for which the objective function can be made to be better than any given finite value. Thus there is no optimal solution, because there is always a feasible solution that gives a better objective function value than does any given proposed solution.

Methods for solving the problem[edit]
If the objective function is concave (maximization problem), or convex (minimization problem) and the constraint set is convex, then the program is called convex and general methods from convex optimization can be used in most cases.
If the objective function is quadratic and the constraints are linear, quadratic programming techniques are used.
If the objective function is a ratio of a concave and a convex function (in the maximization case) and the constraints are convex, then the problem can be transformed to a convex optimization problem using fractional programming techniques.
Several methods are available for solving nonconvex problems. One approach is to use  special formulations of linear programming problems. Another method involves the use of branch and bound techniques, where the program is divided into subclasses to be solved with convex (minimization problem) or linear approximations that form a lower bound on the overall cost within the subdivision. With subsequent divisions, at some point an actual solution will be obtained whose cost is equal to the best lower bound obtained for any of the approximate solutions. This solution is optimal, although possibly not unique. The algorithm may also be stopped early, with the assurance that the best possible solution is within a tolerance from the best point found; such points are called Îµ-optimal. Terminating to Îµ-optimal points is typically necessary to ensure finite termination. This is especially useful for large, difficult problems and problems with uncertain costs or values where the uncertainty can be estimated with an appropriate reliability estimation.
Under differentiability and constraint qualifications, the KarushâKuhnâTucker (KKT) conditions provide necessary conditions for a solution to be optimal. Under convexity, these conditions are also sufficient. If some of the functions are non-differentiable, subdifferential versions of
KarushâKuhnâTucker (KKT) conditions are available.[1]

Examples[edit]
2-dimensional example[edit]
  The blue region is the feasible region. The tangency of the line with the feasible region represents the solution. The line is the best achievable contour line (locus with a given value of the objective function).
A simple problem (shown in the diagram) can be defined by the constraints

x1 â¥ 0
x2 â¥ 0
x12 + x22 â¥ 1
x12 + x22 â¤ 2
with an objective function to be maximized

f(x) = x1 + x2
where x = (x1, x2).

3-dimensional example[edit]
  The tangency of the top surface with the constrained space in the center represents the solution.
Another simple problem (see diagram) can be defined by the constraints

x12 â x22 + x32 â¤ 2
x12 + x22 + x32 â¤ 10
with an objective function to be maximized

f(x) = x1x2 + x2x3
where x = (x1, x2, x3).

See also[edit]
Curve fitting
Least squares minimization
Linear programming
nl (format)
Nonlinear least squares
List of optimization software
Quadratically constrained quadratic programming
Werner Fenchel, who created the foundation for nonlinear programming
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ 
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}RuszczyÅski, Andrzej (2006). Nonlinear Optimization. Princeton, NJ: Princeton University Press. pp.Â xii+454. ISBNÂ 978-0691119151. MRÂ 2199043.


Further reading[edit]
Avriel, Mordecai (2003). Nonlinear Programming: Analysis and Methods. Dover Publishing. ISBNÂ 0-486-43227-0.
Bazaraa, Mokhtar S. and Shetty, C. M. (1979). Nonlinear programming. Theory and algorithms. John Wiley & Sons. ISBNÂ 0-471-78610-1.
Bonnans, J.Â FrÃ©dÃ©ric; Gilbert, J.Â Charles; LemarÃ©chal, Claude; SagastizÃ¡bal, ClaudiaÂ A. (2006). Numerical optimization: Theoretical and practical aspects. Universitext (Second revised ed. of  translation of 1997  FrenchÂ ed.). Berlin: Springer-Verlag. pp.Â xiv+490. doi:10.1007/978-3-540-35447-5. ISBNÂ 3-540-35445-X. MRÂ 2265882.
Luenberger, David G.; Ye, Yinyu (2008). Linear and nonlinear programming. International Series in Operations Research & Management Science. Vol.Â 116 (ThirdÂ ed.). New York: Springer. pp.Â xiv+546. ISBNÂ 978-0-387-74502-2. MRÂ 2423726.
Nocedal, Jorge and Wright, Stephen J. (1999). Numerical Optimization. Springer. ISBNÂ 0-387-98793-2.
Jan Brinkhuis and Vladimir Tikhomirov, Optimization: Insights and Applications, 2005, Princeton University Press
External links[edit]
Mathematical Programming Glossary
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteOptimization: Algorithms, methods, and heuristicsUnconstrained nonlinearFunctions
Golden-section search
Interpolation methods
Line search
NelderâMead method
Successive parabolic interpolation
GradientsConvergence
Trust region
Wolfe conditions
QuasiâNewton
BerndtâHallâHallâHausman
BroydenâFletcherâGoldfarbâShanno and L-BFGS
DavidonâFletcherâPowell
Symmetric rank-one (SR1)
Other methods
Conjugate gradient
GaussâNewton
Gradient
LevenbergâMarquardt
Powell's dog leg method
Truncated Newton
Hessians
Newton's method
Constrained nonlinearGeneral
Barrier methods
Penalty methods
Differentiable
Augmented Lagrangian methods
Sequential quadratic programming
Successive linear programming
Convex optimizationConvex minimization
Cutting-plane method
Reduced gradient (FrankâWolfe)
Subgradient method
Linear andquadraticInterior point
Affine scaling
Ellipsoid algorithm of Khachiyan
Projective algorithm of Karmarkar
Basis-exchange
Simplex algorithm of Dantzig
Revised simplex algorithm
Criss-cross algorithm
Principal pivoting algorithm of Lemke
CombinatorialParadigms
Approximation algorithm
Dynamic programming
Greedy algorithm
Integer programming
Branch and bound/cut
Graph algorithmsMinimum spanning tree
BorÅ¯vka
Prim
Kruskal

    Shortest path
BellmanâFord
SPFA
Dijkstra
FloydâWarshall
Network flows
Dinic
EdmondsâKarp
FordâFulkerson
Pushârelabel maximum flow
Metaheuristics
Evolutionary algorithm
Hill climbing
Local search
Simulated annealing
Tabu search

Software

Authority control: National libraries  
France (data)
United States





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Nonlinear_programming&oldid=1049436578"
		Categories: Optimization algorithms and methodsHidden categories: Articles with short descriptionShort description matches WikidataArticles with BNF identifiersArticles with LCCN identifiers
	
