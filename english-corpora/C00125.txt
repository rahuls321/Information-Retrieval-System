
Title:
Advanced Video Coding
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Most widely used standard for video compression
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}"AVC1" redirects here. Not to be confused with AV1 or VC-1.
.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}Advanced Video CodingAdvanced video coding for generic audiovisual servicesStatusIn forceYear started2003First published17Â AugustÂ 2004Â (2004-08-17)Latest version14.022Â AugustÂ 2021Â (2021-08-22)OrganizationITU-T, ISO, IECCommitteeSG16 (VCEG), MPEGBase standardsH.261, H.262 (aka MPEG-2 Video), H.263, MPEG-1Related standardsH.265 (aka HEVC), H.266 (aka VVC)DomainVideo compressionLicenseMPEG LA[1]Websitehttps://www.itu.int/rec/T-REC-H.264
Advanced Video Coding (AVC), also referred to as H.264 or MPEG-4 Part 10, Advanced Video Coding (MPEG-4 AVC), is a video compression standard based on block-oriented, motion-compensated coding.[2] It is by far the most commonly used format for the recording, compression, and distribution of video content, used by 91% of video industry developers as of September 2019[update].[3][4] It supports resolutions up to and  including 8K UHD.[5][6]
The intent of the H.264/AVC project was to create a standard capable of providing good video quality at substantially lower bit rates than previous standards (i.e., half or less the bit rate of MPEG-2, H.263, or MPEG-4 Part 2), without increasing the complexity of design so much that it would be impractical or excessively expensive to implement. This was achieved with features such as a reduced-complexity integer discrete cosine transform (integer DCT),[6][7][8] variable block-size segmentation, and multi-picture inter-picture prediction. An additional goal was to provide enough flexibility to allow the standard to be applied to a wide variety of applications on a wide variety of networks and systems, including low and high bit rates, low and high resolution video, broadcast, DVD storage, RTP/IP packet networks, and ITU-T multimedia telephony systems. The H.264 standard can be viewed as a "family of standards" composed of a number of different profiles, although its "High profile" is by far the mostly commonly used format. A specific decoder decodes at least one, but not necessarily all profiles. The standard describes the format of the encoded data and how the data is decoded, but it does not specify algorithms for encoding videoÂ â  that is left open as a matter for encoder designers to select for themselves, and a wide variety of encoding schemes has been developed. H.264 is typically used for lossy compression, although it is also possible to create truly lossless-coded regions within lossy-coded pictures or to support rare use cases for which the entire encoding is lossless.
H.264 was standardized by the ITU-T Video Coding Experts Group (VCEG) of Study Group 16 together with the ISO/IEC JTC1 Moving Picture Experts Group (MPEG). The project partnership effort is known as the Joint Video Team (JVT). The ITU-T H.264 standard and the ISO/IEC MPEG-4Â AVC standard (formally, ISO/IECÂ 14496-10Â â MPEG-4 Part 10, Advanced Video Coding) are jointly maintained so that they have identical technical content. The final drafting work on the first version of the standard was completed in May 2003, and various extensions of its capabilities have been added in subsequent editions. High Efficiency Video Coding (HEVC), a.k.a. H.265 and MPEG-H Part 2 is a successor to H.264/MPEG-4Â AVC developed by the same organizations, while earlier standards are still in common use.
H.264 is perhaps best known as being the most commonly used video encoding format on Blu-ray Discs. It is also widely used by streaming Internet sources, such as videos from Netflix, Hulu, Amazon Prime Video, Vimeo, YouTube, and the iTunes Store, Web software such as the Adobe Flash Player and Microsoft Silverlight, and also various HDTV broadcasts over terrestrial (ATSC, ISDB-T, DVB-T or DVB-T2), cable (DVB-C), and satellite (DVB-S and DVB-S2) systems.
H.264 is restricted by patents owned by various parties. A license covering most (but not all) patents essential to H.264 is administered by a patent pool administered by MPEG LA.[9]
The commercial use of patented H.264 technologies requires the payment of royalties to MPEG LA and other patent owners. MPEG LA has allowed the free use of H.264 technologies for streaming Internet video that is free to end users, and Cisco Systems pays royalties to MPEG LA on behalf of the users of binaries for its open source H.264 encoder.

Contents

1 Naming
2 History

2.1 Overall history
2.2 Fidelity range extensions and professional profiles
2.3 Scalable video coding
2.4 Multiview video coding
2.5 3D-AVC and MFC stereoscopic coding
2.6 Versions
2.7 Patent holders


3 Applications

3.1 Derived formats


4 Design

4.1 Features
4.2 Profiles

4.2.1 Feature support in particular profiles


4.3 Levels
4.4 Decoded picture buffering


5 Implementations

5.1 Software encoders
5.2 Hardware


6 Licensing
7 See also
8 References
9 Further reading
10 External links



Naming[edit]
The H.264 name follows the ITU-T naming convention, where the standard is a member of the H.26x line of VCEG video coding standards; the MPEG-4 AVC name relates to the naming convention in ISO/IEC MPEG, where the standard is part 10 of ISO/IEC 14496, which is the suite of standards known as MPEG-4. The standard was developed jointly in a partnership of VCEG and MPEG, after earlier development work in the ITU-T as a VCEG project called H.26L. It is thus common to refer to the standard with names such as H.264/AVC, AVC/H.264, H.264/MPEG-4 AVC, or MPEG-4/H.264 AVC, to emphasize the common heritage. Occasionally, it is also referred to as "the JVT codec", in reference to the Joint Video Team (JVT) organization that developed it.  (Such partnership and multiple naming is not uncommon. For example, the video compression standard known as MPEG-2 also arose from the partnership between MPEG and the ITU-T, where MPEG-2 video is known to the ITU-T community as H.262.[10]) Some software programs (such as VLC media player) internally identify this standard as AVC1.

History[edit]
Overall history[edit]
In early 1998, the Video Coding Experts Group (VCEGÂ â ITU-T SG16 Q.6) issued a call for proposals on a project called H.26L, with the target to double the coding efficiency (which means halving the bit rate necessary for a given level of fidelity) in comparison to any other existing video coding standards for a broad variety of applications. VCEG was chaired by Gary Sullivan (Microsoft, formerly PictureTel, U.S.). The first draft design for that new standard was adopted in August 1999. In 2000, Thomas Wiegand (Heinrich Hertz Institute, Germany) became VCEG co-chair.
In December 2001, VCEG and the Moving Picture Experts Group (MPEGÂ â ISO/IEC JTC 1/SC 29/WG 11) formed a Joint Video Team (JVT), with the charter to finalize the video coding standard.[11] Formal approval of the specification came in March 2003. The JVT was (is) chaired by Gary Sullivan, Thomas Wiegand, and Ajay Luthra (Motorola, U.S.: later Arris, U.S.). In July 2004, the Fidelity Range Extensions (FRExt) project was finalized. From January 2005 to November 2007, the JVT was working on an extension of H.264/AVC towards scalability by an Annex (G) called Scalable Video Coding (SVC). The JVT management team was extended by Jens-Rainer Ohm (RWTH Aachen University, Germany). From July 2006 to November 2009, the JVT worked on Multiview Video Coding (MVC), an extension of H.264/AVC towards 3D television and limited-range free-viewpoint television. That work included the development of two new profiles of the standard: the Multiview High Profile and the Stereo High Profile.
Throughout the development of the standard, additional messages for containing supplemental enhancement information (SEI) have been developed. SEI messages can contain various types of data that indicate the timing of the video pictures or describe various properties of the coded video or how it can be used or enhanced. SEI messages are also defined that can contain arbitrary user-defined data. SEI messages do not affect the core decoding process, but can indicate how the video is recommended to be post-processed or displayed. Some other high-level properties of the video content are conveyed in video usability information (VUI), such as the indication of the color space for interpretation of the video content. As new color spaces have been developed, such as for high dynamic range and wide color gamut video, additional VUI identifiers have been added to indicate them.

Fidelity range extensions and professional profiles[edit]
The standardization of the first version of H.264/AVC was completed in May 2003. In the first project to extend the original standard, the JVT then developed what was called the Fidelity Range Extensions (FRExt). These extensions enabled higher quality video coding by supporting increased sample bit depth precision and higher-resolution color information, including the sampling structures known as Yâ²CBCR 4:2:2 (a.k.a. YUV 4:2:2) and 4:4:4. Several other features were also included in the FRExt project, such as adding an 8Ã8 integer discrete cosine transform (integer DCT) with adaptive switching between the 4Ã4 and 8Ã8 transforms, encoder-specified perceptual-based quantization weighting matrices, efficient inter-picture lossless coding, and support of additional color spaces. The design work on the FRExt project was completed in July 2004, and the drafting work on them was completed in September 2004.
Five other new profiles (see version 7 below) intended primarily for professional applications were then developed, adding extended-gamut color space support, defining additional aspect ratio indicators, defining two additional types of "supplemental enhancement information" (post-filter hint and tone mapping), and deprecating one of the prior FRExt profiles (the High 4:4:4 profile) that industry feedback[by whom?] indicated should have been designed differently.

Scalable video coding[edit]
The next major feature added to the standard was Scalable Video Coding (SVC). Specified in Annex G of H.264/AVC, SVC allows the construction of bitstreams that contain layers of sub-bitstreams that also conform to the standard, including one such bitstream known as the "base layer" that can be decoded by a H.264/AVC codec that does not support SVC. For temporal bitstream scalability (i.e., the presence of a sub-bitstream with a smaller temporal sampling rate than the main bitstream), complete access units are removed from the bitstream when deriving the sub-bitstream. In this case, high-level syntax and inter-prediction reference pictures in the bitstream are constructed accordingly. On the other hand, for spatial and quality bitstream scalability (i.e. the presence of a sub-bitstream with lower spatial resolution/quality than the main bitstream), the NAL (Network Abstraction Layer) is removed from the bitstream when deriving the sub-bitstream. In this case, inter-layer prediction (i.e., the prediction of the higher spatial resolution/quality signal from the data of the lower spatial resolution/quality signal) is typically used for efficient coding. The Scalable Video Coding extensions were completed in November 2007.

Multiview video coding[edit]
The next major feature added to the standard was Multiview Video Coding (MVC).  Specified in Annex H of H.264/AVC, MVC enables the construction of bitstreams that represent more than one view of a video scene.  An important example of this functionality is stereoscopic 3D video coding. Two profiles were developed in the MVC work: Multiview High profile supports an arbitrary number of views, and Stereo High profile is designed specifically for two-view stereoscopic video.  The Multiview Video Coding extensions were completed in November 2009.

3D-AVC and MFC stereoscopic coding[edit]
Additional extensions were later developed that included 3D video coding with joint coding of depth maps and texture (termed 3D-AVC), multi-resolution frame-compatible (MFC) stereoscopic and 3D-MFC coding, various additional combinations of features, and higher frame sizes and frame rates.

Versions[edit]
Versions of the H.264/AVC standard include the following completed revisions, corrigenda, and amendments (dates are final approval dates in ITU-T, while final "International Standard" approval dates in ISO/IEC are somewhat different and slightly later in most cases). Each version represents changes relative to the next lower version that is integrated into the text.

Version 1 (Edition 1): (May 30, 2003) First approved version of H.264/AVC containing Baseline, Main, and Extended profiles.[12]
Version 2 (Edition 1.1): (May 7, 2004) Corrigendum containing various minor corrections.[13]
Version 3 (Edition 2): (March 1, 2005) Major addition containing the first amendment, establishing the Fidelity Range Extensions (FRExt). This version added the High, High 10, High 4:2:2, and High 4:4:4 profiles.[14] After a few years, the High profile became the most commonly used profile of the standard.
Version 4 (Edition 2.1): (September 13, 2005) Corrigendum containing various minor corrections and adding three aspect ratio indicators.[15]
Version 5 (Edition 2.2): (June 13, 2006) Amendment consisting of removal of prior High 4:4:4 profile (processed as a corrigendum in ISO/IEC).[16]
Version 6 (Edition 2.2): (June 13, 2006) Amendment consisting of minor extensions like extended-gamut color space support (bundled with above-mentioned aspect ratio indicators in ISO/IEC).[16]
Version 7 (Edition 2.3): (April 6, 2007) Amendment containing the addition of the High 4:4:4 Predictive profile and four Intra-only profiles (High 10 Intra, High 4:2:2 Intra, High 4:4:4 Intra, and CAVLC 4:4:4 Intra).[17]
Version 8 (Edition 3): (November 22, 2007) Major addition to H.264/AVC containing the amendment for Scalable Video Coding (SVC) containing Scalable Baseline, Scalable High, and Scalable High Intra profiles.[18]
Version 9 (Edition 3.1): (January 13, 2009) Corrigendum containing minor corrections.[19]
Version 10 (Edition 4): (March 16, 2009) Amendment containing definition of a new profile (the Constrained Baseline profile) with only the common subset of capabilities supported in various previously specified profiles.[20]
Version 11 (Edition 4): (March 16, 2009) Major addition to H.264/AVC containing the amendment for Multiview Video Coding (MVC) extension, including the Multiview High profile.[20]
Version 12 (Edition 5): (March 9, 2010) Amendment containing definition of a new MVC profile (the Stereo High profile) for two-view video coding with support of interlaced coding tools and specifying an additional supplemental enhancement information (SEI) message termed the frame packing arrangement SEI message.[21]
Version 13 (Edition 5): (March 9, 2010) Corrigendum containing minor corrections.[21]
Version 14 (Edition 6): (June 29, 2011) Amendment specifying a new level (Level 5.2) supporting higher processing rates in terms of maximum macroblocks per second, and a new profile (the Progressive High profile) supporting only the frame coding tools of the previously specified High profile.[22]
Version 15 (Edition 6): (June 29, 2011) Corrigendum containing minor corrections.[22]
Version 16 (Edition 7): (January 13, 2012) Amendment containing definition of three new profiles intended primarily for real-time communication applications: the Constrained High, Scalable Constrained Baseline, and Scalable Constrained High profiles.[23]
Version 17 (Edition 8): (April 13, 2013) Amendment with additional SEI message indicators.[24]
Version 18 (Edition 8): (April 13, 2013) Amendment to specify the coding of depth map data for 3D stereoscopic video, including a Multiview Depth High profile.[24]
Version 19 (Edition 8): (April 13, 2013) Corrigendum to correct an error in the sub-bitstream extraction process for multiview video.[24]
Version 20 (Edition 8): (April 13, 2013) Amendment to specify additional color space identifiers (including support of ITU-R Recommendation BT.2020 for UHDTV) and an additional model type in the tone mapping information SEI message.[24]
Version 21 (Edition 9): (February 13, 2014) Amendment to specify the Enhanced Multiview Depth High profile.[25]
Version 22 (Edition 9): (February 13, 2014) Amendment to specify the multi-resolution frame compatible (MFC) enhancement for 3D stereoscopic video, the MFC High profile, and minor corrections.[25]
Version 23 (Edition 10): (February 13, 2016) Amendment to specify MFC stereoscopic video with depth maps, the MFC Depth High profile, the mastering display color volume SEI message, and additional color-related VUI codepoint identifiers.[26]
Version 24 (Edition 11): (October 14, 2016) Amendment to specify additional levels of decoder capability supporting larger picture sizes (Levels 6, 6.1, and 6.2), the green metadata SEI message, the alternative depth information SEI message, and additional color-related VUI codepoint identifiers.[27]
Version 25 (Edition 12): (April 13, 2017) Amendment to specify the Progressive High 10 profile, hybrid logâgamma (HLG), and additional color-related VUI code points and SEI messages.[28]
Version 26 (Edition 13): (June 13, 2019) Amendment to specify additional SEI messages for ambient viewing environment, content light level information, content color volume, equirectangular projection, cubemap projection, sphere rotation, region-wise packing, omnidirectional viewport, SEI manifest, and SEI prefix.[29]
Version 27 (Edition 14): (August 22, 2021) Amendment to specify additional SEI messages for annotated regions and shutter interval information, and miscellaneous minor corrections and clarifications.[30]
Patent holders[edit]
Further information: MPEG LA
Part of this section is transcluded from MPEG LA. (edit | history)
The following organizations hold one or more patents in MPEG LA's H.264/AVC patent pool.


H.264/AVC patent holders (as of November 2020[update])[31]


Organization[32]

Active patents

Expired patents

Total patents[31]


Panasonic Corporation

1,135

62

1,197


Godo Kaisha IP Bridge

1,111

19

1,130


LG Electronics

875

115

990


Dolby Laboratories

754

21

775


Toshiba

357

34

391


Microsoft

176

39

215


Nippon Telegraph and Telephone (including NTT Docomo)

187

2

189


Sony

116

31

147


Fraunhofer Society

125

16

141


Google

136

3

139


GE Video Compression

136

0

136


Fujitsu

92

14

106


Mitsubishi Electric

54

50

104


Tagivan II LLC

77

0

77


Samsung Electronics

23

40

63


Maxell

51

2

53


Philips

5

39

44


Vidyo

41

2

43


Ericsson

34

0

34


Electronics and Telecommunications Research Institute (ETRI) of Korea

32

0

32


Applications[edit]
Further information: List of video services using H.264/MPEG-4 AVC
The H.264 video format has a very broad application range that covers all forms of digital compressed video from low bit-rate Internet streaming applications to HDTV broadcast and Digital Cinema applications with nearly lossless coding. With the use of H.264, bit rate savings of 50% or more compared to MPEG-2 Part 2 are reported. For example, H.264 has been reported to give the same Digital Satellite TV quality as current MPEG-2 implementations with less than half the bitrate, with current MPEG-2 implementations working at around 3.5 Mbit/s and H.264 at only 1.5 Mbit/s.[33] Sony claims that 9 Mbit/s AVC recording mode is equivalent to the image quality of the HDV format, which uses approximately 18â25 Mbit/s.[34]
To ensure compatibility and problem-free adoption of H.264/AVC, many standards bodies have amended or added to their video-related standards so that users of these standards can employ H.264/AVC. Both the Blu-ray Disc format and the now-discontinued HD DVD format include the H.264/AVC High Profile as one of three mandatory video compression formats. The Digital Video Broadcast project (DVB) approved the use of H.264/AVC for broadcast television in late 2004.
The Advanced Television Systems Committee (ATSC) standards body in the United States approved the use of H.264/AVC for broadcast television in July 2008, although the standard is not yet used for fixed ATSC broadcasts within the United States.[35][36] It has also been approved for use with the more recent ATSC-M/H (Mobile/Handheld) standard, using the AVC and SVC portions of H.264.[37]
The CCTV (Closed Circuit TV) and Video Surveillance markets have included the technology in many products.
Many common DSLRs use H.264 video wrapped in QuickTime MOV containers as the native recording format.

Derived formats[edit]
AVCHD is a high-definition recording format designed by Sony and Panasonic that uses H.264 (conforming to H.264 while adding additional application-specific features and constraints).
AVC-Intra is an intraframe-only compression format, developed by Panasonic.
XAVC is a recording format designed by Sony that uses level 5.2 of H.264/MPEG-4 AVC, which is the highest level supported by that video standard.[38][39] XAVC can support 4K resolution (4096 Ã 2160 and 3840 Ã 2160) at up to 60Â frames per second (fps).[38][39] Sony has announced that cameras that support XAVC include two CineAlta camerasâthe Sony PMW-F55 and Sony PMW-F5.[40] The Sony PMW-F55 can record XAVC with 4K resolution at 30Â fps at 300 Mbit/s and 2K resolution at 30Â fps at 100 Mbit/s.[41] XAVC can record 4K resolution at 60Â fps with 4:2:2 chroma sampling at 600 Mbit/s.[42][43]

Design[edit]
Features[edit]
  Block diagram of H.264
H.264/AVC/MPEG-4 Part 10 contains a number of new features that allow it to compress video much more efficiently than older standards and to provide more flexibility for application to a wide variety of network environments. In particular, some such key features include:

Multi-picture inter-picture prediction including the following features:
Using previously encoded pictures as references in a much more flexible way than in past standards, allowing up to 16 reference frames (or 32 reference fields, in the case of interlaced encoding) to be used in some cases. In profiles that support non-IDR frames, most levels specify that sufficient buffering should be available to allow for at least 4 or 5 reference frames at maximum resolution. This is in contrast to prior standards, where the limit was typically one; or, in the case of conventional "BÂ pictures" (B-frames), two.
Variable block-size motion compensation (VBSMC) with block sizes as large as 16Ã16 and as small as 4Ã4, enabling precise segmentation of moving regions. The supported luma prediction block sizes include 16Ã16, 16Ã8, 8Ã16, 8Ã8, 8Ã4, 4Ã8, and 4Ã4, many of which can be used together in a single macroblock. Chroma prediction block sizes are correspondingly smaller when chroma subsampling is used.
The ability to use multiple motion vectors per macroblock (one or two per partition) with a maximum of 32 in the case of a B macroblock constructed of 16 4Ã4 partitions. The motion vectors for each 8Ã8 or larger partition region can point to different reference pictures.
The ability to use any macroblock type in B-frames, including I-macroblocks, resulting in much more efficient encoding when using B-frames. This feature was notably left out from MPEG-4 ASP.
Six-tap filtering for derivation of half-pel luma sample predictions, for sharper subpixel motion-compensation. Quarter-pixel motion is derived by linear interpolation of the halfpixel values, to save processing power.
Quarter-pixel precision for motion compensation, enabling precise description of the displacements of moving areas. For  chroma the resolution is typically halved both vertically and horizontally (see 4:2:0) therefore the motion compensation of chroma uses one-eighth chroma pixel grid units.
Weighted prediction, allowing an encoder to specify the use of a scaling and offset when performing motion compensation, and providing a significant benefit in performance in special casesâsuch as fade-to-black, fade-in, and cross-fade transitions. This includes implicit weighted prediction for B-frames, and explicit weighted prediction for P-frames.
Spatial prediction from the edges of neighboring blocks for "intra" coding, rather than the "DC"-only prediction found in MPEG-2 Part 2 and the transform coefficient prediction found in H.263v2 and MPEG-4 Part 2. This includes luma prediction block sizes of 16Ã16, 8Ã8, and 4Ã4 (of which only one type can be used within each macroblock).
Integer discrete cosine transform (integer DCT),[6][8][44] a type of discrete cosine transform (DCT)[8] where the transform is an integer approximation of the standard DCT.[45] It has selectable block sizes[7] and exact-match integer computation to reduce complexity, including:
An exact-match integer 4Ã4 spatial block transform, allowing precise placement of residual signals with little of the "ringing" often found with prior codec designs. It is similar to the standard DCT used in previous standards, but uses a smaller block size and simple integer processing. Unlike the cosine-based formulas and tolerances expressed in earlier standards (such as H.261 and MPEG-2), integer processing provides an exactly specified decoded result.
An exact-match integer 8Ã8 spatial block transform, allowing highly correlated regions to be compressed more efficiently than with the 4Ã4 transform. This design is based on the standard DCT, but simplified and made to provide exactly specified decoding.
Adaptive encoder selection between the 4Ã4 and 8Ã8 transform block sizes for the integer transform operation.
A secondary Hadamard transform performed on "DC" coefficients of the primary spatial transform applied to chroma DC coefficients (and also luma in one special case) to obtain even more compression in smooth regions.
Lossless macroblock coding features including:
A lossless "PCM macroblock" representation mode in which video data samples are represented directly,[46] allowing perfect representation of specific regions and allowing a strict limit to be placed on the quantity of coded data for each macroblock.
An enhanced lossless macroblock representation mode allowing perfect representation of specific regions while ordinarily using substantially fewer bits than the PCM mode.
Flexible interlaced-scan video coding features, including:
Macroblock-adaptive frame-field (MBAFF) coding, using a macroblock pair structure for pictures coded as frames, allowing 16Ã16 macroblocks in field mode (compared with MPEG-2, where field mode processing in a picture that is coded as a frame results in the processing of 16Ã8 half-macroblocks).
Picture-adaptive frame-field coding (PAFF or PicAFF) allowing a freely selected mixture of pictures coded either as complete frames where both fields are combined for encoding or as individual single fields.
A quantization design including:
Logarithmic step size control for easier bit rate management by encoders and simplified inverse-quantization scaling
Frequency-customized quantization scaling matrices selected by the encoder for perceptual-based quantization optimization
An in-loop deblocking filter that helps prevent the blocking artifacts common to other DCT-based image compression techniques, resulting in better visual appearance and compression efficiency
An entropy coding design including:
Context-adaptive binary arithmetic coding (CABAC), an algorithm to losslessly compress syntax elements in the video stream knowing the probabilities of syntax elements in a given context. CABAC compresses data more efficiently than CAVLC but requires considerably more processing to decode.
Context-adaptive variable-length coding (CAVLC), which is a lower-complexity alternative to CABAC for the coding of quantized transform coefficient values. Although lower complexity than CABAC, CAVLC is more elaborate and more efficient than the methods typically used to code coefficients in other prior designs.
A common simple and highly structured variable length coding (VLC) technique for many of the syntax elements not coded by CABAC or CAVLC, referred to as Exponential-Golomb coding (or Exp-Golomb).
Loss resilience features including:
A Network Abstraction Layer (NAL) definition allowing the same video syntax to be used in many network environments. One very fundamental design concept of H.264 is to generate self-contained packets, to remove the header duplication as in MPEG-4's Header Extension Code (HEC).[47] This was achieved by decoupling information relevant to more than one slice from the media stream. The combination of the higher-level parameters is called a parameter set.[47] The H.264 specification includes two types of parameter sets: Sequence Parameter Set (SPS) and Picture Parameter Set (PPS). An active sequence parameter set remains  unchanged throughout a coded video sequence, and an active picture parameter set remains unchanged within a coded picture. The sequence and picture parameter set structures contain information such as picture size, optional coding modes employed, and macroblock to slice group map.[47]
Flexible macroblock ordering (FMO), also known as slice groups, and arbitrary slice ordering (ASO), which are techniques for restructuring the ordering of the representation of the fundamental regions (macroblocks) in pictures. Typically considered an error/loss robustness feature, FMO and ASO can also be used for other purposes.
Data partitioning (DP), a feature providing the ability to separate more important and less important syntax elements into different packets of data, enabling the application of unequal error protection (UEP) and other types of improvement of error/loss robustness.
Redundant slices (RS), an error/loss robustness feature that lets an encoder send an extra representation of a picture region (typically at lower fidelity) that can be used if the primary representation is corrupted or lost.
Frame numbering, a feature that allows the creation of "sub-sequences", enabling temporal scalability by optional inclusion of extra pictures between other pictures, and the detection and concealment of losses of entire pictures, which can occur due to network packet losses or channel errors.
Switching slices, called SP and SI slices, allowing an encoder to direct a decoder to jump into an ongoing video stream for such purposes as video streaming bit rate switching and "trick mode" operation. When a decoder jumps into the middle of a video stream using the SP/SI feature, it can get an exact match to the decoded pictures at that location in the video stream despite using different pictures, or no pictures at all, as references prior to the switch.
A simple automatic process for preventing the accidental emulation of start codes, which are special sequences of bits in the coded data that allow random access into the bitstream and recovery of byte alignment in systems that can lose byte synchronization.
Supplemental enhancement information (SEI) and video usability information (VUI), which are extra information that can be inserted into the bitstream for various purposes such as indicating the color space used the video content or various constraints that apply to the encoding. SEI messages can contain arbitrary user-defined metadata payloads or other messages with syntax and semantics defined in the standard.
Auxiliary pictures, which can be used for such purposes as alpha compositing.
Support of monochrome (4:0:0), 4:2:0, 4:2:2, and 4:4:4 chroma sampling (depending on the selected profile).
Support of sample bit depth precision ranging from 8 to 14 bits per sample (depending on the selected profile).
The ability to encode individual color planes as distinct pictures with their own slice structures, macroblock modes, motion vectors, etc., allowing encoders to be designed with a simple parallelization structure (supported only in the three 4:4:4-capable profiles).
Picture order count, a feature that serves to keep the ordering of the pictures and the values of samples in the decoded pictures isolated from timing information, allowing timing information to be carried and controlled/changed separately by a system without affecting decoded picture content.
These techniques, along with several others, help H.264 to perform significantly better than any prior standard under a wide variety of circumstances in a wide variety of application environments. H.264 can often perform radically better than MPEG-2 videoâtypically obtaining the same quality at half of the bit rate or less, especially on high bit rate and high resolution video content.[48]
Like other ISO/IEC MPEG video standards, H.264/AVC has a reference software implementation that can be freely downloaded.[49] Its main purpose is to give examples of H.264/AVC features, rather than being a useful application per se. Some reference hardware design work has also been conducted in the Moving Picture Experts Group.
The above-mentioned aspects include features in all profiles of H.264. A profile for a codec is a set of features of that codec identified to meet a certain set of specifications of intended applications. This means that many of the features listed are not supported in some profiles. Various profiles of H.264/AVC are discussed in next section.

Profiles[edit]
The standard defines several sets of capabilities, which are referred to as profiles, targeting specific classes of applications. These are declared using a profile code (profile_idc) and sometimes a set of additional constraints applied in the encoder. The profile code and indicated constraints allow a decoder to recognize the requirements for decoding that specific bitstream. (And in many system environments, only one or two profiles are allowed to be used, so decoders in those environments do not need to be concerned with recognizing the less commonly used profiles.) By far the most commonly used profile is the High Profile.
Profiles for non-scalable 2D video applications include the following:

Constrained Baseline Profile (CBP, 66 with constraint set 1)
Primarily for low-cost applications, this profile is most typically used in videoconferencing and mobile applications. It corresponds to the subset of features that are in common between the Baseline, Main, and High Profiles.
Baseline Profile (BP, 66)
Primarily for low-cost applications that require additional data loss robustness, this profile is used in some videoconferencing and mobile applications. This profile includes all features that are supported in the Constrained Baseline Profile, plus three additional features that can be used for loss robustness (or for other purposes such as low-delay multi-point video stream compositing). The importance of this profile has faded somewhat since the definition of the Constrained Baseline Profile in 2009. All Constrained Baseline Profile bitstreams are also considered to be Baseline Profile bitstreams, as these two profiles share the same profile identifier code value.
Extended Profile (XP, 88)
Intended as the streaming video profile, this profile has relatively high compression capability and some extra tricks for robustness to data losses and server stream switching.
Main Profile (MP, 77)
This profile is used for standard-definition digital TV broadcasts that use the MPEG-4 format as defined in the DVB standard.[50] It is not, however, used for high-definition television broadcasts, as the importance of this profile faded when the High Profile was developed in 2004 for that application.
High Profile (HiP, 100)
The primary profile for broadcast and disc storage applications, particularly for high-definition television applications (for example, this is the profile adopted by the Blu-ray Disc storage format and the DVB HDTV broadcast service).
Progressive High Profile (PHiP, 100 with constraint set 4)
Similar to the High profile, but without support of field coding features.
Constrained High Profile (100 with constraint set 4 and 5)
Similar to the Progressive High profile, but without support of B (bi-predictive) slices.
High 10 Profile (Hi10P, 110)
Going beyond typical mainstream consumer product capabilities, this profile builds on top of the High Profile, adding support for up to 10 bits per sample of decoded picture precision.
High 4:2:2 Profile (Hi422P, 122)
Primarily targeting professional applications that use interlaced video, this profile builds on top of the High 10 Profile, adding support for the 4:2:2 chroma sampling format while using up to 10 bits per sample of decoded picture precision.
High 4:4:4 Predictive Profile (Hi444PP, 244)
This profile builds on top of the High 4:2:2 Profile, supporting up to 4:4:4 chroma sampling, up to 14 bits per sample, and additionally supporting efficient lossless region coding and the coding of each picture as three separate color planes.
For camcorders, editing, and professional applications, the standard contains four additional Intra-frame-only profiles, which are defined as simple subsets of other corresponding profiles. These are mostly for professional (e.g., camera and editing system) applications:

High 10 Intra Profile (110 with constraint set 3)
The High 10 Profile constrained to all-Intra use.
High 4:2:2 Intra Profile (122 with constraint set 3)
The High 4:2:2 Profile constrained to all-Intra use.
High 4:4:4 Intra Profile (244 with constraint set 3)
The High 4:4:4 Profile constrained to all-Intra use.
CAVLC 4:4:4 Intra Profile (44)
The High 4:4:4 Profile constrained to all-Intra use and to CAVLC entropy coding (i.e., not supporting CABAC).
As a result of the Scalable Video Coding (SVC) extension, the standard contains five additional scalable profiles, which are defined as a combination of a H.264/AVC profile for the base layer (identified by the second word in the scalable profile name) and tools that achieve the scalable extension:

Scalable Baseline Profile (83)
Primarily targeting video conferencing, mobile, and surveillance applications, this profile builds on top of the Constrained Baseline profile to which the base layer (a subset of the bitstream) must conform. For the scalability tools, a subset of the available tools is enabled.
Scalable Constrained Baseline Profile (83 with constraint set 5)
A subset of the Scalable Baseline Profile intended primarily for real-time communication applications.
Scalable High Profile (86)
Primarily targeting broadcast and streaming applications, this profile builds on top of the H.264/AVC High Profile to which the base layer must conform.
Scalable Constrained High Profile (86 with constraint set 5)
A subset of the Scalable High Profile intended primarily for real-time communication applications.
Scalable High Intra Profile (86 with constraint set 3)
Primarily targeting production applications, this profile is the Scalable High Profile constrained to all-Intra use.
As a result of the Multiview Video Coding (MVC) extension, the standard contains two multiview profiles:

Stereo High Profile (128)
This profile targets two-view stereoscopic 3D video and combines the tools of the High profile with the inter-view prediction capabilities of the MVC extension.
Multiview High Profile (118)
This profile supports two or more views using both inter-picture (temporal) and MVC inter-view prediction, but does not support field pictures and macroblock-adaptive frame-field coding.
The Multi-resolution Frame-Compatible (MFC) extension added two more profiles:

MFC High Profile (134)
A profile for stereoscopic coding with two-layer resolution enhancement.
MFC Depth High Profile (135)

The 3D-AVC extension added two more profiles:

Multiview Depth High Profile (138)
This profile supports joint coding of depth map and video texture information for improved compression of 3D video content.
Enhanced Multiview Depth High Profile (139)
An enhanced profile for combined multiview coding with depth information.
Feature support in particular profiles[edit]



Feature

CBP

BP

XP

MP

ProHiP

HiP

Hi10P

Hi422P

Hi444PP


I and P slices

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes


Bit depth (per sample)

8
8
8
8
8
8
8 to 10
8 to 10
8 to 14


Chroma formats

4:2:0Â 
4:2:0Â 
4:2:0Â 
4:2:0Â 
4:2:0Â 
4:2:0Â 
4:2:0Â 
4:2:0/4:2:2Â 
4:2:0/4:2:2/4:4:4


Flexible macroblock ordering (FMO)

No
Yes
Yes
No
No
No
No
No
No


Arbitrary slice ordering (ASO)

No
Yes
Yes
No
No
No
No
No
No


Redundant slices (RS)

No
Yes
Yes
No
No
No
No
No
No


Data Partitioning

No
No
Yes
No
No
No
No
No
No


SI and SP slices

No
No
Yes
No
No
No
No
No
No


Interlaced coding (PicAFF, MBAFF)

No
No
Yes
Yes
No
Yes
Yes
Yes
Yes


B slices

No
No
Yes
Yes
Yes
Yes
Yes
Yes
Yes


Multiple reference frames

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes


In-loop deblocking filter

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes


CAVLC entropy coding

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes


CABAC entropy coding

No
No
No
Yes
Yes
Yes
Yes
Yes
Yes


4:0:0 (Monochrome)

No
No
No
No
Yes
Yes
Yes
Yes
Yes


8Ã8 vs. 4Ã4 transform adaptivity

No
No
No
No
Yes
Yes
Yes
Yes
Yes


Quantization scaling matrices

No
No
No
No
Yes
Yes
Yes
Yes
Yes


Separate CB and CR QP control

No
No
No
No
Yes
Yes
Yes
Yes
Yes


Separate color plane coding

No
No
No
No
No
No
No
No
Yes


Predictive lossless coding

No
No
No
No
No
No
No
No
Yes

Levels[edit]
As the term is used in the standard, a "level" is a specified set of constraints that indicate a degree of required decoder performance for a profile.  For example, a level of support within a profile specifies the maximum picture resolution, frame rate, and bit rate that a decoder may use.  A decoder that conforms to a given level must be able to decode all bitstreams encoded for that level and all lower levels.


Levels with maximum property values[28]


Level

Maximumdecoding speed(macroblocks/s)

Maximumframe size(macroblocks)

Maximum videobit rate for videocoding layer (VCL) (Constrained Baseline,Baseline, Extendedand Main Profiles)(kbits/s)

Examples for high resolution@ highest frame rate(maximum stored frames) Toggle additional details


1

1,485

99

64

 128Ã96@30.9 (8)176Ã144@15.0 (4)


1b

1,485

99

128

 128Ã96@30.9 (8)176Ã144@15.0 (4)


1.1

3,000

396

192

 176Ã144@30.3 (9)320Ã240@10.0 (3)352Ã288@7.5 (2)


1.2

6,000

396

384

 320Ã240@20.0 (7)352Ã288@15.2 (6)


1.3

11,880

396

768

 320Ã240@36.0 (7)352Ã288@30.0 (6)


2

11,880

396

2,000

 320Ã240@36.0 (7)352Ã288@30.0 (6)


2.1

19,800

792

4,000

 352Ã480@30.0 (7)352Ã576@25.0 (6)


2.2

20,250

1,620

4,000

 352Ã480@30.7 (12)352Ã576@25.6 (10)720Ã480@15.0 (6)720Ã576@12.5 (5)


3

40,500

1,620

10,000

 352Ã480@61.4 (12)352Ã576@51.1 (10)720Ã480@30.0 (6)720Ã576@25.0 (5)


3.1

108,000

3,600

14,000

 720Ã480@80.0 (13)720Ã576@66.7 (11)1,280Ã720@30.0 (5)


3.2

216,000

5,120

20,000

 1,280Ã720@60.0 (5)1,280Ã1,024@42.2 (4)


4

245,760

8,192

20,000

 1,280Ã720@68.3 (9)1,920Ã1,080@30.1 (4)2,048Ã1,024@30.0 (4)


4.1

245,760

8,192

50,000

 1,280Ã720@68.3 (9)1,920Ã1,080@30.1 (4)2,048Ã1,024@30.0 (4)


4.2

522,240

8,704

50,000

 1,280Ã720@145.1 (9)1,920Ã1,080@64.0 (4)2,048Ã1,080@60.0 (4)


5

589,824

22,080

135,000

 1,920Ã1,080@72.3 (13)2,048Ã1,024@72.0 (13)2,048Ã1,080@67.8 (12)2,560Ã1,920@30.7 (5)3,672Ã1,536@26.7 (5)


5.1

983,040

36,864

240,000

 1,920Ã1,080@120.5 (16)2,560Ã1,920@51.2 (9)3,840Ã2,160@31.7 (5)4,096Ã2,048@30.0 (5)4,096Ã2,160@28.5 (5)4,096Ã2,304@26.7 (5)


5.2

2,073,600

36,864

240,000

 1,920Ã1,080@172.0 (16)2,560Ã1,920@108.0 (9)3,840Ã2,160@66.8 (5)4,096Ã2,048@63.3 (5)4,096Ã2,160@60.0 (5)4,096Ã2,304@56.3 (5)


6

4,177,920

139,264

240,000

 3,840Ã2,160@128.9 (16)7,680Ã4,320@32.2 (5)8,192Ã4,320@30.2 (5)


6.1

8,355,840

139,264

480,000

 3,840Ã2,160@257.9 (16)7,680Ã4,320@64.5 (5)8,192Ã4,320@60.4 (5)


6.2

16,711,680

139,264

800,000

 3,840Ã2,160@300.0 (16)7,680Ã4,320@128.9 (5)8,192Ã4,320@120.9 (5)

The maximum bit rate for the High Profile is 1.25 times that of the Constrained Baseline, Baseline, Extended and Main Profiles; 3 times for Hi10P, and 4 times for Hi422P/Hi444PP.
The number of luma samples is 16Ã16=256 times the number of macroblocks (and the number of luma samples per second is 256 times the number of macroblocks per second).

Decoded picture buffering[edit]
Previously encoded pictures are used by H.264/AVC encoders to provide predictions of the values of samples in other pictures.  This allows the encoder to make efficient decisions on the best way to encode a given picture.  At the decoder, such pictures are stored in a virtual decoded picture buffer (DPB).  The maximum capacity of the DPB, in units of frames (or pairs of fields), as shown in parentheses in the right column of the table above, can be computed as follows:

DpbCapacity = min(floor(MaxDpbMbs / (PicWidthInMbs * FrameHeightInMbs)), 16)
Where MaxDpbMbs is a constant value provided in the table below as a function of level number, and PicWidthInMbs and FrameHeightInMbs are the picture width and frame height for the coded video data, expressed in units of macroblocks (rounded up to integer values and accounting for cropping and macroblock pairing when applicable). This formula is specified in sections A.3.1.h and A.3.2.f of the 2017 edition of the standard.[28]





Level

1

1b

1.1

1.2

1.3

2

2.1

2.2

3

3.1

3.2

4

4.1

4.2

5

5.1

5.2

6

6.1

6.2


MaxDpbMbs

396

396

900

2,376

2,376

2,376

4,752

8,100

8,100

18,000

20,480

32,768

32,768

34,816

110,400

184,320

184,320

696,320

696,320

696,320

For example, for an HDTV picture that is 1,920 samples wide (PicWidthInMbs = 120) and 1,080 samples high (FrameHeightInMbs = 68), a Level 4 decoder has a maximum DPB storage capacity of floor(32768/(120*68)) = 4 frames (or 8 fields). Thus, the value 4 is shown in parentheses in the table above in the right column of the row for Level 4 with the frame size 1920Ã1080.
It is important to note that the current picture being decoded is not included in the computation of DPB fullness (unless the encoder has indicated for it to be stored for use as a reference for decoding other pictures or for delayed output timing). Thus, a decoder needs to actually have sufficient memory to handle (at least) one frame more than the maximum capacity of the DPB as calculated above.

Implementations[edit]
  A YouTube video statistics with AVC (H.264) video codec and Opus audio format
In 2009, the HTML5 working group was split between supporters of Ogg Theora, a free video format which is thought to be unencumbered by patents, and H.264, which contains patented technology. As late as July 2009, Google and Apple were said to support H.264, while Mozilla and Opera support Ogg Theora (now Google, Mozilla and Opera all support Theora and WebM with VP8).[51] Microsoft, with the release of Internet Explorer 9, has added support for HTML 5 video encoded using H.264. At the Gartner Symposium/ITXpo in November 2010, Microsoft CEO Steve Ballmer answered the question "HTML 5 or Silverlight?" by saying "If you want to do something that is universal, there is no question the world is going HTML5."[52] In January 2011, Google announced that they were pulling support for H.264 from their Chrome browser and supporting both Theora and WebM/VP8 to use only open formats.[53]
On March 18, 2012, Mozilla announced support for H.264 in Firefox on mobile devices, due to prevalence of H.264-encoded video and the increased power-efficiency of using dedicated H.264 decoder hardware common on such devices.[54] On February 20, 2013, Mozilla implemented support in Firefox for decoding H.264 on Windows 7 and above. This feature relies on Windows' built in decoding libraries.[55] Firefox 35.0, released on January 13, 2015, supports H.264 on OS X 10.6 and higher.[56]
On October 30, 2013, Rowan Trollope from Cisco Systems announced that Cisco would release both binaries and source code of an H.264 video codec called OpenH264 under the Simplified BSD license, and pay all royalties for its use to MPEG LA for any software projects that use Cisco's precompiled binaries, thus making Cisco's OpenH264 binaries free to use. However, any software projects that use Cisco's source code instead of its binaries would be legally responsible for paying all royalties to MPEG LA. Target CPU architectures include x86 and ARM, and target operating systems include Linux, Windows XP and later, Mac OS X, and Android; iOS was notably absent from this list, because it doesn't allow applications to fetch and install binary modules from the Internet.[57][58][59] Also on October 30, 2013, Brendan Eich from Mozilla wrote that it would use Cisco's binaries in future versions of Firefox to add support for H.264 to Firefox where platform codecs are not available.[60] Cisco published the source code to OpenH264 on December 9, 2013.[61]
Although iOS was not supported by the 2013 Cisco software release, Apple updated its Video Toolbox Framework with iOS 8 (released in September 2014) to provide direct access to hardware-based H.264/AVC video encoding and decoding.[58]

Software encoders[edit]

AVC software implementations


Feature

QuickTime

Nero

OpenH264

x264

Main-Concept

Elecard

Â TSEÂ 

Pro-Coder

Avivo

Elemental

Â IPPÂ 


B slices

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
Yes


Multiple reference frames

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
Yes


Interlaced coding (PicAFF, MBAFF)

No
MBAFF
MBAFF
MBAFF
Yes
Yes
No
Yes
MBAFF
Yes
No


CABAC entropy coding

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
Yes


8Ã8 vs. 4Ã4 transform adaptivity

No
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
Yes


Quantization scaling matrices

No
No
Yes
Yes
Yes
No
No
No
No
No
No


Separate CB and CR QP control

No
No
Yes
Yes
Yes
Yes
No
No
No
No
No


Extended chroma formats

No
No
No
4:0:0[62]4:2:04:2:2[63]4:4:4[64]Â Â 
4:2:2
4:2:2
4:2:2
No
No
4:2:04:2:2
No


Largest sample depth (bit)

8
8
8
10[65]
10
8
8
8
8
10
12


Predictive lossless coding

No
No
No
Yes[66]
No
No
No
No
No
No
No

Hardware[edit]
See also: H.264/MPEG-4 AVC products and implementations
Because H.264 encoding and decoding requires significant computing power in specific types of arithmetic operations, software implementations that run on general-purpose CPUs are typically less power efficient. However, the latest[when?] quad-core general-purpose x86 CPUs have sufficient computation power to perform real-time SD and HD encoding. Compression efficiency depends on video algorithmic implementations, not on whether hardware or software implementation is used. Therefore, the difference between hardware and software based implementation is more on power-efficiency, flexibility and cost. To improve the power efficiency and reduce hardware form-factor, special-purpose hardware may be employed, either for the complete encoding or decoding process, or for acceleration assistance within a CPU-controlled environment.
CPU based solutions are known to be much more flexible, particularly when encoding must be done concurrently in multiple formats, multiple bit rates and resolutions (multi-screen video), and possibly with additional features on container format support, advanced integrated advertising features, etc. CPU based software solution generally makes it much easier to load balance multiple concurrent encoding sessions within the same CPU.
The 2nd generation Intel "Sandy Bridge" Core i3/i5/i7 processors introduced at the January 2011 CES (Consumer Electronics Show) offer an on-chip hardware full HD H.264 encoder, known as Intel Quick Sync Video.[67][68]
A hardware H.264 encoder can be an ASIC or an FPGA.
ASIC encoders with H.264 encoder functionality are available from many different semiconductor companies, but the core design used in the ASIC is typically licensed from one of a few companies such as Chips&Media, Allegro DVT, On2 (formerly Hantro, acquired by Google), Imagination Technologies, NGCodec. Some companies have both FPGA and ASIC product offerings.[69]
Texas Instruments manufactures a line of ARM + DSP cores that perform DSP H.264 BP encoding 1080p at 30fps.[70]  This permits flexibility with respect to codecs (which are implemented as highly optimized DSP code) while being more efficient than software on a generic CPU.

Licensing[edit]
See also: Microsoft Corp. v. Motorola Inc. and Qualcomm Inc. v. Broadcom Corp.
In countries where patents on software algorithms are upheld, vendors and commercial users of products that use H.264/AVC are expected to pay patent licensing royalties for the patented technology that their products use.[71] This applies to the Baseline Profile as well.[72]
A private organization known as MPEG LA, which is not affiliated in any way with the MPEG standardization organization, administers the licenses for patents applying to this standard, as well as other patent pools, such as for MPEG-4 Part 2 Video, HEVC and MPEG-DASH. The patent holders include Fujitsu, Panasonic, Sony, Mitsubishi, Apple, Columbia University, KAIST, Dolby, Google, JVC Kenwood, LG Electronics, Microsoft, NTT Docomo, Philips, Samsung, Sharp, Toshiba and ZTE,[73] although the majority of patents in the pool are held by Panasonic (1,197 patents), Godo Kaisha IP Bridge (1,130 patents) and LG Electronics (990 patents).[74]
On August 26, 2010, MPEG LA announced that royalties won't be charged for H.264 encoded Internet video that is free to end users.[75] All other royalties remain in place, such as royalties for products that decode and encode H.264 video as well as to operators of free television and subscription channels.[76]  The license terms are updated in 5-year blocks.[77]
Since the first version of the standard was completed in May 2003 (18 years ago) and the most commonly used profile (the High profile) was completed in June 2004 (17 years ago), a substantial number of the patents that originally applied to the standard have been expiring,[78] although one of the US patents in the MPEG LA H.264 pool lasts at least until 2027.[79]
In 2005, Qualcomm sued Broadcom in US District Court, alleging that Broadcom infringed on two of its patents by making products that were compliant with the H.264 video compression standard.[80]  In 2007, the District Court found that the patents were unenforceable because Qualcomm had failed to disclose them to the JVT prior to the release of the H.264 standard in May 2003.[80] In December 2008, the US Court of Appeals for the Federal Circuit affirmed the District Court's order that the patents be unenforceable but remanded to the District Court with instructions to limit the scope of unenforceability to H.264 compliant products.[80]

See also[edit]
VC-1, a standard designed by Microsoft and approved as a SMPTE standard in 2006
Comparison of H.264 and VC-1
Dirac (video compression format), a video coding design by BBC Research & Development, released in 2008
VP8, a video coding design by On2 Technologies (later purchased by Google), released in 2008
VP9, a video coding design by Google, released in 2013
High Efficiency Video Coding (ITU-T H.265 or ISO/IEC 23008-2), an ITU/ISO/IEC standard, released in 2013
AV1, a video coding design by the Alliance for Open Media, released in 2018
Versatile Video Coding (ITU-T H.266 or ISO/IEC 23091-3), an ITU/ISO/IEC standard, released in 2020
IPTV
Group of pictures
Intra-frame coding
Inter frame
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}MPEG-4, Advanced Video Coding (Part 10) (H.264) (Full draft). Sustainability of Digital Formats. Washington, D.C.: Library of Congress. December 5, 2011. Retrieved December 1, 2021.

^ "H.264Â : Advanced video coding for generic audiovisual services". www.itu.int. Archived from the original on October 31, 2019. Retrieved November 22, 2019.

^ "Video Developer Report 2018" (PDF). Bitmovin. September 2019.

^ "Video Developer Report 2019". Bitmovin. September 2019.

^ "Delivering 8K using AVC/H.264". Mystery Box. Retrieved August 23, 2017.

^ Jump up to: a b c Wang, Hanli; Kwong, S.; Kok, C. (2006). "Efficient prediction algorithm of integer DCT coefficients for H.264/AVC optimization". IEEE Transactions on Circuits and Systems for Video Technology. 16 (4): 547â552. doi:10.1109/TCSVT.2006.871390. S2CIDÂ 2060937.

^ Jump up to: a b Thomson, Gavin; Shah, Athar (2017). "Introducing HEIF and HEVC" (PDF). Apple Inc. Retrieved August 5, 2019.

^ Jump up to: a b c StankoviÄ, Radomir S.; Astola, Jaakko T. (2012). "Reminiscences of the Early Work in DCT: Interview with K.R. Rao" (PDF). Reprints from the Early Days of Information Sciences. 60: 17. Retrieved October 13, 2019.

^ "AVC/H.264 FAQ". www.mpegla.com. Archived from the original on May 7, 2010. Retrieved September 15, 2016.

^ "H.262Â : Information technologyÂ â Generic coding of moving pictures and associated audio information: Video". Retrieved April 15, 2007.

^ Joint Video Team, ITU-T Web site.

^ "ITU-T Recommendation H.264 (05/2003)". ITU. May 30, 2003. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (05/2003) Cor. 1 (05/2004)". ITU. May 7, 2004. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (03/2005)". ITU. March 1, 2005. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (2005) Cor. 1 (09/2005)". ITU. September 13, 2005. Retrieved April 18, 2013.

^ Jump up to: a b "ITU-T Recommendation H.264 (2005) Amd. 1 (06/2006)". ITU. June 13, 2006. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (2005) Amd. 2 (04/2007)". ITU. April 6, 2007. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (11/2007)". ITU. November 22, 2007. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (2007) Cor. 1 (01/2009)". ITU. January 13, 2009. Retrieved April 18, 2013.

^ Jump up to: a b "ITU-T Recommendation H.264 (03/2009)". ITU. March 16, 2009. Retrieved April 18, 2013.

^ Jump up to: a b "ITU-T Recommendation H.264 (03/2010)". ITU. March 9, 2010. Retrieved April 18, 2013.

^ Jump up to: a b "ITU-T Recommendation H.264 (06/2011)". ITU. June 29, 2011. Retrieved April 18, 2013.

^ "ITU-T Recommendation H.264 (01/2012)". ITU. January 13, 2012. Retrieved April 18, 2013.

^ Jump up to: a b c d "ITU-T Recommendation H.264 (04/2013)". ITU. June 12, 2013. Retrieved June 16, 2013.

^ Jump up to: a b "ITU-T Recommendation H.264 (02/2014)". ITU. November 28, 2014. Retrieved February 28, 2016.

^ "ITU-T Recommendation H.264 (02/2016)". ITU. February 13, 2016. Retrieved June 14, 2017.

^ "ITU-T Recommendation H.264 (10/2016)". ITU. October 14, 2016. Retrieved June 14, 2017.

^ Jump up to: a b c "ITU-T Recommendation H.264 (04/2017)". ITU. April 13, 2017. See Tables A-1, A-6 and A-7 for the tabulated level-dependent capabilities. Retrieved June 14, 2017.

^ "H.264: Advanced video coding for generic audiovisual services - Version 26 (Edition 13)". www.itu.int. June 13, 2019. Archived from the original on November 3, 2021. Retrieved November 3, 2021.

^ "H.264: Advanced video coding for generic audiovisual services - Version 27 (Edition 14)". www.itu.int. August 22, 2021. Archived from the original on November 3, 2021. Retrieved November 3, 2021.

^ Jump up to: a b "AVC/H.264 â Patent List" (PDF). MPEG LA. Retrieved July 6, 2019.

^ "AVC/H.264 Licensors". MPEG-LA. Archived from the original on May 30, 2015. Retrieved May 19, 2013.

^ Wenger;  etÂ al. (February 2005). "RFC 3984Â : RTP Payload Format for H.264 Video": 2. {{cite journal}}: Cite journal requires |journal= (help)

^ "Which recording mode is equivalent to the image quality of the High Definition Video (HDV) format?". Sony eSupport. Archived from the original on November 9, 2017. Retrieved December 8, 2018.

^ "ATSC Standard A/72 Part 1: Video System Characteristics of AVC in the ATSC Digital Television System" (PDF). Archived from the original (PDF) on August 7, 2011. Retrieved July 30, 2011.

^ "ATSC Standard A/72 Part 2: AVC Video Transport Subsystem Characteristics" (PDF). Archived from the original (PDF) on August 7, 2011. Retrieved July 30, 2011.

^ "ATSC Standard A/153 Part 7: AVC and SVC Video System Characteristics" (PDF). Archived from the original (PDF) on July 26, 2011. Retrieved July 30, 2011.

^ Jump up to: a b "Sony introduces new XAVC recording format to accelerate 4K development in the professional and consumer markets". Sony. October 30, 2012. Retrieved November 1, 2012.

^ Jump up to: a b "Sony introduces new XAVC recording format to accelerate 4K development in the professional and consumer markets" (PDF). Sony. October 30, 2012. Retrieved November 1, 2012.[permanent dead link]

^ Steve Dent (October 30, 2012). "Sony goes Red-hunting with PMW-F55 and PMW-F5 pro CineAlta 4K Super 35mm sensor camcorders". Engadget. Retrieved November 5, 2012.

^ "F55 CineAlta 4K the future, ahead of schedule" (PDF). Sony. October 30, 2012. Archived from the original (PDF) on November 19, 2012. Retrieved November 1, 2012.

^ "Ultra-fast "SxS PRO+" memory cards transform 4K video capture". Sony. Archived from the original on March 8, 2013. Retrieved November 5, 2012.

^ "Ultra-fast "SxS PRO+" memory cards transform 4K video capture" (PDF). Sony. Archived from the original (PDF) on April 2, 2015. Retrieved November 5, 2012.

^ Kwon, Soon-young; Lee, Joo-kyong; Chung, Ki-dong (2005). "Half-Pixel Correction for MPEG-2/H.264 Transcoding". Image Analysis and Processing â ICIAP 2005. Lecture Notes in Computer Science. Springer Berlin Heidelberg. 3617: 576â583. doi:10.1007/11553595_71. ISBNÂ 978-3-540-28869-5.

^ Britanak, Vladimir; Yip, Patrick C.; Rao, K. R. (2010). Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms and Integer Approximations. Elsevier. pp.Â ix, xiii, 1, 141â304. ISBNÂ 9780080464640.

^ "The H.264/AVC Advanced Video Coding Standard: Overview and Introduction to the Fidelity Range Extensions" (PDF). Retrieved July 30, 2011.

^ Jump up to: a b c RFC 3984, p.3

^ Apple Inc. (March 26, 1999). "H.264 FAQ". Apple. Archived from the original on March 7, 2010. Retrieved May 17, 2010.

^ Karsten Suehring. "H.264/AVC JM Reference Software Download". Iphome.hhi.de. Retrieved May 17, 2010.

^ "TS 101 154Â â V1.9.1Â â Digital Video Broadcasting (DVB); Specification for the use of Video and Audio Coding in Broadcasting Applications based on the MPEG-2 Transport Stream" (PDF). Retrieved May 17, 2010.

^ "Decoding the HTML 5 video codec debate". Ars Technica. July 6, 2009. Retrieved January 12, 2011.

^ "Steve Ballmer, CEO Microsoft, interviewed at Gartner Symposium/ITxpo Orlando 2010". Gartnervideo. November 2010. Archived from the original on October 30, 2021. Retrieved January 12, 2011.

^ "HTML Video Codec Support in Chrome". January 11, 2011. Retrieved January 12, 2011.

^ "Video, Mobile, and the Open Web". March 18, 2012. Retrieved March 20, 2012.

^ "WebRTC enabled, H.264/MP3 support in Win 7 on by default, Metro UI for Windows 8 + moreÂ â Firefox Development Highlights". hacks.mozilla.org. mozilla. February 20, 2013. Retrieved March 15, 2013.

^ "Firefox â Notes (35.0)". Mozilla.

^ "Open-Sourced H.264 Removes Barriers to WebRTC". October 30, 2013. Archived from the original on July 6, 2015. Retrieved November 1, 2013.

^ Jump up to: a b "Cisco OpenH264 project FAQ". Retrieved September 26, 2021.

^ "OpenH264 Simplified BSD License". GitHub. October 27, 2013. Retrieved November 21, 2013.

^ "Video Interoperability on the Web Gets a Boost From Cisco's H.264 Codec". October 30, 2013. Retrieved November 1, 2013.

^ "Updated README Â· cisco/openh264@59dae50". GitHub.

^ "x264 4:0:0 (monochrome) encoding support", Retrieved 2019-06-05.

^ "x264 4:2:2 encoding support", Retrieved 2019-06-05.

^ "x264 4:4:4 encoding support", Retrieved 2019-06-05.

^ "x264 support for 9 and 10-bit encoding", Retrieved 2011-06-22.

^ "x264 replace High 4:4:4 profile lossless with High 4:4:4 Predictive", Retrieved 2011-06-22.

^ "Quick Reference Guide to generation Intel Core Processor Built-in Visuals". Intel Software Network. October 1, 2010. Retrieved January 19, 2011.

^ "Intel Quick Sync Video". www.intel.com. October 1, 2010. Retrieved January 19, 2011.

^ "Design-reuse.com". Design-reuse.com. January 1, 1990. Retrieved May 17, 2010.

^ "Category:DM6467 - Texas Instruments Embedded Processors Wiki". Processors.wiki.ti.com. July 12, 2011. Retrieved July 30, 2011.

^ "Briefing portfolio" (PDF). www.mpegla.com.

^ "OMS Video, A Project of Sun's Open Media Commons Initiative". Archived from the original on May 11, 2010. Retrieved August 26, 2008.

^ "Licensors Included in the AVC/H.264 Patent Portfolio License". MPEG LA. Retrieved June 18, 2019.

^ "AVC/H.264 â Patent List" (PDF). MPEG LA. Retrieved July 6, 2019.

^ "MPEG LA's AVC License Will Not Charge Royalties for Internet Video that is Free to End Users through Life of License" (PDF). MPEG LA. August 26, 2010. Retrieved August 26, 2010.

^ Hachman, Mark (August 26, 2010). "MPEG LA Cuts Royalties from Free Web Video, Forever". pcmag.com. Retrieved August 26, 2010.

^ "AVC FAQ". MPEG LA. August 1, 2002. Archived from the original on May 7, 2010. Retrieved May 17, 2010.

^ "Archived copy" (PDF). Archived from the original (PDF) on May 14, 2015. Retrieved November 20, 2018.{{cite web}}:  CS1 maint: archived copy as title (link)

^ http://www.osnews.com/story/24954/US_Patent_Expiration_for_MP3_MPEG-2_H_264 has a MPEG LA patent US 7826532 that was filed in September 5, 2003 and has a 1546 day term extension. http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=7826532 http://www.google.com/patents/about?id=2onYAAAAEBAJ

^ Jump up to: a b c See Qualcomm Inc. v. Broadcom Corp., No. 2007-1545, 2008-1162 (Fed. Cir. December 1, 2008). For articles in the popular press, see signonsandiego.com, "Qualcomm loses its patent-rights case" and "Qualcomm's patent case goes to jury"; and bloomberg.com "Broadcom Wins First Trial in Qualcomm Patent Dispute"


Further reading[edit]
.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}
Wiegand, Thomas; Sullivan, Gary J.; BjÃ¸ntegaard, Gisle; Luthra, Ajay (July 2003). "Overview of the H.264/AVC Video Coding Standard" (PDF). IEEE Transactions on Circuits and Systems for Video Technology. 13 (7): 560â576. doi:10.1109/TCSVT.2003.815165. Retrieved January 31, 2011.
Topiwala, Pankaj; Sullivan, Gary J.; Luthra, Ajay (August 2004).  Tescher, Andrew G (ed.). "The H.264/AVC Advanced Video Coding Standard: Overview and Introduction to the Fidelity Range Extensions" (PDF). SPIE Applications of Digital Image Processing XXVII. Applications of Digital Image Processing XXVII. 5558: 454. Bibcode:2004SPIE.5558..454S. doi:10.1117/12.564457. S2CIDÂ 2308860. Retrieved January 31, 2011.
Ostermann, J.; Bormans, J.; List, P.; Marpe, D.; Narroschke, M.; Pereira, F.; Stockhammer, T.; Wedi, T. (2004). "Video coding with H.264/AVC: Tools, Performance, and Complexity" (PDF). IEEE Circuits and Systems Magazine. 4 (1): 7â28. doi:10.1109/MCAS.2004.1286980. S2CIDÂ 11105089. Archived from the original (PDF) on July 6, 2017. Retrieved January 31, 2011.
Sullivan, Gary J.; Wiegand, Thomas (January 2005). "Video CompressionâFrom Concepts to the H.264/AVC Standard" (PDF). Proceedings of the IEEE. 93 (1): 18â31. doi:10.1109/jproc.2004.839617. S2CIDÂ 1362034. Retrieved January 31, 2011.
Richardson, Iain E. G. (January 2011). "Learn about video compression and H.264". VCODEX. Vcodex Limited. Retrieved January 31, 2011.

External links[edit]
ITU-T publication page: H.264: Advanced video coding for generic audiovisual services
MPEG-4 AVC/H.264 Information Doom9's Forum
H.264/MPEG-4 Part 10 Tutorials (Richardson)
"Part 10: Advanced Video Coding". ISO publication page: ISO/IEC 14496-10:2010Â â Information technologyÂ â Coding of audio-visual objects.
"H.264/AVC JM Reference Software". IP Homepage. Retrieved April 15, 2007.
"JVT document archive site". Archived from the original on August 8, 2010. Retrieved May 6, 2007.
"Publications". Thomas Wiegand. Retrieved June 23, 2007.
"Publications". Detlev Marpe. Retrieved April 15, 2007.
"Fourth Annual H.264 video codecs comparison". Moscow State University. (dated December 2007)
"Discussion on H.264 with respect to IP cameras in use within the security and surveillance industries". April 3, 2009. (dated April 2009)
"Sixth Annual H.264 video codecs comparison". Moscow State University. (dated May 2010)
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteMultimedia compression and container formatsVideocompressionISO, IEC, MPEG
MJPEG
Motion JPEG 2000
MPEG-1
MPEG-2
Part 2
MPEG-4
Part 2 / ASP
Part 10 / AVC
Part 33 / IVC
MPEG-H
Part 2 / HEVC
MPEG-I
Part 3 / VVC
MPEG-5
Part 1 / EVC
Part 2 / LCEVC
ITU-T, VCEG
H.120
DCT
H.261
H.262
H.263
H.264 / AVC
H.265 / HEVC
H.266 / VVC
DV
SMPTE
VC-1
VC-2
VC-3
VC-5
VC-6
TrueMotion
TrueMotion S
DCT
VP3
VP6
VP7
VP8
VP9
AV1
Others
Apple Video
AVS
Bink
Cinepak
Daala
DVI
FFV1
Huffyuv
Indeo
Lagarith
Microsoft Video 1
MSU Lossless
OMS Video
Pixlet
ProRes
422
4444
QuickTime
Animation
Graphics
RealVideo
RTVideo
SheerVideo
Smacker
Sorenson Video/Spark
Theora
Thor
WMV
XEB
YULS
AudiocompressionISO, IEC, MPEG
MPEG-1 Layer II
Multichannel
MPEG-1 Layer I
MPEG-1 Layer III (MP3)
AAC
HE-AAC
AAC-LD
MPEG Surround
MPEG-4 ALS
MPEG-4 SLS
MPEG-4 DST
MPEG-4 HVXC
MPEG-4 CELP
MPEG-D USAC
MPEG-H 3D Audio
ITU-T
G.711
A-law
Âµ-law
G.718
G.719
G.722
G.722.1
G.722.2
G.723
G.723.1
G.726
G.728
G.729
G.729.1
IETF
Opus
iLBC
Speex
Vorbis
3GPP
AMR
AMR-WB
AMR-WB+
EVRC
EVRC-B
EVS
GSM-HR
GSM-FR
GSM-EFR
ETSI
AC-3
AC-4
DTS
Others
ACELP
ALAC
Asao
ATRAC
AVS
CELT
Codec 2
DRA
FLAC
iSAC
MELP
Monkey's Audio
MT9
Musepack
OptimFROG
OSQ
QCELP
RCELP
RealAudio
RTAudio
SBC
SD2
SHN
SILK
Siren
SMV
SVOPC
TTA
True Audio
TwinVQ
VMR-WB
VSELP
WavPack
WMA
MQA
aptX
aptX HD
aptX Low Latency
aptX Adaptive
LDAC
LHDC
LLAC
ImagecompressionIEC, ISO, IETF, W3C, ITU-T, JPEG
CCITT Group 4
DCT
HEIC
HEVC
JPEG
JPEG XL
JPEG XR
JPEG XT
TIFF/EP
Arithmetic
JBIG
JBIG2
JPEG-LS
JPEG XS
JPEG 2000
LZ
GIF
PNG
TIFF
TIFF/IT
Others
APNG
BPG
DCT
AVIF
AV1
DjVu
EXR
FLIF
ICER
MNG
PGF
QTVR
WBMP
WebP
ContainersISO, IEC
MPEG-ES
MPEG-PES
MPEG-PS
MPEG-TS
ISO/IEC base media file format
MPEG-4 Part 14 (MP4)
Motion JPEG 2000
MPEG-21 Part 9
MPEG media transport
ITU-T
H.222.0
T.802
IETF
RTP
Ogg
SMPTE
GXF
MXF
Others
3GP and 3G2
AMV
ASF
AIFF
AVI
AU
BPG
Bink
Smacker
BMP
DivX Media Format
EVO
Flash Video
HEIF
IFF
M2TS
Matroska
WebM
QuickTime File Format
RatDVD
RealMedia
RIFF
WAV
MOD and TOD
VOB, IFO and BUP
Collaborations
NETVC
MPEG LA
HEVC Advance
Alliance for Open Media
Methods
Discrete cosine transform
DCT
MDCT
Entropy
Arithmetic
Huffman
Modified
FFT
LPC
ACELP
CELP
LSP
WLPC
Lossless
Lossy
LZ
DEFLATE
LZW
PCM
A-law
Âµ-law
ADPCM
DPCM
Transform
Wavelet
Daubechies
DWT
Transform
Lists
Comparison of audio coding formats
Comparison of video codecs
List of codecs
See Compression methods for techniques and Compression software for codecs
vteMPEG (Moving Picture Experts Group)
MPEG-1
2
3
4
7
21
A
B
C
D
E
G
V
M
U
H
I
5
MPEG-1 Parts
Part 1: Systems
Program stream
Part 2: Video
based on H.261
Part 3: Audio
Layer I
Layer II
Layer III
MPEG-2 Parts
Part 1: Systems (H.222.0)
Transport stream
Program stream
Part 2: Video (H.262)
Part 3: Audio
Layer I
Layer II
Layer III
MPEG Multichannel
Part 6: DSM CC
Part 7: Advanced Audio Coding
MPEG-4 Parts
Part 2: Video
based on H.263
Part 3: Audio
Part 6: DMIF
Part 10: Advanced Video Coding (H.264)
Part 11: Scene description
Part 12: ISO base media file format
Part 14: MP4 file format
Part 17: Streaming text format
Part 20: LASeR
Part 22: Open Font Format
Part 33: Internet Video Coding
MPEG-7 Parts
Part 2: Description definition language
MPEG-21 Parts
Parts 2, 3 and 9: Digital Item
Part 5: Rights Expression Language
MPEG-D Parts
Part 1: MPEG Surround
Part 3: Unified Speech and Audio Coding
MPEG-G Parts
Part 1: Transport and Storage of Genomic Information
Part 2: Coding of Genomic Information
Part 3: APIs
Part 4: Reference Software
Part 5: Conformance
MPEG-H Parts
Part 1: MPEG media transport
Part 2: High Efficiency Video Coding (H.265)
Part 3: MPEG-H 3D Audio
Part 12: High Efficiency Image File Format
MPEG-I Parts
Part 3: Versatile Video Coding (H.266)
MPEG-5 Parts
Part 1: Essential Video Coding
Part 2: Low Complexity Enhancement Video Coding
OtherMPEG-DASH
vteHigh-definition (HD)Concepts
High-definition television
High-definition video
Ultra-high-definition television
Resolutions
720p (HD)
1080i (Full HD)
1080p (Full HD)
1440p (Quad HD)
2160p (4K Ultra HD)
4320p (8K Ultra HD)
Analog broadcast(All defunct)
819 line system
HD MAC
MUSE (Hi-Vision)
Digital broadcast
ATSC
DMB-T/H
DVB
ISDB
SBTVD
Audio
Dolby Digital
Surround sound
DSD
DXD
DTS
Filming and storage
DCI
HDV
HD media andcompression
Archival Disc
AV1
Blu-ray
CBHD
D-VHS
DVD-Audio
H.264
H.265
H.266
HD DVD
HD VMD
MPEG-2
MUSE LaserDisc
MVC
Super Audio CD
Ultra HD Blu-ray
Uncompressed
VC-1
Connectors
Component
DisplayPort
DVI
HDMI
VGA
Deployments
List of digital television deployments by country

vteISO standards .mw-parser-output .nobold{font-weight:normal}by standard numberList of ISO standardsÂ / ISO romanizationsÂ / IEC standards1â9999
1
2
3
4
5
6
7
9
16
17
31
-0
-1
-2
-3
-4
-5
-6
-7
-8
-9
-10
-11
-12
-13
68-1
128
216
217
226
228
233
259
261
262
269
302
306
361
428
500
518
519
639
-1
-2
-3
-5
-6
646
657
668
690
704
732
764
838
843
860
898
965
999
1000
1004
1007
1073-1
1073-2
1155
1413
1538
1629
1745
1989
2014
2015
2022
2033
2047
2108
2145
2146
2240
2281
2533
2709
2711
2720
2788
2848
2852
3029
3103
3166
-1
-2
-3
3297
3307
3601
3602
3864
3901
3950
3977
4031
4157
4165
4217
4909
5218
5426
5427
5428
5725
5775
5776
5800
5807
5964
6166
6344
6346
6385
6425
6429
6438
6523
6709
6943
7001
7002
7010
7027
7064
7098
7185
7200
7498
-1
7637
7736
7810
7811
7812
7813
7816
7942
8000
8093
8178
8217
8373
8501-1
8571
8583
8601
8613
8632
8651
8652
8691
8805/8806
8807
8820-5
8859
-1
-2
-3
-4
-5
-6
-7
-8
-8-I
-9
-10
-11
-12
-13
-14
-15
-16
8879
9000/9001
9036
9075
9126
9141
9227
9241
9293
9314
9362
9407
9496
9506
9529
9564
9592/9593
9594
9660
9797-1
9897
9899
9945
9984
9985
9995
10000â19999
10005
10006
10007
10116
10118-3
10160
10161
10165
10179
10206
10218
10303
-11
-21
-22
-28
-238
10383
10487
10585
10589
10628
10646
10664
10746
10861
10957
10962
10967
11073
11170
11179
11404
11544
11783
11784
11785
11801
11889
11898
11940 (-2)
11941
11941 (TR)
11992
12006
12182
12207
12234-2
12620
13211
-1
-2
13216
13250
13399
13406-2
13450
13485
13490
13567
13568
13584
13616
13816
14000
14031
14224
14289
14396
14443
14496
-2
-3
-6
-10
-11
-12
-14
-17
-20
14617
14644
14649
14651
14698
14764
14882
14971
15022
15189
15288
15291
15292
15398
15408
15444
-3
15445
15438
15504
15511
15686
15693
15706
-2
15707
15897
15919
15924
15926
15926 WIP
15930
16023
16262
16355-1
16612-2
16750
16949 (TS)
17024
17025
17100
17203
17369
17442
17799
18000
18004
18014
18245
18629
18916
19005
19011
19092
-1
-2
19114
19115
19125
19136
19407
19439
19500
19501
19502
19503
19505
19506
19507
19508
19509
19510
19600
19752
19757
19770
19775-1
19794-5
19831
20000â29999
20000
20022
20121
20400
20802
21000
21047
21500
21827
22000
22300
22395
23090-3
23270
23271
23360
24517
24613
24617
24707
25178
25964
26000
26262
26300
26324
27000 series
27000
27001
27002
27005
27006
27729
28000
29110
29148
29199-2
29500
30000+
30170
31000
32000
37001
38500
40500
42010
45001
50001
55000
56000
80000

 Category

vteITU recommendations (standards)
Lists: List of ITU-T V-series recommendations
List of ITU letter codesCategories: Category:ITU-R recommendations
Category:ITU-T recommendations
G series (ITU-T)
G.114
G.165
G.703
G.704
G.706
G.707
G.709
G.711
G.718
G.719
G.722
G.722.1
G.722.2
G.729.1
G.723
G.723.1
G.726
G.728
G.729
G.783
G.798
G.806
G.811
G.983
G.984
G.987
G.988
G.991.1
G.991.2
G.992.1
G.992.2
G.992.3
Annex J
Annex L
G.992.4
G.992.5
Annex M
G.993.1
G.993.2
G.7041
G.7042
G.7043
G.8262
G.9700 / G.9701
G.9960
G.9970
G.9972
H series (ITU-T)
H.222.0
H.225.0
H.235
H.239
H.241
H.245
H.248
H.261
H.262/MPEG-2 Video
H.263
H.264/MPEG-4 AVC
H.265/MPEG-H HEVC
H.266/MPEG-I VVC
H.320
H.323
H.323 Gatekeeper
H.324
H.450
V series (ITU-T)
V.10
V.11
V.21
V.22
V.23
V.24
V.61
V.70
V.90
V.92
ITU-R
ITU-R 468 noise weighting
ITU-R BS.1534-1
ITU-R BT.1304
ITU-R BT.470-6
ITU-R BT.470-7
ITU-R BT.601
ITU-R BT.709
ITU-R BT.2020
ITU-R BT.2100
See also: All articles beginning with "ITU"






<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Advanced_Video_Coding&oldid=1067265649"
		Categories: High-definition televisionOpen standards covered by patentsVideo codecsVideo compressionVideotelephonyITU-T recommendationsITU-T H Series RecommendationsH.26xISO standardsMPEG-4IEC standardsHidden categories: CS1 errors: missing periodicalAll articles with dead external linksArticles with dead external links from October 2017Articles with permanently dead external linksCS1 maint: archived copy as titleArticles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from September 2019All articles containing potentially dated statementsArticles with specifically marked weasel-worded phrases from December 2016Articles containing potentially dated statements from November 2020All articles with vague or ambiguous timeVague or ambiguous time from January 2020Use mdy dates from February 2015
	
