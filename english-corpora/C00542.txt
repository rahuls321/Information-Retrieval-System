
Title:
SÃ¸rensenâDice coefficient
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		The SÃ¸rensenâDice coefficient (see below for other names) is a statistic used to gauge the similarity of two samples. It was independently developed by the botanists Thorvald SÃ¸rensen[1] and Lee Raymond Dice,[2] who published in 1948 and 1945 respectively.

Contents

1 Name
2 Formula

2.1 Continuous Dice Coefficient[12]


3 Difference from Jaccard
4 Applications
5 Abundance version
6 See also
7 References
8 External links



Name[edit]
The index is known by several other names, especially SÃ¸rensenâDice index,[3] SÃ¸rensen index and Dice's coefficient. Other variations include the "similarity coefficient" or "index", such as Dice similarity coefficient (DSC). Common alternate spellings for SÃ¸rensen are Sorenson, Soerenson and SÃ¶renson, and all three can also be seen with the âsen ending.
Other names include:

F1 score
Czekanowski's binary (non-quantitative) index[4]
Measure of genetic similarity[5]
Zijdenbos similarity index,[6][7] referring to a 1994 paper of Zijdenbos et al.[8][3]
Formula[edit]
SÃ¸rensen's original formula was intended to be applied to discrete data. Given two sets, X and Y, it is defined as


  
    
      
        D
        S
        C
        =
        
          
            
              2
              
                |
              
              X
              â©
              Y
              
                |
              
            
            
              
                |
              
              X
              
                |
              
              +
              
                |
              
              Y
              
                |
              
            
          
        
      
    
    {\displaystyle DSC={\frac {2|X\cap Y|}{|X|+|Y|}}}
  

where |X| and |Y| are the cardinalities of the two sets (i.e. the number of elements in each set).
The SÃ¸rensen index equals twice the number of elements common to both sets divided by the sum of the number of elements in each set.
When applied to Boolean data, using the definition of true positive (TP), false positive (FP), and false negative (FN), it can be written as


  
    
      
        D
        S
        C
        =
        
          
            
              2
              T
              P
            
            
              2
              T
              P
              +
              F
              P
              +
              F
              N
            
          
        
      
    
    {\displaystyle DSC={\frac {2TP}{2TP+FP+FN}}}
  
.
It is different from the Jaccard index which only counts true positives once in both the numerator and denominator. DSC is the quotient of similarity and ranges between 0 andÂ 1.[9] It can be viewed as a similarity measure over sets.
Similarly to the Jaccard index, the set operations can be expressed in terms of vector operations over binary vectors a and b:


  
    
      
        
          s
          
            v
          
        
        =
        
          
            
              2
              
                |
              
              
                
                  
                    a
                  
                  â
                  
                    
                      
                        b
                      
                      
                        |
                      
                    
                  
                
              
            
            
              
                |
              
              
                
                  
                    a
                  
                  
                    
                      |
                    
                    
                      2
                    
                  
                  +
                  
                    |
                  
                  
                    
                      
                        b
                      
                      
                        
                          |
                        
                        
                          2
                        
                      
                    
                  
                
              
            
          
        
      
    
    {\displaystyle s_{v}={\frac {2|{\bf {{a}\cdot {\bf {{b}|}}}}}{|{\bf {{a}|^{2}+|{\bf {{b}|^{2}}}}}}}}
  

which gives the same outcome over binary vectors and also gives a more general similarity metric over vectors in general terms.
For sets X and Y of keywords used in information retrieval, the coefficient may be defined as twice the shared information (intersection) over the sum of cardinalitiesÂ :[10]
When taken as a string similarity measure, the coefficient may be calculated for two strings, x and y using bigrams as follows:[11]


  
    
      
        s
        =
        
          
            
              2
              
                n
                
                  t
                
              
            
            
              
                n
                
                  x
                
              
              +
              
                n
                
                  y
                
              
            
          
        
      
    
    {\displaystyle s={\frac {2n_{t}}{n_{x}+n_{y}}}}
  

where nt is the number of character bigrams found in both strings, nx is the number of bigrams in string x and ny is the number of bigrams in string y. For example, to calculate the similarity between:

night
nacht
We would find the set of bigrams in each word:

{ni,ig,gh,ht}
{na,ac,ch,ht}
Each set has four elements, and the intersection of these two sets has only one element: ht.
Inserting these numbers into the formula, we calculate, sÂ =Â (2Â Â·Â 1)Â /Â (4Â +Â 4)Â =Â 0.25.

Continuous Dice Coefficient[12][edit]
For a discrete ground truth and continuous measures following formula can be used:

  
    
      
        c
        D
        C
        =
        
          
            
              2
              
                |
              
              X
              â©
              Y
              
                |
              
            
            
              c
              â
              
                |
              
              X
              
                |
              
              +
              
                |
              
              Y
              
                |
              
            
          
        
      
    
    {\displaystyle cDC={\frac {2|X\cap Y|}{c*|X|+|Y|}}}
  

where c can be computed as follows:

  
    
      
        c
        =
        
          
            
              Î£
              
                a
                
                  i
                
              
              
                b
                
                  i
                
              
            
            
              Î£
              
                a
                
                  i
                
              
              sign
              â¡
              
                (
                
                  b
                  
                    i
                  
                
                )
              
            
          
        
      
    
    {\displaystyle c={\frac {\Sigma a_{i}b_{i}}{\Sigma a_{i}\operatorname {sign} {(b_{i})}}}}
  
 
If 
  
    
      
        Î£
        
          a
          
            i
          
        
        sign
        â¡
        
          (
          
            b
            
              i
            
          
          )
        
        =
        0
      
    
    {\displaystyle \Sigma a_{i}\operatorname {sign} {(b_{i})}=0}
  
 which means no overlap between A and B, c is set to 1 arbitrarily.

Difference from Jaccard[edit]
This coefficient is not very different in form from the Jaccard index. In fact, both are equivalent in the sense that given a value for the SÃ¸rensenâDice coefficient 
  
    
      
        S
      
    
    {\displaystyle S}
  
, one can calculate the respective Jaccard index value 
  
    
      
        J
      
    
    {\displaystyle J}
  
 and vice versa, using the equations 
  
    
      
        J
        =
        S
        
          /
        
        (
        2
        â
        S
        )
      
    
    {\displaystyle J=S/(2-S)}
  
 and 
  
    
      
        S
        =
        2
        J
        
          /
        
        (
        1
        +
        J
        )
      
    
    {\displaystyle S=2J/(1+J)}
  
.
Since the SÃ¸rensenâDice coefficient does not satisfy the triangle inequality, it can be considered a semimetric version of the Jaccard index.[4]
The function ranges between zero and one, like Jaccard. Unlike Jaccard, the corresponding difference function


  
    
      
        d
        =
        1
        â
        
          
            
              2
              
                |
              
              X
              â©
              Y
              
                |
              
            
            
              
                |
              
              X
              
                |
              
              +
              
                |
              
              Y
              
                |
              
            
          
        
      
    
    {\displaystyle d=1-{\frac {2|X\cap Y|}{|X|+|Y|}}}
  

is not a proper distance metric as it does not satisfy the triangle inequality.[4] The simplest counterexample of this is given by the three sets {a}, {b}, and {a,b}, the distance between the first two being 1, and the difference between the third and each of the others being one-third. To satisfy the triangle inequality, the sum of any two of these three sides must be greater than or equal to the remaining side. However, the distance between {a} and {a,b} plus the distance between {b} and {a,b} equals 2/3 and is therefore less than the distance between {a} and {b} which is 1.

Applications[edit]
The SÃ¸rensenâDice coefficient is useful for ecological community data (e.g. Looman & Campbell, 1960[13]). Justification for its use is primarily  empirical rather than theoretical (although it can be justified  theoretically as the intersection of two fuzzy sets[14]). As compared to Euclidean distance, the SÃ¸rensen distance retains sensitivity in more heterogeneous data sets and gives less weight to outliers.[15] Recently the Dice score (and its variations, e.g. logDice taking a logarithm of it) has become popular in computer lexicography for measuring the lexical association score of two given words.[16]
logDice is also used as part of the Mash Distance for genome and metagenome distance estimation[17]
Finally, Dice is used in image segmentation, in particular for comparing algorithm output against reference masks in medical applications.[8]

Abundance version[edit]
The expression is easily extended to abundance instead of presence/absence of species. This quantitative version is known by several names:

Quantitative SÃ¸rensenâDice index[4]
Quantitative SÃ¸rensen index[4]
Quantitative Dice index[4]
BrayâCurtis similarity (1 minus the Bray-Curtis dissimilarity)[4]
Czekanowski's quantitative index[4]
Steinhaus index[4]
Pielou's percentage similarity[4]
1 minus the Hellinger distance[18]
Proportion of specific agreement[19] or positive agreement[20]
See also[edit]
Correlation
F1 score
Jaccard index
Hamming distance
Mantel test
Morisita's overlap index
Most frequent k characters
Overlap coefficient
Renkonen similarity index (due to Olavi Renkonen)
Tversky index
Universal adaptive strategy theory (UAST)
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}SÃ¸rensen, T. (1948). "A method of establishing groups of equal amplitude in plant sociology based on similarity of species and its application to analyses of the vegetation on Danish commons". Kongelige Danske Videnskabernes Selskab. 5 (4): 1â34.

^ Dice, Lee R. (1945). "Measures of the Amount of Ecologic Association Between Species". Ecology. 26 (3): 297â302. doi:10.2307/1932409. JSTORÂ 1932409.

^ Jump up to: a b Carass, A.; Roy, S.; Gherman, A.; Reinhold, J.C.; Jesson, A.;  etÂ al. (2020). "Evaluating White Matter Lesion Segmentations with Refined SÃ¸rensen-Dice Analysis". Scientific Reports. 10 (1): 8242. Bibcode:2020NatSR..10.8242C. doi:10.1038/s41598-020-64803-w. ISSNÂ 2045-2322. PMCÂ 7237671. PMIDÂ 32427874.

^ Jump up to: a b c d e f g h i j Gallagher, E.D., 1999. COMPAH Documentation, University of Massachusetts, Boston

^ Nei, M.; Li, W.H. (1979). "Mathematical model for studying genetic variation in terms of restriction endonucleases". PNAS. 76 (10): 5269â5273. Bibcode:1979PNAS...76.5269N. doi:10.1073/pnas.76.10.5269. PMCÂ 413122. PMIDÂ 291943.

^ Prescott, J.W.; Pennell, M.; Best, T.M.; Swanson, M.S.; Haq, F.; Jackson, R.; Gurcan, M.N. (2009). An automated method to segment the femur for osteoarthritis research. IEEE. doi:10.1109/iembs.2009.5333257. PMCÂ 2826829.

^ Swanson, M.S.; Prescott, J.W.; Best, T.M.; Powell, K.; Jackson, R.D.; Haq, F.; Gurcan, M.N. (2010). "Semi-automated segmentation to assess the lateral meniscus in normal and osteoarthritic knees". Osteoarthritis and Cartilage. 18 (3): 344â353. doi:10.1016/j.joca.2009.10.004. ISSNÂ 1063-4584. PMCÂ 2826568. PMIDÂ 19857510.

^ Jump up to: a b Zijdenbos, A.P.; Dawant, B.M.; Margolin, R.A.; Palmer, A.C. (1994). "Morphometric analysis of white matter lesions in MR images: method and validation". IEEE Transactions on Medical Imaging. 13 (4): 716â724. doi:10.1109/42.363096. ISSNÂ 0278-0062. PMIDÂ 18218550.

^ http://www.sekj.org/PDF/anbf40/anbf40-415.pdf

^ van Rijsbergen, Cornelis Joost (1979). Information Retrieval. London: Butterworths. ISBNÂ 3-642-12274-4.

^ Kondrak, Grzegorz; Marcu, Daniel; Knight, Kevin (2003). "Cognates Can Improve Statistical Translation Models" (PDF). Proceedings of HLT-NAACL 2003: Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. pp.Â 46â48.

^ Shamir, Reuben R.; Duchin, Yuval; Kim, Jinyoung; Sapiro, Guillermo; Harel, Noam (2018-04-25). "Continuous Dice Coefficient: a Method for Evaluating Probabilistic Segmentations": 306977. doi:10.1101/306977v1. {{cite journal}}: Cite journal requires |journal= (help)

^ Looman, J.; Campbell, J.B. (1960). "Adaptation of Sorensen's K (1948) for estimating unit affinities in prairie vegetation". Ecology. 41 (3): 409â416. doi:10.2307/1933315. JSTORÂ 1933315.

^ Roberts, D.W. (1986). "Ordination on the basis of fuzzy set theory". Vegetatio. 66 (3): 123â131. doi:10.1007/BF00039905. S2CIDÂ 12573576.

^ McCune, Bruce & Grace, James (2002) Analysis of Ecological Communities. Mjm Software Design; ISBNÂ 0-9721290-0-6.

^ RychlÃ½, P. (2008) A lexicographer-friendly association score. Proceedings of the Second Workshop on Recent Advances in Slavonic Natural Language Processing RASLAN 2008: 6â9

^ Ondov, Brian D., et al. "Mash: fast genome and metagenome distance estimation using MinHash." Genome biology 17.1 (2016): 1-14.

^ Bray, J. Roger; Curtis, J. T. (1957). "An Ordination of the Upland Forest Communities of Southern Wisconsin". Ecological Monographs. 27 (4): 326â349. doi:10.2307/1942268. JSTORÂ 1942268.

^ Ayappa, Indu; Norman, Robert G (2000). "Non-Invasive Detection of Respiratory Effort-Related Arousals (RERAs) by a Nasal Cannula/Pressure Transducer System". Sleep. 23 (6): 763â771. doi:10.1093/sleep/23.6.763. PMIDÂ 11007443.

^ John Uebersax. "Raw Agreement Indices".


External links[edit]



The Wikibook Algorithm implementation has a page on the topic of: Dice's coefficient





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=SÃ¸rensenâDice_coefficient&oldid=1060760306"
		Categories: Information retrieval evaluationString metricsMeasure theorySimilarity measuresHidden categories: CS1 errors: missing periodical
	
