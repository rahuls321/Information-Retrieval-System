In linear algebra, a Hankel matrix (or catalecticant matrix), named after Hermann Hankel, is a square matrix in which each ascending skew-diagonal from left to right is constant, e.g.:More generally, a Hankel matrix is any                     n        ×        n              {\displaystyle n\times n}   matrix                     A              {\displaystyle A}   of the formIn terms of the components, if the                     i        ,        j              {\displaystyle i,j}   element of                     A              {\displaystyle A}   is denoted with                               A                      i            j                                {\displaystyle A_{ij}}  , and assuming                     i        ≤        j              {\displaystyle i\leq j}  , then we have                               A                      i            ,            j                          =                  A                      i            +            k            ,            j            −            k                                {\displaystyle A_{i,j}=A_{i+k,j-k}}   for all                     k        =        0        ,        .        .        .        ,        j        −        i        .              {\displaystyle k=0,...,j-i.}   Properties The Hankel matrix is a symmetric matrix.Let                               J                      n                                {\displaystyle J_{n}}   be the                     n        ×        n              {\displaystyle n\times n}   exchange matrix.  If                     H              {\displaystyle H}   is a                     m        ×        n              {\displaystyle m\times n}   Hankel matrix, then                     H        =        T                  J                      n                                {\displaystyle H=TJ_{n}}   where                     T              {\displaystyle T}   is a                     m        ×        n              {\displaystyle m\times n}   Toeplitz matrix.If                     T              {\displaystyle T}   is real symmetric, then                     H        =        T                  J                      n                                {\displaystyle H=TJ_{n}}   will have the same eigenvalues as                     T              {\displaystyle T}   up to sign.The Hilbert matrix is an example of a Hankel matrix. Hankel operator A Hankel operator on a Hilbert space is one whose matrix is a (possibly infinite) Hankel matrix with respect to an orthonormal basis. As indicated above, a Hankel Matrix is a matrix with constant values along its antidiagonals, which means that a Hankel matrix                     A              {\displaystyle A}   must satisfy, for all rows                     i              {\displaystyle i}   and columns                     j              {\displaystyle j}  ,                     (                  A                      i            ,            j                                    )                      i            ,            j            ≥            1                                {\displaystyle (A_{i,j})_{i,j\geq 1}}  . Note that every entry                               A                      i            ,            j                                {\displaystyle A_{i,j}}   depends only on                     i        +        j              {\displaystyle i+j}  .Let the corresponding Hankel Operator be                               H                      α                                {\displaystyle H_{\alpha }}  . Given a Hankel matrix                     A              {\displaystyle A}  , the corresponding Hankel operator is then defined as                               H                      α                          (        u        )        =        A        u              {\displaystyle H_{\alpha }(u)=Au}  .We are often interested in Hankel operators                               H                      α                          :                  ℓ                      2                                    (                                                    Z                                            +                                      ∪            {            0            }                    )                →                  ℓ                      2                                    (                                                    Z                                            +                                      ∪            {            0            }                    )                      {\displaystyle H_{\alpha }:\ell ^{2}\left(\mathbb {Z} ^{+}\cup \{0\}\right)\rightarrow \ell ^{2}\left(\mathbb {Z} ^{+}\cup \{0\}\right)}   over the Hilbert space                               ℓ                      2                          (                  Z                )              {\displaystyle \ell ^{2}(\mathbf {Z} )}  , the space of square integrable bilateral complex sequences. For any                     u        ∈                  ℓ                      2                          (                  Z                )              {\displaystyle u\in \ell ^{2}(\mathbf {Z} )}  , we haveWe are often interested in approximations of the Hankel operators, possibly by low-order operators. In order to approximate the output of the operator, we can use the spectral norm (operator 2-norm) to measure the error of our approximation. This suggests singular value decomposition as a possible technique to approximate the action of the operator.Note that the matrix                     A              {\displaystyle A}   does not have to be finite. If it is infinite, traditional methods of computing individual singular vectors will not work directly. We also require that the approximation is a Hankel matrix, which can be shown with AAK theory.The determinant of a Hankel matrix is called a catalecticant. Hankel matrix transform The Hankel matrix transform, or simply Hankel transform, produces the sequence of the determinants of the Hankel matrices formed from the given sequence.  Namely, the sequence                     {                  h                      n                                    }                      n            ≥            0                                {\displaystyle \{h_{n}\}_{n\geq 0}}   is the Hankel transform of the sequence                     {                  b                      n                                    }                      n            ≥            0                                {\displaystyle \{b_{n}\}_{n\geq 0}}   whenThe Hankel transform is invariant under the binomial transform of a sequence.  That is, if one writesas the binomial transform of the sequence                     {                  b                      n                          }              {\displaystyle \{b_{n}\}}  , then one has Applications of Hankel matrices Hankel matrices are formed when, given a sequence of output data, a realization of an underlying state-space or hidden Markov model is desired.  The singular value decomposition of the Hankel matrix provides a means of computing the A, B, and C matrices which define the state-space realization. The Hankel matrix formed from the signal has been found useful for decomposition of non-stationary signals and time-frequency representation.= Method of moments for polynomial distributions =The method of moments applied to polynomial distributions results in a Hankel matrix that needs to be inverted in order to obtain the weight parameters of the polynomial distribution approximation.= Positive Hankel matrices and the Hamburger moment problems = See also Toeplitz matrix, an "upside down" (i.e., row-reversed) Hankel matrixCauchy matrixVandermonde matrix Notes  References Brent R.P. (1999), "Stability of fast algorithms for structured linear systems", Fast Reliable Algorithms for Matrices with Structure (editors—T. Kailath, A.H. Sayed), ch.4 (SIAM).Victor Y. Pan (2001). Structured matrices and polynomials: unified superfast algorithms. Birkhäuser. ISBN 0817642404.J.R. Partington (1988). An introduction to Hankel operators. LMS Student Texts. Vol. 13. Cambridge University Press. ISBN 0-521-36791-3.P. Jain and R.B. Pachori, An iterative approach for decomposition of multi-component non-stationary signals based on eigenvalue decomposition of the Hankel matrix, Journal of the Franklin Institute, vol. 352, issue 10, pp. 4017–4044, October 2015.P. Jain and R.B. Pachori, Event-based method for instantaneous fundamental frequency estimation from voiced speech based on eigenvalue decomposition of Hankel matrix, IEEE/ACM Transactions on Audio, Speech and Language Processing, vol. 22. issue 10, pp. 1467–1482, October 2014.R.R. Sharma and R.B. Pachori, Time-frequency representation using IEVDHM-HT with application to classification of epileptic EEG signals, IET Science, Measurement & Technology, vol. 12, issue 01, pp. 72–82, January 2018.