
Title:
FloydâWarshall algorithm
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Algorithm for finding all-pairs shortest paths in graphs, allowing some edge weights to be negative
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}"Floyd's algorithm" redirects here. For cycle detection, see Floyd's cycle-finding algorithm. For computer graphics, see FloydâSteinberg dithering.
.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}FloydâWarshall algorithmClassAll-pairs shortest path problem (for weighted graphs)Data structureGraphWorst-case performance
  
    
      
        Î
        (
        
          |
        
        V
        
          
            |
          
          
            3
          
        
        )
      
    
    {\displaystyle \Theta (|V|^{3})}
  
Best-case performance
  
    
      
        Î
        (
        
          |
        
        V
        
          
            |
          
          
            3
          
        
        )
      
    
    {\displaystyle \Theta (|V|^{3})}
  
Average performance
  
    
      
        Î
        (
        
          |
        
        V
        
          
            |
          
          
            3
          
        
        )
      
    
    {\displaystyle \Theta (|V|^{3})}
  
Worst-case space complexity
  
    
      
        Î
        (
        
          |
        
        V
        
          
            |
          
          
            2
          
        
        )
      
    
    {\displaystyle \Theta (|V|^{2})}
  

.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Graph and treesearch algorithms
Î±âÎ²
A*
B*
Backtracking
Beam
BellmanâFord
Best-first
Bidirectional
BorÅ¯vka
Branch & bound
BFS
British Museum
D*
DFS
Dijkstra
Edmonds
FloydâWarshall
Fringe search
Hill climbing
IDA*
Iterative deepening
Johnson
Jump point
Kruskal
Lexicographic BFS
LPA*
Prim
SMA*

Listings
Graph algorithms
Search algorithms
List of graph algorithms

Related topics
Dynamic programming
Graph traversal
Tree traversal
Search games
Graph coloring
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
In computer science, the FloydâWarshall algorithm (also known as Floyd's algorithm, the RoyâWarshall algorithm, the RoyâFloyd algorithm, or the WFI algorithm) is an algorithm for finding shortest paths in a directed weighted graph with positive or negative edge weights (but with no negative cycles).[1][2] A single execution of the algorithm will find the lengths (summed weights) of shortest paths between all pairs of vertices. Although it does not return details of the paths themselves, it is possible to reconstruct the paths with simple modifications to the algorithm. Versions of the algorithm can also be used for finding the transitive closure of a relation 
  
    
      
        R
      
    
    {\displaystyle R}
  
, or (in connection with the Schulze voting system) widest paths between all pairs of vertices in a weighted graph.

Contents

1 History and naming
2 Algorithm
3 Example
4 Behavior with negative cycles
5 Path reconstruction

5.1 Pseudocode [11]


6 Analysis
7 Applications and generalizations
8 Implementations
9 Comparison with other shortest path algorithms
10 References
11 External links



History and naming[edit]
The FloydâWarshall algorithm is an example of dynamic programming, and was published in its currently recognized form by Robert Floyd in 1962.[3]  However, it is essentially the same as algorithms previously published by Bernard Roy in 1959[4] and also by Stephen Warshall in 1962[5] for finding the transitive closure of a graph,[6] and is closely related to Kleene's algorithm (published in 1956) for converting a deterministic finite automaton into a regular expression.[7] The modern formulation of the algorithm as three nested for-loops was first described by Peter Ingerman, also in 1962.[8]

Algorithm[edit]
The FloydâWarshall algorithm compares all possible paths through the graph between each pair of vertices. It is able to do this with 
  
    
      
        Î
        (
        
          |
        
        V
        
          
            |
          
          
            3
          
        
        )
      
    
    {\displaystyle \Theta (|V|^{3})}
  
 comparisons in a graph, even though there may be up to 
  
    
      
        Î©
        (
        
          |
        
        V
        
          
            |
          
          
            2
          
        
        )
      
    
    {\displaystyle \Omega (|V|^{2})}
  
 edges in the graph, and every combination of edges is tested.  It does so by incrementally improving an estimate on the shortest path between two vertices, until the estimate is optimal.
Consider a graph 
  
    
      
        G
      
    
    {\displaystyle G}
  
 with vertices 
  
    
      
        V
      
    
    {\displaystyle V}
  
 numbered 1 throughÂ 
  
    
      
        N
      
    
    {\displaystyle N}
  
. Further consider a function 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k)}
  
 that returns the shortest possible path from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to 
  
    
      
        j
      
    
    {\displaystyle j}
  
 using vertices only from the set 
  
    
      
        {
        1
        ,
        2
        ,
        â¦
        ,
        k
        }
      
    
    {\displaystyle \{1,2,\ldots ,k\}}
  
 as intermediate points along the way.  Now, given this function, our goal is to find the shortest path from each 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to each 
  
    
      
        j
      
    
    {\displaystyle j}
  
 using any vertex in 
  
    
      
        {
        1
        ,
        2
        ,
        â¦
        ,
        N
        }
      
    
    {\displaystyle \{1,2,\ldots ,N\}}
  
.
For each of these pairs of vertices, the 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k)}
  
 could be either

(1) a path that does not go through 
  
    
      
        k
      
    
    {\displaystyle k}
  
 (only uses vertices in the set 
  
    
      
        {
        1
        ,
        â¦
        ,
        k
        â
        1
        }
      
    
    {\displaystyle \{1,\ldots ,k-1\}}
  
.)
or

(2) a path that does go through 
  
    
      
        k
      
    
    {\displaystyle k}
  
 (from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to 
  
    
      
        k
      
    
    {\displaystyle k}
  
 and then from 
  
    
      
        k
      
    
    {\displaystyle k}
  
 to 
  
    
      
        j
      
    
    {\displaystyle j}
  
, both only using intermediate vertices inÂ 
  
    
      
        {
        1
        ,
        â¦
        ,
        k
        â
        1
        }
      
    
    {\displaystyle \{1,\ldots ,k-1\}}
  
)
We know that the best path from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to 
  
    
      
        j
      
    
    {\displaystyle j}
  
 that only uses vertices 
  
    
      
        1
      
    
    {\displaystyle 1}
  
 through 
  
    
      
        k
        â
        1
      
    
    {\displaystyle k-1}
  
 is defined by 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        â
        1
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k-1)}
  
, and it is clear that if there was a better path from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to 
  
    
      
        k
      
    
    {\displaystyle k}
  
 to 
  
    
      
        j
      
    
    {\displaystyle j}
  
, then the length of this path would be the concatenation of the shortest path from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to 
  
    
      
        k
      
    
    {\displaystyle k}
  
 (only using intermediate vertices in 
  
    
      
        {
        1
        ,
        â¦
        ,
        k
        â
        1
        }
      
    
    {\displaystyle \{1,\ldots ,k-1\}}
  
) and the shortest path from 
  
    
      
        k
      
    
    {\displaystyle k}
  
 to 
  
    
      
        j
      
    
    {\displaystyle j}
  
 (only using intermediate vertices inÂ 
  
    
      
        {
        1
        ,
        â¦
        ,
        k
        â
        1
        }
      
    
    {\displaystyle \{1,\ldots ,k-1\}}
  
).
If 
  
    
      
        w
        (
        i
        ,
        j
        )
      
    
    {\displaystyle w(i,j)}
  
 is the weight of the edge between vertices 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        j
      
    
    {\displaystyle j}
  
, we can define 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k)}
  
 in terms of the following recursive formula: the base case is


  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        0
        )
        =
        w
        (
        i
        ,
        j
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,0)=w(i,j)}
  

and the recursive case is


  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        )
        =
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k)=}
  


  
    
      
        
          m
          i
          n
        
        
          
            (
          
        
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        â
        1
        )
        ,
      
    
    {\displaystyle \mathrm {min} {\Big (}\mathrm {shortestPath} (i,j,k-1),}
  


  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        k
        ,
        k
        â
        1
        )
        +
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        k
        ,
        j
        ,
        k
        â
        1
        )
        
          
            )
          
        
      
    
    {\displaystyle \mathrm {shortestPath} (i,k,k-1)+\mathrm {shortestPath} (k,j,k-1){\Big )}}
  
.
This formula is the heart of the FloydâWarshall algorithm. The algorithm works by first computing 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k)}
  
 for all 
  
    
      
        (
        i
        ,
        j
        )
      
    
    {\displaystyle (i,j)}
  
 pairs for 
  
    
      
        k
        =
        1
      
    
    {\displaystyle k=1}
  
, then 
  
    
      
        k
        =
        2
      
    
    {\displaystyle k=2}
  
, and so on.  This process continues until 
  
    
      
        k
        =
        N
      
    
    {\displaystyle k=N}
  
, and we have found the shortest path for all 
  
    
      
        (
        i
        ,
        j
        )
      
    
    {\displaystyle (i,j)}
  
 pairs using any intermediate vertices. Pseudocode for this basic version follows:

let dist be a |V| Ã |V| array of minimum distances initialized to â (infinity)
for each edge (u, v) do
    dist[u][v] â w(u, v)  // The weight of the edge (u, v)
for each vertex v do
    dist[v][v] â 0
for k from 1 to |V|
    for i from 1 to |V|
        for j from 1 to |V|
            if dist[i][j] > dist[i][k] + dist[k][j] 
                dist[i][j] â dist[i][k] + dist[k][j]
            end if

Example[edit]
The algorithm above is executed on the graph on the left below:

Prior to the first recursion of the outer loop, labeled k = 0 above, the only known paths correspond to the single edges in the graph. At k = 1, paths that go through the vertex 1 are found: in particular, the path [2,1,3] is found, replacing the path [2,3] which has fewer edges but is longer (in terms of weight). At k = 2, paths going through the vertices {1,2} are found. The red and blue boxes show how the path [4,2,1,3] is assembled from the two known paths [4,2] and [2,1,3] encountered in previous iterations, with 2 in the intersection. The path [4,2,3] is not considered, because [2,1,3] is the shortest path encountered so far from 2 to 3. At k = 3, paths going through the vertices {1,2,3} are found. Finally, at k = 4, all shortest paths are found.
The distance matrix at each iteration of k, with the updated distances in bold, will be:





k = 0

j


1
2
3
4


i

1

0
â
â2
â


2

4
0
3
â


3

â
â
0
2


4

â
â1
â
0





k = 1

j


1
2
3
4


i

1

0
â
â2
â


2

4
0
2
â


3

â
â
0
2


4

â
â1
â
0





k = 2

j


1
2
3
4


i

1

0
â
â2
â


2

4
0
2
â


3

â
â
0
2


4

3
â1
1
0





k = 3

j


1
2
3
4


i

1

0
â
â2
0


2

4
0
2
4


3

â
â
0
2


4

3
â1
1
0





k = 4

j


1
2
3
4


i

1

0
â1
â2
0


2

4
0
2
4


3

5
1
0
2


4

3
â1
1
0


Behavior with negative cycles[edit]
A negative cycle is a cycle whose edges sum to a negative value.  There is no shortest path between any pair of vertices 
  
    
      
        i
      
    
    {\displaystyle i}
  
, 
  
    
      
        j
      
    
    {\displaystyle j}
  
 which form part of a negative cycle,  because path-lengths from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to 
  
    
      
        j
      
    
    {\displaystyle j}
  
 can be arbitrarily small (negative).  For numerically meaningful output, the FloydâWarshall algorithm assumes that there are no negative cycles.  Nevertheless, if there are negative cycles, the FloydâWarshall algorithm can be used to detect them.  The intuition is as follows:

The FloydâWarshall algorithm iteratively revises path lengths between all pairs of vertices 
  
    
      
        (
        i
        ,
        j
        )
      
    
    {\displaystyle (i,j)}
  
, including where 
  
    
      
        i
        =
        j
      
    
    {\displaystyle i=j}
  
;
Initially, the length of the path 
  
    
      
        (
        i
        ,
        i
        )
      
    
    {\displaystyle (i,i)}
  
 is zero;
A path 
  
    
      
        [
        i
        ,
        k
        ,
        â¦
        ,
        i
        ]
      
    
    {\displaystyle [i,k,\ldots ,i]}
  
 can only improve upon this if it has length less than zero, i.e. denotes a negative cycle;
Thus, after the algorithm, 
  
    
      
        (
        i
        ,
        i
        )
      
    
    {\displaystyle (i,i)}
  
 will be negative if there exists a negative-length path from 
  
    
      
        i
      
    
    {\displaystyle i}
  
 back to 
  
    
      
        i
      
    
    {\displaystyle i}
  
.
Hence, to detect negative cycles using the FloydâWarshall algorithm, one can inspect the diagonal of the path matrix, and the presence of a negative number indicates that the graph contains at least one negative cycle.[9] During the execution of the algorithm, if there is a negative cycle, exponentially large numbers can appear, as large as 
  
    
      
        Î©
        (
        â
        
          6
          
            n
            â
            1
          
        
        
          w
          
            m
            a
            x
          
        
        )
      
    
    {\displaystyle \Omega (\cdot 6^{n-1}w_{max})}
  
, where 
  
    
      
        
          w
          
            m
            a
            x
          
        
      
    
    {\displaystyle w_{max}}
  
 is the largest absolute value of a negative edge in the graph. To avoid overflow/underflow problems one should check for negative numbers on the diagonal of the path matrix within the inner for loop of the algorithm.[10] Obviously, in an undirected graph a negative edge creates a negative cycle  (i.e., a closed walk) involving its incident vertices. Considering all edges of the above example graph as undirected, e.g. the vertex sequence 4 â 2 â 4 is a cycle with weight sum â2.

Path reconstruction[edit]
The FloydâWarshall algorithm typically only provides the lengths of the paths between all pairs of vertices. With simple modifications, it is possible to create a method to reconstruct the actual path between any two endpoint vertices. While one may be inclined to store the actual path from each vertex to each other vertex, this is not necessary, and in fact, is very costly in terms of memory. Instead, the shortest-path tree can be calculated for each node in 
  
    
      
        Î
        (
        
          |
        
        E
        
          |
        
        )
      
    
    {\displaystyle \Theta (|E|)}
  
 time using 
  
    
      
        Î
        (
        
          |
        
        V
        
          |
        
        )
      
    
    {\displaystyle \Theta (|V|)}
  
 memory to store each tree which allows us to efficiently reconstruct a path from any two connected vertices.

Pseudocode [11][edit]
let dist be a 
  
    
      
        
          |
        
        V
        
          |
        
        Ã
        
          |
        
        V
        
          |
        
      
    
    {\displaystyle |V|\times |V|}
  
 array of minimum distances initialized to 
  
    
      
        â
      
    
    {\displaystyle \infty }
  
 (infinity)
let next be a 
  
    
      
        
          |
        
        V
        
          |
        
        Ã
        
          |
        
        V
        
          |
        
      
    
    {\displaystyle |V|\times |V|}
  
 array of vertex indices initialized to null

procedure FloydWarshallWithPathReconstruction() is
    for each edge (u, v) do
        dist[u][v] â w(u, v)  // The weight of the edge (u, v)
        next[u][v] â v
    for each vertex v do
        dist[v][v] â 0
        next[v][v] â v
    for k from 1 to |V| do // standard Floyd-Warshall implementation
        for i from 1 to |V|
            for j from 1 to |V|
                if dist[i][j] > dist[i][k] + dist[k][j] then
                    dist[i][j] â dist[i][k] + dist[k][j]
                    next[i][j] â next[i][k]

procedure Path(u, v)
    if next[u][v] = null then
        return []
    path = [u]
    while u â  v
        u â next[u][v]
        path.append(u)
    return path

Analysis[edit]
Let 
  
    
      
        n
      
    
    {\displaystyle n}
  
 be 
  
    
      
        
          |
        
        V
        
          |
        
      
    
    {\displaystyle |V|}
  
, the number of vertices. To find all 
  
    
      
        
          n
          
            2
          
        
      
    
    {\displaystyle n^{2}}
  
 of 

  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k)}
  
 (for all 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        j
      
    
    {\displaystyle j}
  
) from those of

  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        k
        â
        1
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,k-1)}
  
 requires 
  
    
      
        2
        
          n
          
            2
          
        
      
    
    {\displaystyle 2n^{2}}
  
 operations. Since we begin with

  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        0
        )
        =
        
          e
          d
          g
          e
          C
          o
          s
          t
        
        (
        i
        ,
        j
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,0)=\mathrm {edgeCost} (i,j)}
  
 and compute the sequence of 
  
    
      
        n
      
    
    {\displaystyle n}
  
 matrices 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        1
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,1)}
  
, 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        2
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,2)}
  
, 
  
    
      
        â¦
      
    
    {\displaystyle \ldots }
  
, 
  
    
      
        
          s
          h
          o
          r
          t
          e
          s
          t
          P
          a
          t
          h
        
        (
        i
        ,
        j
        ,
        n
        )
      
    
    {\displaystyle \mathrm {shortestPath} (i,j,n)}
  
, the total number of operations used is 

  
    
      
        n
        â
        2
        
          n
          
            2
          
        
        =
        2
        
          n
          
            3
          
        
      
    
    {\displaystyle n\cdot 2n^{2}=2n^{3}}
  
. Therefore, the complexity of the algorithm is 
  
    
      
        Î
        (
        
          n
          
            3
          
        
        )
      
    
    {\displaystyle \Theta (n^{3})}
  
.

Applications and generalizations[edit]
The FloydâWarshall algorithm can be used to solve the following problems, among others:

Shortest paths in directed graphs (Floyd's algorithm).
Transitive closure of directed graphs (Warshall's algorithm). In Warshall's original formulation of the algorithm, the graph is unweighted and represented by a Boolean adjacency matrix. Then the addition operation is replaced by logical conjunction (AND) and the minimum operation by logical disjunction (OR).
Finding a regular expression denoting the regular language accepted by a finite automaton (Kleene's algorithm, a closely related generalization of the FloydâWarshall algorithm)[12]
Inversion of real matrices (GaussâJordan algorithm) [13]
Optimal routing. In this application one is interested in finding the path with the maximum flow between two vertices. This means that, rather than taking minima as in the pseudocode above, one instead takes maxima. The edge weights represent fixed constraints on flow. Path weights represent bottlenecks; so the addition operation above is replaced by the minimum operation.
Fast computation of Pathfinder networks.
Widest paths/Maximum bandwidth paths
Computing canonical form of difference bound matrices (DBMs)
Computing the similarity between graphs
Transitive closure in AND/OR/threshold graphs.[14]
Implementations[edit]
Implementations are available for many programming languages.

For C++, in the boost::graph library
For C#, at QuickGraph
For C#, at QuickGraphPCL (A fork of QuickGraph with better compatibility with projects using Portable Class Libraries.)
For Java, in the Apache Commons Graph library
For JavaScript, in the Cytoscape library
For MATLAB, in the Matlab_bgl package
For Perl, in the Graph module
For Python, in the SciPy library (module scipy.sparse.csgraph) or NetworkX library
For R, in packages e1071 and Rfast
Comparison with other shortest path algorithms[edit]
The FloydâWarshall algorithm is a good choice for computing paths between all pairs of vertices in dense graphs, in which most or all pairs of vertices are connected by edges. For sparse graphs with non-negative edge weights, lower asymptotic complexity can be obtained by running Dijkstra's algorithm from each possible starting vertex, since the worst-case running time of repeated Dijkstra (
  
    
      
        O
        (
        
          |
        
        E
        
          |
        
        
          |
        
        V
        
          |
        
        +
        
          |
        
        V
        
          
            |
          
          
            2
          
        
        log
        â¡
        
          |
        
        V
        
          |
        
        )
      
    
    {\displaystyle O(|E||V|+|V|^{2}\log |V|)}
  
 using Fibonacci heaps) is smaller than the 
  
    
      
        O
        (
        
          |
        
        V
        
          
            |
          
          
            3
          
        
        )
      
    
    {\displaystyle O(|V|^{3})}
  
 running time of the FloydâWarshall algorithm when 
  
    
      
        
          |
        
        E
        
          |
        
      
    
    {\displaystyle |E|}
  
 is significantly smaller than 
  
    
      
        
          |
        
        V
        
          
            |
          
          
            2
          
        
      
    
    {\displaystyle |V|^{2}}
  
. For sparse graphs with negative edges but no negative cycles, Johnson's algorithm can be used, with the same asymptotic running time as the repeated Dijkstra approach.
There are also known algorithms using fast matrix multiplication to speed up all-pairs shortest path computation in dense graphs, but these typically make extra assumptions on the edge weights (such as requiring them to be small integers).[15][16] In addition, because of the high constant factors in their running time, they would only provide a speedup over the FloydâWarshall algorithm for very large graphs.

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L. (1990). Introduction to Algorithms (1stÂ ed.). MIT Press and McGraw-Hill. ISBNÂ 0-262-03141-8. See in particular Section 26.2, "The FloydâWarshall algorithm", pp.Â 558â565 and Section 26.4, "A general framework for solving path problems in directed graphs", pp.Â 570â576.

^ Kenneth H. Rosen (2003). Discrete Mathematics and Its Applications, 5th Edition. Addison Wesley. ISBNÂ 978-0-07-119881-3.

^ Floyd, Robert W. (June 1962). "Algorithm 97: Shortest Path". Communications of the ACM. 5 (6): 345. doi:10.1145/367766.368168. S2CIDÂ 2003382.

^ Roy, Bernard (1959). "TransitivitÃ© et connexitÃ©". C. R. Acad. Sci. Paris (in French). 249: 216â218.

^ Warshall, Stephen (January 1962). "A theorem on Boolean matrices". Journal of the ACM. 9 (1): 11â12. doi:10.1145/321105.321107. S2CIDÂ 33763989.

^ Weisstein, Eric W. "Floyd-Warshall Algorithm". MathWorld.

^ Kleene, S. C. (1956). "Representation of events in nerve nets and finite automata".  In C. E. Shannon and J. McCarthy (ed.). Automata Studies. Princeton University Press. pp.Â 3â42.

^ Ingerman, Peter Z. (November 1962). "Algorithm 141: Path Matrix". Communications of the ACM. 5 (11): 556. doi:10.1145/368996.369016. S2CIDÂ 29010500.

^ Hochbaum, Dorit (2014). "Section 8.9: Floyd-Warshall algorithm for all pairs shortest paths" (PDF). Lecture Notes for IEOR 266: Graph Algorithms and Network Flows. Department of Industrial Engineering and Operations Research, University of California, Berkeley.

^ 
Stefan Hougardy (April 2010). "The FloydâWarshall algorithm on graphs with negative cycles". Information Processing Letters. 110 (8â9): 279â281. doi:10.1016/j.ipl.2010.02.001.

^ "Free Algorithms Book".

^ Gross, Jonathan L.; Yellen, Jay (2003), Handbook of Graph Theory, Discrete Mathematics and Its Applications, CRC Press, p.Â 65, ISBNÂ 9780203490204.

^ Penaloza, Rafael. "Algebraic Structures for Transitive Closure". CiteSeerXÂ 10.1.1.71.7650. {{cite journal}}: Cite journal requires |journal= (help)

^ Gillies, Donald (1993). Scheduling Tasks with AND/OR precedence contraints (PhD Thesis, Appendix B) (PDF) (Report).

^ Zwick, Uri (May 2002), "All pairs shortest paths using bridging sets and rectangular matrix multiplication", Journal of the ACM, 49 (3): 289â317, arXiv:cs/0008011, doi:10.1145/567112.567114, S2CIDÂ 1065901.

^ Chan, Timothy M. (January 2010), "More algorithms for all-pairs shortest paths in weighted graphs", SIAM Journal on Computing, 39 (5): 2075â2089, CiteSeerXÂ 10.1.1.153.6864, doi:10.1137/08071990x.


External links[edit]



Wikimedia Commons has media related to Floyd-Warshall algorithm.

Interactive animation of the FloydâWarshall algorithm
Interactive animation of the FloydâWarshall algorithm (Technical University of Munich)
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}hidevteOptimization: Algorithms, methods, and heuristicsshowUnconstrained nonlinearFunctions
Golden-section search
Interpolation methods
Line search
NelderâMead method
Successive parabolic interpolation
GradientsConvergence
Trust region
Wolfe conditions
QuasiâNewton
BerndtâHallâHallâHausman
BroydenâFletcherâGoldfarbâShanno and L-BFGS
DavidonâFletcherâPowell
Symmetric rank-one (SR1)
Other methods
Conjugate gradient
GaussâNewton
Gradient
LevenbergâMarquardt
Powell's dog leg method
Truncated Newton
Hessians
Newton's method
showConstrained nonlinearGeneral
Barrier methods
Penalty methods
Differentiable
Augmented Lagrangian methods
Sequential quadratic programming
Successive linear programming
showConvex optimizationConvex minimization
Cutting-plane method
Reduced gradient (FrankâWolfe)
Subgradient method
Linear andquadraticInterior point
Affine scaling
Ellipsoid algorithm of Khachiyan
Projective algorithm of Karmarkar
Basis-exchange
Simplex algorithm of Dantzig
Revised simplex algorithm
Criss-cross algorithm
Principal pivoting algorithm of Lemke
hideCombinatorialParadigms
Approximation algorithm
Dynamic programming
Greedy algorithm
Integer programming
Branch and bound/cut
Graph algorithmsMinimum spanning tree
BorÅ¯vka
Prim
Kruskal

    Shortest path
BellmanâFord
SPFA
Dijkstra
FloydâWarshall
Network flows
Dinic
EdmondsâKarp
FordâFulkerson
Pushârelabel maximum flow
showMetaheuristics
Evolutionary algorithm
Hill climbing
Local search
Simulated annealing
Tabu search

Software





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=FloydâWarshall_algorithm&oldid=1068224327"
		Categories: Graph algorithmsRouting algorithmsPolynomial-time problemsDynamic programmingGraph distanceHidden categories: CS1 French-language sources (fr)CS1 errors: missing periodicalArticles with short descriptionShort description matches WikidataCommons category link is on WikidataArticles with example pseudocode
	
