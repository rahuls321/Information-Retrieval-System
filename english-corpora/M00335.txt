In mathematics, the dimension theorem for vector spaces states that all bases of a vector space have equally many elements. This number of elements may be finite or infinite (in the latter case, it is a cardinal number), and defines the dimension of the vector space.Formally, the dimension theorem for vector spaces states thatGiven a vector space V, any two bases have the same cardinality.As a basis is a generating set that is linearly independent, the theorem is a consequence of the following theorem, which is also useful:In a vector space V, if G is a generating set, and I is a linearly independent set, then the cardinality of I is not larger than the cardinality of G.In particular if V is finitely generated, then all its bases are finite and have the  same number of elements.While the proof of the existence of a basis for any vector space in the general case requires Zorn's lemma and is in fact equivalent to the axiom of choice, the uniqueness of the cardinality of the basis requires only the ultrafilter lemma, which is strictly weaker (the proof given below, however, assumes trichotomy, i.e., that all cardinal numbers are comparable, a statement which is also equivalent to the axiom of choice). The theorem can be generalized to arbitrary R-modules for rings R having invariant basis number.In the finitely generated case the proof uses only elementary arguments of algebra, and does not require the axiom of choice nor its weaker variants. Proof Let V be a vector space, {ai: i ∈ I}  be a linearly independent set of elements of V, and {bj: j ∈ J}  be a generating set. One has to prove that the cardinality of I is not larger than that of J.If J is finite, this results from the Steinitz exchange lemma. (Indeed, the Steinitz exchange lemma implies every finite subset of I has cardinality not larger than that of J, hence I is finite with cardinality not larger than that of J.) If J is finite, a proof based on matrix theory is also possible.Assume that J is infinite. If I is finite, there is nothing to prove. Thus, we may assume that I is also infinite. Let us suppose that the cardinality of I is larger than that of J. We have to prove that this leads to a contradiction. By Zorn's lemma, every linearly independent set is contained in a maximal linearly independent set K. This maximality implies that K spans V and is therefore a basis (the maximality implies that every element of V is linearly dependent from the elements of K, and therefore is a linear combination of elements of K). As the cardinality of K is greater than or equal to the cardinality of I, one may replace {ai: i ∈ I}  with K, that is, one may suppose, without loss of generality, that {ai: i ∈ I}  is a basis. Thus, every bj can be written as a finite sum                                          b                          j                                =                      ∑                          i              ∈                              E                                  j                                                                          λ                          i              ,              j                                            a                          i                                ,                      {\displaystyle \textstyle b_{j}=\sum _{i\in E_{j}}\lambda _{i,j}a_{i},}  where                               E                      j                                {\displaystyle E_{j}}   is a finite subset of                     I        .              {\displaystyle I.}   As J is infinite,                                           ⋃                          j              ∈              J                                            E                          j                                            {\displaystyle \textstyle \bigcup _{j\in J}E_{j}}   has the same cardinality as J. Therefore                                           ⋃                          j              ∈              J                                            E                          j                                            {\displaystyle \textstyle \bigcup _{j\in J}E_{j}}   has cardinality smaller than that of I. So there is some                               i                      0                          ∈        I              {\displaystyle i_{0}\in I}   which does not appear in any                               E                      j                                {\displaystyle E_{j}}  .  The corresponding                               a                                    i                              0                                                          {\displaystyle a_{i_{0}}}   can be expressed as a finite linear combination of                               b                      j                                {\displaystyle b_{j}}  s, which in turn can be expressed as finite linear combination of                               a                      i                                {\displaystyle a_{i}}  s, not involving                               a                                    i                              0                                                          {\displaystyle a_{i_{0}}}  . Hence                               a                                    i                              0                                                          {\displaystyle a_{i_{0}}}   is linearly dependent on the other                               a                      i                                {\displaystyle a_{i}}  s, which provides the desired contradiction. Kernel extension theorem for vector spaces This application of the dimension theorem is sometimes itself called the dimension theorem. LetT: U → Vbe a linear transformation. Thendim(range(T)) + dim(kernel(T)) = dim(U),that is, the dimension of U is equal to the dimension of the transformation's range plus the dimension of the kernel. See rank–nullity theorem for a fuller discussion. Notes  References 