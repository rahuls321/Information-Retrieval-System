
Title:
Adjacency matrix
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Square matrix used to represent a graph or network
In graph theory and computer science, an adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.
In the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. If the graph is undirected (i.e. all of its edges are bidirectional), the adjacency matrix is symmetric. 
The relationship between a graph and the eigenvalues and eigenvectors of its adjacency matrix is studied in spectral graph theory.
The adjacency matrix of a graph should be distinguished from its incidence matrix, a different matrix representation whose elements indicate whether vertexâedge pairs are incident or not, and its degree matrix, which contains information about the degree of each vertex.

Contents

1 Definition

1.1 Of a bipartite graph
1.2 Variations


2 Examples

2.1 Undirected graphs
2.2 Directed graphs
2.3 Trivial graphs


3 Properties

3.1 Spectrum
3.2 Isomorphism and invariants
3.3 Matrix powers


4 Data structures
5 See also
6 References
7 External links



Definition[edit]
For a simple graph with vertex set U = {u1, â¦, un}, the adjacency matrix is a square nâÃân matrix A such that its element Aij is one when there is an edge from vertex ui to vertex uj, and zero when there is no edge.[1] The diagonal elements of the matrix are all zero, since edges from a vertex to itself (loops) are not allowed in simple graphs. It is also sometimes useful in algebraic graph theory to replace the nonzero elements with algebraic variables.[2] The same concept can be extended to multigraphs and graphs with loops by storing the number of edges between each two vertices in the corresponding matrix element, and by allowing nonzero diagonal elements. Loops may be counted either once (as a single edge) or twice (as two vertex-edge incidences), as long as a consistent convention is followed. Undirected graphs often use the latter convention of counting loops twice, whereas directed graphs typically use the former convention.

Of a bipartite graph[edit]
The adjacency matrix A of a bipartite graph whose two parts have r and s vertices can be written in the form 


  
    
      
        A
        =
        
          
            (
            
              
                
                  
                    0
                    
                      r
                      ,
                      r
                    
                  
                
                
                  B
                
              
              
                
                  
                    B
                    
                      
                        T
                      
                    
                  
                
                
                  
                    0
                    
                      s
                      ,
                      s
                    
                  
                
              
            
            )
          
        
        ,
      
    
    {\displaystyle A={\begin{pmatrix}0_{r,r}&B\\B^{\mathsf {T}}&0_{s,s}\end{pmatrix}},}
  

where B is an râÃâs matrix, and 0r,r and 0s,s represent the râÃâr and sâÃâs zero matrices. In this case, the smaller matrix B uniquely represents the graph, and the remaining parts of A can be discarded as redundant. B is sometimes called the biadjacency matrix.
Formally, let G = (U, V, E) be a bipartite graph with parts U = {u1, â¦, ur}, V = {v1, â¦, vs} and edges E. The biadjacency matrix is the râÃâs 0â1 matrix B in which bi,j = 1 if and only if (ui, vj) â E.
If G is a bipartite multigraph or weighted graph, then the elements bi,j are taken to be the number of edges between the vertices or the weight of the edge (ui, vj), respectively.

Variations[edit]
An (a, b, c)-adjacency matrix A of a simple graph has Ai,j = a if (i, j) is an edge, b if it is not, and c on the diagonal. The Seidel adjacency matrix is a (â1, 1, 0)-adjacency matrix. This matrix is used in studying strongly regular graphs and two-graphs.[3]
The distance matrix has in position (i, j) the distance between vertices vi and vj. The distance is the length of a shortest path connecting the vertices. Unless lengths of edges are explicitly provided, the length of a path is the number of edges in it. The distance matrix resembles a high power of the adjacency matrix, but instead of telling only whether or not two vertices are connected (i.e., the connection matrix, which contains boolean values), it gives the exact distance between them.

Examples[edit]
Undirected graphs[edit]
The convention followed here (for undirected graphs) is that each edge adds 1 to the appropriate cell in the matrix, and each loop adds 2.[4] This allows the degree of a vertex to be easily found by taking the sum of the values in either its respective row or column in the adjacency matrix.



Labeled graph

Adjacency matrix





  
    
      
        
          
            (
            
              
                
                  2
                
                
                  1
                
                
                  0
                
                
                  0
                
                
                  1
                
                
                  0
                
              
              
                
                  1
                
                
                  0
                
                
                  1
                
                
                  0
                
                
                  1
                
                
                  0
                
              
              
                
                  0
                
                
                  1
                
                
                  0
                
                
                  1
                
                
                  0
                
                
                  0
                
              
              
                
                  0
                
                
                  0
                
                
                  1
                
                
                  0
                
                
                  1
                
                
                  1
                
              
              
                
                  1
                
                
                  1
                
                
                  0
                
                
                  1
                
                
                  0
                
                
                  0
                
              
              
                
                  0
                
                
                  0
                
                
                  0
                
                
                  1
                
                
                  0
                
                
                  0
                
              
            
            )
          
        
      
    
    {\displaystyle {\begin{pmatrix}2&1&0&0&1&0\\1&0&1&0&1&0\\0&1&0&1&0&0\\0&0&1&0&1&1\\1&1&0&1&0&0\\0&0&0&1&0&0\end{pmatrix}}}
  

Coordinates are 1â6.




Nauru graph



Coordinates are 0â23.
White fields are zeros, colored fields are ones.


Directed graphs[edit]
The adjacency matrix of a directed graph can be asymmetric. One can define the adjacency matrix of a directed graph either such that 

a non-zero element Aij indicates an edge from i to j or
it indicates an edge from j to i.
The former definition is commonly used in graph theory and social network analysis (e.g., sociology, political science, economics, psychology).[5] The latter is more common in other applied sciences (e.g., dynamical systems, physics, network science) where A is sometimes used to describe linear dynamics on graphs.[6]
Using the first definition, the in-degrees of a vertex can be computed by summing the entries of the corresponding column and the out-degree of vertex by summing the entries of the corresponding row. When using the second definition, the in-degree of a vertex is given by the corresponding row sum and the out-degree is given by the corresponding column sum.



Labeled graph

Adjacency matrix



Directed Cayley graph of S4



Coordinates are 0â23.
As the graph is directed, the matrix is not necessarily symmetric.


Trivial graphs[edit]
The adjacency matrix of a complete graph contains all ones except along the diagonal where there are only zeros. The adjacency matrix of an empty graph is a zero matrix.

Properties[edit]
Spectrum[edit]
The adjacency matrix of an undirected simple graph is symmetric, and therefore has a complete set of real eigenvalues and an orthogonal eigenvector basis. The set of eigenvalues of a graph is the spectrum of the graph.[7] It is common to denote the eigenvalues by 
  
    
      
        
          Î»
          
            1
          
        
        â¥
        
          Î»
          
            2
          
        
        â¥
        â¯
        â¥
        
          Î»
          
            n
          
        
        .
      
    
    {\displaystyle \lambda _{1}\geq \lambda _{2}\geq \cdots \geq \lambda _{n}.}
  

The greatest eigenvalue 
  
    
      
        
          Î»
          
            1
          
        
      
    
    {\displaystyle \lambda _{1}}
  
 is bounded above by the maximum degree. This can be seen as result of the PerronâFrobenius theorem, but it can be proved easily. Let v be one eigenvector associated to 
  
    
      
        
          Î»
          
            1
          
        
      
    
    {\displaystyle \lambda _{1}}
  
 and x the component in which v has maximum absolute value. Without loss of generality assume vx is positive since otherwise you simply take the eigenvector 
  
    
      
        â
        v
      
    
    {\displaystyle -v}
  
, also associated to 
  
    
      
        
          Î»
          
            1
          
        
      
    
    {\displaystyle \lambda _{1}}
  
. Then


  
    
      
        
          Î»
          
            1
          
        
        
          v
          
            x
          
        
        =
        (
        A
        v
        
          )
          
            x
          
        
        =
        
          â
          
            y
            =
            1
          
          
            n
          
        
        
          A
          
            x
            ,
            y
          
        
        
          v
          
            y
          
        
        â¤
        
          â
          
            y
            =
            1
          
          
            n
          
        
        
          A
          
            x
            ,
            y
          
        
        
          v
          
            x
          
        
        =
        
          v
          
            x
          
        
        deg
        â¡
        (
        x
        )
        .
      
    
    {\displaystyle \lambda _{1}v_{x}=(Av)_{x}=\sum _{y=1}^{n}A_{x,y}v_{y}\leq \sum _{y=1}^{n}A_{x,y}v_{x}=v_{x}\deg(x).}
  

For d-regular graphs, d is the first eigenvalue of A for the vector v = (1, â¦, 1) (it is easy to check that it is an eigenvalue and it is the maximum because of the above bound). The multiplicity of this eigenvalue is the number of connected components of G, in particular 
  
    
      
        
          Î»
          
            1
          
        
        >
        
          Î»
          
            2
          
        
      
    
    {\displaystyle \lambda _{1}>\lambda _{2}}
  
 for connected graphs. It can be shown that for each eigenvalue 
  
    
      
        
          Î»
          
            i
          
        
      
    
    {\displaystyle \lambda _{i}}
  
, its opposite 
  
    
      
        â
        
          Î»
          
            i
          
        
        =
        
          Î»
          
            n
            +
            1
            â
            i
          
        
      
    
    {\displaystyle -\lambda _{i}=\lambda _{n+1-i}}
  
 is also an eigenvalue of A if G is a bipartite graph.[8] In particular âd is an eigenvalue of bipartite graphs.
The difference 
  
    
      
        
          Î»
          
            1
          
        
        â
        
          Î»
          
            2
          
        
      
    
    {\displaystyle \lambda _{1}-\lambda _{2}}
  
 is called the spectral gap and it is related to the expansion of G. It is also useful to introduce the spectral radius of 
  
    
      
        A
      
    
    {\displaystyle A}
  
 denoted by 
  
    
      
        Î»
        (
        G
        )
        =
        
          max
          
            
              |
              
                Î»
                
                  i
                
              
              |
            
            <
            d
          
        
        
          |
        
        
          Î»
          
            i
          
        
        
          |
        
      
    
    {\displaystyle \lambda (G)=\max _{\left|\lambda _{i}\right|<d}|\lambda _{i}|}
  
. This number is bounded by 
  
    
      
        Î»
        (
        G
        )
        â¥
        2
        
          
            d
            â
            1
          
        
        â
        o
        (
        1
        )
      
    
    {\displaystyle \lambda (G)\geq 2{\sqrt {d-1}}-o(1)}
  
. This bound is tight in the Ramanujan graphs, which have applications in many areas.

Isomorphism and invariants[edit]
Suppose two directed or undirected graphs G1 and G2 with adjacency matrices A1 and A2 are given. G1 and G2 are isomorphic if and only if there exists a permutation matrix P such that


  
    
      
        P
        
          A
          
            1
          
        
        
          P
          
            â
            1
          
        
        =
        
          A
          
            2
          
        
        .
      
    
    {\displaystyle PA_{1}P^{-1}=A_{2}.}
  

In particular, A1 and A2 are similar and therefore have the same minimal polynomial, characteristic polynomial, eigenvalues, determinant and trace. These can therefore serve as isomorphism invariants of graphs. However, two graphs may possess the same set of eigenvalues but not be isomorphic.[9] Such linear operators are said to be isospectral.

Matrix powers[edit]
If A is the adjacency matrix of the directed or undirected graph G, then the matrix An (i.e., the matrix product of n copies of A) has an interesting interpretation: the element (i, j) gives the number of (directed or undirected) walks of length n from vertex i to vertex j. If n is the smallest nonnegative integer, such that for some i, j, the element (i, j) of An is positive, then n is the distance between vertex i and vertex j. This implies, for example, that the number of triangles in an undirected graph G is exactly the trace of A3 divided by 6. The adjacency matrix can be used to determine whether or not the graph is connected.

Data structures[edit]
The adjacency matrix may be used as a data structure for the representation of graphs in computer programs for manipulating graphs. The main alternative data structure, also in use for this application, is the adjacency list.[10][11]
Because each entry in the adjacency matrix requires only one bit, it can be represented in a very compact way, occupying only |Vâ|2â/â8 bytes to represent a directed graph, or (by using a packed triangular format and only storing the lower triangular part of the matrix) approximately |Vâ|2â/â16 bytes to represent an undirected graph. Although slightly more succinct representations are possible, this method gets close to the information-theoretic lower bound for the minimum number of bits needed to represent all n-vertex graphs.[12] For storing graphs in text files, fewer bits per byte can be used to ensure that all bytes are text characters, for instance by using a Base64 representation.[13] Besides avoiding wasted space, this compactness encourages locality of reference.
However, for a large sparse graph, adjacency lists require less storage space, because they do not waste any space to represent edges that are not present.[11][14]
An alternative form of adjacency matrix (which, however, requires a larger amount of space) replaces the numbers in each element of the matrix with pointers to edge objects (when edges are present) or null pointers (when there is no edge).[14] It is also possible to store edge weights directly in the elements of an adjacency matrix.[11]
Besides the space tradeoff, the different data structures also facilitate different operations. Finding all vertices adjacent to a given vertex in an adjacency list is as simple as reading the list, and takes time proportional to the number of neighbors. With an adjacency matrix, an entire row must instead be scanned, which takes a larger amount of time, proportional to the number of vertices in the whole graph. On the other hand, testing whether there is an edge between two given vertices can be determined at once with an adjacency matrix, while requiring time proportional to the minimum degree of the two vertices with the adjacency list.[11][14]

See also[edit]
Laplacian matrix
Self-similarity matrix
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Biggs, Norman (1993), Algebraic Graph Theory, Cambridge Mathematical Library (2ndÂ ed.), Cambridge University Press, Definition 2.1, p.Â 7.

^ Harary, Frank (1962), "The determinant of the adjacency matrix of a graph", SIAM Review, 4 (3): 202â210, Bibcode:1962SIAMR...4..202H, doi:10.1137/1004057, MRÂ 0144330.

^ Seidel, J. J. (1968). "Strongly Regular Graphs with (â1, 1, 0) Adjacency Matrix Having Eigenvalue 3". Lin. Alg. Appl. 1 (2): 281â298. doi:10.1016/0024-3795(68)90008-6.

^ Shum, Kenneth; Blake, Ian (2003-12-18). "Expander graphs and codes". Volume 68 of DIMACS series in discrete mathematics and theoretical computer science. Algebraic Coding Theory and Information Theory: DIMACS Workshop, Algebraic Coding Theory and Information Theory. American Mathematical Society. p.Â 63. ISBNÂ 9780821871102.

^ 
Borgatti, Steve; Everett, Martin; Johnson, Jeffrey (2018), Analyzing Social Networks (2ndÂ ed.), SAGE, p.Â 20

^ 
Newman, Mark (2018), Networks (2ndÂ ed.), Oxford University Press, p.Â 110

^ Biggs (1993), Chapter 2 ("The spectrum of a graph"), pp.Â 7â13.

^ Brouwer, Andries E.; Haemers, Willem H. (2012), "1.3.6 Bipartite graphs", Spectra of Graphs, Universitext, New York: Springer, pp.Â 6â7, doi:10.1007/978-1-4614-1939-6, ISBNÂ 978-1-4614-1938-9, MRÂ 2882891

^ Godsil, Chris; Royle, Gordon Algebraic Graph Theory, Springer (2001), ISBNÂ 0-387-95241-1, p.164

^ Goodrich & Tamassia (2015), p.Â 361: "There are two data structures that people often use to represent graphs, the adjacency list and the adjacency matrix."

^ Jump up to: a b c d Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2001), "Section 22.1: Representations of graphs", Introduction to Algorithms (SecondÂ ed.), MIT Press and McGraw-Hill, pp.Â 527â531, ISBNÂ 0-262-03293-7.

^ TurÃ¡n, GyÃ¶rgy (1984), "On the succinct representation of graphs", Discrete Applied Mathematics, 8 (3): 289â294, doi:10.1016/0166-218X(84)90126-4, MRÂ 0749658.

^ McKay, Brendan, Description of graph6 and sparse6 encodings.

^ Jump up to: a b c Goodrich, Michael T.; Tamassia, Roberto (2015), Algorithm Design and Applications, Wiley, p.Â 363.


External links[edit]



Wikimedia Commons has media related to Adjacency matrices of graphs.

Weisstein, Eric W. "Adjacency matrix". MathWorld.
Fluffschack â an educational Java web start game demonstrating the relationship between adjacency matrices and graphs.
Open Data Structures - Section 12.1 - AdjacencyMatrix: Representing a Graph by a Matrix, Pat Morin
CafÃ© mathÂ : Adjacency Matrices of GraphsÂ : Application of the adjacency matrices to the computation generating series of walks.
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}show.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteGraph representationsData structures
Graph (abstract data type)
Adjacency list
Edge list
Adjacency matrix
Incidence matrix
XML-based formats
DGML
DotML
GEXF
GraphML
GXL
XGMML
Text-based formats
DOT
Graph Modelling Language (GML)
LCF notation for cubic Hamiltonian graphs
Newick format for trees
Trivial Graph Format
Related concepts
Graph database
Graph drawing
Linked data

showvteMatrix classesExplicitly constrained entries
Alternant
Anti-diagonal
Anti-Hermitian
Anti-symmetric
Arrowhead
Band
Bidiagonal
Bisymmetric
Block-diagonal
Block
Block tridiagonal
Boolean
Cauchy
Centrosymmetric
Conference
Complex Hadamard
Copositive
Diagonally dominant
Diagonal
Discrete Fourier Transform
Elementary
Equivalent
Frobenius
Generalized permutation
Hadamard
Hankel
Hermitian
Hessenberg
Hollow
Integer
Logical
Matrix unit
Metzler
Moore
Nonnegative
Pentadiagonal
Permutation
Persymmetric
Polynomial
Quaternionic
Signature
Skew-Hermitian
Skew-symmetric
Skyline
Sparse
Sylvester
Symmetric
Toeplitz
Triangular
Tridiagonal
Unitary
Vandermonde
Walsh
Z
Constant
Exchange
Hilbert
Identity
Lehmer
Of ones
Pascal
Pauli
Redheffer
Shift
Zero
Conditions on eigenvalues or eigenvectors
Companion
Convergent
Defective
Diagonalizable
Hurwitz
Positive-definite
Stieltjes
Satisfying conditions on products or inverses
Congruent
Idempotent or Projection
Invertible
Involutory
Nilpotent
Normal
Orthogonal
Unimodular
Unipotent
Totally unimodular
Weighing
With specific applications
Adjugate
Alternating sign
Augmented
BÃ©zout
Carleman
Cartan
Circulant
Cofactor
Commutation
Confusion
Coxeter
Distance
Duplication and elimination
Euclidean distance
Fundamental (linear differential equation)
Generator
Gram
Hessian
Householder
Jacobian
Moment
Payoff
Pick
Random
Rotation
Seifert
Shear
Similarity
Symplectic
Totally positive
Transformation
Used in statistics
Centering
Correlation
Covariance
Design
Doubly stochastic
Fisher information
Hat
Precision
Stochastic
Transition
Used in graph theory
Adjacency
Biadjacency
Degree
Edmonds
Incidence
Laplacian
Seidel adjacency
Tutte
Used in science and engineering
CabibboâKobayashiâMaskawa
Density
Fundamental (computer vision)
Fuzzy associative
Gamma
Gell-Mann
Hamiltonian
Irregular
Overlap
S
State transition
Substitution
Z (chemistry)
Related terms
Jordan normal form
Linear independence
Matrix exponential
Matrix representation of conic sections
Perfect matrix
Pseudoinverse
Row echelon form
Wronskian

List of matrices
Category:Matrices

Authority control 
Integrated Authority File (Germany)





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Adjacency_matrix&oldid=1063132659"
		Categories: Algebraic graph theoryMatricesGraph data structuresHidden categories: Articles with short descriptionShort description matches WikidataCommons category link is on WikidataArticles with GND identifiers
	
