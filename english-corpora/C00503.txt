
Title:
Evolutionary algorithm
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Part of a series on theEvolutionary algorithm
Artificial development
Artificial life
Cellular evolutionary algorithm
Cultural algorithm
Differential evolution
Effective fitness
Evolutionary computation
Evolution strategy
Gaussian adaptation
Evolutionary multimodal optimization
Particle swarm optimization
Memetic algorithm
Natural evolution strategy
Neuroevolution
Promoter based genetic algorithm
Spiral optimization algorithm
Self-modifying code
Polymorphic code

Genetic algorithm
Chromosome
Clonal selection algorithm
Crossover
Mutation
Genetic memory
Genetic fuzzy systems
Selection
Fly algorithm

Genetic programming
Cartesian genetic programming
Linear genetic programming
Grammatical evolution
Multi expression programming
Genetic Improvement
Schema
Eurisko
Parity benchmark
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
Part of a series onArtificial intelligence
showMajor goals
Artificial general intelligence
Planning
Computer vision
General game playing
Knowledge reasoning
Machine learning
Natural language processing
Robotics

hideApproaches
Symbolic
Deep learning
Bayesian networks
Evolutionary algorithms

showPhilosophy
Chinese room
Friendly AI
Control problem/Takeover
Ethics
Existential risk
Turing test

showHistory
Timeline
Progress
AI winter

showTechnology
Applications
Projects
Programming languages

showGlossary
Glossary
vte
In computational intelligence (CI), an evolutionary algorithm (EA) is a subset of evolutionary computation,[1] a generic population-based metaheuristic optimization algorithm. An EA uses mechanisms inspired by biological evolution, such as reproduction, mutation, recombination, and selection. Candidate solutions to the optimization problem play the role of individuals in a population, and the fitness function determines the quality of the solutions (see also loss function). Evolution of the population then takes place after the repeated application of the above operators.
Evolutionary algorithms often perform well approximating solutions to all types of problems because they ideally do not make any assumption about the underlying fitness landscape. Techniques from evolutionary algorithms applied to the modeling of biological evolution are generally limited to explorations of microevolutionary processes and planning models based upon cellular processes. In most real applications of EAs, computational complexity is a prohibiting factor.[2] In fact, this computational complexity is due to fitness function evaluation. Fitness approximation is one of the solutions to overcome this difficulty. However, seemingly simple EA can solve often complex problems;[citation needed] therefore, there may be no direct link between algorithm complexity and problem complexity.

Contents

1 Implementation
2 Types
3 Comparison to biological processes
4 Related techniques
5 Other population-based metaheuristic methods
6 Examples
7 Gallery
8 References
9 External links
10 Bibliography



Implementation[edit]
The following is an example of a generic single-objective genetic algorithm.
Step One: Generate the initial population of individuals randomly. (First generation)
Step Two: Repeat the following regenerational steps until termination:

Evaluate the fitness of each individual in the population (time limit, sufficient fitness achieved, etc.)
Select the fittest individuals for reproduction. (Parents)
Breed new individuals through crossover and mutation operations to give birth to offspring.
Replace the least-fit individuals of the population with new individuals.
Types[edit]
Similar techniques differ in genetic representation and other implementation details, and the nature of the particular applied problem.

Genetic algorithm â This is the most popular type of EA. One seeks the solution of a problem in the form of strings of numbers (traditionally binary, although the best representations are usually those that reflect something about the problem being solved),[2] by applying operators such as recombination and mutation (sometimes one, sometimes both).  This type of EA is often used in optimization problems.
Genetic programming â Here the solutions are in the form of computer programs, and their fitness is determined by their ability to solve a computational problem. There are many variants of Genetic Programming, including Cartesian genetic programming, Gene expression programming, Grammatical Evolution, Linear genetic programming, Multi expression programming etc.
Evolutionary programming â Similar to genetic programming, but the structure of the program is fixed and its numerical parameters are allowed to evolve.
Evolution strategy â Works with vectors of real numbers as representations of solutions, and typically uses self-adaptive mutation rates.
Differential evolution â Based on vector differences and is therefore primarily suited for numerical optimization problems.
Neuroevolution â Similar to genetic programming but the genomes represent artificial neural networks by describing structure and connection weights. The genome encoding can be direct or indirect.
Learning classifier system â Here the solution is a set of classifiers (rules or conditions). A Michigan-LCS evolves at the level of individual classifiers whereas a Pittsburgh-LCS uses populations of classifier-sets. Initially, classifiers were only binary, but now include real, neural net, or S-expression types. Fitness is typically determined with either a strength or accuracy based reinforcement learning or supervised learning approach.
Comparison to biological processes[edit]
A possible limitation[according to whom?] of many evolutionary algorithms is their lack of a clear genotypeâphenotype distinction. In nature, the fertilized egg cell undergoes a complex process known as embryogenesis to become a mature phenotype. This indirect encoding is believed to make the genetic search more robust (i.e. reduce the probability of fatal mutations), and also may improve the evolvability of the organism.[3][4] Such indirect (also known as generative or developmental) encodings also enable evolution to exploit the regularity in the environment.[5] Recent work in the field of artificial embryogeny, or artificial developmental systems, seeks to address these concerns. And gene expression programming successfully explores a genotypeâphenotype system, where the genotype consists of linear multigenic chromosomes of fixed length and the phenotype consists of multiple expression trees or computer programs of different sizes and shapes.[6][improper synthesis?]

Related techniques[edit]
Swarm algorithms[clarification needed] include:

Ant colony optimization is based on the ideas of ant foraging by pheromone communication to form paths.[7] Primarily suited for combinatorial optimization and graph problems.
The runner-root algorithm (RRA) is inspired by the function of runners and roots of plants in nature.[8]
Artificial bee colony algorithm is based on the honey bee foraging behaviour. Primarily proposed for numerical optimization and extended to solve combinatorial, constrained and multi-objective optimization problems.
Bees algorithm is based on the foraging behaviour of honey bees. It has been applied in many applications such as routing and scheduling.
Cuckoo search is inspired by the brooding parasitism of the cuckoo species. It also uses LÃ©vy flights, and thus it suits for global optimization problems.
Particle swarm optimization is based on the ideas of animal flocking behaviour.[7] Also primarily suited for numerical optimization problems.
Other population-based metaheuristic methods[edit]
Hunting Search â A method inspired by the group hunting of some animals such as wolves that organize their position to surround the prey, each of them relative to the position of the others and especially that of their leader. It is a continuous optimization method[9] adapted as a combinatorial optimization method.[10]
Adaptive dimensional search â Unlike nature-inspired metaheuristic techniques, an adaptive dimensional search algorithm does not implement any metaphor as an underlying principle. Rather it uses a simple performance-oriented method, based on the update of the search dimensionality ratio (SDR) parameter at each iteration.[11]
Firefly algorithm is inspired by the behavior of fireflies, attracting each other by flashing light. This is especially useful for multimodal optimization.
Harmony search â Based on the ideas of musicians' behavior in searching for better harmonies. This algorithm is suitable for combinatorial optimization as well as parameter optimization.
Gaussian adaptation â Based on information theory. Used for maximization of manufacturing yield, mean fitness or average information. See for instance Entropy in thermodynamics and information theory.
Memetic algorithm â A hybrid method, inspired by Richard Dawkins's notion of a meme, it commonly takes the form of a population-based algorithm coupled with individual learning procedures capable of performing local refinements. Emphasizes the exploitation of problem-specific knowledge, and tries to orchestrate local and global search in a synergistic way.
Examples[edit]
In 2020, Google stated that their AutoML-Zero can successfully rediscover classic algorithms such as the concept of neural networks.[12]
The computer simulations Tierra and Avida attempt to model macroevolutionary dynamics.

Gallery[edit]
[13]
[14]
[15]


		
			
			
A two-population EA search over a constrained Rosenbrock function with bounded global optimum.

			
		
		
			
			
A two-population EA search over a constrained Rosenbrock function. Global optimum is not bounded.

			
		
		
			
			
Estimation of distribution algorithm over Keane's function

			
		
		
			
			
A two-population EA search of a bounded optima of Simionescu's function.

			
		

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Vikhar, P. A. (2016). "Evolutionary algorithms: A critical review and its future prospects". Proceedings of the 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Jalgaon: 261â265. doi:10.1109/ICGTSPICC.2016.7955308. ISBNÂ 978-1-5090-0467-6. S2CIDÂ 22100336.

^ Jump up to: a b Cohoon, J;  etÂ al. (2002-11-26). Evolutionary algorithms for the physical design of VLSI circuits (PDF). Advances in Evolutionary Computing: Theory and Applications. Springer, pp. 683-712, 2003. ISBNÂ 978-3-540-43330-9.

^ G.S. Hornby and J.B. Pollack. "Creating high-level components with a generative representation for body-brain evolution". Artificial Life, 8(3):223â246, 2002.

^ Jeff Clune, Benjamin Beckmann, Charles Ofria, and Robert Pennock. "Evolving Coordinated Quadruped Gaits with the HyperNEAT Generative Encoding" Archived 2016-06-03 at the Wayback Machine. Proceedings of the IEEE Congress on Evolutionary Computing Special Section on Evolutionary Robotics, 2009. Trondheim, Norway.

^ J. Clune, C. Ofria, and R. T. Pennock, "How a generative encoding fares as problem-regularity decreases", in PPSN (G. Rudolph, T. Jansen, S. M. Lucas, C. Poloni, and N. Beume, eds.), vol. 5199 of Lecture Notes in Computer Science, pp. 358â367, Springer, 2008.

^ Ferreira, C., 2001. "Gene Expression Programming: A New Adaptive Algorithm for Solving Problems". Complex Systems, Vol. 13, issue 2: 87â129.

^ Jump up to: a b Slowik, Adam; Kwasnicka, Halina (2018). "Nature Inspired Methods and Their Industry ApplicationsâSwarm Intelligence Algorithms". IEEE Transactions on Industrial Informatics. Institute of Electrical and Electronics Engineers (IEEE). 14 (3): 1004â1015. doi:10.1109/tii.2017.2786782. ISSNÂ 1551-3203. S2CIDÂ 3707290.

^ F. Merrikh-Bayat, "The runner-root algorithm: A metaheuristic for solving unimodal and multimodal optimization problems inspired by runners and roots of plants in nature", Applied Soft Computing, Vol. 33, pp. 292â303, 2015

^ Oftadeh, R.; Mahjoob, M.J.; Shariatpanahi, M. (October 2010). "A novel meta-heuristic optimization algorithm inspired by group hunting of animals: Hunting search". Computers & Mathematics with Applications. 60 (7): 2087â2098. doi:10.1016/j.camwa.2010.07.049.

^ Amine Agharghor; Mohammed Essaid Riffi (2017). "First Adaptation of Hunting Search Algorithm for the Quadratic Assignment Problem". Europe and MENA Cooperation Advances in Information and Communication Technologies. Advances in Intelligent Systems and Computing. 520: 263â267. doi:10.1007/978-3-319-46568-5_27. ISBNÂ 978-3-319-46567-8.

^ HasanÃ§ebi, O., Kazemzadeh Azad, S. (2015), "Adaptive Dimensional Search: A New Metaheuristic Algorithm for Discrete Truss Sizing Optimization", Computers and Structures, 154, 1â16.

^ Gent, Edd (13 April 2020). "Artificial intelligence is evolving all by itself". Science | AAAS. Archived from the original on 16 April 2020. Retrieved 16 April 2020.

^ Simionescu, P.A.; Beale, D.G.; Dozier, G.V. (2004). "Constrained optimization problem solving using estimation of distribution algorithms" (PDF). Proc. of the 2004 Congress on Evolutionary Computation - CEC2004. Portland, OR: 1647â1653. doi:10.1109/CEC.2006.1688506. S2CIDÂ 1717817. Retrieved 7 January 2017. {{cite journal}}: Cite journal requires |journal= (help)

^ Simionescu, P.A.; Dozier, G.V.; Wainwright, R.L. (2006). "A Two-Population Evolutionary Algorithm for Constrained Optimization Problems" (PDF). 2006 IEEE International Conference on Evolutionary Computation. Proc 2006 IEEE International Conference on Evolutionary Computation. Vancouver, Canada. pp.Â 1647â1653. doi:10.1109/CEC.2006.1688506. ISBNÂ 0-7803-9487-9. S2CIDÂ 1717817. Retrieved 7 January 2017.

^ Simionescu, P.A. (2014). Computer Aided Graphing and Simulation Tools for AutoCAD Users (1stÂ ed.). Boca Raton, FL: CRC Press. ISBNÂ 978-1-4822-5290-3.


External links[edit]
An Overview of the History and Flavors of Evolutionary Algorithms
Bibliography[edit]
Ashlock, D. (2006), Evolutionary Computation for Modeling and Optimization, Springer, ISBNÂ 0-387-22196-4.
BÃ¤ck, T. (1996), Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms, Oxford Univ. Press.
BÃ¤ck, T., Fogel, D., Michalewicz, Z. (1997), Handbook of Evolutionary Computation, Oxford Univ. Press.
Banzhaf, W., Nordin, P., Keller, R., Francone, F. (1998), Genetic Programming - An Introduction, Morgan Kaufmann, San Francisco
Eiben, A.E., Smith, J.E. (2003), Introduction to Evolutionary Computing, Springer.
Holland, J. H. (1992), Adaptation in Natural and Artificial Systems, The University of Michigan Press, Ann Arbor
Michalewicz Z., Fogel D.B. (2004). How To Solve It: Modern Heuristics, Springer.
Benko, Attila; Dosa, Gyorgy; Tuza, Zsolt (2010). "Bin Packing/Covering with Delivery, solved with the evolution of algorithms". 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA). pp.Â 298â302. doi:10.1109/BICTA.2010.5645312. ISBNÂ 978-1-4244-6437-1. S2CIDÂ 16875144.
Poli, R.; Langdon, W. B.; McPhee, N. F. (2008). A Field Guide to Genetic Programming. Lulu.com, freely available from the internet. ISBNÂ 978-1-4092-0073-4. Archived from the original on 2016-05-27. Retrieved 2011-03-05.[self-published source]
Price, K., Storn, R.M., Lampinen, J.A., (2005). "Differential Evolution: A Practical Approach to Global Optimization", Springer.
Ingo Rechenberg (1971): Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD thesis). Reprinted by Fromman-Holzboog (1973).
Hans-Paul Schwefel (1974): Numerische Optimierung von Computer-Modellen (PhD thesis). Reprinted by BirkhÃ¤user (1977).
Simon, D. (2013): Evolutionary Optimization Algorithms, Wiley.
Computational Intelligence: A Methodological Introduction by Kruse, Borgelt, Klawonn, Moewes, Steinbrecher, Held, 2013, Springer, ISBNÂ 978-1-4471-5012-1
Rahman, Rosshairy Abd.; Kendall, Graham; Ramli, Razamin; Jamari, Zainoddin; Ku-Mahamud, Ku Ruhana (2017). "Shrimp Feed Formulation via Evolutionary Algorithm with Power Heuristics for Handling Constraints". Complexity. 2017: 1â12. doi:10.1155/2017/7053710.




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Evolutionary_algorithm&oldid=1066200544"
		Categories: CyberneticsEvolutionEvolutionary algorithmsOptimization algorithms and methodsHidden categories: Webarchive template wayback linksCS1 errors: missing periodicalAll articles with unsourced statementsArticles with unsourced statements from June 2018All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from May 2013Articles that may contain original research from May 2013Wikipedia articles needing clarification from January 2018
	
