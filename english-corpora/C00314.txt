
Title:
Automata theory
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Study of abstract machines and automata



Classes of automata (Clicking on each layer gets an article on that subject)  The automaton described by this state diagram starts in state S1, and changes states following the arrows marked 0 or 1 according to the input symbols as they arrive. The double circle marks S1 as an accepting state. Since all paths from S1 to itself contain an even number of arrows marked 0, this automaton accepts strings containing even numbers of 0s.Automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science. The word automata comes from the Greek word Î±á½ÏÏÎ¼Î±ÏÎ¿Ï, which means "self-acting, self-willed, self-moving". An automaton (Automata in plural) is an abstract self-propelled computing device which follows a predetermined sequence of operations automatically. An automaton with a finite number of states is called a Finite Automaton (FA) or Finite-State Machine (FSM).
The figure at right illustrates a finite-state machine, which belongs to a well-known type of automaton.  This automaton consists of states (represented in the figure by circles) and transitions (represented by arrows).  As the automaton sees a symbol of input, it makes a transition (or jump) to another state, according to its transition function, which takes the previous state and current input symbol as its arguments.
Automata theory is closely related to formal language theory. In this context, automata are used as finite representations of formal languages that may be infinite. Automata are often classified by the class of formal languages they can recognize, as in the Chomsky hierarchy, which describes a nesting relationship between major classes of automata. Automata play a major role in theory of computation, compiler construction, artificial intelligence, parsing and formal verification.

Contents

1 History
2 Automata

2.1 Informal description
2.2 Formal definition


3 Variant definitions of automata
4 Classes of automata

4.1 Discrete, continuous, and hybrid automata


5 Hierarchy in terms of powers
6 Applications
7 Automata simulators
8 Connection to category theory
9 See also
10 References
11 Further reading
12 External links



History[edit]
The theory of abstract automata was developed in the mid-20th century in connection with finite automata.[1] Automata theory was initially considered a branch of mathematical systems theory, studying the behavior of discrete-parameter systems. Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems.[2] The theory of the finite-state transducer was developed under different names by different research communities.[3] The earlier concept of Turing machines were also included in the discipline along with new forms of infinite-state automaton, such as pushdown automata.
1956 saw the publication of Automata Studies, which collected work by scientists including Claude Shannon, W. Ross Ashby, John von Neumann, Marvin Minsky, Edward F. Moore, and Stephen Cole Kleene.[4] With the publication of this volume, "automata theory emerged as a relatively autonomous discipline".[5] The book included Kleene's description of the set of regular events, or regular languages, and a relatively stable measure of complexity in Turing machine programs by Shannon.[6] 
In the same year, Noam Chomsky described the Chomsky hierarchy, a correspondence between automata and formal grammars,[7] and Ross Ashby published An Introduction to Cybernetics, an accessible textbook explaining automata and information using basic set theory.
The study of linear automata[specify] led to the Myhill-Nerode theorem,[8] which gives a necessary and sufficient condition for a formal language to be regular, and an exact count of the number of states in a minimal machine for the language. The pumping lemma for regular languages, also useful in regularity proofs, was proven in this period by Michael O. Rabin and Dana Scott, along with the computational equivalence of deterministic and nondeterministic finite automata.[9] 
In the 1960s, a body of algebraic results known as "structure theory" or "algebraic decomposition theory" emerged, which dealt with the realization of sequential machines from smaller machines by interconnection.[10] While any finite automaton can be simulated using a  universal gate set, this requires that the simulating circuit contain loops of arbitrary complexity. Structure theory deals with the "loop-free" realizability of machines.[5]
The theory of computational complexity also took shape in the 1960s.[11][12] By the end of the decade, automata theory came to be seen as "the pure mathematics of computer science".[5]

Automata[edit]
What follows is a general definition of automaton, which restricts a broader definition of system to one viewed as acting in discrete time-steps, with its state behavior and outputs defined at each step by unchanging functions of only its state and input.[5]

Informal description[edit]
An automaton runs when it is given some sequence of inputs in discrete (individual) time steps or steps. An automaton processes one input picked from a set of symbols or letters, which is called an input alphabet. The symbols received by the automaton as input at any step are a sequence of symbols called words. An automaton has a set of states. At each moment during a run of the automaton, the automaton is in one of its states. When the automaton receives new input it moves to another state (or transitions) based on a transition function that takes the previous state and current input symbol as parameters. At the same time, another function called the output function produces symbols from the output alphabet, also according to the previous state and current input symbol. The automaton reads the symbols of the input word and transitions between states until the word is read completely, if it is finite in length, at which point the automaton halts. A state at which the automaton halts is called the final state.
To investigate the possible state/input/output sequences in an automaton using formal language theory, a machine can be assigned a starting state and a set of accepting states. Then, depending on whether a run starting from the starting state ends in an accepting state, the automaton can be said to accept or reject an input sequence. The set of all the words accepted by an automaton is called the language recognized by the automaton. A familiar example of a machine recognizing a language is an electronic lock which accepts or rejects attempts to enter the correct code.

Formal definition[edit]
Automaton
An automaton can be represented formally by a 5-tuple 
  
    
      
        M
        =
        â¨
        Î£
        ,
        Î
        ,
        Q
        ,
        Î´
        ,
        Î»
        â©
      
    
    {\displaystyle M=\langle \Sigma ,\Gamma ,Q,\delta ,\lambda \rangle }
  
, where:

  
    
      
        Î£
      
    
    {\displaystyle \Sigma }
  
 is a finite set of symbols, called the input alphabet of the automaton,

  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
 is another finite set of symbols, called the output alphabet of the automaton,

  
    
      
        Q
      
    
    {\displaystyle Q}
  
 is a set of states,

  
    
      
        Î´
      
    
    {\displaystyle \delta }
  
 is the next-state function or transition function 
  
    
      
        Î´
        :
        Q
        Ã
        Î£
        â
        Q
      
    
    {\displaystyle \delta :Q\times \Sigma \to Q}
  
 mapping state-input pairs to successor states,

  
    
      
        Î»
      
    
    {\displaystyle \lambda }
  
 is the next-output function 
  
    
      
        Î»
        :
        Q
        Ã
        Î£
        â
        Î
      
    
    {\displaystyle \lambda :Q\times \Sigma \to \Gamma }
  
 mapping state-input pairs to outputs.
If 
  
    
      
        Q
      
    
    {\displaystyle Q}
  
 is finite, then 
  
    
      
        M
      
    
    {\displaystyle M}
  
 is a finite automaton.[5]
Input word
An automaton reads a finite string of symbols 
  
    
      
        
          a
          
            1
          
        
        
          a
          
            2
          
        
        .
        .
        .
        
          a
          
            n
          
        
      
    
    {\displaystyle a_{1}a_{2}...a_{n}}
  
, where 
  
    
      
        
          a
          
            i
          
        
        â
        Î£
      
    
    {\displaystyle a_{i}\in \Sigma }
  
, which is called an input word. The set of all words is denoted by 
  
    
      
        
          Î£
          
            â
          
        
      
    
    {\displaystyle \Sigma ^{*}}
  
.
Run
A sequence of states 
  
    
      
        
          q
          
            0
          
        
        ,
        
          q
          
            1
          
        
        ,
        .
        .
        .
        
          q
          
            n
          
        
      
    
    {\displaystyle q_{0},q_{1},...q_{n}}
  
, where 
  
    
      
        
          q
          
            i
          
        
        â
        Q
      
    
    {\displaystyle q_{i}\in Q}
  
 such that 
  
    
      
        
          q
          
            i
          
        
        =
        Î´
        (
        
          q
          
            i
            â
            1
          
        
        ,
        
          a
          
            i
          
        
        )
      
    
    {\displaystyle q_{i}=\delta (q_{i-1},a_{i})}
  
 for 
  
    
      
        0
        <
        i
        â¤
        n
      
    
    {\displaystyle 0<i\leq n}
  
, is a run of the automaton on an input 
  
    
      
        
          a
          
            1
          
        
        
          a
          
            2
          
        
        .
        .
        .
        
          a
          
            n
          
        
        â
        
          Î£
          
            â
          
        
      
    
    {\displaystyle a_{1}a_{2}...a_{n}\in \Sigma ^{*}}
  
 starting from state 
  
    
      
        
          q
          
            0
          
        
      
    
    {\displaystyle q_{0}}
  
. In other words, at first the automaton is at the start state 
  
    
      
        
          q
          
            0
          
        
      
    
    {\displaystyle q_{0}}
  
, and receives input 
  
    
      
        
          a
          
            1
          
        
      
    
    {\displaystyle a_{1}}
  
. For 
  
    
      
        
          a
          
            1
          
        
      
    
    {\displaystyle a_{1}}
  
 and every following 
  
    
      
        
          a
          
            i
          
        
      
    
    {\displaystyle a_{i}}
  
 in the input string, the automaton picks the next state 
  
    
      
        
          q
          
            i
          
        
      
    
    {\displaystyle q_{i}}
  
 according to the transition function 
  
    
      
        Î´
        (
        
          q
          
            i
            â
            1
          
        
        ,
        
          a
          
            i
          
        
        )
      
    
    {\displaystyle \delta (q_{i-1},a_{i})}
  
, until the last symbol 
  
    
      
        
          a
          
            n
          
        
      
    
    {\displaystyle a_{n}}
  
 has been read, leaving the machine in the final state of the run, 
  
    
      
        
          q
          
            n
          
        
      
    
    {\displaystyle q_{n}}
  
. Similarly, at each step, the automaton emits an output symbol according to the output function 
  
    
      
        Î»
        (
        
          q
          
            i
            â
            1
          
        
        ,
        
          a
          
            i
          
        
        )
      
    
    {\displaystyle \lambda (q_{i-1},a_{i})}
  
.
The transition function 
  
    
      
        Î´
      
    
    {\displaystyle \delta }
  
 is extended inductively into 
  
    
      
        
          
            Î´
            Â¯
          
        
        :
        Q
        Ã
        
          Î£
          
            â
          
        
        â
        Q
      
    
    {\displaystyle {\overline {\delta }}:Q\times \Sigma ^{*}\to Q}
  
 to describe the machine's behavior when fed whole input words. For the empty string 
  
    
      
        Îµ
      
    
    {\displaystyle \varepsilon }
  
, 
  
    
      
        
          
            Î´
            Â¯
          
        
        (
        q
        ,
        Îµ
        )
        =
        q
      
    
    {\displaystyle {\overline {\delta }}(q,\varepsilon )=q}
  
 for all states 
  
    
      
        q
      
    
    {\displaystyle q}
  
, and for strings 
  
    
      
        w
        a
      
    
    {\displaystyle wa}
  
 where 
  
    
      
        a
      
    
    {\displaystyle a}
  
 is the last symbol and 
  
    
      
        w
      
    
    {\displaystyle w}
  
 is the (possibly empty) rest of the string, 
  
    
      
        
          
            Î´
            Â¯
          
        
        (
        q
        ,
        w
        a
        )
        =
        Î´
        (
        
          
            Î´
            Â¯
          
        
        (
        q
        ,
        w
        )
        ,
        a
        )
      
    
    {\displaystyle {\overline {\delta }}(q,wa)=\delta ({\overline {\delta }}(q,w),a)}
  
.[10] The output function 
  
    
      
        Î»
      
    
    {\displaystyle \lambda }
  
 may be extended similarly into 
  
    
      
        
          
            Î»
            Â¯
          
        
        (
        q
        ,
        w
        )
      
    
    {\displaystyle {\overline {\lambda }}(q,w)}
  
, which gives the complete output of the machine when run on word 
  
    
      
        w
      
    
    {\displaystyle w}
  
 from state 
  
    
      
        q
      
    
    {\displaystyle q}
  
.
Acceptor
In order to study an automaton with the theory of formal languages, an automaton may be considered as an acceptor, replacing the output alphabet and function 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
 and 
  
    
      
        Î»
      
    
    {\displaystyle \lambda }
  
 with

  
    
      
        
          q
          
            0
          
        
        â
        Q
      
    
    {\displaystyle q_{0}\in Q}
  
, a designated start state, and

  
    
      
        F
      
    
    {\displaystyle F}
  
, a set of states of 
  
    
      
        Q
      
    
    {\displaystyle Q}
  
 (i.e. 
  
    
      
        F
        â
        Q
      
    
    {\displaystyle F\subseteq Q}
  
) called accept states.
This allows the following to be defined:
Accepting word
A word 
  
    
      
        w
        =
        
          a
          
            1
          
        
        
          a
          
            2
          
        
        .
        .
        .
        
          a
          
            n
          
        
        â
        
          Î£
          
            â
          
        
      
    
    {\displaystyle w=a_{1}a_{2}...a_{n}\in \Sigma ^{*}}
  
 is an accepting word for the automaton if 
  
    
      
        
          
            Î´
            Â¯
          
        
        (
        
          q
          
            0
          
        
        ,
        w
        )
        â
        F
      
    
    {\displaystyle {\overline {\delta }}(q_{0},w)\in F}
  
, that is, if after consuming the whole string 
  
    
      
        w
      
    
    {\displaystyle w}
  
 the machine is in an accept state.
Recognized language
The language 
  
    
      
        L
        â
        
          Î£
          
            â
          
        
      
    
    {\displaystyle L\subseteq \Sigma ^{*}}
  
 recognized by an automaton is the set of all the words that are accepted by the automaton, 
  
    
      
        L
        =
        {
        w
        â
        
          Î£
          
            â
          
        
        Â 
        
          |
        
        Â 
        
          
            Î´
            Â¯
          
        
        (
        
          q
          
            0
          
        
        ,
        w
        )
        â
        F
        }
      
    
    {\displaystyle L=\{w\in \Sigma ^{*}\ |\ {\overline {\delta }}(q_{0},w)\in F\}}
  
.[13]
Recognizable languages
The recognizable languages are the set of languages that are recognized by some automaton. For finite automata the recognizable languages are regular languages. For different types of automata, the recognizable languages are different.
Variant definitions of automata[edit]
Automata are defined to study useful machines under mathematical formalism. So, the definition of an automaton is open to variations according to the "real world machine", which we want to model using the automaton. People have studied many variations of automata. The following are some popular variations in the definition of different components of automata.

Input
Finite input: An automaton that accepts only finite sequence of symbols. The above introductory definition only encompasses finite words.
Infinite input: An automaton that accepts infinite words (Ï-words). Such automata are called Ï-automata.
Tree word input: The input may be a tree of symbols instead of sequence of symbols. In this case after reading each symbol, the automaton reads all the successor symbols in the input tree. It is said that the automaton makes one copy of itself for each successor and each such copy starts running on one of the successor symbols from the state according to the transition relation of the automaton. Such an automaton is called a tree automaton.
Infinite tree inputÂ : The two extensions above can be combined, so the automaton reads a tree structure with (in)finite branches. Such an automaton is called an infinite tree automaton
States
Single state: An automaton with one state, also called a combinational circuit, performs a transformation which may implement combinational logic.[10]
Finite states: An automaton that contains only a finite number of states.
Infinite states: An automaton that may not have a finite number of states, or even a countable number of states. Different kinds of abstract memory may be used to give such machines finite descriptions.
Stack memory: An automaton may also contain some extra memory in the form of a stack in which symbols can be pushed and popped. This kind of automaton is called a pushdown automaton
Queue memory: An automaton may have memory in the form of a queue. Such a machine is called queue machine and is Turing-complete.
Tape memory: The inputs and outputs of automata are often described as input and output tapes. Some machines have additional working tapes, including the Turing machine, linear bounded automaton, and log-space transducer.
Transition function
Deterministic: For a given current state and an input symbol, if an automaton can only jump to one and only one state then it is a deterministic automaton.
Nondeterministic: An automaton that, after reading an input symbol, may jump into any of a number of states, as licensed by its transition relation. Notice that the term transition function is replaced by transition relation: The automaton non-deterministically decides to jump into one of the allowed choices. Such automata are called nondeterministic automata.
Alternation: This idea is quite similar to tree automaton but orthogonal. The automaton may run its multiple copies on the same next read symbol. Such automata are called alternating automata. Acceptance condition must satisfy all runs of such copies to accept the input.
Acceptance condition
Acceptance of finite words: Same as described in the informal definition above.
Acceptance of infinite words: an omega automaton cannot have final states, as infinite words never terminate. Rather, acceptance of the word is decided by looking at the infinite sequence of visited states during the run.
Probabilistic acceptance: An automaton need not strictly accept or reject an input. It may accept the input with some probability between zero and one. For example, quantum finite automaton, geometric automaton and metric automaton have probabilistic acceptance.
Different combinations of the above variations produce many classes of automaton.
Automata theory is a subject matter that studies properties of various types of automata. For example, the following questions are studied about a given type of automata.

Which class of formal languages is recognizable by some type of automata? (Recognizable languages)
Are certain automata closed under union, intersection, or complementation of formal languages? (Closure properties)
How expressive is a type of automata in terms of recognizing a class of formal languages? And, their relative expressive power? (Language hierarchy)
Automata theory also studies the existence or nonexistence of any effective algorithms to solve problems similar to the following list:

Does an automaton accept any input word? (Emptiness checking)
Is it possible to transform a given non-deterministic automaton into deterministic automaton without changing the recognizable language? (Determinization)
For a given formal language, what is the smallest automaton that recognizes it? (Minimization)
Classes of automata[edit]
The following is an incomplete list of types of automata.




Automaton

Recognizable language


Nondeterministic/Deterministic finite-state machine (FSM)

regular languages


Deterministic pushdown automaton (DPDA)

deterministic context-free languages


Pushdown automaton (PDA)

context-free languages


Linear bounded automaton (LBA)

context-sensitive languages


Turing machine

recursively enumerable languages


Deterministic BÃ¼chi automaton

Ï-limit languages


Nondeterministic BÃ¼chi automaton

Ï-regular languages


Rabin automaton, Streett automaton, Parity automaton, Muller automaton

Discrete, continuous, and hybrid automata[edit]
Normally automata theory describes the states of abstract machines but there are discrete automata, analog automata or continuous automata, or hybrid discrete-continuous automata, which use digital data, analog data or continuous time, or digital and analog data, respectively.

Hierarchy in terms of powers[edit]
The following is an incomplete hierarchy in terms of powers of different types of virtual machines. The hierarchy reflects the nested categories of languages the machines are able to accept.[14] 




Automaton


Deterministic Finite Automaton (DFA)  -- Lowest Power 
(same power) Â Â  
  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
  Â Â (same power) 
Nondeterministic Finite Automaton (NFA)
(above is weaker) Â Â  
  
    
      
        â©
      
    
    {\displaystyle \cap }
  
 Â Â  (below is stronger) 
Deterministic Push Down Automaton  (DPDA-I) 
with 1 push-down store 

  
    
      
        â©
      
    
    {\displaystyle \cap }
  
 
Nondeterministic Push Down Automaton (NPDA-I) 
with 1 push-down store 

  
    
      
        â©
      
    
    {\displaystyle \cap }
  
 
Linear Bounded Automaton (LBA) 

  
    
      
        â©
      
    
    {\displaystyle \cap }
  
 
Deterministic Push Down Automaton (DPDA-II) 
with 2 push-down stores 

  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
 
Nondeterministic Push Down Automaton (NPDA-II) 
with 2 push-down stores 

  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
 
Deterministic Turing Machine (DTM) 

  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
 
Nondeterministic Turing Machine (NTM) 

  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
 
Probabilistic Turing Machine (PTM) 

  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
 
Multitape Turing Machine (MTM) 

  
    
      
        
          |
        
        
          |
        
      
    
    {\displaystyle ||}
  
 
Multidimensional Turing Machine


Applications[edit]
Each model in automata theory plays important roles in several applied areas. Finite automata are used in text processing, compilers, and hardware design. Context-free grammar (CFGs) are used in programming languages and artificial intelligence. Originally, CFGs were used in the study of the human languages. Cellular automata are used in the field of artificial life, the most famous example being John Conway's Game of Life. Some other examples which could be explained using automata theory in biology include mollusk and pine cones growth and pigmentation patterns. Going further, a theory suggesting that the whole universe is computed by some sort of a discrete automaton, is advocated by some scientists. The idea originated in the work of Konrad Zuse, and was popularized in America by Edward Fredkin. Automata also appear in the theory of finite fields: the set of irreducible polynomials which can be written as composition of degree two polynomials is in fact a regular language.[15]
Another problem for which automata can be used is the induction of regular languages.

Automata simulators[edit]
Automata simulators are pedagogical tools used to teach, learn and research automata theory. An automata simulator takes as input the description of an automaton and then simulates its working for an arbitrary input string. The description of the automaton can be entered in several ways. An automaton can be defined in a symbolic language  or its specification may be entered in a predesigned form or its transition diagram may be drawn by clicking and dragging the mouse. Well known automata simulators include Turing's World, JFLAP, VAS, TAGS and SimStudio.[16]

Connection to category theory[edit]
One can define several distinct categories of automata[17] following the automata classification into different types described in the previous section. The mathematical category of deterministic automata, sequential machines or sequential automata, and Turing machines with automata homomorphisms defining the arrows between automata is a Cartesian closed category,[18][19] it has both categorical limits and colimits. An automata homomorphism maps a quintuple of an automaton Ai onto the quintuple of another automaton 
 Aj.[20] Automata homomorphisms can also be considered as automata transformations or as semigroup homomorphisms, when the state space, S, of the automaton is defined as a semigroup Sg. Monoids are also considered as a suitable setting for automata in monoidal categories.[21][22][23]

Categories of variable automata
One could also define a variable automaton, in the sense of Norbert Wiener in his book on The Human Use of Human Beings via the endomorphisms 
  
    
      
        
          A
          
            i
          
        
        â
        
          A
          
            i
          
        
      
    
    {\displaystyle A_{i}\to A_{i}}
  
. Then, one can show that such variable automata homomorphisms form a mathematical group. In the case of non-deterministic, or other complex kinds of automata, the latter set of endomorphisms may become, however, a variable automaton groupoid. Therefore, in the most general case, categories of variable automata of any kind are categories of groupoids or groupoid categories. Moreover, the category of reversible automata is then a 
2-category, and also a subcategory of the 2-category of groupoids, or the groupoid category.

See also[edit]
Boolean differential calculus
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Mahoney, Michael S. "The Structures of Computation and the Mathematical Structure of Nature". The Rutherford Journal. Retrieved 2020-06-07.

^ Booth, Taylor (1967). Sequential Machines and Automata Theory. New York: John Wiley & Sons. p.Â 1-13. ISBNÂ 0-471-08848-X.

^ Ashby, William Ross (1967-01-15). "The Place of the Brain in the Natural World" (PDF). Currents in Modern Biology. 1 (2): 95â104. doi:10.1016/0303-2647(67)90021-4. PMIDÂ 6060865.: "The theories, now well developed, of the "finite-state machine" (Gill, 1962), of the "noiseless transducer" (Shannon and Weaver, 1949), of the "state-determined system" (Ashby, 1952), and of the "sequential circuit", are essentially homologous."

^ Ashby, W. R.;  etÂ al. (1956).  C.E. Shannon; J. McCarthy (eds.). Automata Studies. Princeton, N.J.: Princeton University Press.

^ Jump up to: a b c d e Arbib, Michael (1969). Theories of Abstract Automata. Englewood Cliffs, N.J.: Prentice-Hall.

^ Li, Ming; Paul, Vitanyi (1997). An Introduction to Kolmogorov Complexity and its Applications. New York: Springer-Verlag. p.Â 84.

^ Chomsky, Noam (1956). "Three models for the description of language" (PDF). IRE Transactions on Information Theory. 2 (3): 113â124. doi:10.1109/TIT.1956.1056813.

^ Nerode, A. (1958). "Linear Automaton Transformations". Proceedings of the American Mathematical Society. 9 (4): 541. doi:10.1090/S0002-9939-1958-0135681-9.

^ Rabin, Michael; Scott, Dana (Apr 1959). "Finite Automata and Their Decision Problems" (PDF). IBM Journal of Research and Development. 3 (2): 114â125. doi:10.1147/rd.32.0114. Archived from the original on 2010-12-14.{{cite journal}}:  CS1 maint: unfit URL (link)

^ Jump up to: a b c Hartmanis, J.; Stearns, R.E. (1966). Algebraic Structure Theory of Sequential Machines. Englewood Cliffs, N.J.: Prentice-Hall.

^ Hartmanis, J.; Stearns, R. E. (1964). "Computational complexity of recursive sequences" (PDF).

^ Fortnow, Lance; Homer, Steve (2002). "A Short History of Computational Complexity" (PDF).

^ Moore, Cristopher (2019-07-31). "Automata, languages, and grammars". arXiv:1907.12713 [cs.CC].

^ Yan, Song Y. (1998). An Introduction to Formal Languages and Machine Computation. Singapore: World Scientific Publishing Co. Pte. Ltd. pp.Â 155â156. ISBNÂ 9789810234225.

^ Ferraguti, A.; Micheli, G.; Schnyder, R. (2018), Irreducible compositions of degree two polynomials over finite fields have regular structure, The Quarterly Journal of Mathematics, vol.Â 69, Oxford University Press, pp.Â 1089â1099, arXiv:1701.06040, doi:10.1093/qmath/hay015, S2CIDÂ 3962424

^ Chakraborty, P.; Saxena, P. C.; Katti, C. P. (2011). "Fifty Years of Automata Simulation: A Review". ACM Inroads. 2 (4): 59â70. doi:10.1145/2038876.2038893. S2CIDÂ 6446749.

^ JirÃ­ AdÃ¡mek and VÄra TrnkovÃ¡. 1990. Automata and Algebras in Categories. Kluwer Academic Publishers:Dordrecht and Prague

^ Mac Lane, Saunders (1971). Categories for the Working Mathematician. New York: Springer. ISBNÂ 9780387900360.

^ Cartesian closed category Archived 16 November 2011 at the Wayback Machine

^ The Category of Automata Archived 15 September 2011 at the Wayback Machine

^ http://www.math.cornell.edu/~worthing/asl2010.pdf James Worthington.2010.Determinizing, Forgetting, and Automata in Monoidal Categories. ASL North American Annual Meeting, 17 March 2010

^ Aguiar, M. and Mahajan, S.2010. "Monoidal Functors, Species, and Hopf Algebras".

^ Meseguer, J., Montanari, U.: 1990 Petri nets are monoids. Information and Computation 88:105â155


Further reading[edit]
John E. Hopcroft, Rajeev Motwani, Jeffrey D. Ullman (2000). Introduction to Automata Theory, Languages, and Computation (2ndÂ ed.). Pearson Education. ISBNÂ 978-0-201-44124-6.{{cite book}}:  CS1 maint: uses authors parameter (link)
Michael Sipser (1997). Introduction to the Theory of Computation. PWS Publishing. ISBNÂ 978-0-534-94728-6. Part One: Automata and Languages, chapters 1â2, pp.Â 29â122. Section 4.1: Decidable Languages, pp.Â 152â159. Section 5.1: Undecidable Problems from Language Theory, pp.Â 172â183.
Elaine Rich (2008). Automata, Computability and Complexity: Theory and Applications. Pearson. ISBNÂ 978-0-13-228806-4.
Salomaa, Arto (1985). Computation and automata. Encyclopedia of Mathematics and Its Applications. Vol.Â 25. Cambridge University Press. ISBNÂ 978-0-521-30245-6. ZblÂ 0565.68046.
Anderson, James A. (2006). Automata theory with modern applications. With contributions by Tom Head. Cambridge: Cambridge University Press. ISBNÂ 978-0-521-61324-8. ZblÂ 1127.68049.
Conway, J.H. (1971). Regular algebra and finite machines. Chapman and Hall Mathematics Series. London: Chapman & Hall. ZblÂ 0231.94041.
John M. Howie (1991) Automata and Languages, Clarendon Press ISBNÂ 0-19-853424-8 MR1254435
Sakarovitch, Jacques (2009). Elements of automata theory. Translated from the French by Reuben Thomas. Cambridge University Press. ISBNÂ 978-0-521-84425-3. ZblÂ 1188.68177.
James P. Schmeiser, David T. Barnard (1995). Producing a top-down parse order with bottom-up parsing. Elsevier North-Holland.{{cite book}}:  CS1 maint: uses authors parameter (link)
Igor Aleksander, F.Keith Hanna (1975). Automata TheoryÂ : An Engineering Approach. New York: Crane Russak. ISBNÂ 978-0-8448-0657-0.{{cite book}}:  CS1 maint: uses authors parameter (link)
Marvin Minsky (1967). ComputationÂ : Finite and infinite machines. Princeton, N.J.: Prentice Hall.
John C. Martin (2011). Introduction to Languages and The Theory of Computation. New York, NY 10020: McGraw Hill. ISBNÂ 978-0-07-319146-1.{{cite book}}:  CS1 maint: location (link)
External links[edit]
JFLAP
dk.brics.automaton
libfa
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}show.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteAutomata theory: formal languages and formal grammarsChomsky hierarchyGrammarsLanguagesAbstract machines
Type-0
â
Type-1
â
â
â
â
â
Type-2
â
â
Type-3
â
â

Unrestricted
(no common name)
Context-sensitive
Positive range concatenation
Indexed
â
Linear context-free rewriting systems
Tree-adjoining
Context-free
Deterministic context-free
Visibly pushdown
Regular
â
Non-recursive

Recursively enumerable
Decidable
Context-sensitive
Positive range concatenation*
Indexed*
â
Linear context-free rewriting language
Tree-adjoining
Context-free
Deterministic context-free
Visibly pushdown
Regular
Star-free
Finite

Turing machine
Decider
Linear-bounded
PTIME Turing Machine
Nested stack
Thread automaton
restricted Tree stack automaton
Embedded pushdown
Nondeterministic pushdown
Deterministic pushdown
Visibly pushdown
Finite
Counter-free (with aperiodic finite monoid)
Acyclic finite
Each category of languages, except those marked by a *, is a proper subset of the category directly above it. Any language in each category is generated by a grammar and by an automaton in the category in the same line.
showvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip (SoCs)
Energy consumption (Green computing)
Electronic design automation
Hardware acceleration
Computer systems organization
Computer architecture
Embedded system
Real-time computing
Dependability
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain-specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software maintenance
Programming team
Open-source model
Theory of computation
Model of computation
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Humanâcomputer interaction
Interaction design
Social computing
Ubiquitous computing
Visualization
Accessibility
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi-task learning
Cross-validation
Graphics
Animation
Rendering
Image manipulation
Graphics processing unit
Mixed reality
Virtual reality
Image compression
Solid modeling
Applied computing
E-commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
WikiProject
 Commons

showvteIndustrial and applied mathematicsComputational
Algorithms
design
analysis
Automata theory
Coding theory
Computational logic
Cryptography
Information theory
Discrete
Computer algebra
Computational number theory
Combinatorics
Graph theory
Discrete geometry
Analysis
Approximation theory
Clifford analysis
Clifford algebra
Differential equations
Complex differential equations
Ordinary differential equations
Partial differential equations
Stochastic differential equations
Differential geometry
Differential forms
Gauge theory
Geometric analysis
Dynamical systems
Chaos theory
Control theory
Functional analysis
Operator algebra
Operator theory
Harmonic analysis
Fourier analysis
Multilinear algebra
Exterior
Geometric
Tensor
Vector
Multivariable calculus
Exterior
Geometric
Tensor
Vector
Numerical analysis
Numerical linear algebra
Numerical methods for ordinary differential equations
Numerical methods for partial differential equations
Validated numerics
Variational calculus
Probability theory
DistributionsÂ (random variables)
Stochastic processesÂ / analysis
Path integral
Stochastic variational calculus
Mathematicalphysics
Analytical mechanics
Lagrangian
Hamiltonian
Field theory
Classical
Conformal
Effective
Gauge
Quantum
Statistical
Topological
Perturbation theory
in quantum mechanics
Potential theory
String theory
Bosonic
Topological
Supersymmetry
Supersymmetric quantum mechanics
Supersymmetric theory of stochastic dynamics
 Algebraic structures
Algebra of physical space
Feynman integral
Poisson algebra
Quantum group
Renormalization group
Representation theory
Spacetime algebra
Superalgebra
Supersymmetry algebra

Decision sciences
Game theory
Operations research
Optimization
Social choice theory
Statistics
Mathematical economics
Mathematical finance
Other applications
Biology
Chemistry
Psychology
Sociology
"The Unreasonable Effectiveness of Mathematics in the Natural Sciences"
Related
Mathematics
Organizations
Society for Industrial and Applied Mathematics
Japan Society for Industrial and Applied Mathematics
SociÃ©tÃ© de MathÃ©matiques AppliquÃ©es et Industrielles
International Council for Industrial and Applied Mathematics

Category
Mathematics portalÂ / outlineÂ / topics list

showAuthority control General
Integrated Authority File (Germany)
National libraries
France (data)
United States
Japan
Other
Faceted Application of Subject Terminology





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Automata_theory&oldid=1068367236"
		Categories: Automata (computation)Hidden categories: CS1 maint: unfit URLWebarchive template wayback linksArticles with short descriptionShort description matches WikidataUse dmy dates from May 2019Articles needing more detailed referencesCS1 maint: uses authors parameterCS1 maint: locationArticles with GND identifiersArticles with BNF identifiersArticles with LCCN identifiersArticles with NDL identifiersArticles with FAST identifiers
	
