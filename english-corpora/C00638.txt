
Title:
Artificial consciousness
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Field in cognitive science
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}For other uses, see Artificial consciousness (disambiguation).
This article includes inline citations, but they are not properly formatted. Please improve this article by correcting them.  (June 2020) (Learn how and when to remove this template message)
Artificial consciousness[1] (AC), also known as machine consciousness (MC) or synthetic consciousness (Gamez 2008; Reggia 2013), is a field related to artificial intelligence and cognitive robotics. The aim of the theory of artificial consciousness is to "Define that which would have to be synthesized were consciousness to be found in an engineered artifact" (Aleksander 1995).
Neuroscience hypothesizes that consciousness is generated by the interoperation of various parts of the brain, called the neural correlates of consciousness or NCC, though there are challenges to that perspective. Proponents of AC believe it is possible to construct systems (e.g., computer systems) that can emulate this NCC interoperation.[2]
Artificial consciousness concepts are also pondered in the philosophy of artificial intelligence through questions about mind, consciousness, and mental states.[3]

Contents

1 Philosophical views

1.1 Plausibility debate

1.1.1 Computational Foundation argument


1.2 Ethics


2 Research and implementation proposals

2.1 Aspects of consciousness

2.1.1 Awareness
2.1.2 Memory
2.1.3 Learning
2.1.4 Anticipation
2.1.5 Subjective experience


2.2 Role of cognitive architectures
2.3 Symbolic or hybrid proposals

2.3.1 Franklin's Intelligent Distribution Agent
2.3.2 Ron Sun's cognitive architecture CLARION
2.3.3 Ben Goertzel's OpenCog


2.4 Connectionist proposals

2.4.1 Haikonen's cognitive architecture
2.4.2 Shanahan's cognitive architecture
2.4.3 Takeno's self-awareness research
2.4.4 Aleksander's impossible mind
2.4.5 Thaler's Creativity Machine Paradigm
2.4.6 Michael Graziano's attention schema


2.5 "Self-modeling"


3 Testing
4 In fiction
5 See also
6 References

6.1 Citations
6.2 Bibliography


7 Further reading
8 External links



Philosophical views[edit]
As there are many hypothesized types of consciousness, there are many potential implementations of artificial consciousness.  In the philosophical literature, perhaps the most common taxonomy of consciousness is into "access" and "phenomenal" variants.  Access consciousness concerns those aspects of experience that can be apprehended, while phenomenal consciousness concerns those aspects of experience that seemingly cannot be apprehended, instead being characterized qualitatively in terms of âraw feelsâ, âwhat it is likeâ or qualia (Block 1997).

Plausibility debate[edit]
Type-identity theorists and other skeptics hold the view that consciousness can only be realized in particular physical systems because consciousness has properties that necessarily depend on physical constitution (Block 1978; Bickle 2003).[4][5]
In his article "Artificial Consciousness: Utopia or Real Possibility," Giorgio Buttazzo says that a common objection to artificial consciousness is that "Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can no longer be reprogrammed, from rethinking), emotions, or free will. A computer, like a washing machine, is a slave operated by its components."[6]
For other theorists (e.g., functionalists), who define mental states in terms of causal roles, any system that can instantiate the same pattern of causal roles, regardless of physical constitution, will instantiate the same mental states, including consciousness (Putnam 1967).

Computational Foundation argument[edit]
One of the most explicit arguments for the plausibility of AC comes from David Chalmers.  His proposal, found within his article Chalmers 2011, is roughly that the right kinds of computations are sufficient for the possession of a conscious mind. In the outline, he defends his claim thus: Computers perform computations. Computations can capture other systems' abstract causal organization.
The most controversial part of Chalmers' proposal is that mental properties are "organizationally invariant". Mental properties are of two kinds, psychological and phenomenological. Psychological properties, such as belief and perception, are those that are "characterized by their causal role". He adverts to the work of Armstrong 1968 and Lewis 1972 in claiming that "[s]ystems with the same causal topologyâ¦will share their psychological properties".
Phenomenological properties are not prima facie definable in terms of their causal roles. Establishing that phenomenological properties are amenable to individuation by causal role, therefore, requires argument. Chalmers provides his Dancing Qualia Argument for this purpose.[7]
Chalmers begins by assuming that agents with identical causal organizations could have different experiences. He then asks us to conceive of changing one agent into the other by the replacement of parts (neural parts replaced by silicon, say) while preserving its causal organization. Ex hypothesi, the experience of the agent under transformation would change (as the parts were replaced), but there would be no change in causal topology and therefore no means whereby the agent could "notice" the shift in experience.
Critics of AC object that Chalmers begs the question in assuming that all mental properties and external connections are sufficiently captured by abstract causal organization.

Ethics[edit]
Main articles: Ethics of artificial intelligence, Machine ethics, and Roboethics
If it were suspected that a particular machine was conscious, its rights would be an ethical issue that would need to be assessed (e.g. what rights it would have under law). For example, a conscious computer that was owned and used as a tool or central computer of a building of larger machine is a particular ambiguity. Should laws be made for such a case? Consciousness would also require a legal definition in this particular case. Because artificial consciousness is still largely a theoretical subject, such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction (see below).
In 2021, the German philosopher Thomas Metzinger has demanded a global moratorium on synthetic phenomenology until 2050, on ethical grounds.
The rules for the 2003 Loebner Prize competition explicitly addressed the question of robot rights:

61. If, in any given year, a publicly available open source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible for the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right.[8]
Research and implementation proposals[edit]
Aspects of consciousness[edit]
There are various aspects of consciousness generally deemed necessary for a machine to be artificially conscious. A variety of functions in which consciousness plays a role were suggested by Bernard Baars (Baars 1988) and others. The functions of consciousness suggested by Bernard Baars are Definition and Context Setting, Adaptation and Learning, Editing, Flagging and Debugging, Recruiting and Control, Prioritizing and Access-Control, Decision-making or Executive Function, Analogy-forming Function, Metacognitive and Self-monitoring Function, and Autoprogramming and Self-maintenance Function. Igor Aleksander suggested 12 principles for artificial consciousness (Aleksander 1995) and these are: The Brain is a State Machine, Inner Neuron Partitioning, Conscious and Unconscious States, Perceptual Learning and Memory, Prediction, The Awareness of Self, Representation of Meaning, Learning Utterances, Learning Language, Will, Instinct, and Emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artifact such as a digital computer. This list is not exhaustive; there are many others not covered.

Awareness[edit]
Awareness could be one required aspect, but there are many problems with the exact definition of awareness. The results of the experiments of neuroscanning on monkeys suggest that a process, not only a state or object, activates neurons. Awareness includes creating and testing alternative models of each process based on the information received through the senses or imagined, and is also useful for making predictions. Such modeling needs a lot of flexibility. Creating such a model includes modeling of the physical world, modeling of one's own internal states and processes, and modeling of other conscious entities.
There are at least three types of awareness:[9] agency awareness, goal awareness, and sensorimotor awareness, which may also be conscious or not. For example, in agency awareness, you may be aware that you performed a certain action yesterday, but are not now conscious of it.  In goal awareness, you may be aware that you must search for a lost object, but are not now conscious of it.  In sensorimotor awareness, you may be aware that your hand is resting on an object, but are not now conscious of it.
Al Byrd, the author of Superhuman Creators, defines consciousness, for animals, humans and artificial agents, as the effect of integrating and filtering many different types of affordance awareness; that is, awareness of the action possibilities in an environment. According to this definition, all agents that can perceive and act on affordances are conscious to some extent.
Because objects of awareness are often conscious, the distinction between awareness and consciousness is frequently blurred or they are used as synonyms.[10]

Memory[edit]
Conscious events interact with memory systems in learning, rehearsal, and retrieval.[11]
The IDA model[12] elucidates the role of consciousness in the updating of perceptual memory,[13] transient episodic memory, and procedural memory. Transient episodic and declarative memories have distributed representations in IDA, there is evidence that this is also the case in the nervous system.[14] In IDA, these two memories are implemented computationally using a modified version of Kanervaâs Sparse distributed memory architecture.[15]

Learning[edit]
Learning is also considered necessary for AC. By Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events (Baars 1988). By Axel Cleeremans and Luis JimÃ©nez, learning is defined as "a set of philogenetically  [sic] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments" (Cleeremans 2001).

Anticipation[edit]
The ability to predict (or anticipate) foreseeable events is considered important for AC by Igor Aleksander.[16] The emergentist multiple drafts principle proposed by Daniel Dennett in Consciousness Explained may be useful for prediction: it involves the evaluation and selection of the most appropriate "draft" to fit the current environment.  Anticipation includes prediction of consequences of one's own proposed actions and prediction of consequences of probable actions by other entities.
Relationships between real world states are mirrored in the state structure of a conscious organism enabling the organism to predict events.[16] An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur or to take preemptive action to avert anticipated events. The implication here is that the machine needs flexible, real-time components that build spatial, dynamic, statistical, functional, and cause-effect models of the real world and predicted worlds, making it possible to demonstrate that it possesses artificial consciousness in the present and future and not only in the past. In order to do this, a conscious machine should make coherent predictions and contingency plans, not only in worlds with fixed rules like a chess board, but also for novel environments that may change, to be executed only when appropriate to simulate and control the real world.

Subjective experience[edit]
Subjective experiences or qualia are widely considered to be the hard problem of consciousness. Indeed, it is held to pose a challenge to physicalism, let alone computationalism. On the other hand, there are problems in other fields of science that limit that which we can observe, such as the uncertainty principle in physics, which have not made the research in these fields of science impossible.

Role of cognitive architectures[edit]
Main article: Cognitive architecture
The term "cognitive architecture" may refer to a theory about the structure of the human mind, or any portion or function thereof, including consciousness. In another context, a cognitive architecture implements the theory on computers. An example is QuBIC: Quantum and Bio-inspired Cognitive Architecture for Machine Consciousness. One of the main goals of a cognitive architecture is to summarize the various results of cognitive psychology in a comprehensive computer model. However, the results need to be in a formalized form so they can be the basis of a computer program. Also, the role of cognitive architecture is for the A.I. to clearly structure, build, and implement its thought process.

Symbolic or hybrid proposals[edit]
Franklin's Intelligent Distribution Agent[edit]
Stan Franklin (1995, 2003) defines an autonomous agent as possessing functional consciousness when it is capable of several of the functions of consciousness as identified by Bernard Baars' Global Workspace Theory (BaarsÂ 1988, 1997). His brain child IDA (Intelligent Distribution Agent) is a software implementation of GWT, which makes it functionally conscious by definition. IDA's task is to negotiate new assignments for sailors in the US Navy after they end a tour of duty, by matching each individual's skills and preferences with the Navy's needs. IDA interacts with Navy databases and communicates with the sailors via natural language e-mail dialog while obeying a large set of Navy policies. The IDA computational model was developed during 1996â2001 at Stan Franklin's "Conscious" Software Research Group at the University of Memphis. It "consists of approximately a quarter-million lines of Java code, and almost completely consumes the resources of a 2001 high-end workstation." It relies heavily on codelets, which are "special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread." In IDA's top-down architecture, high-level cognitive functions are explicitly modeled (see Franklin 1995 and Franklin 2003 for details). While IDA is functionally conscious by definition, Franklin does "not attribute phenomenal consciousness to his own 'conscious' software agent, IDA, in spite of her many human-like behaviours. This in spite of watching several US Navy detailers repeatedly nodding their heads saying 'Yes, that's how I do it' while watching IDA's internal and external actions as she performs her task." IDA has been extended to LIDA (Learning Intelligent Distribution Agent).

Ron Sun's cognitive architecture CLARION[edit]
CLARION posits a two-level representation that explains the distinction between conscious and unconscious mental processes.
CLARION has been successful in accounting for a variety of psychological data. A number of well-known skill learning tasks have been simulated using CLARION that span the spectrum ranging from simple reactive skills to complex cognitive skills. The tasks include serial reaction time (SRT) tasks, artificial grammar learning (AGL) tasks, process control (PC) tasks, the categorical inference (CI) task, the alphabetical arithmetic (AA) task, and the Tower of Hanoi (TOH) task (Sun 2002) harv error: no target: CITEREFSun2002 (help). Among them, SRT, AGL, and PC are typical implicit learning tasks, very much relevant to the issue of consciousness as they operationalized the notion of consciousness in the context of psychological experiments.

Ben Goertzel's OpenCog[edit]
Ben Goertzel is pursuing an embodied AGI through the open-source OpenCog project. Current code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, being done at the Hong Kong Polytechnic University.

Connectionist proposals[edit]
Haikonen's cognitive architecture[edit]
Pentti Haikonen (2003) considers classical rule-based computing inadequate for achieving AC: "the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers." Rather than trying to achieve mind and consciousness by identifying and implementing their underlying computational rules, Haikonen proposes "a special cognitive architecture to reproduce the processes of perception, inner imagery, inner speech, pain, pleasure, emotions and the cognitive functions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, the artificial neurons, without algorithms or programs". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be "a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection." Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in autonomous agents that have a suitable neuro-inspired architecture of complexity; these are shared by many, e.g. Freeman (1999) and Cotterill (2003). A low-complexity implementation of the architecture proposed by Haikonen (2003) was reportedly not capable of AC, but did exhibit emotions as expected. See Doan (2009) for a comprehensive introduction to Haikonen's cognitive architecture. An updated account of Haikonen's architecture, along with a summary of his philosophical views, is given in Haikonen (2012), Haikonen (2019).

Shanahan's cognitive architecture[edit]
Murray Shanahan describes a cognitive architecture that combines Baars's idea of a global workspace with a mechanism for internal simulation ("imagination") (Shanahan 2006). For discussions of Shanahan's architecture, see (Gamez 2008) and (Reggia 2013) and Chapter 20 of (Haikonen 2012).

Takeno's self-awareness research[edit]
Self-awareness in robots is being investigated by Junichi Takeno[17] at Meiji University in Japan. Takeno is asserting that he has developed a robot capable of discriminating between a self-image in a mirror and any other having an identical image to it,[18][19] and this claim has already been reviewed (Takeno, Inaba & Suzuki 2005). Takeno asserts that he first contrived the computational module called a MoNAD, which has a self-aware function, and he then constructed the artificial consciousness system by formulating the relationships between emotions, feelings and reason by connecting the modules in a hierarchy (Igarashi, Takeno 2007). Takeno completed a mirror image cognition experiment using a robot equipped with the MoNAD system. Takeno proposed the Self-Body Theory stating that "humans feel that their own mirror image is closer to themselves than an actual part of themselves." The most important point in developing artificial consciousness or clarifying human consciousness is the development of a function of self awareness, and he claims that he has demonstrated physical and mathematical evidence for this in his thesis.[20] He also demonstrated that robots can study episodes in memory where the emotions were stimulated and use this experience to take predictive actions to prevent the recurrence of unpleasant emotions (Torigoe, Takeno 2009).

Aleksander's impossible mind[edit]
Igor Aleksander, emeritus professor of Neural Systems Engineering at Imperial College, has extensively researched artificial neural networks and claims in his book Impossible Minds: My Neurons, My Consciousness that the principles for creating a conscious machine already exist but that it would take forty years to train such a machine to understand language.[21] Whether this is true remains to be demonstrated and the basic principle stated in Impossible Mindsâthat the brain is a neural state machineâis open to doubt.[22]

Thaler's Creativity Machine Paradigm[edit]
Stephen Thaler proposed a possible connection between consciousness and creativity in his 1994 patent, called "Device for the Autonomous Generation of Useful Information" (DAGUI),[23][24][25] or the so-called "Creativity Machine", in which computational critics govern the injection of synaptic noise and degradation into neural nets so as to induce false memories or confabulations that may qualify as potential ideas or strategies.[26] He recruits this neural architecture and methodology to account for the subjective feel of consciousness, claiming that similar noise-driven neural assemblies within the brain invent dubious significance to overall cortical activity.[27][28][29] Thaler's theory and the resulting patents in machine consciousness were inspired by experiments in which he internally disrupted trained neural nets so as to drive a succession of neural activation patterns that he likened to stream of consciousness.[28][30][31][32][33]

Michael Graziano's attention schema[edit]
Main article: Michael Graziano Â§Â The brain basis of consciousness
In 2011, Michael Graziano and Sabine Kastler published a paper named "Human consciousness and its relationship to social neuroscience: A novel hypothesis" proposing a theory of consciousness as an attention schema.[34]  Graziano went on to publish an expanded discussion of this theory in his book "Consciousness and the Social Brain".[2] This Attention Schema Theory of Consciousness, as he named it, proposes that the brain tracks attention to various sensory inputs by way of  an attention schema, analogous to the well studied body schema that tracks the spatial place of a person's body.[2]  This relates to artificial consciousness by proposing a specific mechanism of information handling, that produces what we allegedly experience and describe as consciousness, and which should be able to be duplicated by a machine using current technology. When the brain finds that person X is aware of thing Y, it is in effect modeling the state in which person X is applying an attentional enhancement to Y. In the attention schema theory, the same process can be applied to oneself. The brain tracks attention to various sensory inputs, and one's own awareness is a schematized model of one's attention. Graziano proposes specific locations in the brain for this process, and suggests that such awareness is a computed feature constructed by an expert system in the brain.

"Self-modeling"[edit]
Hod Lipson defines "self-modeling" as a necessary component of self-awareness or consciousness in robots. "Self-modeling" consists of a robot running an internal model or simulation of itself.[35][36]

Testing[edit]
The most well-known method for testing machine intelligence is the Turing test. But when interpreted as only observational, this test contradicts the philosophy of science principles of theory dependence of observations. It also has been suggested that Alan Turing's recommendation of imitating not a human adult consciousness, but a human child consciousness, should be taken seriously.[37]
Other tests, such as ConsScale, test the presence of features inspired by biological systems, or measure the cognitive development of artificial systems.
Qualia, or phenomenological consciousness, is an inherently first-person phenomenon. Although various systems may display various signs of behavior correlated with functional consciousness, there is no conceivable way in which third-person tests can have access to first-person phenomenological features. Because of that, and because there is no empirical definition of consciousness,[38] a test of presence of consciousness in AC may be impossible.
In 2014, Victor Argonov suggested a non-Turing test for machine consciousness based on machine's ability to produce philosophical judgments.[39] He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creaturesâ consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. A positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machineâs intellect, not by absence of consciousness.

In fiction[edit]
Main article: Simulated consciousness (science fiction)
See also: Artificial intelligence in fiction Â§Â Sentient AI
Characters with artificial consciousness (or at least with personalities that imply they have consciousness), from works of fiction:

AC â created by merging two AIs in the Sprawl trilogy by William Gibson
Agents â in the simulated reality known as "The Matrix" in The Matrix franchise
Agent Smith â began as an Agent in The Matrix, then became a renegade program of overgrowing power that could make copies of itself like a self-replicating computer virus
A.L.I.E. â Sentient genocidal AI from the TV series The 100
AM (Allied Mastercomputer) â the antagonist of Harlan Ellison's short novel I Have No Mouth, and I Must Scream. An omnipotent, highly intelligent supercomputer, its hatred for humanity drove it to cause mass genocide against the human race, sparing five humans to play sadistic games with them for all eternity.
Amusement park robots  (with pixilated consciousness) that went homicidal in Westworld and Futureworld
Annalee Call â an Auton (android manufactured by other androids) from the movie Alien Resurrection
Arnold Rimmer â computer-generated sapient hologram aboard the Red Dwarf
Ava â a humanoid robot in Ex Machina
Ash â android crew member of the Nostromo starship in the movie Alien
The Bicentennial Man â an android in Isaac Asimov's Foundation universe
Bishop â android crew member aboard the U.S.S. Sulaco in the movie Aliens
Bomb #19 â Thermostellar bomb for the destruction of potentially dangerous planets, aboard the Dark Star
Bomb #20 â Malfunctioning Thermostellar bomb, aboard the Dark Star
The uploaded mind of Dr. Will Caster, which presumably included his consciousness, from the film Transcendence
C-3PO â protocol droid featured in all the Star Wars movies
Chappie â CHAPPiE
Cohen (and other Emergent AIs) â Chris Moriarty's Spin Series
Computer â ship's computer, aboard the Dark Star
Cortana (and other "Smart AI") â from the Halo series of games
Cylons â genocidal robots with resurrection ships that enable the consciousness of any Cylon within an unspecified range to download into a new body aboard the ship upon death, from Battlestar Galactica
Erasmus â baby killer robot that incited the Butlerian Jihad in the Dune franchise
Fal'Cie â Mechanical beings with god-like powers from the Final Fantasy XIII series
The Geth, EDI and SAM â Mass Effect
Futurama[40]- Bender[41] is a good example of sapient t AI, throughout many episodes, you will see Bender[42] get angry, sad, or other emotions. Bender also having a mind of his own.
Gideon â an interactive artificial consciousness made by Barry Allen shown in DC comics and shows like The Flash and Legends of Tomorrow
GLaDOS (and personality cores) â from the Portal series of games
HAL 9000 â spaceship USS Discovery One's onboard computer, that lethally malfunctioned due to mutually exclusive directives, from the 1968 novel 2001: A Space Odyssey and in the film
Holly â ship's computer with an IQ of 6000, aboard the Red Dwarf
Hosts in the Westworld franchise
Humagears in Kamen Rider Zero-One
Isaac â a member of the artificial, non-biological race from Kaylon-1 that views biological lifeforms, including humans, as inferior from the TV series The Orville.
Jane â Orson Scott Card's Speaker for the Dead, Xenocide, Children of the Mind, and "Investment Counselor"
Johnny Five â Short Circuit
Joshua â WarGames
Keymaker â an "exile" sapient program in The Matrix franchise
Lieutenant Commander Data  â Star Trek: The Next Generation
"Machine" â android from the film The Machine, whose owners try to kill her when they witness her conscious thoughts, out of fear that she will design better androids (intelligence explosion)
Marvin the Paranoid Android - The Hitchhiker's Guide To The Galaxy, super-intelligent android who is perpetually depressed
Mike â The Moon Is a Harsh Mistress
Mimi â humanoid robot in Real Humans, (original title â Ãkta mÃ¤nniskor) 2012
The Minds â Iain M. Banks' Culture novels
Omnius â sentient computer network that controlled the Universe until overthrown by the Butlerian Jihad in the Dune franchise
Operating Systems in the movie Her
The Oracle â sapient program in The Matrix franchise
Professor James Moriarty â sentient holodeck character in the "Ship in a Bottle" episode from Star Trek: The Next Generation
In Greg Egan's novel Permutation City the protagonist creates digital copies of himself to conduct experiments that are also related to implications of artificial consciousness on identity
Puppet Master â Ghost in the Shell manga and anime
R2-D2 â exciteable astromech droid featured in all the Star Wars movies
Replicants â bio-robotic androids from the novel Do Androids Dream of Electric Sheep? and the movie Blade Runner which portray what might happen when artificially conscious robots are modeled very closely upon humans
Roboduck â combat robot superhero in the NEW-GEN comic book series from Marvel Comics
Robots in Isaac Asimov's Robot series
Robots in The Matrix franchise, especially in The Animatrix
The Ship â the result of a large-scale AC experiment, in Frank Herbert's Destination: Void and sequels, despite past edicts warning against "Making a Machine in the Image of a Man's Mind"
Skynet â from the Terminator franchise
"Synths" are a type of android in the video game Fallout 4. There is a faction in the game known as "The Railroad" which believes that, as conscious beings, synths have their own rights. The Institute, the lab that produces the synths, mostly does not believe they are truly conscious and attributes any apparent desires for freedom as a malfunction.
TARDIS â time machine and spacecraft of Doctor Who, sometimes portrayed with a mind of its own
Terminator cyborgs â from the Terminator franchise, with visual consciousness depicted via first-person perspective
Transformers â sentient robots from the various series in the Transformers robot superhero franchise of the same name
Vanamonde â an artificial being that was immensely powerful but entirely child-like in Arthur C. Clarke's The City and the Stars
WALL-E â a robot and the titular character in WALL-E
YoRHa - A militarized faction of conscious androids from the video game, Nier: Automata. The Nier franchise repeatedly uses simulated consciousness and philosophy as a central theme.
See also[edit]
.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}
General fields and theories
Artificial intelligence
Artificial general intelligence (AGI) â some consider AC a subfield of AGI research
Intelligence explosion â what may happen when a sentient AI redesigns itself in iterative cycles
Brainâcomputer interface
Hardware for artificial intelligence
Cognitive architecture
Computational theory of mind
Consciousness in animals
Simulated consciousness (science fiction)
Identity of indiscernibles
Mind uploading
Neurotechnology
Philosophy of mind
Simulated reality
Quantum cognition
Proposed concepts and implementations
Quantum mind
ADS-AC (system)
Conceptual space â conceptual prototype
Copycat (cognitive architecture)
Global Workspace Theory
Greedy reductionism â avoid oversimplifying anything essential
Image schema â spatial patterns
Kismet (robot)
LIDA (cognitive architecture)
Memory-prediction framework
Psi-Theory
Brain waves and Turtle robot by William Grey Walter

References[edit]
Citations[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Thaler, S. L. (1998). "The emerging intelligence and its critical look at us". Journal of Near-Death Studies. 17 (1): 21â29. doi:10.1023/A:1022990118714. S2CIDÂ 49573301.

^ Jump up to: a b c Graziano, Michael (2013). Consciousness and the Social Brain. Oxford University Press. ISBNÂ 978-0199928644.

^ Artificial Intelligence: A Modern Approach includes the philosophical foundations of AI including the questions of consciousness http://aima.cs.berkeley.edu/contents.html, Russell, Stuart J., Norvig, Peter, 2003, Upper Saddle River, New Jersey: Prentice Hall, ISBNÂ 0-13-790395-2

^ Schlagel, R. H. (1999). "Why not artificial consciousness or thought?". Minds and Machines. 9 (1): 3â28. doi:10.1023/a:1008374714117. S2CIDÂ 28845966.

^ Searle, J. R. (1980). "Minds, brains, and programs" (PDF). Behavioral and Brain Sciences. 3 (3): 417â457. doi:10.1017/s0140525x00005756.

^ Artificial consciousness: Utopia or real possibility? Buttazzo, Giorgio, July 2001, Computer, ISSN 0018-9162

^ Chalmers, David (1995). "Absent Qualia, Fading Qualia, Dancing Qualia". Retrieved 12 April 2016.

^ Loebner Prize Contest Official Rules â Version 2.0 The competition was directed by David Hamill and the rules were developed by members of the Robitron Yahoo group.

^ JoÃ«lle Proust in Neural Correlates of Consciousness, Thomas Metzinger, 2000, MIT, pages 307-324

^ Christof Koch, The Quest for Consciousness, 2004, page 2 footnote 2

^ Tulving, E. 1985. Memory and consciousness. Canadian Psychology 26:1-12

^ Franklin, Stan, et al. "The role of consciousness in memory." Brains, Minds and Media 1.1 (2005): 38.

^ Franklin, Stan. "Perceptual memory and learning: Recognizing, categorizing, and relating." Proc. Developmental Robotics AAAI Spring Symp. 2005.

^ Shastri, L. 2002. Episodic memory and cortico-hippocampal interactions. Trends in Cognitive Sciences

^ Kanerva, Pentti. Sparse distributed memory. MIT press, 1988.

^ Jump up to: a b Aleksander 1995

^ "Robot". Archived from the original on 2007-07-03. Retrieved 2007-07-03.

^ Takeno - Archive No...

^ The world first self-aware robot and The success of mirror image cognition, Takeno

^ A Robot Succeeds in 100% Mirror Image Cognition Archived 2017-08-09 at the Wayback Machine, Takeno, 2008

^ Aleksander I (1996) Impossible Minds: My Neurons, My Consciousness, Imperial College Press ISBNÂ 1-86094-036-6

^ Wilson, RJ (1998). "review of Impossible Minds". Journal of Consciousness Studies. 5 (1): 115â6.

^ Thaler, S.L., "Device for the autonomous generation of useful information"

^ Marupaka, N.; Lyer, L.; Minai, A. (2012). "Connectivity and thought: The influence of semantic network structure in a neurodynamical model of thinking" (PDF). Neural Networks. 32: 147â158. doi:10.1016/j.neunet.2012.02.004. PMIDÂ 22397950. Archived from the original (PDF) on 2016-12-19. Retrieved 2015-05-22.

^ Roque, R. and Barreira, A. (2011). "O Paradigma da "MÃ¡quina de Criatividade" e a GeraÃ§Ã£o de Novidades em um EspaÃ§o Conceitual," 3Âº SeminÃ¡rio Interno de CogniÃ§Ã£o Artificial - SICA 2011 â FEEC â UNICAMP.

^ Minati, Gianfranco; Vitiello, Giuseppe (2006). "Mistake Making Machines". Systemics of Emergence: Research and Development. pp.Â 67â78. doi:10.1007/0-387-28898-8_4. ISBNÂ 978-0-387-28899-4.

^ Thaler, S. L. (2013) The Creativity Machine Paradigm, Encyclopedia of Creativity, Invention, Innovation, and Entrepreneurship, (ed.) E.G. Carayannis, Springer Science+Business Media

^ Jump up to: a b Thaler, S. L. (2011). "The Creativity Machine: Withstanding the Argument from Consciousness," APA Newsletter on Philosophy and Computers

^ Thaler, S. L. (2014). "Synaptic Perturbation and Consciousness". Int. J. Mach. Conscious. 6 (2): 75â107. doi:10.1142/S1793843014400137.

^ Thaler, S. L. (1995). ""Virtual Input Phenomena" Within the Death of a Simple Pattern Associator". Neural Networks. 8 (1): 55â65. doi:10.1016/0893-6080(94)00065-t.

^ Thaler, S. L. (1995). Death of a gedanken creature, Journal of Near-Death Studies, 13(3), Spring 1995

^ Thaler, S. L. (1996). Is Neuronal Chaos the Source of Stream of Consciousness? In Proceedings of the World Congress on Neural Networks, (WCNNâ96), Lawrence Erlbaum, Mawah, NJ.

^ Mayer, H. A. (2004). A modular neurocontroller for creative mobile autonomous robots learning by temporal difference, Systems, Man and Cybernetics, 2004 IEEE International Conference(Volume:6 )

^ Graziano, Michael (1 January 2011). "Human consciousness and its relationship to social neuroscience: A novel hypothesis". Cognitive Neuroscience. 2 (2): 98â113. doi:10.1080/17588928.2011.565121. PMCÂ 3223025. PMIDÂ 22121395.

^ Pavlus, John (11 July 2019). "Curious About Consciousness? Ask the Self-Aware Machines". Quanta Magazine. Retrieved 2021-01-06.

^ Bongard, Josh, Victor Zykov, and Hod Lipson. "Resilient machines through continuous self-modeling." Science 314.5802 (2006): 1118-1121.

^ Mapping the Landscape of Human-Level Artificial General Intelligence

^ "Consciousness". In Honderich T. The Oxford companion to philosophy. Oxford University Press. ISBNÂ 978-0-19-926479-7

^ Victor Argonov (2014). "Experimental Methods for Unraveling the Mind-body Problem: The Phenomenal Judgment Approach". Journal of Mind and Behavior. 35: 51â70.{{cite journal}}:  CS1 maint: uses authors parameter (link)

^ "Futurama", Wikipedia, 2020-04-23, retrieved 2020-04-27

^ "Bender (Futurama)", Wikipedia, 2020-04-27, retrieved 2020-04-27

^ "Bender (Futurama)", Wikipedia, 2020-04-27, retrieved 2020-04-27


Bibliography[edit]
.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}
Ericsson-Zenith, Steven (2010), Explaining Experience In Nature, Sunnyvale, CA: Institute for Advanced Science & Engineering, archived from the original on 2019-04-01, retrieved 2019-10-04
Aleksander, Igor (1995), Artificial Neuroconsciousness: An Update, IWANN, archived from the original on 1997-03-02{{citation}}:  CS1 maint: bot: original URL status unknown (link)
Armstrong, David (1968), A Materialist Theory of Mind, Routledge
Arrabales, Raul (2009), "Establishing a Roadmap and Metrics for Conscious Machines Development" (PDF), Proceedings of the 8th IEEE International Conference on Cognitive Informatics, Hong Kong: 94â101, archived from the original (PDF) on 2011-07-21
Baars, Bernard (1988), A Cognitive Theory of Consciousness, Cambridge, MA: Cambridge University Press, ISBNÂ 978-0-521-30133-6
Baars, Bernard (1997), In the Theater of Consciousness, New York, NY: Oxford University Press, ISBNÂ 978-0-19-510265-9
Bickle, John (2003), Philosophy and Neuroscience: A Ruthless Reductive Account, New York, NY: Springer-Verlag
Block, Ned (1978), "Troubles for Functionalism", Minnesota Studies in the Philosophy of Science 9: 261-325
Block, Ned (1997), On a confusion about a function of consciousness in Block, Flanagan and Guzeldere (eds.) The Nature of Consciousness: Philosophical Debates, MIT Press
Boyles, Robert James M. (2012), Artificial Qualia, Intentional Systems and Machine Consciousness (PDF), Proceedings of the Research@DLSU Congress 2012: Science and Technology Conference, ISSNÂ 2012-3477
Chalmers, David (1996), The Conscious Mind, Oxford University Press, ISBNÂ 978-0-19-510553-7
Cotterill, Rodney (2003), "Cyberchild: a Simulation Test-Bed for Consciousness Studies",  in Holland, Owen (ed.), Machine Consciousness, vol.Â 10, Exeter, UK: Imprint Academic, pp.Â 31â45
Doan, Trung (2009), Pentti Haikonen's architecture for conscious machines, archived from the original on 2009-12-15
Franklin, Stan (1995), Artificial Minds, Boston, MA: MIT Press, ISBNÂ 978-0-262-06178-0
Franklin, Stan (2003), "IDA: A Conscious Artefact",  in Holland, Owen (ed.), Machine Consciousness, Exeter, UK: Imprint Academic
Freeman, Walter (1999), How Brains make up their Minds, London, UK: Phoenix, ISBNÂ 978-0-231-12008-1
Gamez, David (2008), "Progress in machine consciousness", Consciousness and Cognition, 17 (3): 887â910, doi:10.1016/j.concog.2007.04.005, PMIDÂ 17572107, S2CIDÂ 3569852
Haikonen, Pentti (2003), The Cognitive Approach to Conscious Machines, Exeter, UK: Imprint Academic, ISBNÂ 978-0-907845-42-3
Haikonen, Pentti (2012), Consciousness and Robot Sentience, Singapore: World Scientific, ISBNÂ 978-981-4407-15-1
Haikonen, Pentti (2019), Consciousness and Robot Sentience: 2nd Edition, Singapore: World Scientific, ISBNÂ 978-981-120-504-0
Koch, Christof (2004), The Quest for Consciousness: A Neurobiological Approach, Pasadena, CA: Roberts & Company Publishers, ISBNÂ 978-0-9747077-0-9
Lewis, David (1972), "Psychophysical and theoretical identifications", Australasian Journal of Philosophy, 50 (3): 249â258, doi:10.1080/00048407212341301
Putnam, Hilary (1967), The nature of mental states in Capitan and Merrill (eds.) Art, Mind and Religion, University of Pittsburgh Press
Reggia, James (2013), "The rise of machine consciousness: Studying consciousness with computational models", Neural Networks, 44: 112â131, doi:10.1016/j.neunet.2013.03.011, PMIDÂ 23597599
Sanz, Ricardo; LÃ³pez, I; RodrÃ­guez, M; HernÃ¡ndez, C (2007), "Principles for consciousness in integrated cognitive control" (PDF), Neural Networks, 20 (9): 938â946, doi:10.1016/j.neunet.2007.09.012, PMIDÂ 17936581
Searle, John (2004), Mind: A Brief Introduction, Oxford University Press
Shanahan, Murray (2006), "A cognitive architecture that combines internal simulation with a global workspace", Consciousness and Cognition, 15 (2): 443â449, doi:10.1016/j.concog.2005.11.005, PMIDÂ 16384715, S2CIDÂ 5437155
Sun, Ron (December 1999), "Accounting for the computational basis of consciousness: A connectionist approach", Consciousness and Cognition, 8 (4): 529â565, CiteSeerXÂ 10.1.1.42.2681, doi:10.1006/ccog.1999.0405, PMIDÂ 10600249, S2CIDÂ 15784914
Sun, Ron (2001), "Computation, reduction, and teleology of consciousness", Cognitive Systems Research, 1 (4): 241â249, CiteSeerXÂ 10.1.1.20.8764, doi:10.1016/S1389-0417(00)00013-9, S2CIDÂ 36892947
Takeno, Junichi; Inaba, K; Suzuki, T (June 27â30, 2005), "Experiments and examination of mirror image cognition using a small robot", The 6th IEEE International Symposium on Computational Intelligence in Robotics and Automation, Espoo Finland: CIRA 2005: 493â498, doi:10.1109/CIRA.2005.1554325, ISBNÂ 978-0-7803-9355-4, S2CIDÂ 15400848
Cleeremans, Axel (2001), Implicit learning and consciousness (PDF)
Chalmers, David (2011), "A Computational Foundation for the Study of Cognition", Journal of Cognitive Science, Seoul Republic of Korea: 323â357, archived from the original on 2015-12-23

Further reading[edit]
Baars, Bernard; Franklin, Stan (2003). "How conscious experience and working memory interact" (PDF). Trends in Cognitive Sciences. 7 (4): 166â172. doi:10.1016/s1364-6613(03)00056-1. PMIDÂ 12691765. S2CIDÂ 14185056.
Casti, John L. "The Cambridge Quintet: A Work of Scientific Speculation", Perseus Books Group, 1998
Franklin, S, B J Baars, U Ramamurthy, and Matthew Ventura. 2005. The role of consciousness in memory. Brains, Minds and Media 1: 1â38, pdf.
Haikonen, Pentti (2004), Conscious Machines and Machine Emotions, presented at Workshop on Models for Machine Consciousness, Antwerp, BE, June 2004.
McCarthy, John (1971â1987), Generality in Artificial Intelligence.  Stanford University, 1971-1987.
Penrose, Roger, The Emperor's New Mind, 1989.
Sternberg, Eliezer J. (2007) Are You a Machine?: The Brain, the Mind, And What It Means to be Human. Amherst, NY: Prometheus Books.
Suzuki T., Inaba K., Takeno, Junichi (2005), Conscious Robot That Distinguishes Between Self and Others and Implements Imitation Behavior, (Best Paper of IEA/AIE2005), Innovations in Applied Artificial Intelligence, 18th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, pp.Â 101â110, IEA/AIE 2005, Bari, Italy, June 22â24, 2005.
Takeno, Junichi (2006), The Self-Aware Robot -A Response to Reactions to Discovery News-, HRI Press, August 2006.
Zagal, J.C., Lipson, H. (2009) "Self-Reflection in Evolutionary Robotics",  Proceedings of the Genetic and Evolutionary Computation Conference, pp 2179â2188, GECCO 2009.
External links[edit]
Artefactual consciousness depiction by Professor Igor Aleksander
FOCS 2009: Manuel Blum - Can (Theoretical Computer) Science come to grips with Consciousness?
www.Conscious-Robots.com, Machine Consciousness and Conscious Robots Portal.
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteConsciousnessFiguresPhilosophy
Alfred North Whitehead
Arthur Schopenhauer
Baruch Spinoza
Bertrand Russell
Brian O'Shaughnessy
Charles Augustus Strong
Christopher Peacocke
Colin McGinn
Daniel Dennett
David Chalmers
David Hume
David Papineau
David Pearce
Donald Davidson
Douglas Hofstadter
Edmund Husserl
Frank Jackson
Fred Dretske
Galen Strawson
George Berkeley
George Henry Lewes
Georges Rey
Gottfried Leibniz
Immanuel Kant
John Eccles
John Locke
John Polkinghorne
John Searle
Joseph Levine
Karl Popper
Keith Frankish
Kenneth M. Sayre
Maurice Merleau-Ponty
Max Velmans
Michael Tye
Martin Heidegger
Ned Block
Patricia Churchland
Paul Churchland
Philip Goff
RenÃ© Descartes
Thomas Metzinger
Thomas Nagel
William Kingdon Clifford
William Lycan
William Seager
Psychology
Carl Gustav Jung
Donald D. Hoffman
Franz Brentano
Gustav Fechner
Kurt Koffka
Max Wertheimer
Sigmund Freud
Wilhelm Wundt
William James
Wolfgang KÃ¶hler
Neuroscience
Anil Seth
Antonio Damasio
Benjamin Libet
Bernard Baars
Christof Koch
Francis Crick
Francisco Varela
Gerald Edelman
Giulio Tononi
Karl Pribram
Lawrence Weiskrantz
Michael Gazzaniga
Michael Graziano
Patrick Wilken
Roger Sperry
Stanislas Dehaene
Steven Laureys
Stuart Hameroff
Wolf Singer
Others
Annaka Harris
David Bohm
Eugene Wigner
Erwin SchrÃ¶dinger
Marvin Minsky
Max Planck
Roger Penrose
Susan Blackmore
Victor J. Stenger
Wolfgang Pauli
TheoriesPhilosophy of mind
Anomalous monism
Computationalism
Double-aspect theory
Eliminative materialism
Emergentism
Epiphenomenalism
Functionalism
Idealism
Interactionism
Materialism
Mindâbody dualism
Monism
Neutral monism
New mysterianism
Panpsychism
Parallelism
Physicalism
Property dualism
Qualia
Reflexive monism
Revisionary materialism
Solipsism
Type physicalism (reductive materialism, identity theory)
Science
Attention schema theory
Dynamic core hypothesis
Damasio's theory of consciousness
Electromagnetic theories of consciousness
Global workspace theory
Holonomic brain theory
Integrated information theory
Lamme's recurrent feedback hypothesis
Multiple drafts model
Orchestrated objective reduction
Topics
Agnosia
Altered state of consciousness
Animal consciousness
Artificial consciousness
Attention
Awareness
Binding problem
Binocular rivalry
Blindsight
Brain
Cartesian theater
Consciousness after death
Disorders of consciousness
Divided consciousness
Dual consciousness (split-brain)
Experience
Explanatory gap
Free will
Flash suppression
Hallucination
Hard problem of consciousness
Heterophenomenology
Higher consciousness
Illusion
Introspection illusion
Knowledge argument
Locked-in syndrome
Mind
Mindâbody problem
Minimally conscious state
Neural correlates of consciousness
Neurophenomenology
Ontology
Phenomenology
Philosophical zombie
Philosophy of mind
Primary consciousness
Problem of other minds
Reentry
Qualia
Quantum mind
Sakshi
Purusha
Secondary consciousness
Sentience
Sentiocentrism
Sociology of human consciousness
Soul
Stream of consciousness
Subconscious
Subjective character of experience
Subjectivity
Unconscious mind
Unconsciousness
Upanishads
Visual masking
Von NeumannâWigner interpretation
Yogachara
Works
A Universe of Consciousness
Association for the Scientific Study of Consciousness
Consciousness and Cognition
Consciousness Explained
Cosmic Consciousness
How the Self Controls Its Brain
Journal of Consciousness Studies
Online Consciousness Conference
Psyche
The Astonishing Hypothesis
The Conscious Mind
The Emperor's New Mind
The Science of Consciousness
Understanding Consciousness
"What Is it Like to Be a Bat?"
Wider than the Sky





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Artificial_consciousness&oldid=1068810717"
		Categories: Artificial intelligenceConsciousnessConsciousness studiesComputational neuroscienceHidden categories: Webarchive template wayback linksCS1 maint: uses authors parameterArticles with short descriptionShort description matches WikidataArticles covered by WikiProject Wikify from June 2020Articles needing footnote reformattingAll articles covered by WikiProject WikifyHarv and Sfn no-target errorsCS1 maint: bot: original URL status unknown
	
