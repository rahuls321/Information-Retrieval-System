
Title:
Beam search
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Heuristic search algorithm
.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Graph and treesearch algorithms
Î±âÎ²
A*
B*
Backtracking
Beam
BellmanâFord
Best-first
Bidirectional
BorÅ¯vka
Branch & bound
BFS
British Museum
D*
DFS
Dijkstra
Edmonds
FloydâWarshall
Fringe search
Hill climbing
IDA*
Iterative deepening
Johnson
Jump point
Kruskal
Lexicographic BFS
LPA*
Prim
SMA*

Listings
Graph algorithms
Search algorithms
List of graph algorithms

Related topics
Dynamic programming
Graph traversal
Tree traversal
Search games
Graph coloring
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
In computer science, beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set. Beam search is an optimization of best-first search that reduces its memory requirements. Best-first search is a graph search which orders all partial solutions (states) according to some heuristic. But in beam search, only a predetermined number of best partial solutions are kept as candidates.[1] It is thus a greedy algorithm.
The term "beam search" was coined by Raj Reddy of Carnegie Mellon University in 1977.[2]

Contents

1 Details
2 Uses
3 Variants
4 References



Details[edit]
Beam search uses breadth-first search to build its search tree. At each level of the tree, it generates all successors of the states at the current level, sorting them in increasing order of heuristic cost.[3] However, it only stores a predetermined number, 
  
    
      
        Î²
      
    
    {\displaystyle \beta }
  
, of best states at each level (called the beam width). Only those states are expanded next.  The greater the beam width, the fewer states are pruned. With an infinite beam width, no states are pruned and beam search is identical to breadth-first search. The beam width bounds the memory required to perform the search. Since a goal state could potentially be pruned, beam search sacrifices completeness (the guarantee that an algorithm will terminate with a solution, if one exists). Beam search is not optimal (that is, there is no guarantee that it will find the best solution).
[4]

Uses[edit]
A beam search is most often used to maintain tractability in large systems with insufficient amount of memory to store the entire search tree.[5] For example, it has been used in many machine translation systems.[6] (The state of the art now primarily uses neural machine translation based methods.) To select the best translation, each part is processed, and many different ways of translating the words appear. The top best translations according to their sentence structures are kept, and the rest are discarded. The translator then evaluates the translations according to a given criterion, choosing the translation which best keeps the goals. The first use of a beam search was in the Harpy Speech Recognition System, CMU 1976.[7]

Variants[edit]
Beam search has been made complete by combining it with depth-first search, resulting in beam stack search[8] and depth-first beam search,[5] and with limited discrepancy search,[9] resulting in beam search using limited discrepancy backtracking[5] (BULB). The resulting search algorithms are anytime algorithms that find good but likely sub-optimal solutions quickly, like beam search, then backtrack and continue to find improved solutions until convergence to an optimal solution.
In the context of a local search, we call local beam search a specific algorithm that begins selecting 
  
    
      
        Î²
      
    
    {\displaystyle \beta }
  
 randomly generated states and then, for each level of the search tree, it always considers 
  
    
      
        Î²
      
    
    {\displaystyle \beta }
  
 new states among all the possible successors of the current ones, until it reaches a goal.[10][11]
Since local beam search often ends up on local maxima, a common solution is to choose the next 
  
    
      
        Î²
      
    
    {\displaystyle \beta }
  
 states in a random way, with a probability dependent from the heuristic evaluation of the states. This kind of search is called stochastic beam search.[12]
Other variants are flexible beam search and recovery beam search.[11]

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"FOLDOC - Computing Dictionary". foldoc.org. Retrieved 2016-04-11.

^ Reddy, D. Raj. "Speech Understanding Systems: A Summary of Results of the Five-Year Research Effort. Department of Computer Science.", 1977.

^ "BRITISH MUSEUM SEARCH". bradley.bradley.edu. Retrieved 2016-04-11.

^ Norvig, Peter (1992-01-01). Paradigms of Artificial Intelligence Programming: Case Studies in Common LISP. Morgan Kaufmann. ISBNÂ 9781558601918.

^ Jump up to: a b c Furcy, David. Koenig, Sven. "Limited Discrepancy Beam Search". 2005. "Archived copy" (PDF). Archived from the original (PDF) on 2008-05-16. Retrieved 2007-12-22.{{cite web}}:  CS1 maint: archived copy as title (link)

^ Tillmann, Christoph. Ney, Hermann. "Word Reordering and a Dynamic Programming Beam Search Algorithm for Statistical Machine Translation". "Archived copy" (PDF). Archived from the original (PDF) on 2006-06-18. Retrieved 2007-12-22.{{cite web}}:  CS1 maint: archived copy as title (link)

^ Lowerre, Bruce. "The Harpy Speech Recognition System",  Ph.D. thesis, Carnegie Mellon University, 1976

^ Zhou, Rong. Hansen, Eric. "Beam-Stack Search: Integrating Backtracking with Beam Search". 2005. http://www.aaai.org/Library/ICAPS/2005/icaps05-010.php

^ CiteSeerx:Â 10.1.1.34.2426

^ Svetlana Lazebnik. "Local search algorithms" (PDF). University of North Carolina at Chapel Hill, Department of Computer Science. p.Â 15. Archived (PDF) from the original on 2011-07-05.

^ Jump up to: a b Pushpak Bhattacharyya. "Beam Search". Indian Institute of Technology Bombay, Department of Computer Science and Engineering (CSE). pp.Â 39â40. Archived from the original on 2018-11-21.

^ James Parker (2017-09-28). "Local Search" (PDF). University of Minnesota. p.Â 17. Archived (PDF) from the original on 2017-10-13. Retrieved 2018-11-21.






<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Beam_search&oldid=1066171110"
		Categories: Search algorithmsHidden categories: CS1 maint: archived copy as titleArticles with short descriptionShort description is different from Wikidata
	
