
Title:
Selection sort
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Sorting algorithm
This article includes a list of references, related reading or external links, but its sources remain unclear because it lacks inline citations. Please help to improve this article by introducing more precise citations.  (May 2019) (Learn how and when to remove this template message)
.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}Selection sortClassSorting algorithmData structureArrayWorst-case performance
  
    
      
        O
        (
        
          n
          
            2
          
        
        )
      
    
    {\displaystyle O(n^{2})}
  
 comparisons, 
  
    
      
        O
        (
        n
        )
      
    
    {\displaystyle O(n)}
  
 swapsBest-case performance
  
    
      
        O
        (
        
          n
          
            2
          
        
        )
      
    
    {\displaystyle O(n^{2})}
  
 comparisons, 
  
    
      
        O
        (
        1
        )
      
    
    {\displaystyle O(1)}
  
 swapAverage performance
  
    
      
        O
        (
        
          n
          
            2
          
        
        )
      
    
    {\displaystyle O(n^{2})}
  
 comparisons, 
  
    
      
        O
        (
        n
        )
      
    
    {\displaystyle O(n)}
  
 swapsWorst-case space complexity
  
    
      
        O
        (
        1
        )
      
    
    {\displaystyle O(1)}
  
 auxiliary
In computer science, selection sort is an in-place comparison sorting algorithm. It has an O(n2) time complexity, which makes it inefficient on large lists, and generally performs worse than the similar insertion sort. Selection sort is noted for its simplicity and has performance advantages over more complicated algorithms in certain situations, particularly where auxiliary memory is limited.
The algorithm divides the input list into two parts: a sorted sublist of items which is built up from left to right at the front (left) of the list and a sublist of the remaining unsorted items that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, exchanging (swapping) it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right. 
The time efficiency of selection sort is quadratic, so there are a number of sorting techniques which have better time complexity than selection sort.  One thing which distinguishes selection sort from other sorting algorithms is that it makes the minimum possible number of swaps, n â 1 in the worst case.

Contents

1 Example
2 Implementations
3 Complexity
4 Comparison to other sorting algorithms
5 Variants
6 See also
7 References
8 External links



Example[edit]
Here is an example of this sort algorithm sorting five elements:



Sorted sublist

Unsorted sublist

Least element in unsorted list


()

(11, 25, 12, 22, 64)

11


(11)

(25, 12, 22, 64)

12


(11, 12)

(25, 22, 64)

22


(11, 12, 22)

(25, 64)

25


(11, 12, 22, 25)

(64)

64


(11, 12, 22, 25, 64)

()



  Selection sort animation. Red is current min. Yellow is sorted list. Blue is current item.
(Nothing appears changed on these last two lines because the last two numbers were already in order.)
Selection sort can also be used on list structures that make add and remove efficient, such as a linked list. In this case it is more common to remove the minimum element from the remainder of the list, and then insert it at the end of the values sorted so far. For example:

arr[] = 64 25 12 22 11

// Find the minimum element in arr[0...4]
// and place it at beginning
11 25 12 22 64

// Find the minimum element in arr[1...4]
// and place it at beginning of arr[1...4]
11 12 25 22 64

// Find the minimum element in arr[2...4]
// and place it at beginning of arr[2...4]
11 12 22 25 64

// Find the minimum element in arr[3...4]
// and place it at beginning of arr[3...4]
11 12 22 25 64 

Implementations[edit]
This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.  (May 2019) (Learn how and when to remove this template message)
Below is an implementation in C.

/* a[0] to a[aLength-1] is the array to sort */
int i,j;
int aLength; // initialise to a's length

/* advance the position through the entire array */
/*   (could do i < aLength-1 because single element is also min element) */
for (i = 0; i < aLength-1; i++)
{
    /* find the min element in the unsorted a[i .. aLength-1] */

    /* assume the min is the first element */
    int jMin = i;
    /* test against elements after i to find the smallest */
    for (j = i+1; j < aLength; j++)
    {
        /* if this element is less, then it is the new minimum */
        if (a[j] < a[jMin])
        {
            /* found new minimum; remember its index */
            jMin = j;
        }
    }

    if (jMin != i) 
    {
        swap(a[i], a[jMin]);
    }
}

Complexity[edit]
Selection sort is not difficult to analyze compared to other sorting algorithms, since none of the loops depend on the data in the array. Selecting the minimum requires scanning 
  
    
      
        n
      
    
    {\displaystyle n}
  
 elements (taking 
  
    
      
        n
        â
        1
      
    
    {\displaystyle n-1}
  
 comparisons) and then swapping it into the first position. Finding the next lowest element requires scanning the remaining 
  
    
      
        n
        â
        1
      
    
    {\displaystyle n-1}
  
 elements and so on. Therefore, the total number of comparisons is

  
    
      
        (
        n
        â
        1
        )
        +
        (
        n
        â
        2
        )
        +
        .
        .
        .
        +
        1
        =
        
          â
          
            i
            =
            1
          
          
            n
            â
            1
          
        
        i
      
    
    {\displaystyle (n-1)+(n-2)+...+1=\sum _{i=1}^{n-1}i}
  

By arithmetic progression,

  
    
      
        
          â
          
            i
            =
            1
          
          
            n
            â
            1
          
        
        i
        =
        
          
            
              (
              n
              â
              1
              )
              +
              1
            
            2
          
        
        (
        n
        â
        1
        )
        =
        
          
            1
            2
          
        
        n
        (
        n
        â
        1
        )
        =
        
          
            1
            2
          
        
        (
        
          n
          
            2
          
        
        â
        n
        )
      
    
    {\displaystyle \sum _{i=1}^{n-1}i={\frac {(n-1)+1}{2}}(n-1)={\frac {1}{2}}n(n-1)={\frac {1}{2}}(n^{2}-n)}
  

which is of complexity 
  
    
      
        O
        (
        
          n
          
            2
          
        
        )
      
    
    {\displaystyle O(n^{2})}
  
 in terms of number of comparisons. Each of these scans requires one swap for 
  
    
      
        n
        â
        1
      
    
    {\displaystyle n-1}
  
 elements (the final element is already in place).

Comparison to other sorting algorithms[edit]
Among quadratic sorting algorithms (sorting algorithms with a simple average-case of Î(n2)), selection sort almost always outperforms bubble sort and gnome sort. Insertion sort is very similar in that after the kth iteration, the first 
  
    
      
        k
      
    
    {\displaystyle k}
  
 elements in the array are in sorted order. Insertion sort's advantage is that it only scans as many elements as it needs in order to place the 
  
    
      
        k
        +
        1
      
    
    {\displaystyle k+1}
  
st element, while selection sort must scan all remaining elements to find the 
  
    
      
        k
        +
        1
      
    
    {\displaystyle k+1}
  
st element.
Simple calculation shows that insertion sort will therefore usually perform about half as many comparisons as selection sort, although it can perform just as many or far fewer depending on the order the array was in prior to sorting. It can be seen as an advantage for some real-time applications that selection sort will perform identically regardless of the order of the array, while insertion sort's running time can vary considerably. However, this is more often an advantage for insertion sort in that it runs much more efficiently if the array is already sorted or "close to sorted."
While selection sort is preferable to insertion sort in terms of number of writes (
  
    
      
        n
        â
        1
      
    
    {\displaystyle n-1}
  
 swaps versus up to 
  
    
      
        n
        (
        n
        â
        1
        )
        
          /
        
        2
      
    
    {\displaystyle n(n-1)/2}
  
 swaps, with each swap being two writes), this is roughly twice the theoretical minimum achieved by cycle sort, which performs at most n writes.  This can be important if writes are significantly more expensive than reads, such as with EEPROM or Flash memory, where every write lessens the lifespan of the memory.
Selection sort can be implemented without unpredictable branches for the benefit of CPU branch predictors, by finding the location of the minimum with branch-free code and then performing the swap unconditionally.
Finally, selection sort is greatly outperformed on larger arrays by 
  
    
      
        Î
        (
        n
        log
        â¡
        n
        )
      
    
    {\displaystyle \Theta (n\log n)}
  
 divide-and-conquer algorithms such as mergesort. However, insertion sort or selection sort are both typically faster for small arrays (i.e. fewer than 10â20 elements). A useful optimization in practice for the recursive algorithms is to switch to insertion sort or selection sort for "small enough" sublists.

Variants[edit]
Heapsort greatly improves the basic algorithm by using an implicit heap data structure to speed up finding and removing the lowest datum. If implemented correctly, the heap will allow finding the next lowest element in 
  
    
      
        Î
        (
        log
        â¡
        n
        )
      
    
    {\displaystyle \Theta (\log n)}
  
 time instead of 
  
    
      
        Î
        (
        n
        )
      
    
    {\displaystyle \Theta (n)}
  
 for the inner loop in normal selection sort, reducing the total running time to 
  
    
      
        Î
        (
        n
        log
        â¡
        n
        )
      
    
    {\displaystyle \Theta (n\log n)}
  
.
A bidirectional variant of selection sort (called double selection sort or sometimes cocktail sort due to its similarity to cocktail shaker sort) finds both the minimum and maximum values in the list in every pass. This requires three comparisons per two items (a pair of elements is compared, then the greater is compared to the maximum and the lesser is compared to the minimum) rather than regular selection sort's one comparison per item, but requires only half as many passes, a net 25% savings.
Selection sort can be implemented as a stable sort if, rather than swapping in step 2, the minimum value is inserted into the first position and the intervening values shifted up. However, this modification either requires a data structure that supports efficient insertions or deletions, such as a linked list, or it leads to performing 
  
    
      
        Î
        (
        
          n
          
            2
          
        
        )
      
    
    {\displaystyle \Theta (n^{2})}
  
 writes.
In the bingo sort variant, items are sorted by repeatedly looking through the remaining items to find the greatest value and moving all items with that value to their final location.[1] Like counting sort, this is an efficient variant if there are many duplicate values: selection sort does one pass through the remaining items for each item moved, while Bingo sort does one pass for each value.  After an initial pass to find the greatest value, subsequent passes move every item with that value to its final location while finding the next value as in the following pseudocode (arrays are zero-based and the for-loop includes both the top and bottom limits, as in Pascal):

bingo(array A)

{ This procedure sorts in ascending order by
  repeatedly moving maximal items to the end. }
begin
    last := length(A) - 1;

    { The first iteration is written to look very similar to the subsequent ones,
      but without swaps. }
    nextMax := A[last];
    for i := last - 1 downto 0 do
        if A[i] > nextMax then
            nextMax := A[i];
    while (last > 0) and (A[last] = nextMax) do
        last := last - 1;

    while last > 0 do begin
        prevMax := nextMax;
        nextMax := A[last];
        for i := last - 1 downto 0 do
             if A[i] > nextMax then
                 if A[i] <> prevMax then
                     nextMax := A[i];
                 else begin
                     swap(A[i], A[last]);
                     last := last - 1;
                 end
        while (last > 0) and (A[last] = nextMax) do
            last := last - 1;
    end;
end;

Thus, if on average there are more than two items with the same value, bingo sort can be expected to be faster because it executes the inner loop fewer times than selection sort.

See also[edit]
Selection algorithm
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ Â This article incorporates public domain materialÂ from theÂ NIST document:Â .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Black, Paul E. "Bingo sort". Dictionary of Algorithms and Data Structures.


.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}
Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching, Third Edition. AddisonâWesley, 1997. ISBNÂ 0-201-89685-0. Pages 138â141 of Section 5.2.3: Sorting by Selection.
Anany Levitin. Introduction to the Design & Analysis of Algorithms, 2nd Edition. ISBNÂ 0-321-35828-7. Section 3.1: Selection Sort, pp 98â100.
Robert Sedgewick. Algorithms in C++, Parts 1â4: Fundamentals, Data Structure, Sorting, Searching: Fundamentals, Data Structures, Sorting, Searching Pts. 1â4, Second Edition. AddisonâWesley Longman, 1998. ISBNÂ 0-201-35088-2. Pages 273â274

External links[edit]



The Wikibook Algorithm implementation has a page on the topic of: Selection sort

Animated Sorting Algorithms: Selection Sort at the Wayback Machine (archived 7 March 2015) â graphical demonstration
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteSorting algorithmsTheory
Computational complexity theory
Big O notation
Total order
Lists
Inplacement
Stability
Comparison sort
Adaptive sort
Sorting network
Integer sorting
X + Y sorting
Transdichotomous model
Quantum sort
Exchange sorts
Bubble sort
Cocktail shaker sort
Oddâeven sort
Comb sort
Gnome sort
Proportion extend sort
Quicksort
Slowsort
Stooge sort
Bogosort
Selection sorts
Selection sort
Heapsort
Smoothsort
Cartesian tree sort
Tournament sort
Cycle sort
Weak-heap sort
Insertion sorts
Insertion sort
Shellsort
Splaysort
Tree sort
Library sort
Patience sorting
Merge sorts
Merge sort
Cascade merge sort
Oscillating merge sort
Polyphase merge sort
Distribution sorts
American flag sort
Bead sort
Bucket sort
Burstsort
Counting sort
Interpolation sort
Pigeonhole sort
Proxmap sort
Radix sort
Flashsort
Concurrent sorts
Bitonic sorter
Batcher oddâeven mergesort
Pairwise sorting network
Samplesort
Hybrid sorts
Block merge sort
Kirkpatrick-Reisch sort
Timsort
Introsort
Spreadsort
Merge-insertion sort
Other
Topological sorting
Pre-topological order
Pancake sorting
Spaghetti sort





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Selection_sort&oldid=1061437484"
		Categories: Sorting algorithmsComparison sortsHidden categories: Articles with short descriptionShort description matches WikidataArticles lacking in-text citations from May 2019All articles lacking in-text citationsArticles needing additional references from May 2019All articles needing additional referencesWebarchive template wayback linksArticles with example C code
	
