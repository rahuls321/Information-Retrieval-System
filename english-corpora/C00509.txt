
Title:
Self-balancing binary search tree
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Any node-based binary search tree that automatically keeps its height the same
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:Â "Self-balancing binary search tree"Â âÂ newsÂ Â· newspapersÂ Â· booksÂ Â· scholarÂ Â· JSTOR  (November 2010) (Learn how and when to remove this template message)
  An example of an unbalanced tree; following the path from the root to a node takes an average of 3.27 node accesses
  The same tree after being height-balanced; the average path effort decreased to 3.00 node accesses
In computer science, a self-balancing binary search tree (BST) is any node-based binary search tree that automatically keeps its height (maximal number of levels below the root) small in the face of arbitrary item insertions and deletions.[1]
These operations when designed for a self-balancing binary search tree, contain precautionary measures against boundlessly increasing tree height, so that these abstract data structures receive the attribute "self-balancing".
For the height-balanced binary trees the height is defined to be logarithmic 
  
    
      
        
          
            O
          
        
        (
        log
        â¡
        n
        )
      
    
    {\displaystyle {\mathcal {O}}(\log n)}
  
 in the number 
  
    
      
        n
      
    
    {\displaystyle n}
  
 of items. This is the case for many binary search trees, such as the AVL trees and the redâblack trees â the latter was called symmetric binary B-tree[2] and was renamed; it can, however, still be confused with the generic concept of self-balancing binary search tree because of the initials.
But the Splay trees and Treaps are considered self-balancing as well, although their height is not guaranteed to be logarithmic in the number of items.
The self-balancing binary search trees provide efficient implementations for mutable ordered lists, and can be used for other abstract data structures such as associative arrays, priority queues and sets.

Contents

1 Overview
2 Implementations
3 Applications
4 See also
5 References
6 External links



Overview[edit]
  Tree rotations are very common internal operations on self-balancing binary trees to keep perfect or near-to-perfect balance.
Most operations on a binary search tree (BST) take time directly proportional to the height of the tree, so it is desirable to keep the height small. A binary tree with height h can contain at most 20+21+Â·Â·Â·+2hÂ =Â 2h+1â1 nodes. It follows that for any tree with n nodes and height h:


  
    
      
        n
        â¤
        
          2
          
            h
            +
            1
          
        
        â
        1
      
    
    {\displaystyle n\leq 2^{h+1}-1}
  

And that implies:


  
    
      
        h
        â¥
        â
        
          log
          
            2
          
        
        â¡
        (
        n
        +
        1
        )
        â
        1
        â
        â¥
        â
        
          log
          
            2
          
        
        â¡
        n
        â
      
    
    {\displaystyle h\geq \lceil \log _{2}(n+1)-1\rceil \geq \lfloor \log _{2}n\rfloor }
  
.
In other words, the minimum height of a binary tree with n nodes is log2(n), rounded down; that is, 
  
    
      
        â
        
          log
          
            2
          
        
        â¡
        n
        â
      
    
    {\displaystyle \lfloor \log _{2}n\rfloor }
  
.[1]
However, the simplest algorithms for BST item insertion may yield a tree with height n in rather common situations.  For example, when the items are inserted in sorted key order, the tree degenerates into a linked list with n nodes.  The difference in performance between the two situations may be enormous: for example, when nÂ =Â 1,000,000, the minimum height is 
  
    
      
        â
        
          log
          
            2
          
        
        â¡
        (
        1
        ,
        000
        ,
        000
        )
        â
        =
        19
      
    
    {\displaystyle \lfloor \log _{2}(1,000,000)\rfloor =19}
  
.
If the data items are known ahead of time, the height can be kept small, in the average sense, by adding values in a random order, resulting in a random binary search tree.  However, there are many situations (such as online algorithms) where this randomization is not viable.
Self-balancing binary trees solve this problem by performing transformations on the tree (such as tree rotations) at key insertion times, in order to keep the height proportional to log2(n). Although a certain overhead is involved, it is not bigger than the always necessary lookup cost and may be justified by ensuring fast execution of all operations.
While it is possible to maintain a BST with minimum height with expected 
  
    
      
        O
        (
        log
        â¡
        n
        )
      
    
    {\displaystyle O(\log n)}
  
 time operations (lookup/insertion/removal), the additional space requirements required to maintain such a structure tend to outweigh the decrease in search time. For comparison, an AVL tree is guaranteed to be within a factor of 1.44 of the optimal height while requiring only two additional bits of storage in a naive implementation.[1] Therefore, most self-balancing BST algorithms keep the height within a constant factor of this lower bound.
In the asymptotic ("Big-O") sense, a self-balancing BST structure containing n items allows the lookup, insertion, and removal of an item in O(log n) worst-case time, and ordered enumeration of all items in O(n) time.  For some implementations these are per-operation time bounds, while for others they are amortized bounds over a sequence of operations.  These times are asymptotically optimal among all data structures that manipulate the key only through comparisons.

Implementations[edit]
Data structures implementing this type of tree include:

2â3 tree
AA tree
AVL tree
B-tree
Redâblack tree
Scapegoat tree
Splay tree
Tango tree
Treap
Weight-balanced tree
Applications[edit]
Self-balancing binary search trees can be used in a natural way to construct and maintain ordered lists, such as priority queues.  They can also be used for associative arrays; key-value pairs are simply inserted with an ordering based on the key alone. In this capacity, self-balancing BSTs have a number of advantages and disadvantages over their main competitor, hash tables. One advantage of self-balancing BSTs is that they allow fast (indeed, asymptotically optimal) enumeration of the items in key order, which hash tables do not provide.  One disadvantage is that their lookup algorithms get more complicated when there may be multiple items with the same key. Self-balancing BSTs have better worst-case lookup performance than hash tables (O(log n) compared to O(n)), but have worse average-case performance (O(log n) compared to O(1)).
Self-balancing BSTs can be used to implement any algorithm that requires mutable ordered lists, to achieve optimal worst-case asymptotic performance. For example, if binary tree sort is implemented with a self-balancing BST, we have a very simple-to-describe yet asymptotically optimal O(n log n) sorting algorithm. Similarly, many algorithms in computational geometry exploit variations on self-balancing BSTs to solve problems such as the line segment intersection problem and the point location problem efficiently.  (For average-case performance, however, self-balancing BSTs may be less efficient than other solutions.  Binary tree sort, in particular, is likely to be slower than merge sort, quicksort, or heapsort, because of the tree-balancing overhead as well as cache access patterns.)
Self-balancing BSTs are flexible data structures, in that it's easy to extend them to efficiently record additional information or perform new operations. For example, one can record the number of nodes in each subtree having a certain property, allowing one to count the number of nodes in a certain key range with that property in O(log n) time. These extensions can be used, for example, to optimize database queries or other list-processing algorithms.

See also[edit]
Search data structure
DayâStoutâWarren algorithm
Fusion tree
Skip list
Sorting
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ a b c Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching, Second Edition. Addison-Wesley, 1998. .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBNÂ 0-201-89685-0. Section 6.2.3: Balanced Trees, pp.458â481.

^ Paul E. Black, "redâblack tree", in Dictionary of Algorithms and Data Structures [online], Vreda Pieterse and Paul E. Black, eds. 13 April 2015. (accessed 03 October 2016) Available from: https://xlinux.nist.gov/dads/HTML/redblack.html


External links[edit]
Dictionary of Algorithms and Data Structures: Height-balanced binary search tree
GNU libavl, a LGPL-licensed library of binary tree implementations in C, with documentation
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteTree data structuresSearch trees(dynamic sets/associative arrays)
2â3
2â3â4
AA
(a,b)
AVL
B
B+
B*
Bx
(Optimal)Â Binary search
Dancing
HTree
Interval
Order statistic
(Left-leaning)Â Redâblack
Scapegoat
Splay
T
Treap
UB
Weight-balanced
Heaps
Binary
Binomial
Brodal
Fibonacci
Leftist
Pairing
Skew
van Emde Boas
Weak
Tries
Ctrie
C-trie (compressed ADT)
Hash
Radix
Suffix
Ternary search
X-fast
Y-fast
Spatial data partitioning trees
Ball
BK
BSP
Cartesian
Hilbert R
k-d (implicit k-d)
M
Metric
MVP
Octree
Priority R
Quad
R
R+
R*
Segment
VP
X
Other trees
Cover
Exponential
Fenwick
Finger
Fractal tree index
Fusion
Hash calendar
iDistance
K-ary
Left-child right-sibling
Link/cut
Log-structured merge
Merkle
PQ
Range
SPQR
Top

vteWell-known data structuresTypes
Collection
Container
Abstract
Associative array
Multimap
Retrieval Data Structure
List
Stack
Queue
Double-ended queue
Priority queue
Double-ended priority queue
Set
Multiset
Disjoint-set
Arrays
Bit array
Circular buffer
Dynamic array
Hash table
Hashed array tree
Sparse matrix
Linked
Association list
Linked list
Skip list
Unrolled linked list
XOR linked list
Trees
B-tree
Binary search tree
AA tree
AVL tree
Redâblack tree
Self-balancing tree
Splay tree
Heap
Binary heap
Binomial heap
Fibonacci heap
R-tree
R* tree
R+ tree
Hilbert R-tree
Trie
Hash tree
Graphs
Binary decision diagram
Directed acyclic graph
Directed acyclic word graph

List of data structures





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Self-balancing_binary_search_tree&oldid=1060319407"
		Categories: Binary treesTrees (data structures)Hidden categories: Articles with short descriptionShort description is different from WikidataArticles needing additional references from November 2010All articles needing additional references
	
