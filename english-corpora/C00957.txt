
Title:
Linear code
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		In coding theory, a linear code is an error-correcting code for which any linear combination of codewords is also a codeword. Linear codes are traditionally partitioned into block codes and convolutional codes, although turbo codes can be seen as a hybrid of these two types.[1] Linear codes allow for more efficient encoding and decoding algorithms than other codes (cf. syndrome decoding).[citation needed]
Linear codes are used in forward error correction and are applied in methods for transmitting symbols (e.g., bits) on a communications channel so that, if errors occur in the communication, some errors can be corrected or detected by the recipient of a message block.  The codewords in a linear block code are blocks of symbols that are encoded using more symbols than the original value to be sent.[2]  A linear code of length n transmits blocks containing n symbols.  For example, the [7,4,3] Hamming code is a linear binary code which represents 4-bit messages using 7-bit codewords.  Two distinct codewords differ in at least three bits.  As a consequence, up to two errors per codeword can be detected while a single error can be corrected.[3]  This code contains 24=16 codewords.

Contents

1 Definition and parameters
2 Generator and check matrices
3 Example: Hamming codes
4 Example: Hadamard codes
5 Nearest neighbor algorithm
6 Popular notation
7 Singleton bound
8 Bonisoli's theorem
9 Examples
10 Generalization
11 See also
12 References

12.1 Bibliography


13 External links



Definition and parameters[edit]
A linear code of length n and rank k is a linear subspace C with dimension k of the vector space 
  
    
      
        
          
            F
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {F} _{q}^{n}}
  
 where 
  
    
      
        
          
            F
          
          
            q
          
        
      
    
    {\displaystyle \mathbb {F} _{q}}
  
 is the finite field with q elements.  Such a code is called a q-ary code.  If qÂ =Â 2 or qÂ =Â 3, the code is described as a binary code, or a ternary code respectively.  The vectors in C are called codewords.  The size of a code is the number of codewords and equals qk.
The weight of a codeword is the number of its elements that are nonzero and the distance between two codewords is the Hamming distance between them, that is, the number of elements in which they differ.  The distance d of the linear code is the minimum weight of its nonzero codewords, or equivalently, the minimum distance between distinct codewords.  A linear code of length n, dimension k, and distance d is called an [n,k,d] code.
We want to give 
  
    
      
        
          
            F
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {F} _{q}^{n}}
  
 the standard basis because each coordinate represents a "bit" that is transmitted across a "noisy channel" with some small probability of transmission error (a binary symmetric channel). If some other basis is used then this model cannot be used and the Hamming metric does not measure the number of errors in transmission, as we want it to.

Generator and check matrices[edit]
As a linear subspace of 
  
    
      
        
          
            F
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {F} _{q}^{n}}
  
, the entire code C (which may be very large) may be represented as the span of a set of 
  
    
      
        k
      
    
    {\displaystyle k}
  
 codewords (known as a basis in linear algebra). These basis codewords are often collated in the rows of a matrix G known as a generating matrix for the code C. When G has the block matrix form 
  
    
      
        
          G
        
        =
        [
        
          I
          
            k
          
        
        
          |
        
        P
        ]
      
    
    {\displaystyle {\boldsymbol {G}}=[I_{k}|P]}
  
, where 
  
    
      
        
          I
          
            k
          
        
      
    
    {\displaystyle I_{k}}
  
 denotes the 
  
    
      
        k
        Ã
        k
      
    
    {\displaystyle k\times k}
  
 identity matrix and P is some 
  
    
      
        k
        Ã
        (
        n
        â
        k
        )
      
    
    {\displaystyle k\times (n-k)}
  
 matrix, then we say G is in standard form.
A matrix H representing a linear function 
  
    
      
        Ï
        :
        
          
            F
          
          
            q
          
          
            n
          
        
        â
        
          
            F
          
          
            q
          
          
            n
            â
            k
          
        
      
    
    {\displaystyle \phi :\mathbb {F} _{q}^{n}\to \mathbb {F} _{q}^{n-k}}
  
 whose kernel is C is called a check matrix of C (or sometimes a parity check matrix).  Equivalently, H is a matrix whose null space is C.  If C is a code with a generating matrix G in standard form, 
  
    
      
        
          G
        
        =
        [
        
          I
          
            k
          
        
        
          |
        
        P
        ]
      
    
    {\displaystyle {\boldsymbol {G}}=[I_{k}|P]}
  
, then 
  
    
      
        
          H
        
        =
        [
        â
        
          P
          
            T
          
        
        
          |
        
        
          I
          
            n
            â
            k
          
        
        ]
      
    
    {\displaystyle {\boldsymbol {H}}=[-P^{T}|I_{n-k}]}
  
 is a check matrix for C.   The code generated by H is called the dual code of C. It can be verified that G is a 
  
    
      
        k
        Ã
        n
      
    
    {\displaystyle k\times n}
  
 matrix, while H is a 
  
    
      
        (
        n
        â
        k
        )
        Ã
        n
      
    
    {\displaystyle (n-k)\times n}
  
 matrix.
Linearity guarantees that the minimum Hamming distance d between a codeword c0 and any of the other codewords cÂ â Â c0 is independent of c0.  This follows from the property that the difference cÂ âÂ c0 of two codewords in C is also a codeword (i.e., an element of the subspace C), and the property that d(c,Â c0)Â =Â d(cÂ âÂ c0,Â 0).  These properties imply that


  
    
      
        
          min
          
            c
            â
            C
            ,
            Â 
            c
            â 
            
              c
              
                0
              
            
          
        
        d
        (
        c
        ,
        
          c
          
            0
          
        
        )
        =
        
          min
          
            c
            â
            C
            ,
            Â 
            c
            â 
            
              c
              
                0
              
            
          
        
        d
        (
        c
        â
        
          c
          
            0
          
        
        ,
        0
        )
        =
        
          min
          
            c
            â
            C
            ,
            Â 
            c
            â 
            0
          
        
        d
        (
        c
        ,
        0
        )
        =
        d
        .
      
    
    {\displaystyle \min _{c\in C,\ c\neq c_{0}}d(c,c_{0})=\min _{c\in C,\ c\neq c_{0}}d(c-c_{0},0)=\min _{c\in C,\ c\neq 0}d(c,0)=d.}
  

In other words, in order to find out the minimum distance between the codewords of a linear code, one would only need to look at the non-zero codewords. The non-zero codeword with the smallest weight has then the minimum distance to the zero codeword, and hence determines the minimum distance of the code.
The distance d of a linear code C also equals the minimum number of linearly dependent columns of the check matrix H.
Proof: Because  
  
    
      
        
          H
        
        â
        
          
            c
          
          
            T
          
        
        =
        
          0
        
      
    
    {\displaystyle {\boldsymbol {H}}\cdot {\boldsymbol {c}}^{T}={\boldsymbol {0}}}
  
, which is equivalent to 
  
    
      
        
          â
          
            i
            =
            1
          
          
            n
          
        
        (
        
          c
          
            i
          
        
        â
        
          
            H
            
              i
            
          
        
        )
        =
        
          0
        
      
    
    {\displaystyle \sum _{i=1}^{n}(c_{i}\cdot {\boldsymbol {H_{i}}})={\boldsymbol {0}}}
  
, where 
  
    
      
        
          
            H
            
              i
            
          
        
      
    
    {\displaystyle {\boldsymbol {H_{i}}}}
  
 is the 
  
    
      
        
          i
          
            t
            h
          
        
      
    
    {\displaystyle i^{th}}
  
 column of 
  
    
      
        
          H
        
      
    
    {\displaystyle {\boldsymbol {H}}}
  
. Remove those items with 
  
    
      
        
          c
          
            i
          
        
        =
        0
      
    
    {\displaystyle c_{i}=0}
  
, those 
  
    
      
        
          
            H
            
              i
            
          
        
      
    
    {\displaystyle {\boldsymbol {H_{i}}}}
  
 with 
  
    
      
        
          c
          
            i
          
        
        â 
        0
      
    
    {\displaystyle c_{i}\neq 0}
  
 are linearly dependent. Therefore, 
  
    
      
        d
      
    
    {\displaystyle d}
  
 is at least the minimum number of linearly dependent columns. On another hand, consider the minimum set of linearly dependent columns 
  
    
      
        {
        
          
            H
            
              j
            
          
        
        
          |
        
        j
        â
        S
        }
      
    
    {\displaystyle \{{\boldsymbol {H_{j}}}|j\in S\}}
  
 where 
  
    
      
        S
      
    
    {\displaystyle S}
  
 is the column index set.  
  
    
      
        
          â
          
            i
            =
            1
          
          
            n
          
        
        (
        
          c
          
            i
          
        
        â
        
          
            H
            
              i
            
          
        
        )
        =
        
          â
          
            j
            â
            S
          
        
        (
        
          c
          
            j
          
        
        â
        
          
            H
            
              j
            
          
        
        )
        +
        
          â
          
            j
            â
            S
          
        
        (
        
          c
          
            j
          
        
        â
        
          
            H
            
              j
            
          
        
        )
        =
        
          0
        
      
    
    {\displaystyle \sum _{i=1}^{n}(c_{i}\cdot {\boldsymbol {H_{i}}})=\sum _{j\in S}(c_{j}\cdot {\boldsymbol {H_{j}}})+\sum _{j\notin S}(c_{j}\cdot {\boldsymbol {H_{j}}})={\boldsymbol {0}}}
  
. Now consider the vector 
  
    
      
        
          
            c
            â²
          
        
      
    
    {\displaystyle {\boldsymbol {c'}}}
  
 such that 
  
    
      
        
          c
          
            j
          
          â²
        
        =
        0
      
    
    {\displaystyle c_{j}'=0}
  
 if 
  
    
      
        j
        â
        S
      
    
    {\displaystyle j\notin S}
  
. Note 
  
    
      
        
          
            c
            â²
          
        
        â
        C
      
    
    {\displaystyle {\boldsymbol {c'}}\in C}
  
 because 
  
    
      
        
          H
        
        â
        
          
            
              c
              â²
            
          
          
            T
          
        
        =
        
          0
        
      
    
    {\displaystyle {\boldsymbol {H}}\cdot {\boldsymbol {c'}}^{T}={\boldsymbol {0}}}
  
 . Therefore, we have 
  
    
      
        d
        â¤
        w
        t
        (
        
          
            c
            â²
          
        
        )
      
    
    {\displaystyle d\leq wt({\boldsymbol {c'}})}
  
, which is the minimum number of linearly dependent columns in 
  
    
      
        
          H
        
      
    
    {\displaystyle {\boldsymbol {H}}}
  
. The claimed property is therefore proven.

Example: Hamming codes[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Hamming code
As the first class of linear codes developed for error correction purpose, Hamming codes have been widely used in digital communication systems. For any positive integer 
  
    
      
        r
        â¥
        2
      
    
    {\displaystyle r\geq 2}
  
, there exists a 
  
    
      
        [
        
          2
          
            r
          
        
        â
        1
        ,
        
          2
          
            r
          
        
        â
        r
        â
        1
        ,
        3
        
          ]
          
            2
          
        
      
    
    {\displaystyle [2^{r}-1,2^{r}-r-1,3]_{2}}
  
 Hamming code. Since 
  
    
      
        d
        =
        3
      
    
    {\displaystyle d=3}
  
, this Hamming code can correct a 1-bit error.
ExampleÂ : The linear block code with the following generator matrix and parity check matrix is a 
  
    
      
        [
        7
        ,
        4
        ,
        3
        
          ]
          
            2
          
        
      
    
    {\displaystyle [7,4,3]_{2}}
  
 Hamming code.


  
    
      
        
          G
        
        =
        
          
            (
            
              
                
                  1
                  Â 
                  0
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  0
                
              
              
                
                  0
                  Â 
                  1
                  Â 
                  0
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                
              
              
                
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  1
                
              
              
                
                  0
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  0
                  Â 
                  1
                
              
            
            )
          
        
        ,
      
    
    {\displaystyle {\boldsymbol {G}}={\begin{pmatrix}1\ 0\ 0\ 0\ 1\ 1\ 0\\0\ 1\ 0\ 0\ 0\ 1\ 1\\0\ 0\ 1\ 0\ 1\ 1\ 1\\0\ 0\ 0\ 1\ 1\ 0\ 1\end{pmatrix}},}
  
  
  
    
      
        
          H
        
        =
        
          
            (
            
              
                
                  1
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  1
                  Â 
                  0
                  Â 
                  0
                
              
              
                
                  1
                  Â 
                  1
                  Â 
                  1
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  0
                
              
              
                
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  1
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                
              
            
            )
          
        
      
    
    {\displaystyle {\boldsymbol {H}}={\begin{pmatrix}1\ 0\ 1\ 1\ 1\ 0\ 0\\1\ 1\ 1\ 0\ 0\ 1\ 0\\0\ 1\ 1\ 1\ 0\ 0\ 1\end{pmatrix}}}
  

Example: Hadamard codes[edit]
Main article: Hadamard code
Hadamard code is a 
  
    
      
        [
        
          2
          
            r
          
        
        ,
        r
        ,
        
          2
          
            r
            â
            1
          
        
        
          ]
          
            2
          
        
      
    
    {\displaystyle [2^{r},r,2^{r-1}]_{2}}
  
 linear code and is capable of correcting many errors. Hadamard code could be constructed column by columnÂ : the 
  
    
      
        
          i
          
            t
            h
          
        
      
    
    {\displaystyle i^{th}}
  
 column is the bits of the binary representation of integer 
  
    
      
        i
      
    
    {\displaystyle i}
  
, as shown in the following example. Hadamard code has minimum distance 
  
    
      
        
          2
          
            r
            â
            1
          
        
      
    
    {\displaystyle 2^{r-1}}
  
 and therefore can correct 
  
    
      
        
          2
          
            r
            â
            2
          
        
        â
        1
      
    
    {\displaystyle 2^{r-2}-1}
  
 errors.
Example:  The linear block code with the following generator matrix is a 
  
    
      
        [
        8
        ,
        3
        ,
        4
        
          ]
          
            2
          
        
      
    
    {\displaystyle [8,3,4]_{2}}
  
 Hadamard code:

  
    
      
        
          
            G
          
          
            H
            a
            d
          
        
        =
        
          
            (
            
              
                
                  0
                  Â 
                  0
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  1
                  Â 
                  1
                
              
              
                
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                  Â 
                  0
                  Â 
                  0
                  Â 
                  1
                  Â 
                  1
                
              
              
                
                  0
                  Â 
                  1
                  Â 
                  0
                  Â 
                  1
                  Â 
                  0
                  Â 
                  1
                  Â 
                  0
                  Â 
                  1
                
              
            
            )
          
        
      
    
    {\displaystyle {\boldsymbol {G}}_{Had}={\begin{pmatrix}0\ 0\ 0\ 0\ 1\ 1\ 1\ 1\\0\ 0\ 1\ 1\ 0\ 0\ 1\ 1\\0\ 1\ 0\ 1\ 0\ 1\ 0\ 1\end{pmatrix}}}
  
.
Hadamard code is a special case of ReedâMuller code. If we take the first column (the all-zero column) out from 
  
    
      
        
          
            G
          
          
            H
            a
            d
          
        
      
    
    {\displaystyle {\boldsymbol {G}}_{Had}}
  
, we get 
  
    
      
        [
        7
        ,
        3
        ,
        4
        
          ]
          
            2
          
        
      
    
    {\displaystyle [7,3,4]_{2}}
  
 simplex code, which is the dual code  of Hamming code.

Nearest neighbor algorithm[edit]
The parameter d is closely related to the error correcting ability of the code. The following construction/algorithm illustrates this (called the nearest neighbor decoding algorithm):
Input: A received vector v in 
  
    
      
        
          
            F
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {F} _{q}^{n}}
  
 .
Output: A codeword 
  
    
      
        w
      
    
    {\displaystyle w}
  
 in 
  
    
      
        C
      
    
    {\displaystyle C}
  
 closest to 
  
    
      
        v
      
    
    {\displaystyle v}
  
, if any.

Starting with 
  
    
      
        t
        =
        0
      
    
    {\displaystyle t=0}
  
, repeat the following two steps.
Enumerate the elements of the ball of (Hamming) radius 
  
    
      
        t
      
    
    {\displaystyle t}
  
 around the received word 
  
    
      
        v
      
    
    {\displaystyle v}
  
, denoted 
  
    
      
        
          B
          
            t
          
        
        (
        v
        )
      
    
    {\displaystyle B_{t}(v)}
  
.
For each 
  
    
      
        w
      
    
    {\displaystyle w}
  
 in 
  
    
      
        
          B
          
            t
          
        
        (
        v
        )
      
    
    {\displaystyle B_{t}(v)}
  
, check if 
  
    
      
        w
      
    
    {\displaystyle w}
  
 in 
  
    
      
        C
      
    
    {\displaystyle C}
  
. If so, return 
  
    
      
        w
      
    
    {\displaystyle w}
  
 as the solution.
Increment 
  
    
      
        t
      
    
    {\displaystyle t}
  
. Fail only when 
  
    
      
        t
        >
        (
        d
        â
        1
        )
        
          /
        
        2
      
    
    {\displaystyle t>(d-1)/2}
  
 so enumeration is complete and no solution has been found.
We say that a linear 
  
    
      
        C
      
    
    {\displaystyle C}
  
 is 
  
    
      
        t
      
    
    {\displaystyle t}
  
-error correcting if there is at most one codeword in 
  
    
      
        
          B
          
            t
          
        
        (
        v
        )
      
    
    {\displaystyle B_{t}(v)}
  
, for each 
  
    
      
        v
      
    
    {\displaystyle v}
  
 in 
  
    
      
        
          
            F
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {F} _{q}^{n}}
  
.

Popular notation[edit]
Main article: Block code Â§Â Popular notation
Codes in general are often denoted by the letter C, and a code of length n and of rank k (i.e., having k code words in its basis and k rows in its generating matrix) is generally referred to as an (n,Â k) code. Linear block codes are frequently denoted as [n,Â k,Â d] codes, where d refers to the code's minimum Hamming distance between any two code words.
(The [n,Â k,Â d] notation should not be confused with the (n,Â M,Â d) notation used to denote a non-linear code of length n, size M (i.e., having M code words), and minimum Hamming distance d.)

Singleton bound[edit]
Lemma (Singleton bound): Every linear [n,k,d] code C satisfies 
  
    
      
        k
        +
        d
        â¤
        n
        +
        1
      
    
    {\displaystyle k+d\leq n+1}
  
.
A code C whose parameters satisfy k+d=n+1 is called maximum distance separable or MDS. Such codes, when they exist, are in some sense best possible.
If C1 and C2 are two codes of length n and if there is a permutation p in the symmetric group Sn for which (c1,...,cn) in C1 if and only if (cp(1),...,cp(n)) in C2, then we say C1 and C2 are permutation equivalent. In more generality, if there is an 
  
    
      
        n
        Ã
        n
      
    
    {\displaystyle n\times n}
  
 monomial matrix 
  
    
      
        M
        :
        
          
            F
          
          
            q
          
          
            n
          
        
        â
        
          
            F
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle M\colon \mathbb {F} _{q}^{n}\to \mathbb {F} _{q}^{n}}
  
 which sends C1 isomorphically to C2 then we say C1 and C2 are equivalent.
Lemma: Any linear code is permutation equivalent to a code which is in standard form.

Bonisoli's theorem[edit]
A code is defined to be equidistant if and only if there exists some constant d such that the distance between any two of the code's distinct codewords is equal to d.[4] In 1984 Arrigo Bonisoli determined the structure of linear one-weight codes over finite fields and proved that every equidistant linear code is a sequence of dual Hamming codes.[5]

Examples[edit]
Some examples of linear codes include:

.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}
Repetition codes
Parity codes
Cyclic codes
Hamming codes
Golay code, both the binary and ternary versions
Polynomial codes, of which BCH codes are an example
ReedâSolomon codes
ReedâMuller codes
Goppa codes
Low-density parity-check codes
Expander codes
Multidimensional parity-check codes
Toric codes
Turbo codes

Generalization[edit]
Hamming spaces over non-field alphabets have also been considered, especially over finite rings, most notably Galois rings over Z4. This gives rise to modules instead of vector spaces and ring-linear codes (identified with submodules) instead of linear codes. The typical metric used in this case the Lee distance. There exist a Gray isometry between 
  
    
      
        
          
            Z
          
          
            2
          
          
            2
            m
          
        
      
    
    {\displaystyle \mathbb {Z} _{2}^{2m}}
  
 (i.e. GF(22m)) with the Hamming distance and 
  
    
      
        
          
            Z
          
          
            4
          
          
            m
          
        
      
    
    {\displaystyle \mathbb {Z} _{4}^{m}}
  
 (also denoted as GR(4,m)) with the Lee distance; its main attraction is that it establishes a correspondence between some "good" codes that are not linear over 
  
    
      
        
          
            Z
          
          
            2
          
          
            2
            m
          
        
      
    
    {\displaystyle \mathbb {Z} _{2}^{2m}}
  
 as images of ring-linear codes from 
  
    
      
        
          
            Z
          
          
            4
          
          
            m
          
        
      
    
    {\displaystyle \mathbb {Z} _{4}^{m}}
  
.[6][7][8]
More recently,[when?] some authors have referred to such codes over rings simply as linear codes as well.[9]

See also[edit]
Decoding methods
References[edit]

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}William E. Ryan and Shu Lin (2009). Channel Codes: Classical and Modern. Cambridge University Press. p.Â 4. ISBNÂ 978-0-521-84868-8.

^ MacKay, David, J.C. (2003). Information Theory, Inference, and Learning Algorithms (PDF). Cambridge University Press. p.Â 9. Bibcode:2003itil.book.....M. ISBNÂ 9780521642989. In a linear block code, the extra 
  
    
      
        N
        â
        K
      
    
    {\displaystyle N-K}
  
 bits are linear functions of the original 
  
    
      
        K
      
    
    {\displaystyle K}
  
 bits; these extra bits are called parity-check bits

^ Thomas M. Cover and Joy A. Thomas (1991). Elements of Information Theory. John Wiley & Sons, Inc. pp.Â 210â211. ISBNÂ 978-0-471-06259-2.

^ Etzion, Tuvi; Raviv, Netanel (2013). "Equidistant codes in the Grassmannian". arXiv:1308.6231 [math.CO].

^ Bonisoli, A. (1984). "Every equidistant linear code is a sequence of dual Hamming codes". Ars Combinatoria. 18: 181â186.

^ Marcus Greferath (2009). "An Introduction to Ring-Linear Coding Theory".  In Massimiliano Sala; Teo Mora; Ludovic Perret; Shojiro Sakata; Carlo Traverso (eds.). GrÃ¶bner Bases, Coding, and Cryptography. Springer Science & Business Media. ISBNÂ 978-3-540-93806-4.

^ "Encyclopedia of Mathematics". www.encyclopediaofmath.org.

^ J.H. van Lint (1999). Introduction to Coding Theory (3rdÂ ed.). Springer. Chapter 8: Codes over â¤4. ISBNÂ 978-3-540-64133-9.

^ S.T. Dougherty; J.-L. Kim; P. Sole (2015). "Open Problems in Coding Theory".  In Steven Dougherty; Alberto Facchini; Andre Gerard Leroy; Edmund Puczylowski; Patrick Sole (eds.). Noncommutative Rings and Their Applications. American Mathematical Soc. p.Â 80. ISBNÂ 978-1-4704-1032-2.


Bibliography[edit]
J. F. Humphreys; M. Y. Prest (2004). Numbers, Groups and Codes (2ndÂ ed.). Cambridge University Press. ISBNÂ 978-0-511-19420-7. Chapter 5 contains a more gentle introduction (than this article) to the subject of linear codes.
External links[edit]
q-ary code generator program
Code Tables: Bounds on the parameters of various types of codes, IAKS, FakultÃ¤t fÃ¼r Informatik, UniversitÃ¤t Karlsruhe (TH)]. Online, up to date table of the optimal binary codes, includes non-binary codes.
The database of Z4 codes Online, up to date database of optimal Z4 codes.




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Linear_code&oldid=1068909404"
		Categories: Coding theoryFinite fieldsHidden categories: All articles with unsourced statementsArticles with unsourced statements from April 2018All articles with vague or ambiguous timeVague or ambiguous time from May 2015
	
