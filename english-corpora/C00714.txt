
Title:
Quantum information
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Information held in the state of a quantum system
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}For the journal, see Quantum Information (journal).
    Optical lattices use lasers to separate rubidium atoms (red) for use as information bits in neutral-atom quantum processorsâprototype devices which designers are trying to develop into full-fledged quantum computers.[1] Credit: NIST 
Quantum information is the information of the state of a quantum system.  It is the basic entity of study in quantum information theory,[2] and can be manipulated using quantum information processing techniques. Quantum information refers to both the technical definition in terms of Von Neumann entropy and the general computational term.
It is an interdisciplinary field that involves quantum mechanics, computer science, information theory, philosophy and cryptography among other fields.[3][4] Its study is also relevant to disciplines such as cognitive science, psychology and neuroscience.[5] Its main focus is in extracting information from matter at the microscopic scale. Observation in science is one of the most important ways of acquiring information and measurement is required in order to quantify the observation, making this crucial to the scientific method. In quantum mechanics, due to the uncertainty principle, non-commuting observables cannot be precisely measured simultaneously, as an eigenstate in one basis is not an eigenstate in the other basis. As both variables are not simultaneously well defined, a quantum state can never contain definitive information about both variables.[5]
Information is something that is encoded in the state of a quantum system;[6] it is physical.[6] While quantum mechanics deals with examining properties of matter at the microscopic level,[7][5] quantum information science focuses on extracting information from those properties,[5] and quantum computation manipulates and processes information â performs logical operations â using quantum information processing techniques.[8]
Quantum information, like classical information, can be processed using digital computers, transmitted from one location to another, manipulated with algorithms, and analyzed with computer science and mathematics. Just like the basic unit of classical information is the bit, quantum information deals with qubits. Quantum information can be measured using Von Neumann entropy.
Recently, the field of quantum computing has become an active research area because of the possibility to disrupt modern computation, communication, and cryptography.[8]

Contents

1 History and development

1.1 Development from fundamental quantum mechanics

1.1.1 Development from communication
1.1.2 Development from atomic physics and relativity
1.1.3 Development from cryptography
1.1.4 Development from computer science and mathematics


1.2 Development from information theory


2 Qubits and information theory
3 Quantum information processing
4 Relation to quantum mechanics
5 Entropy and information

5.1 Classical information theory

5.1.1 Shannon entropy
5.1.2 RÃ©nyi entropy


5.2 Quantum information theory

5.2.1 Von Neumann entropy




6 Applications
7 Journals
8 See also
9 Notes
10 References



History and development[edit]
Development from fundamental quantum mechanics[edit]
The history of quantum information theory began at the turn of the 20th century when classical physics was revolutionized into quantum physics. The theories of classical physics were predicting absurdities such as the ultraviolet catastrophe, or electrons spiraling into the nucleus. At first these problems were brushed aside by adding ad hoc hypotheses to classical physics. Soon, it became apparent that a new theory must be created in order to make sense of these absurdities, and the theory of quantum mechanics was born.[2]
Quantum mechanics was formulated by SchrÃ¶dinger using wave mechanics and Heisenberg using matrix mechanics.[9] The equivalence of these methods was proven later.[10] Their formulations described the dynamics of microscopic systems but had several unsatisfactory aspects in describing measurement processes. Von Neumann formulated quantum theory using operator algebra in a way that it described measurement as well as dynamics.[11] These studies emphasized the philosophical aspects of measurement rather than a quantitative approach to extracting information via measurements.
See: Dynamical Pictures



Evolution

Picture (.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte)


of:

Heisenberg

Interaction

SchrÃ¶dinger


Ket state

constant


  
    
      
        
          |
        
        
          Ï
          
            
              I
            
          
        
        (
        t
        )
        â©
        =
        
          e
          
            i
            
              H
              
                0
                ,
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
        
          |
        
        
          Ï
          
            
              S
            
          
        
        (
        t
        )
        â©
      
    
    {\displaystyle |\psi _{\rm {I}}(t)\rangle =e^{iH_{0,\mathrm {S} }~t/\hbar }|\psi _{\rm {S}}(t)\rangle }
  



  
    
      
        
          |
        
        
          Ï
          
            
              S
            
          
        
        (
        t
        )
        â©
        =
        
          e
          
            â
            i
            
              H
              
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
        
          |
        
        
          Ï
          
            
              S
            
          
        
        (
        0
        )
        â©
      
    
    {\displaystyle |\psi _{\rm {S}}(t)\rangle =e^{-iH_{\rm {S}}~t/\hbar }|\psi _{\rm {S}}(0)\rangle }
  



Observable


  
    
      
        
          A
          
            
              H
            
          
        
        (
        t
        )
        =
        
          e
          
            i
            
              H
              
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
        
          A
          
            
              S
            
          
        
        
          e
          
            â
            i
            
              H
              
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
      
    
    {\displaystyle A_{\rm {H}}(t)=e^{iH_{\rm {S}}~t/\hbar }A_{\rm {S}}e^{-iH_{\rm {S}}~t/\hbar }}
  



  
    
      
        
          A
          
            
              I
            
          
        
        (
        t
        )
        =
        
          e
          
            i
            
              H
              
                0
                ,
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
        
          A
          
            
              S
            
          
        
        
          e
          
            â
            i
            
              H
              
                0
                ,
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
      
    
    {\displaystyle A_{\rm {I}}(t)=e^{iH_{0,\mathrm {S} }~t/\hbar }A_{\rm {S}}e^{-iH_{0,\mathrm {S} }~t/\hbar }}
  


constant


Density matrix

constant


  
    
      
        
          Ï
          
            
              I
            
          
        
        (
        t
        )
        =
        
          e
          
            i
            
              H
              
                0
                ,
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
        
          Ï
          
            
              S
            
          
        
        (
        t
        )
        
          e
          
            â
            i
            
              H
              
                0
                ,
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
      
    
    {\displaystyle \rho _{\rm {I}}(t)=e^{iH_{0,\mathrm {S} }~t/\hbar }\rho _{\rm {S}}(t)e^{-iH_{0,\mathrm {S} }~t/\hbar }}
  



  
    
      
        
          Ï
          
            
              S
            
          
        
        (
        t
        )
        =
        
          e
          
            â
            i
            
              H
              
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
        
          Ï
          
            
              S
            
          
        
        (
        0
        )
        
          e
          
            i
            
              H
              
                
                  S
                
              
            
            Â 
            t
            
              /
            
            â
          
        
      
    
    {\displaystyle \rho _{\rm {S}}(t)=e^{-iH_{\rm {S}}~t/\hbar }\rho _{\rm {S}}(0)e^{iH_{\rm {S}}~t/\hbar }}
  





Development from communication[edit]
In 1960s, Stratonovich, Helstrom and Gordon[12] proposed a formulation of optical communications using quantum mechanics. This was the first historical appearance of quantum information theory. They mainly studied error probabilities and channel capacities for communication.[12][13] Later, Holevo obtained an upper bound of communication speed in the transmission of a classical message via a quantum channel.[14][15]

Development from atomic physics and relativity[edit]
In the 1970s, techniques for manipulating single-atom quantum states, such as the atom trap and the scanning tunneling microscope, began to be developed, making it possible to isolate single atoms and arrange them in arrays. Prior to these developments, precise control over single quantum systems was not possible, and experiments utilized coarser, simultaneous control over a large number of quantum systems.[2] The development of viable single-state manipulation techniques led to increased interest in the field of quantum information and computation.
In the 1980s, interest arose in whether it might be possible to use quantum effects to disprove Einstein's theory of relativity. If it were possible to clone an unknown quantum state, it would be possible to use entangled quantum states to transmit information faster than the speed of light, disproving Einstein's theory. However, the no-cloning theorem showed that such cloning is impossible. The theorem was one of the earliest results of quantum information theory.[2]

Development from cryptography[edit]
See also: Quantum cryptography
Despite all the excitement and interest over studying isolated quantum systems and trying to find a way to circumvent the theory of relativity, research in quantum information theory became stagnant in the 1980s. However, around the same time another avenue started dabbling into quantum information and computation: Cryptography. In a general sense, cryptography is the problem of doing communication or computation involving two or more parties who may not trust one another.[2]
Bennett and Brassard developed a communication channel on which it is impossible to eavesdrop without being detected, a way of communicating secretly at long distances using the BB84 quantum cryptographic protocol.[16] The key idea was the use of the fundamental principle of quantum mechanics that observation disturbs the observed, and the introduction of an eavesdropper in a secure communication line will immediately let the two parties trying to communicate know of the presence of the eavesdropper.

Development from computer science and mathematics[edit]
See also: Quantum supremacy and Quantum algorithm
With the advent of Alan Turing's revolutionary ideas of a programmable computer, or Turing machine, he showed that any real-world computation can be translated into an equivalent computation involving a Turing machine.[17][18] This is known as the ChurchâTuring thesis.
Soon enough, the first computers were made and computer hardware grew at such a fast pace that the growth, through experience in production, was codified into an empirical relationship called Moore's law. This 'law' is a projective trend that states that the number of transistors in an integrated circuit doubles every two years.[19] As transistors began to become smaller and smaller in order to pack more power per surface area, quantum effects started to show up in the electronics resulting in inadvertent interference. This led to the advent of quantum computing, which used quantum mechanics to design algorithms.
At this point, quantum computers showed promise of being much faster than classical computers for certain specific problems. One such example problem was developed by David Deutsch and Richard Jozsa, known as the DeutschâJozsa algorithm. This problem however held little to no practical applications.[2] Peter Shor in 1994 came up with a very important and practical problem, one of finding the prime factors of an integer. The discrete logarithm problem as it was called, could be solved efficiently on a quantum computer but not on a classical computer hence showing that quantum computers are more powerful than Turing machines.

Development from information theory[edit]
Around the time computer science was making a revolution, so was information theory and communication, through Claude Shannon.[20][21][22] Shannon developed two fundamental theorems of information theory: noiseless channel coding theorem and noisy channel coding theorem. He also showed that error correcting codes could be used to protect information being sent.
Quantum information theory also followed a similar trajectory, Ben Schumacher in 1995 made an analogue to Shannon's noiseless coding theorem using the qubit. A theory of error-correction also developed, which allows quantum computers to make efficient computations regardless of noise, and make reliable communication over noisy quantum channels.[2]

Qubits and information theory[edit]
Quantum information differs strongly from classical information, epitomized by the bit, in many striking and unfamiliar ways.  While the fundamental unit of classical information is the bit, the most basic unit of quantum information is the qubit. Classical information is measured using Shannon entropy, while the quantum mechanical analogue is Von Neumann entropy.  Given a statistical ensemble of quantum mechanical systems with the density matrix 
  
    
      
        Ï
      
    
    {\displaystyle \rho }
  
, it is given by 
  
    
      
        S
        (
        Ï
        )
        =
        â
        Tr
        â¡
        (
        Ï
        ln
        â¡
        Ï
        )
        .
      
    
    {\displaystyle S(\rho )=-\operatorname {Tr} (\rho \ln \rho ).}
  
[2]  Many of the same entropy measures in classical information theory can also be generalized to the quantum case, such as Holevo entropy[23] and the conditional quantum entropy.
Unlike classical digital states (which are discrete), a qubit is continuous-valued, describable by a direction on the Bloch sphere.  Despite being continuously valued in this way, a qubit is the smallest possible unit of quantum information, and despite the qubit state being continuous-valued, it is impossible to measure the value precisely. Five famous theorems describe the limits on manipulation of quantum information.[2] 

no-teleportation theorem, which states that a qubit cannot be (wholly) converted into classical bits; that is, it cannot be fully "read".
no-cloning theorem, which prevents an arbitrary qubit from being copied.
no-deleting theorem, which prevents an arbitrary qubit from being deleted.
no-broadcast theorem, which prevents an arbitrary qubit from being delivered to multiple recipients, although it can be transported from place to place (e.g. via quantum teleportation).
no-hiding theorem, which demonstrates the conservation of quantum information.
These theorems prove that quantum information within the universe is conserved. They open up possibilities in quantum information processing.

Quantum information processing[edit]
The state of a qubit contains all of its information. This state is frequently expressed as a vector on the Bloch sphere. This state can be changed by applying linear transformations or quantum gates to them. These unitary transformations are described as rotations on the Bloch Sphere. While classical gates correspond to the familiar operations of Boolean logic, quantum gates are physical unitary operators.

Due to the volatility of quantum systems and the impossibility of copying states, the storing of quantum information is much more difficult than storing classical information. Nevertheless, with the use of quantum error correction quantum information can still be reliably stored in principle. The existence of quantum error correcting codes has also led to the possibility of fault-tolerant quantum computation.
Classical bits can be encoded into and subsequently retrieved from configurations of qubits, through the use of quantum gates.  By itself, a single qubit can convey no more than one bit of accessible classical information about its preparation.  This is Holevo's theorem.  However, in superdense coding a sender, by acting on one of two entangled qubits, can convey two bits of accessible information about their joint state to a receiver.
Quantum information can be moved about, in a quantum channel, analogous to the concept of a classical communications channel. Quantum messages have a finite size, measured in qubits; quantum channels have a finite channel capacity, measured in qubits per second.
Quantum information, and changes in quantum information, can be quantitatively measured by using an analogue of Shannon entropy, called the von Neumann entropy.
In some cases quantum algorithms can be used to perform computations faster than in any known classical algorithm. The most famous example of this is Shor's algorithm that can factor numbers in polynomial time, compared to the best classical algorithms that take sub-exponential time. As factorization is an important part of the safety of RSA encryption, Shor's algorithm sparked the new field of post-quantum cryptography that tries to find encryption schemes that remain safe even when quantum computers are in play.  Other examples of algorithms that demonstrate quantum supremacy include Grover's search algorithm, where the quantum algorithm gives a quadratic speed-up over the best possible classical algorithm. The complexity class of problems efficiently solvable by a quantum computer is known as BQP.
Quantum key distribution (QKD) allows unconditionally secure transmission of classical information, unlike classical encryption, which can always be broken in principle, if not in practice.  Do note that certain subtle points regarding the safety of QKD are still hotly debated.
The study of all of the above topics and differences comprises quantum information theory.

Relation to quantum mechanics[edit]
Quantum mechanics is the study of how microscopic physical systems change dynamically in nature. In the field of quantum information theory, the quantum systems studied are abstracted away from any real world counterpart. A qubit might for instance physically be a photon in a linear optical quantum computer, an ion in a trapped ion quantum computer, or it might be a large collection of atoms as in a superconducting quantum computer. Regardless of the physical implementation, the limits and features of qubits implied by quantum information theory hold as all these systems are  mathematically described by the same apparatus of density matrices over the complex numbers. Another important difference with quantum mechanics is that, while quantum mechanics often studies infinite-dimensional systems such as a harmonic oscillator, quantum information theory concerns both with continuous-variable systems[24] and finite-dimensional systems.[25][26][27]

Entropy and information[edit]
Entropy measures the uncertainty in the state of a physical system.[2] Entropy can be studied from the point of view of both the classical and quantum information theories.

Classical information theory[edit]
Classical information is based on the concepts of information laid out by Claude Shannon. Classical information, in principle, can be stored in a bit of binary strings. Any system having two states is a capable bit.[28]

Shannon entropy[edit]
Main article: Entropy (information theory)
See also: Shannon's source coding theorem
Shannon entropy is the quantification of the information gained by measuring the value of a random variable. Another way of thinking about it is by looking at the uncertainty of a system prior to measurement. As a result, entropy, as pictured by Shannon, can be seen either as a measure of the uncertainty prior to making a measurement or as a measure of information gained after making said measurement.[2]
Shannon entropy, written as a functional of a discrete probability distribution, 
  
    
      
        P
        (
        
          x
          
            1
          
        
        )
        ,
        P
        (
        
          x
          
            2
          
        
        )
        ,
        .
        .
        .
        ,
        P
        (
        
          x
          
            n
          
        
        )
      
    
    {\displaystyle P(x_{1}),P(x_{2}),...,P(x_{n})}
  
 associated with events 
  
    
      
        
          x
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          x
          
            n
          
        
      
    
    {\displaystyle x_{1},...,x_{n}}
  
, can be seen as the average information associated with this set of events, in units of bits:

  
    
      
        H
        (
        X
        )
        =
        H
        [
        P
        (
        
          x
          
            1
          
        
        )
        ,
        P
        (
        
          x
          
            2
          
        
        )
        ,
        .
        .
        .
        ,
        P
        (
        
          x
          
            n
          
        
        )
        ]
        =
        â
        
          â
          
            i
            =
            1
          
          
            n
          
        
        P
        (
        
          x
          
            i
          
        
        )
        
          log
          
            2
          
        
        â¡
        P
        (
        
          x
          
            i
          
        
        )
      
    
    {\displaystyle H(X)=H[P(x_{1}),P(x_{2}),...,P(x_{n})]=-\sum _{i=1}^{n}P(x_{i})\log _{2}P(x_{i})}
  

This definition of entropy can be used to quantify the physical resources required to store the output of an information source. The ways of interpreting Shannon entropy discussed above are usually only meaningful when the number of samples of an experiment is large.[29]

RÃ©nyi entropy[edit]
Main article: RÃ©nyi entropy
The RÃ©nyi entropy is a generalization of Shannon entropy defined above. The RÃ©nyi entropy of order r, written as a function of a discrete probability distribution, 
  
    
      
        P
        (
        
          a
          
            1
          
        
        )
        ,
        P
        (
        
          a
          
            2
          
        
        )
        ,
        .
        .
        .
        ,
        P
        (
        
          a
          
            n
          
        
        )
      
    
    {\displaystyle P(a_{1}),P(a_{2}),...,P(a_{n})}
  
, associated with events 
  
    
      
        
          a
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          a
          
            n
          
        
      
    
    {\displaystyle a_{1},...,a_{n}}
  
, is defined as:[28]

  
    
      
        
          H
          
            r
          
        
        (
        A
        )
        =
        
          
            1
            
              1
              â
              r
            
          
        
        
          log
          
            2
          
        
        â¡
        
          â
          
            i
            =
            1
          
          
            n
          
        
        
          P
          
            r
          
        
        (
        
          a
          
            i
          
        
        )
      
    
    {\displaystyle H_{r}(A)={1 \over 1-r}\log _{2}\sum _{i=1}^{n}P^{r}(a_{i})}
  

for 
  
    
      
        0
        <
        r
        <
        â
      
    
    {\displaystyle 0<r<\infty }
  
 and 
  
    
      
        r
        â 
        1
      
    
    {\displaystyle r\neq 1}
  
.
We arrive at the definition of Shannon entropy from RÃ©nyi when 
  
    
      
        r
        â
        1
      
    
    {\displaystyle r\rightarrow 1}
  
, of Hartley entropy (or max-entropy) when 
  
    
      
        r
        â
        0
      
    
    {\displaystyle r\rightarrow 0}
  
, and min-entropy when 
  
    
      
        r
        â
        â
      
    
    {\displaystyle r\rightarrow \infty }
  
.

Quantum information theory[edit]
Quantum information theory is largely an extension of classical information theory to quantum systems. Classical information is produced when measurements of quantum systems are made.[28]

Von Neumann entropy[edit]
Main article: Von Neumann entropy
One interpretation of Shannon entropy was the uncertainty associated with a probability distribution. When we want to describe the information or the uncertainty of a quantum state, the probability distributions are simply swapped out by density operators 
  
    
      
        Ï
      
    
    {\displaystyle \rho }
  
.

  
    
      
        S
        (
        Ï
        )
        â¡
        â
        
          t
          r
        
        (
        Ï
        Â 
        
          log
          
            2
          
        
        â¡
        Â 
        Ï
        )
        =
        â
        
          â
          
            i
          
        
        
          Î»
          
            i
          
        
        Â 
        
          log
          
            2
          
        
        â¡
        Â 
        
          Î»
          
            i
          
        
      
    
    {\displaystyle S(\rho )\equiv -\mathrm {tr} (\rho \ \log _{2}\ \rho )=-\sum _{i}\lambda _{i}\ \log _{2}\ \lambda _{i}}
  


  
    
      
        
          Î»
          
            i
          
        
      
    
    {\displaystyle \lambda _{i}}
  
s are the eigenvalues of 
  
    
      
        Ï
      
    
    {\displaystyle \rho }
  
.
Von Neumann plays a similar role in quantum information that Shannon entropy does in classical information

Applications[edit]
Quantum communication
Quantum communication is one of the applications of quantum physics and quantum information. There are some famous theorems such as the no-cloning theorem that illustrate some important properties in quantum communication. Dense coding and quantum teleportation are also applications of quantum communication. They are two opposite ways to communicate using qubits. While teleportation transfers one qubit from Alice and Bob by communicating two classical bits under the assumption that Alice and Bob have a pre-shared Bell state, dense coding transfers two classical bits from Alice to Bob by using one qubit, again under the same assumption, that Alice and Bob have a pre-shared Bell state.
Quantum key distribution

Main article: Quantum key distribution
One of the best known applications of quantum cryptography is quantum key distribution which provide a theoretical solution to the security issue of a classical key. The advantage of quantum key distribution is that it is impossible to copy a quantum key because of the no-cloning theorem. If someone tries to read encoded data, the quantum state being transmitted will change. This could be used to detect eavesdropping.

BB84
The first quantum key distribution scheme BB84, developed by Charles Bennett and Gilles Brassard in 1984. It is usually explained as a method of securely communicating a private key from a third party to another for use in one-time pad encryption.[2]

E91
E91 was made by Artur Ekert in 1991. His scheme uses entangled pairs of photons. These two photons can be created by Alice, Bob, or by a third party including eavesdropper Eve. One of the photons is distributed to Alice and the other to Bob so that each one ends up with one photon from the pair.
This scheme relies on two properties of quantum entanglement:

The entangled states are perfectly correlated which means that if Alice and Bob both measure their particles having either a vertical or horizontal polarization, they always get the same answer with 100% probability. The same is true if they both measure any other pair of complementary (orthogonal) polarizations. This necessitates that the two distant parties have exact directionality synchronization. However, from quantum mechanics theory the quantum state is completely random so that it is impossible for Alice to predict if she will get vertical polarization or horizontal polarization results.
Any attempt at eavesdropping by Eve destroys this quantum entanglement such that Alice and Bob can detect.
B92
B92 is a simpler version of BB84.[30]
The main difference between B92 and BB84:

B92 only needs two states
BB84 needs 4 polarization states
Like the BB84, Alice transmits to Bob a string of photons encoded with randomly chosen bits but this time the bits Alice chooses the bases she must use. Bob still randomly chooses a basis by which to measure but if he chooses the wrong basis, he will not measure anything which is guaranteed by quantum mechanics theories. Bob can simply tell Alice after each bit she sends whether or not he measured it correctly.[31]
Quantum computation

Main article: Quantum computing
The most widely used model in quantum computation is the quantum circuit, which are based on the quantum bit "qubit". Qubit is somewhat analogous to the bit in classical computation. Qubits can be in a 1 or 0 quantum state, or they can be in a superposition of the 1 and 0 states. However, when qubits are measured the result of the measurement is always either a 0 or a 1; the probabilities of these two outcomes depend on the quantum state that the qubits were in immediately prior to the measurement.
Any quantum computation algorithm can be represented as a network of quantum logic gates.
Quantum decoherence

Main article: Quantum decoherence
If a quantum system were perfectly isolated, it would maintain coherence perfectly, but it would be impossible to test the entire system. If it is not perfectly isolated, for example during a measurement, coherence is shared with the environment and appears to be lost with time; this process is called quantum decoherence. As a result of this process, quantum behavior is apparently lost, just as energy appears to be lost by friction in classical mechanics.
Quantum error correction

Main article: Quantum error correction
QEC is used in quantum computing to protect quantum information from errors due to decoherence and other quantum noise. Quantum error correction is essential if one is to achieve fault-tolerant quantum computation that can deal not only with noise on stored quantum information, but also with faulty quantum gates, faulty quantum preparation, and faulty measurements.
Peter Shor first discovered this method of formulating a quantum error correcting code by storing the information of one qubit onto a highly entangled state of ancilla qubits. A quantum error correcting code protects quantum information against errors.

Journals[edit]
Many journals publish research in quantum information science, although only a few are dedicated to this area. Among these are:

International Journal of Quantum Information
Quantum Information & Computation
Quantum Information Processing
npj Quantum Information[32]
Quantum[33]
Quantum Science and Technology[34]
See also[edit]
.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}
Categorical quantum mechanics
Einstein's thought experiments
Interpretations of quantum mechanics
POVM (positive operator valued measure)
Quantum clock
Quantum cognition
Quantum foundations
Quantum information science
Quantum statistical mechanics
Qutrit
Typical subspace

Notes[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"Free-Images.com â Free Public Domain Images". free-images.com. Retrieved 2020-11-13.

^ Jump up to: a b c d e f g h i j k l Nielsen, Michael A. (2010). Quantum computation and quantum information. Chuang, Isaac L. (10th anniversaryÂ ed.). Cambridge: Cambridge University Press. ISBNÂ 978-1107002173. OCLCÂ 665137861.

^ Bokulich, Alisa; Jaeger, Gregg (2010). Philosophy of Quantum Information and Entanglement. Cambridge University Press. ISBNÂ 978-1-139-48766-5.

^ Benatti, Fabio; Fannes, Mark; Floreanini, Roberto; Petritis, Dimitri (2010). Quantum Information, Computation and Cryptography: An Introductory Survey of Theory, Technology and Experiments. Springer Science & Business Media. ISBNÂ 978-3-642-11913-2.

^ Jump up to: a b c d Hayashi, Masahito (2017). Quantum Information Theory. Graduate Texts in Physics. doi:10.1007/978-3-662-49725-8. ISBNÂ 978-3-662-49723-4.[pageÂ needed]

^ Jump up to: a b Preskill, John. "Lecture notes for physics 229." Quantum information and computation 16 (1998).

^ "The Feynman Lectures on Physics Vol. III Ch. 1: Quantum Behavior". wayback.archive-it.org. Retrieved 2020-11-11.

^ Jump up to: a b Lo, Hoi-Kwong; Spiller, Tim; Popescu, Sandu (1998). Introduction to Quantum Computation and Information. World Scientific. ISBNÂ 978-981-02-4410-1.

^ Mahan, Gerald D. (2008-12-29). Quantum Mechanics in a Nutshell. Princeton University Press. doi:10.2307/j.ctt7s8nw. ISBNÂ 978-1-4008-3338-2. JSTORÂ j.ctt7s8nw.

^ Perlman, H. S. (November 1964). "Equivalence of the Schroedinger and Heisenberg Pictures". Nature. 204 (4960): 771â772. Bibcode:1964Natur.204..771P. doi:10.1038/204771b0. S2CIDÂ 4194913.

^ Neumann, John von (2018-02-27). Mathematical Foundations of Quantum Mechanics: New Edition. Princeton University Press. ISBNÂ 978-0-691-17856-1.

^ Jump up to: a b Gordon, J. (September 1962). "Quantum Effects in Communications Systems". Proceedings of the IRE. 50 (9): 1898â1908. doi:10.1109/JRPROC.1962.288169. S2CIDÂ 51631629.

^ Helstrom, Carl Wilhelm (1976). Quantum Detection and Estimation Theory. Academic Press. ISBNÂ 978-0-08-095632-9.[pageÂ needed]

^ A. S. Holevo, âBounds for the Quantity of Information Transmitted by a Quantum Communication Channelâ, Probl. Peredachi Inf., 9:3 (1973); Problems Inform. Transmission, 9:3 (1973),

http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=ppi&paperid=903&option_lang=eng

^ A. S. Holevo, âOn Capacity of a Quantum Communications Channelâ, Probl. Peredachi Inf., 15:4 (1979); Problems Inform. Transmission, 15:4 (1979),

http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=ppi&paperid=1507&option_lang=eng

^ Bennett, Charles H.; Brassard, Gilles (December 2014). "Quantum cryptography: Public key distribution and coin tossing". Theoretical Computer Science. 560: 7â11. arXiv:2003.06557. doi:10.1016/j.tcs.2014.05.025. S2CIDÂ 27022972.

^ Weisstein, Eric W. "ChurchâTuring Thesis". mathworld.wolfram.com. Retrieved 2020-11-13.

^ Deutsch, D. (8 July 1985). "Quantum theory, the ChurchâTuring principle and the universal quantum computer". Proceedings of the Royal Society of London A: Mathematical and Physical Sciences. 400 (1818): 97â117. Bibcode:1985RSPSA.400...97D. doi:10.1098/rspa.1985.0070. S2CIDÂ 1438116.

^ Moore, G.E. (January 1998). "Cramming More Components Onto Integrated Circuits". Proceedings of the IEEE. 86 (1): 82â85. doi:10.1109/JPROC.1998.658762. S2CIDÂ 6519532.

^ Shannon, C. E. (October 1948). "A Mathematical Theory of Communication". Bell System Technical Journal. 27 (4): 623â656. doi:10.1002/j.1538-7305.1948.tb00917.x. hdl:11858/00-001M-0000-002C-4314-2.

^ "A Mathematical Theory of Communication" (PDF). 1998-07-15. Archived (PDF) from the original on 1998-07-15. Retrieved 2020-11-13.

^ Shannon, C. E.; Weaver, W. (1949). "The mathematical theory of communication". {{cite journal}}: Cite journal requires |journal= (help)

^ "Alexandr S. Holevo". Mi.ras.ru. Retrieved 4 December 2018.

^ Weedbrook, Christian; Pirandola, Stefano; GarcÃ­a-PatrÃ³n, RaÃºl; Cerf, Nicolas J.; Ralph, Timothy C.; Shapiro, Jeffrey H.; Lloyd, Seth (1 May 2012). "Gaussian quantum information". Reviews of Modern Physics. 84 (2): 621â669. arXiv:1110.3234. Bibcode:2012RvMP...84..621W. doi:10.1103/RevModPhys.84.621. S2CIDÂ 119250535.

^ 
Masahito Hayashi, "Quantum Information Theory: Mathematical Foundation"[pageÂ needed]

^ J. Watrous, The Theory of Quantum Information (Cambridge Univ. Press, 2018). Freely available at [1]

^ Wilde, Mark M. (2013). "Concepts in Quantum Shannon Theory". Quantum Information Theory. pp.Â 3â25. doi:10.1017/cbo9781139525343.002. ISBNÂ 9781139525343.

^ Jump up to: a b c Jaeger, Gregg (2007-04-03). Quantum Information: An Overview. Springer Science & Business Media. ISBNÂ 978-0-387-36944-0.

^ Watrous, John. "CS 766/QIC 820 Theory of Quantum Information (Fall 2011)." (2011).

^ Bennett, Charles H. (1992-05-25). "Quantum cryptography using any two nonorthogonal states". Physical Review Letters. 68 (21): 3121â3124. Bibcode:1992PhRvL..68.3121B. doi:10.1103/PhysRevLett.68.3121. PMIDÂ 10045619.

^ "Quantum Key Distribution - QKD". www.cse.wustl.edu. Retrieved 2020-11-21.

^ "npj Quantum Information". Nature.com. Retrieved 4 December 2018.

^ "Quantum Homepage". Quantum-journal.org. Retrieved 4 December 2018.

^ "Quantum Science and Technology". IOP Publishing. Retrieved 12 January 2019.


References[edit]
.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}
Bennett, C.H.; Shor, P.W. (1998). "Quantum information theory". IEEE Transactions on Information Theory. 44 (6): 2724â2742. doi:10.1109/18.720553.
Gregg Jaeger's book on Quantum Information, Springer, New York, 2007, ISBNÂ 0-387-35725-4
Lectures at the Institut Henri PoincarÃ© (slides and videos)
International Journal of Quantum Information World Scientific
Quantum Information Processing Springer
Michael A. Nielsen, Isaac L. Chuang, "Quantum Computation and Quantum Information"
J. Watrous, The Theory of Quantum Information (Cambridge Univ. Press, 2018). Freely available at [2]
John Preskill, Course Information for Physics 219/Computer Science 219 Quantum Computation, Caltech [3]
Masahito Hayashi, "Quantum Information: An Introduction"
Masahito Hayashi, "Quantum Information Theory: Mathematical Foundation"
Benatti, Fabio (2009). "Quantum Information Theory". Quantum Entropies. Theoretical and Mathematical Physics. pp.Â 255â315. CiteSeerXÂ 10.1.1.89.1572. doi:10.1007/978-1-4020-9306-7_6. ISBNÂ 978-1-4020-9305-0.
Wilde, Mark M. (2017). "Preface to the Second Edition". Quantum Information Theory. pp.Â xiâxii. arXiv:1106.1445. doi:10.1017/9781316809976.001. ISBNÂ 9781316809976.
Vlatko Vedral, "Introduction to Quantum Information Science"
Weedbrook, Christian; Pirandola, Stefano; GarcÃ­a-PatrÃ³n, RaÃºl; Cerf, Nicolas J.; Ralph, Timothy C.; Shapiro, Jeffrey H.; Lloyd, Seth (1 May 2012). "Gaussian quantum information". Reviews of Modern Physics. 84 (2): 621â669. arXiv:1110.3234. Bibcode:2012RvMP...84..621W. doi:10.1103/RevModPhys.84.621. S2CIDÂ 119250535.

.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}showvteQuantum information scienceGeneral
DiVincenzo's criteria
NISQ era
Quantum computing
Timeline
Cloud-based
Quantum information
Quantum programming
Qubit
physical vs. logical
Quantum processors
Theorems
Bell's
Gleason's
GottesmanâKnill
Holevo's
MargolusâLevitin
No-broadcast
No-cloning
No-communication
No-deleting
No-hiding
No-teleportation
PBR
Quantum threshold
SolovayâKitaev
Quantumcommunication
Classical capacity
entanglement-assisted
Quantum capacity
Entanglement distillation
LOCC
Quantum channel
Quantum network
Quantum cryptography
Quantum key distribution
BB84
SARG04
Three-stage quantum cryptography protocol
Quantum Secret Sharing
Quantum teleportation
Superdense coding
Quantum algorithms
BernsteinâVazirani
DeutschâJozsa
Grover's
Quantum counting
Quantum phase estimation
Shor's
Simon's
Amplitude amplification
Linear systems of equations
Quantum annealing
Quantum Fourier transform
Quantum neural network
Universal quantum simulator
Quantumcomplexity theory
BQP
EQP
QIP
QMA
PostBQP
Quantumcomputing models
Adiabatic quantum computation
Differentiable quantum computing
One-way quantum computer
cluster state
Quantum circuit
Quantum logic gate
Quantum Turing machine
Topological quantum computer
Quantumerror correction
Codes
CSS
Quantum convolutional
stabilizer
Shor
Steane
Toric
gnu
Entanglement-assisted quantum error correction
PhysicalimplementationsQuantum optics
Boson sampling
Cavity QED
Circuit QED
Linear optical quantum computing
KLM protocol
Ultracold atoms
Optical lattice
Trapped ion quantum computer
Spin-based
Kane QC
Spin qubit QC
Nitrogen-vacancy center
Nuclear magnetic resonance QC
Superconductingquantum computing
Charge qubit
Flux qubit
Phase qubit
Transmon
Quantumprogramming
OpenQASM-Qiskit-IBM QX
Quil-Forest/Rigetti QCS
Cirq
Q#
libquantum
many others...
 Quantum mechanics topics
showvteQuantum mechanicsBackground
Introduction
History
Timeline
Classical mechanics
Old quantum theory
Glossary
Fundamentals
Born rule
Braâket notation
 Complementarity
Density matrix
Energy level
Ground state
Excited state
Degenerate levels
Zero-point energy
Entanglement
Hamiltonian
Interference
Decoherence
Measurement
Nonlocality
Quantum state
Superposition
Tunnelling
Scattering theory
Symmetry in quantum mechanics
Uncertainty
Wave function
Collapse
Waveâparticle duality
Formulations
Formulations
Heisenberg
Interaction
Matrix mechanics
SchrÃ¶dinger
Path integral formulation
Phase space
Equations
Dirac
KleinâGordon
Pauli
Rydberg
SchrÃ¶dinger
Interpretations
Interpretations
Bayesian
Consistent histories
Copenhagen
de BroglieâBohm
Ensemble
Hidden-variable
Local
Many-worlds
Objective collapse
Quantum logic
Relational
Transactional
Van Neumann-Wigner
Experiments
Bell's inequality
DavissonâGermer
Delayed-choice quantum eraser
Double-slit
FranckâHertz
MachâZehnder interferometer
ElitzurâVaidman
Popper
Quantum eraser
SternâGerlach
Wheeler's delayed choice
Science
Quantum biology
Quantum chemistry
Quantum chaos
Quantum cosmology
Quantum differential calculus
Quantum dynamics
Quantum geometry
Quantum measurement problem
Quantum stochastic calculus
Quantum spacetime
Technology
Quantum algorithms
Quantum amplifier
Quantum bus
Quantum cellular automata
Quantum finite automata
Quantum channel
Quantum circuit
Quantum complexity theory
Quantum computing
Timeline
Quantum cryptography
Quantum electronics
Quantum error correction
Quantum imaging
Quantum image processing
Quantum information
Quantum key distribution
Quantum logic
Quantum logic gates
Quantum machine
Quantum machine learning
Quantum metamaterial
Quantum metrology
Quantum network
Quantum neural network
Quantum optics
Quantum programming
Quantum sensing
Quantum simulator
Quantum teleportation
Extensions
Casimir effect
Quantum statistical mechanics
Quantum field theory
History
Quantum gravity
Relativistic quantum mechanics

 Category
 Physics portal
 Commons

showvteEmerging technologiesFieldsQuantum
algorithms
amplifier
bus
cellular automata
channel
circuit
complexity theory
computing
clock
cryptography
post-quantum
dynamics
electronics
error correction
finite automata
image processing
imaging
information
key distribution
logic
logic gates
machine
machine learning
metamaterial
network
neural network
optics
programming
sensing
simulator
teleportation
Other
Anti-gravity
Acoustic levitation
Cloak of invisibility
Digital scent technology
Force field
Plasma window
Immersive virtual reality
Magnetic refrigeration
Phased-array optics
Thermoacoustic heat engine

 Category
 List

Authority control: National libraries  
Japan





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Quantum_information&oldid=1068302646"
		Categories: Quantum information theoryHidden categories: Wikipedia articles needing page number citations from December 2020CS1 errors: missing periodicalArticles with short descriptionShort description is different from WikidataPages using div col with small parameterArticles with NDL identifiers
	
