
Title:
Metaheuristic
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Optimization technique
In computer science and mathematical optimization, a metaheuristic is a higher-level procedure or heuristic designed to find, generate, or select a heuristic (partial search algorithm) that may provide a sufficiently good solution to an optimization problem, especially with incomplete or imperfect information or limited computation capacity.[1][2] Metaheuristics sample a subset of solutions which is otherwise too large to be completely enumerated or otherwise explored. Metaheuristics may make relatively few assumptions about the optimization problem being solved and so may be usable for a variety of problems.[3]
Compared to optimization algorithms and iterative methods, metaheuristics do not guarantee that a globally optimal solution can be found on some class of problems.[3] Many metaheuristics implement some form of stochastic optimization, so that the solution found is dependent on the set of random variables generated.[2] In combinatorial optimization, by searching over a large set of feasible solutions, metaheuristics can often find good solutions with less computational effort than optimization algorithms, iterative methods, or simple heuristics.[3] As such, they are useful  approaches for optimization problems.[2] Several books and survey papers have been published on the subject.[2][3][4][5][6]
Most literature on metaheuristics is experimental in nature, describing empirical results based on computer experiments with the algorithms. But some formal theoretical results are also available, often on convergence and the possibility of finding the global optimum.[3] Many metaheuristic methods have been published with claims of novelty and practical efficacy. While the field also features high-quality research, many of the publications have been of poor quality; flaws include vagueness, lack of conceptual elaboration, poor experiments, and ignorance of previous literature.[7]

Contents

1 Properties
2 Classification

2.1 Local search vs. global search
2.2 Single-solution vs. population-based
2.3 Hybridization and memetic algorithms
2.4 Parallel metaheuristics
2.5 Nature-inspired and metaphor-based metaheuristics


3 Applications
4 Metaheuristic Optimization Frameworks (MOFs)
5 Contributions
6 See also
7 References
8 Further reading
9 External links



Properties[edit]
These are properties that characterize most metaheuristics:[3]

Metaheuristics are strategies that guide the search process.
The goal is to efficiently explore the search space in order to find nearâoptimal solutions.
Techniques which constitute metaheuristic algorithms range from simple local search procedures to complex learning processes.
Metaheuristic algorithms are approximate and usually non-deterministic.
Metaheuristics are not problem-specific.
Classification[edit]
  Euler diagram of the different classifications of metaheuristics.[8]
There are a wide variety of metaheuristics[2] and a number of properties with respect to which to classify them.[3]

Local search vs. global search[edit]
One approach is to characterize the type of search strategy.[3] One type of search strategy is an improvement on simple local search algorithms. A well known local search algorithm is the hill climbing method which is used to find local optimums. However, hill climbing does not guarantee finding global optimum solutions.
Many metaheuristic ideas were proposed to improve local search heuristic in order to find better solutions. Such metaheuristics include simulated annealing, tabu search, iterated local search, variable neighborhood search, and GRASP.[3] These metaheuristics can both be classified as local search-based or global search metaheuristics.
Other global search metaheuristic that are not local search-based are usually population-based metaheuristics. Such metaheuristics include ant colony optimization, evolutionary computation, particle swarm optimization, genetic algorithm, and rider optimization algorithm[9]

Single-solution vs. population-based[edit]
Another classification dimension is single solution vs population-based searches.[3][6] Single solution approaches focus on modifying and improving a single candidate solution; single solution metaheuristics include simulated annealing, iterated local search, variable neighborhood search, and guided local search.[6] Population-based approaches maintain and improve multiple candidate solutions, often using population characteristics to guide the search; population based metaheuristics include evolutionary computation, genetic algorithms, and particle swarm optimization.[6] Another category of metaheuristics  is Swarm intelligence which is a collective behavior of decentralized, self-organized agents in a population or swarm. Ant colony optimization,[10] particle swarm optimization,[6] social cognitive optimization are examples of this category.

Hybridization and memetic algorithms[edit]
A hybrid metaheuristic is one that combines a metaheuristic with other optimization approaches, such as algorithms from mathematical programming, constraint programming, and machine learning. Both components of a hybrid metaheuristic may run concurrently and exchange information to guide the search.
On the other hand, Memetic algorithms[11] represent the synergy of evolutionary or any population-based approach with separate individual learning or local improvement procedures for problem search. An example of memetic algorithm is the use of a local search algorithm instead of a basic mutation operator in evolutionary algorithms.

Parallel metaheuristics[edit]
A parallel metaheuristic is one that uses the techniques of parallel programming to run multiple metaheuristic searches in parallel; these may range from simple distributed schemes to concurrent search runs that interact to improve the overall solution.

Nature-inspired and metaphor-based metaheuristics[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main articles: Swarm intelligence and List of metaphor-inspired metaheuristics
A very active area of research is the design of nature-inspired metaheuristics. Many recent metaheuristics, especially evolutionary computation-based algorithms, are inspired by natural systems. Nature acts as a source of concepts, mechanisms and principles for designing of artificial computing systems to deal with complex computational problems. Such metaheuristics include simulated annealing, evolutionary algorithms, ant colony optimization and particle swarm optimization. A large number of more recent metaphor-inspired metaheuristics have started to attract criticism in the research community for hiding their lack of novelty behind an elaborate metaphor.[7]

Applications[edit]
Metaheuristics are used for combinatorial optimization in which an optimal solution is sought over a discrete search-space. An example problem is the travelling salesman problem where the search-space of candidate solutions grows faster than exponentially as the size of the problem increases, which makes an exhaustive search for the optimal solution infeasible. Additionally, multidimensional combinatorial problems, including most design problems in engineering[12][13][14] such as form-finding and behavior-finding, suffer from the curse of dimensionality, which also makes them infeasible for exhaustive search or analytical methods. Metaheuristics are also widely used for jobshop scheduling and job selection problems.[citation needed] Popular metaheuristics for combinatorial problems include simulated annealing by Kirkpatrick et al.,[15] genetic algorithms by Holland et al.,[16] scatter search[17] and tabu search[18] by Glover. Literature review on metaheuristic optimization,[19]
suggested that it was Fred Glover who coined the word metaheuristics.[20]

Metaheuristic Optimization Frameworks (MOFs)[edit]
A MOF can be defined as ââa set of software tools that provide a correct and reusable implementation of a set of metaheuristics, and the basic mechanisms to accelerate the implementation of its partner subordinate heuristics (possibly including solution encodings and technique-specific operators), which are necessary to solve a particular problem instance using techniques providedââ.[21]
There are many candidate optimization tools which can be considered as a MOF of varying feature: Comet, EvA2, evolvica, Evolutionary::Algorithm, GAPlayground, jaga, JCLEC, JGAP, jMetal, n-genes, Open Beagle, Opt4j, ParadisEO/EO, Pisa, Watchmaker, FOM, Hypercube, HotFrame, Templar, EasyLocal, iOpt, OptQuest, JDEAL, Optimization Algorithm Toolkit, HeuristicLab, MAFRA, Localizer, GALIB, DREAM, Discropt, MALLBA, MAGMA, UOF[21] and OptaPlanner.

Contributions[edit]
Many different metaheuristics are in existence and new variants are continually being proposed. Some of the most significant contributions to the field are:

1952: Robbins and Monro work on stochastic optimization methods.[22]
1954: Barricelli carry out the first simulations of the evolution process and use them on general optimization problems.[23]
1963: Rastrigin proposes random search.[24]
1965: Matyas proposes random optimization.[25]
1965: Nelder and Mead propose a simplex heuristic, which was shown by Powell to converge to non-stationary points on some problems.[26]
1965: Ingo Rechenberg discovers the first Evolution Strategies algorithm.[27]
1966: Fogel et al. propose evolutionary programming.[28]
1970: Hastings proposes the MetropolisâHastings algorithm.[29]
1970: Cavicchio proposes adaptation of control parameters for an optimizer.[30]
1970: Kernighan and Lin propose a graph partitioning method, related to variable-depth search and prohibition-based (tabu) search.[31]
1975: Holland proposes the genetic algorithm.[16]
1977: Glover proposes scatter search.[17]
1978: Mercer and Sampson propose a metaplan for tuning an optimizer's parameters by using another optimizer.[32]
1980: Smith describes genetic programming.[33]
1983: Kirkpatrick et al. propose simulated annealing.[15]
1986: Glover proposes tabu search, first mention of the term metaheuristic.[18]
1989: Moscato proposes memetic algorithms.[11]
1990: Moscato and Fontanari,[34] and Dueck and Scheuer,[35] independently proposed a deterministic update rule for simulated annealing which accelerated the search. This led to the threshold accepting metaheuristic.
1992: Dorigo introduces ant colony optimization in his PhD thesis.[10]
1995: Wolpert and Macready prove the no free lunch theorems.[36][37][38][39]
See also[edit]
Stochastic search
Meta-optimization
Matheuristics
Hyper-heuristics
Swarm intelligence
Genetic algorithms
Genetic programming
Simulated annealing
Workforce modeling
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ 
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}R. Balamurugan; A.M. Natarajan; K. Premalatha (2015). "Stellar-Mass Black Hole Optimization for Biclustering Microarray Gene Expression Data". Applied Artificial Intelligence. 29 (4): 353â381. doi:10.1080/08839514.2015.1016391. S2CIDÂ 44624424.

^ Jump up to: a b c d e Bianchi, Leonora; Marco Dorigo; Luca Maria Gambardella; Walter J. Gutjahr (2009). "A survey on metaheuristics for stochastic combinatorial optimization" (PDF). Natural Computing. 8 (2): 239â287. doi:10.1007/s11047-008-9098-4. S2CIDÂ 9141490.

^ Jump up to: a b c d e f g h i j 
Blum, C.; Roli, A. (2003). "Metaheuristics in combinatorial optimization: Overview and conceptual comparison". 35 (3). ACM Computing Surveys: 268â308. {{cite journal}}: Cite journal requires |journal= (help)

^ 
Goldberg, D.E. (1989). Genetic Algorithms in Search, Optimization and Machine Learning. Kluwer Academic Publishers. ISBNÂ 978-0-201-15767-3.

^ 
Glover, F.; Kochenberger, G.A. (2003). Handbook of metaheuristics. Vol.Â 57. Springer, International Series in Operations Research & Management Science. ISBNÂ 978-1-4020-7263-5.

^ Jump up to: a b c d e 
Talbi, E-G. (2009). Metaheuristics: from design to implementation. Wiley. ISBNÂ 978-0-470-27858-1.

^ Jump up to: a b SÃ¶rensen, Kenneth (2015). "Metaheuristicsâthe metaphor exposed" (PDF). International Transactions in Operational Research. 22: 3â18. CiteSeerXÂ 10.1.1.470.3422. doi:10.1111/itor.12001. Archived from the original (PDF) on 2013-11-02.

^ Classification of metaheuristics

^ D, Binu (2019). "RideNN: A New Rider Optimization Algorithm-Based Neural Network for Fault Diagnosis in Analog Circuits". IEEE Transactions on Instrumentation and Measurement. 68 (1): 2â26. doi:10.1109/TIM.2018.2836058. S2CIDÂ 54459927.

^ Jump up to: a b M. Dorigo, Optimization, Learning and Natural Algorithms, PhD thesis, Politecnico di Milano, Italie, 1992.

^ Jump up to: a b Moscato, P. (1989). "On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts: Towards Memetic Algorithms". Caltech Concurrent Computation Program (report 826).

^ TomoiagÄ B, ChindriÅ M, Sumper A, Sudria-Andreu A, Villafafila-Robles R. Pareto Optimal Reconfiguration of Power Distribution Systems Using a Genetic Algorithm Based on NSGA-II.  Energies. 2013; 6(3):1439â1455.

^ Ganesan, T.; Elamvazuthi, I.; Ku Shaari, Ku Zilati; Vasant, P. (2013-03-01). "Swarm intelligence and gravitational search algorithm for multi-objective optimization of synthesis gas production". Applied Energy. 103: 368â374. doi:10.1016/j.apenergy.2012.09.059.

^ Ganesan, T.; Elamvazuthi, I.; Vasant, P. (2011-11-01). Evolutionary normal-boundary intersection (ENBI) method for multi-objective optimization of green sand mould system. 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE). pp.Â 86â91. doi:10.1109/ICCSCE.2011.6190501. ISBNÂ 978-1-4577-1642-3. S2CIDÂ 698459.

^ Jump up to: a b 
Kirkpatrick, S.; Gelatt Jr., C.D.; Vecchi, M.P. (1983). "Optimization by Simulated Annealing". Science. 220 (4598): 671â680. Bibcode:1983Sci...220..671K. CiteSeerXÂ 10.1.1.123.7607. doi:10.1126/science.220.4598.671. PMIDÂ 17813860. S2CIDÂ 205939.

^ Jump up to: a b 
Holland, J.H. (1975). Adaptation in Natural and Artificial Systems. University of Michigan Press. ISBNÂ 978-0-262-08213-6.

^ Jump up to: a b 
Glover, Fred (1977). "Heuristics for Integer programming Using Surrogate Constraints". Decision Sciences. 8 (1): 156â166. CiteSeerXÂ 10.1.1.302.4071. doi:10.1111/j.1540-5915.1977.tb01074.x.

^ Jump up to: a b 
Glover, F. (1986). "Future Paths for Integer Programming and Links to Artificial Intelligence". Computers and Operations Research. 13 (5): 533â549. doi:10.1016/0305-0548(86)90048-1.

^ X. S. Yang, Metaheuristic optimization, Scholarpedia, 6(8):11472 (2011).

^ Glover F., (1986). Future paths for integer programming and links to artificial intelligence, Computers and Operations Research, 13, 533â549 (1986).

^ Jump up to: a b Moscato, P. (2012). "Metaheuristic optimization frameworks a survey and benchmarking". Soft Comput. 16 (3): 527â561. doi:10.1007/s00500-011-0754-8. hdl:11441/24597. S2CIDÂ 1497912.

^ 
Robbins, H.; Monro, S. (1951). "A Stochastic Approximation Method" (PDF). Annals of Mathematical Statistics. 22 (3): 400â407. doi:10.1214/aoms/1177729586.

^ 
Barricelli, N.A. (1954). "Esempi numerici di processi di evoluzione". Methodos: 45â68.

^ 
Rastrigin, L.A. (1963). "The convergence of the random search method in the extremal control of a many parameter system". Automation and Remote Control. 24 (10): 1337â1342.

^ 
Matyas, J. (1965). "Random optimization". Automation and Remote Control. 26 (2): 246â253.

^ 
Nelder, J.A.; Mead, R. (1965). "A simplex method for function minimization". Computer Journal. 7 (4): 308â313. doi:10.1093/comjnl/7.4.308. S2CIDÂ 2208295.

^ 
Rechenberg, Ingo (1965). "Cybernetic Solution Path of an Experimental Problem". Royal Aircraft Establishment, Library Translation.

^ 
Fogel, L.; Owens, A.J.; Walsh, M.J. (1966). Artificial Intelligence through Simulated Evolution. Wiley. ISBNÂ 978-0-471-26516-0.

^ 
Hastings, W.K. (1970). "Monte Carlo Sampling Methods Using Markov Chains and Their Applications". Biometrika. 57 (1): 97â109. Bibcode:1970Bimka..57...97H. doi:10.1093/biomet/57.1.97. S2CIDÂ 21204149.

^ 
Cavicchio, D.J. (1970). "Adaptive search using simulated evolution". Technical Report. University of Michigan, Computer and Communication Sciences Department. hdl:2027.42/4042.

^ 
Kernighan, B.W.; Lin, S. (1970). "An efficient heuristic procedure for partitioning graphs". Bell System Technical Journal. 49 (2): 291â307. doi:10.1002/j.1538-7305.1970.tb01770.x.

^ 
Mercer, R.E.; Sampson, J.R. (1978). "Adaptive search using a reproductive metaplan". Kybernetes. 7 (3): 215â228. doi:10.1108/eb005486.

^ 
Smith, S.F. (1980). A Learning System Based on Genetic Adaptive Algorithms (PhD Thesis). University of Pittsburgh.

^ Moscato, P.; Fontanari, J.F. (1990), "Stochastic versus deterministic update in simulated annealing", Physics Letters A, 146 (4): 204â208, Bibcode:1990PhLA..146..204M, doi:10.1016/0375-9601(90)90166-L

^ Dueck, G.; Scheuer, T. (1990), "Threshold accepting: A general purpose optimization algorithm appearing superior to simulated annealing", Journal of Computational Physics, 90 (1): 161â175, Bibcode:1990JCoPh..90..161D, doi:10.1016/0021-9991(90)90201-B, ISSNÂ 0021-9991

^ 
Wolpert, D.H.; Macready, W.G. (1995). "No free lunch theorems for search". Technical Report SFI-TR-95-02-010. Santa Fe Institute. S2CIDÂ 12890367.

^ Igel, Christian, Toussaint, Marc (Jun 2003). "On classes of functions for which No Free Lunch results hold". Information Processing Letters. 86 (6): 317â321. arXiv:cs/0108011. doi:10.1016/S0020-0190(03)00222-9. ISSNÂ 0020-0190. S2CIDÂ 147624.{{cite journal}}:  CS1 maint: multiple names: authors list (link)

^ Auger, Anne, Teytaud, Olivier (2010). "Continuous Lunches Are Free Plus the Design of Optimal Optimization Algorithms". Algorithmica. 57 (1): 121â146. CiteSeerXÂ 10.1.1.186.6007. doi:10.1007/s00453-008-9244-5. ISSNÂ 0178-4617. S2CIDÂ 1989533.{{cite journal}}:  CS1 maint: multiple names: authors list (link)

^ Stefan Droste; Thomas Jansen; Ingo Wegener (2002). "Optimization with Randomized Search Heuristics â The (A)NFL Theorem, Realistic Scenarios, and Difficult Functions". Theoretical Computer Science. 287 (1): 131â144. CiteSeerXÂ 10.1.1.35.5850. doi:10.1016/s0304-3975(02)00094-4.


Further reading[edit]
SÃ¶rensen, Kenneth; Sevaux, Marc; Glover, Fred (2017-01-16). "A History of Metaheuristics" (PDF).  In MartÃ­, Rafael; Panos, Pardalos; Resende, Mauricio (eds.). Handbook of Heuristics. Springer. ISBNÂ 978-3-319-07123-7.
External links[edit]
Fred Glover and Kenneth SÃ¶rensen (ed.). "Metaheuristics". Scholarpedia.
EU/ME forum for researchers in the field.
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteOptimization: Algorithms, methods, and heuristicsUnconstrained nonlinearFunctions
Golden-section search
Interpolation methods
Line search
NelderâMead method
Successive parabolic interpolation
GradientsConvergence
Trust region
Wolfe conditions
QuasiâNewton
BerndtâHallâHallâHausman
BroydenâFletcherâGoldfarbâShanno and L-BFGS
DavidonâFletcherâPowell
Symmetric rank-one (SR1)
Other methods
Conjugate gradient
GaussâNewton
Gradient
LevenbergâMarquardt
Powell's dog leg method
Truncated Newton
Hessians
Newton's method
Constrained nonlinearGeneral
Barrier methods
Penalty methods
Differentiable
Augmented Lagrangian methods
Sequential quadratic programming
Successive linear programming
Convex optimizationConvex minimization
Cutting-plane method
Reduced gradient (FrankâWolfe)
Subgradient method
Linear andquadraticInterior point
Affine scaling
Ellipsoid algorithm of Khachiyan
Projective algorithm of Karmarkar
Basis-exchange
Simplex algorithm of Dantzig
Revised simplex algorithm
Criss-cross algorithm
Principal pivoting algorithm of Lemke
CombinatorialParadigms
Approximation algorithm
Dynamic programming
Greedy algorithm
Integer programming
Branch and bound/cut
Graph algorithmsMinimum spanning tree
BorÅ¯vka
Prim
Kruskal

    Shortest path
BellmanâFord
SPFA
Dijkstra
FloydâWarshall
Network flows
Dinic
EdmondsâKarp
FordâFulkerson
Pushârelabel maximum flow
Metaheuristics
Evolutionary algorithm
Hill climbing
Local search
Simulated annealing
Tabu search

Software





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Metaheuristic&oldid=1067642288"
		Categories: MetaheuristicsHidden categories: CS1 errors: missing periodicalCS1 maint: multiple names: authors listArticles with short descriptionShort description is different from WikidataUse American English from January 2019All Wikipedia articles written in American EnglishAll articles with unsourced statementsArticles with unsourced statements from September 2019
	
