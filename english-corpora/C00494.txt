
Title:
Hyper-threading
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}This article is about Intel's proprietary SMT implementation. For the application protocol, see Hypertext Transfer Protocol.
Proprietary simultaneous multithreading implementation by Intel


  In this high-level depiction of HTT, instructions are fetched from RAM (differently colored boxes represent the instructions of four different processes), decoded and reordered by the front end (white boxes represent pipeline bubbles), and passed to the execution core capable of executing instructions from two different programs during the same clock cycle.[1][2][3]
Hyper-threading (officially called Hyper-Threading Technology or HT Technology and abbreviated as HTT or HT) is Intel's proprietary simultaneous multithreading (SMT) implementation used to improve parallelization of computations (doing multiple tasks at once) performed on x86 microprocessors. It was introduced on Xeon server processors in February 2002 and on PentiumÂ 4 desktop processors in November 2002.[4] Since then, Intel has included this technology in Itanium, Atom, and Core 'i' Series CPUs, among others.
[5]
For each processor core that is physically present, the operating system addresses two virtual (logical) cores and shares the workload between them when possible. The main function of hyper-threading is to increase the number of independent instructions in the pipeline; it takes advantage of superscalar architecture, in which multiple instructions operate on separate data in parallel. With HTT, one physical core appears as two processors to the operating system, allowing concurrent scheduling of two processes per core. In addition, two or more processes can use the same resources: If resources for one process are not available, then another process can continue if its resources are available.
In addition to requiring simultaneous multithreading support in the operating system, hyper-threading can be properly utilized only with an operating system specifically optimized for it.[6]

Contents

1 Overview
2 History
3 Performance claims
4 Drawbacks
5 Security
6 See also
7 References
8 External links



Overview[edit]
  A 3Â GHz model of the Intel PentiumÂ 4 processor that incorporates Hyper-Threading Technology[7]
Hyper-Threading Technology is a form of simultaneous multithreading technology introduced by Intel, while the concept behind the technology has been patented by Sun Microsystems. Architecturally, a processor with Hyper-Threading Technology consists of two logical processors per core, each of which has its own processor architectural state. Each logical processor can be individually halted, interrupted or directed to execute a specified thread, independently from the other logical processor sharing the same physical core.[8]
Unlike a traditional dual-processor configuration that uses two separate physical processors, the logical processors in a hyper-threaded core share the execution resources. These resources include the execution engine, caches, and system bus interface; the sharing of resources allows two logical processors to work with each other more efficiently, and allows a logical processor to borrow resources from a stalled logical core (assuming both logical cores are associated with the same physical core). A processor stalls when it is waiting for data it has sent for so it can finish processing the present thread. The degree of benefit seen when using a hyper-threaded or multi core processor depends on the needs of the software, and how well it and the operating system are written to manage the processor efficiently.[8]
Hyper-threading works by duplicating certain sections of the processorâthose that store the architectural stateâbut not duplicating the main execution resources.  This allows a hyper-threading processor to appear as the usual "physical" processor and an extra "logical" processor to the host operating system (HTT-unaware operating systems see two "physical" processors), allowing the operating system to schedule two threads or processes simultaneously and appropriately. When execution resources would not be used by the current task in a processor without hyper-threading, and especially when the processor is stalled, a hyper-threading equipped processor can use those execution resources to execute another scheduled task. (The processor may stall due to a cache miss, branch misprediction, or data dependency.)[9]
This technology is transparent to operating systems and programs. The minimum that is required to take advantage of hyper-threading is symmetric multiprocessing (SMP) support in the operating system, as the logical processors appear as standard separate processors.
It is possible to optimize operating system behavior on multi-processor hyper-threading capable systems. For example, consider an SMP system with two physical processors that are both hyper-threaded (for a total of four logical processors). If the operating system's thread scheduler is unaware of hyper-threading, it will treat all four logical processors the same. If only two threads are eligible to run, it might choose to schedule those threads on the two logical processors that happen to belong to the same physical processor; that processor would become extremely busy while the other would idle, leading to poorer performance than is possible by scheduling the threads onto different physical processors. This problem can be avoided by improving the scheduler to treat logical processors differently from physical processors; in a sense, this is a limited form of the scheduler changes that are required for NUMA systems.

History[edit]
The first published paper describing what is now known as hyper-threading in a general purpose computer was written by Edward S. Davidson and Leonard. E. Shar in 1973.[10]
Denelcor, Inc. introduced multi-threading with the Heterogeneous Element Processor (HEP) in 1982. The HEP pipeline could not hold multiple instructions from the same process. Only one instruction from a given process was allowed to be present in the pipeline at any point in time.  Should an instruction from a given process block the pipe, instructions from other processes would continue after the pipeline drained.
US patent for the technology behind hyper-threading was granted to Kenneth Okin at Sun Microsystems in November 1994.  At that time, CMOS process technology was not advanced enough to allow for a cost-effective implementation.[11]
Intel implemented hyper-threading on an x86 architecture processor in 2002 with the Foster MP-based Xeon. It was also included on the 3.06Â GHz Northwood-based PentiumÂ 4 in the same year, and then remained as a feature in every PentiumÂ 4Â HT, PentiumÂ 4 Extreme Edition and Pentium Extreme Edition processor since. The Intel Core & Core 2 processor lines (2006) that succeeded the Pentium 4 model line didn't utilize hyper-threading. The processors based on the Core microarchitecture did not have hyper-threading because the Core microarchitecture was a descendant of the older P6 microarchitecture. The P6 microarchitecture was used in earlier iterations of Pentium processors, namely, the Pentium Pro, PentiumÂ II and PentiumÂ III (plus their Celeron & Xeon derivatives at the time).
Intel released the Nehalem microarchitecture (CoreÂ i7) in November 2008, in which hyper-threading made a return. The first generation Nehalem processors contained four physical cores and effectively scaled to eight threads. Since then, both two- and six-core models have been released, scaling four and twelve threads respectively.[12] Earlier Intel Atom cores were in-order processors, sometimes with hyper-threading ability, for low power mobile PCs and low-price desktop PCs.[13] The ItaniumÂ 9300 launched with eight threads per processor (two threads per core) through enhanced hyper-threading technology. The next model, the Itanium 9500 (Poulson), features a 12-wide issue architecture, with eight CPU cores with support for eight more virtual cores via hyper-threading.[14] The Intel XeonÂ 5500 server chips also utilize two-way hyper-threading.[15][16]

Performance claims[edit]
According to Intel, the first hyper-threading implementation used only 5% more die area than the comparable non-hyperthreaded processor, but the performance was 15â30% better.[17][18] Intel claims up to a 30% performance improvement compared with an otherwise identical, non-simultaneous multithreading PentiumÂ 4. Tom's Hardware states: "In some cases a P4 running at 3.0Â GHz with HT on can even beat a P4 running at 3.6Â GHz with HT turned off."[19] Intel also claims significant performance improvements with a hyper-threading-enabled PentiumÂ 4 processor in some artificial-intelligence algorithms.
Overall the performance history of hyper-threading was a mixed one in the beginning. As one commentary on high-performance computing from November 2002 notes:[20]


Hyper-Threading can improve the performance of some MPI applications, but not all. Depending on the cluster configuration and, most importantly, the nature of the application running on the cluster, performance gains can vary or even be negative. The next step is to use performance tools to understand what areas contribute to performance gains and what areas contribute to performance degradation.


As a result, performance improvements are very application-dependent;[21] however, when running two programs that require full attention of the processor, it can actually seem like one or both of the programs slows down slightly when Hyper-Threading Technology is turned on.[22] This is due to the replay system of the PentiumÂ 4 tying up valuable execution resources, equalizing the processor resources between the two programs, which adds a varying amount of execution time. The PentiumÂ 4 "Prescott" and the Xeon "Nocona" processors received a replay queue that reduces execution time needed for the replay system and completely overcomes the performance penalty.[23]
According to a November 2009 analysis by Intel, performance impacts of hyper-threading result in increased overall latency in case the execution of threads does not result in significant overall throughput gains, which vary[21] by the application.  In other words, overall processing latency is significantly increased due to hyper-threading, with the negative effects becoming smaller as there are more simultaneous threads that can effectively use the additional hardware resource utilization provided by hyper-threading.[24] A similar performance analysis is available for the effects of hyper-threading when used to handle tasks related to managing network traffic, such as for processing interrupt requests generated by network interface controllers (NICs).[25] Another paper claims no performance improvements when hyper-threading is used for interrupt handling.[26]

Drawbacks[edit]

When the first HT processors were released, many operating systems were not optimized for hyper-threading technology (e.g. Windows 2000 and Linux older than 2.4).[27]
In 2006, hyper-threading was criticised for energy inefficiency.[28] For example, specialist low-power CPU design company ARM stated that simultaneous multithreading can use up to 46% more power than ordinary dual-core designs. Furthermore, they claimed that SMT increases cache thrashing by 42%, whereas dual core results in a 37% decrease.[29]
In 2010, ARM said it might include simultaneous multithreading in its future chips;[30] however, this was rejected in favor of their 2012 64-bit design.[31]
In 2013, Intel dropped SMT in favor of out-of-order execution for its Silvermont processor cores, as they found this gave better performance with better power efficiency than a lower number of cores with SMT.[32]
In 2017, it was revealed Intel's Skylake and Kaby Lake processors had a bug with their implementation of hyper-threading that could cause data loss.[33] Microcode updates were later released to address the issue.[34]
In 2019, with Coffee Lake, Intel began to move away from including hyper-threading in mainstream Core i7 desktop processors except for highest-end Core i9 parts or Pentium Gold CPUs.[35] It also started recommending disabling hyper-threading as new CPU vulnerability attacks were revealed which could be mitigated by disabling HT.[36]

Security[edit]
In May 2005, Colin Percival demonstrated that a malicious thread on a PentiumÂ 4 can use a timing-based side-channel attack to monitor the memory access patterns of another thread with which it shares a cache, allowing the theft of cryptographic information. This is not actually a timing attack, as the malicious thread measures the time of only its own execution. Potential solutions to this include the processor changing its cache eviction strategy or the operating system preventing the simultaneous execution, on the same physical core, of threads with different privileges.[37] In 2018 the OpenBSD operating system has disabled hyper-threading "in order to avoid data potentially leaking from applications to other software" caused by the Foreshadow/L1TF vulnerabilities.[38][39] In 2019 a set of vulnerabilities led to security experts recommending the disabling of hyper-threading on all devices.[40]

See also[edit]
Barrel processor
Computer multitasking
Multi-core processor
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Stokes, Jon (3 October 2002). "Introduction to Multithreading, Superthreading and Hyperthreading". Ars Technica. pp.Â 2â3. Retrieved 30 September 2015.

^ Deborah T. Marr; Frank Binns; David L. Hill; Glenn Hinton; David A. Koufaty; J. Alan Miller; Michael Upton (12 December 2006). "Hyper-Threading Technology Architecture and Microarchitecture" (PDF). cs.sfu.ca. Archived from the original (PDF) on 23 September 2015. Retrieved 30 September 2015.

^ Anand Lal Shimpi (5 October 2012). "The Haswell Front End â Intel's Haswell Architecture Analyzed". AnandTech. Retrieved 30 September 2015.

^ "Intel PentiumÂ 4 3.06GHz CPU with Hyper-Threading Technology: Killing Two Birds with a Stone." X-bit labs. Archived from the original on 31 May 2014. Retrieved 4 June 2014.

^ "IntelÂ® Hyper-Threading Technology (IntelÂ® HT Technology)". Intel. Retrieved 24 October 2021.

^ Intel Required Components Interchangeability List for the Intel PentiumÂ 4 Processor with HT Technology, includes list of Operating Systems that include optimizations for Hyper-Threading Technology; they are Windows XP ProfessionalÂ 64, Windows XP MCE, Windows XP Home, Windows XP Professional, some versions of Linux such as COSIX LinuxÂ 4.0, RedHat LinuxÂ 9 (Professional and Personal versions), RedFlag Linux DesktopÂ 4.0 and SuSe LinuxÂ 8.2 (Professional and Personal versions)

^ "Intel Processor Spec Finder: SL6WK".

^ Jump up to: a b Thomadakis, Michael E. (17 March 2011). "The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms" (PDF). Texas A&M University. p.Â 23. Archived from the original (PDF) on 11 August 2014. Retrieved 21 March 2014.

^ Hennessy, John L.; Patterson, David A. (7 December 2017). Computer Architecture: A Quantitative Approach. AsanoviÄ, Krste,, Bakos, Jason D.,, Colwell, Robert P.,, Bhattacharjee, Abhishek, 1984-, Conte, Thomas M., 1964- (SixthÂ ed.). Cambridge, MA. ISBNÂ 978-0128119051. OCLCÂ 983459758.

^ "A multiminiprocessor system implemented through pipelining", by Leonard Shar and Edward Davidson, IEEE Computer, Feb. 1974, pp. 42-51, vol. 7 https://www.computer.org/csdl/magazine/co/1974/02/4251/13rRUyoyhIt

^ Okin, Kenneth (1 November 1994), United States Patent: 5361337 - Method and apparatus for rapidly switching processes in a computer system, archived from the original on 21 September 2015, retrieved 24 May 2016

^ "Page Unavailable". www.intel.com.

^ "IntelÂ® Atomâ¢ Processor Microarchitecture". Intel.com. 18 March 2011. Retrieved 5 April 2011.

^ "Intel Discloses New Itanium Poulson Features". Tomshardware.com. 24 August 2011. Retrieved 2 July 2017.

^ "Server Processor Index Page". Intel.com. 18 March 2011. Retrieved 5 April 2011.

^ "Intel Xeon ProcessorÂ 5500 Series". Intel.com. Retrieved 5 April 2011.

^  (PDF). 19 October 2012 https://web.archive.org/web/20121019025809/http://www.intel.com/technology/itj/2002/volume06issue01/vol6iss1_hyper_threading_technology.pdf. Archived from the original (PDF) on 19 October 2012. {{cite web}}: Missing or empty |title= (help)

^ 12331095 (28 April 2011). "How to Determine the Effectiveness of Hyper-Threading Technology with an Application". software.intel.com.{{cite web}}:  CS1 maint: numeric names: authors list (link)

^ "Summary: In Some Cases The P4Â 3.0HT Can Even Beat The 3.6Â GHz VersionÂ : Single CPU in Dual Operation: P4Â 3.06Â GHz with Hyper-Threading Technology". Tomshardware.com. 14 November 2002. Retrieved 5 April 2011.

^ Tau Leng; Rizwan Ali; Jenwei Hsieh; Christopher Stanton (November 2002). "A Study of Hyper-Threading in High-Performance Computing Clusters" (PDF). Dell. p.Â 4. Retrieved 12 November 2012.

^ Jump up to: a b Joel Hruska (24 July 2012). "Maximized performance: Comparing the effects of Hyper-Threading, software updates". extremetech.com. Retrieved 2 March 2015.

^ "CPU Performance Evaluation - Benchmark - Pentium 4 2.8 and 3.0". users.telenet.be.

^ "Replay: Unknown Features of the NetBurst Core. Page 15". Replay: Unknown Features of the NetBurst Core. Xbitlabs. Archived from the original on 14 May 2011. Retrieved 24 April 2011.

^ Valles, Antonio (20 November 2009). "Performance Insights to Intel Hyper-Threading Technology". Intel. Archived from the original on 17 February 2015. Retrieved 26 February 2015.

^ "Network Tuning and Performance". calomel.org. 12 November 2013. Retrieved 26 February 2015.

^ "Linux kernel documentation: Scaling in the Linux Networking Stack". kernel.org. 1 December 2014. Retrieved 2 March 2015. Per-cpu load can be observed using the mpstat utility, but note that on processors with hyperthreading (HT), each hyperthread is represented as a separate CPU.  For interrupt handling, HT has shown no benefit in initial tests, so limit the number of queues to the number of CPU cores in the system.

^ "Hyper-Threading Technology â Operating systems that include optimizations for Hyper-Threading Technology". Intel.com. 19 September 2011. Retrieved 29 February 2012.

^ Sustainable Practices: Concepts, Methodologies, Tools and Applications. Information Resources Management Association. December 2013. p.Â 666. ISBNÂ 9781466648524.

^ "ARM is no fan of HyperThreading". theinquirer.net. 2 August 2006. Archived from the original on 6 September 2009. Retrieved 29 February 2012.{{cite web}}:  CS1 maint: unfit URL (link)

^ Jermoluk, Tom (13 October 2010). "About MIPS and MIPS | TOP500 Supercomputing Sites". Top500.org. Archived from the original on 13 June 2011. Retrieved 5 April 2011.

^ "ARM launches first 64bit processor core for servers and smartphones". Tech Design Forum. 30 October 2012.

^ Rik Myslewski (8 May 2013). "Deep inside Intel's first viable mobile processor: Silvermont". The Register. Retrieved 13 January 2014.

^ Chirgwin, Richard (25 June 2017). "Intel's Skylake and Kaby Lake CPUs have nasty hyper-threading bug". The Register. Retrieved 4 July 2017.

^ "Skylake, Kaby Lake Chips Have a Crash Bug with Hyperthreading Enabled". Ars Technica. 26 June 2017. Retrieved 25 November 2017.

^ Cutress, Ian (23 April 2019). "Intel 9th Gen Core Processors: All the Desktop and Mobile 45W CPUs Announced". AnandTech.

^ Armasu, Lucian (14 May 2019). "Intel's New Spectre-Like Flaw Affects Chips Made Since 2008". Tom's Hardware.

^ Percival, Colin (14 May 2005). "Cache Missing for Fun and Profit" (PDF). Daemonology.net. Retrieved 14 June 2016.

^ "OpenBSD disables Intel's hyper-threading over CPU data leak fears". Retrieved 24 August 2018.

^ "'Disable SMT/Hyperthreading in all Intel BIOSes' - MARC". marc.info. Retrieved 24 August 2018.

^ Greenberg, Andy (14 May 2019). "Meltdown Redux: Intel Flaw Lets Hackers Siphon Secrets from Millions of PCs". WIRED. Retrieved 14 May 2019.


External links[edit]
Intel Demonstrates Breakthrough Processor Design, a press release from August 2001
Intel â high level overview of Hyper-threading
Hyper-threading on MSDN Magazine
introductory article from Ars Technica
US Patent Number 4,847,755
Merom, Conroe, Woodcrest lose HyperThreading
ZDnet: Hyperthreading hurts server performance, say developers
ARM is no fan of HyperThreading - Outlines problems of SMT solutions
The Impact of Hyper-Threading on Processor Resource Utilization in Production Applications

.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteProcessor technologiesModels
Abstract machine
Stored-program computer
Finite-state machine
with datapath
Hierarchical
Deterministic finite automaton
Queue automaton
Cellular automaton
Quantum cellular automaton
Turing machine
Alternating Turing machine
Universal
PostâTuring
Quantum
Nondeterministic Turing machine
Probabilistic Turing machine
Hypercomputation
Zeno machine
Belt machine
Stack machine
Register machines
Counter
Pointer
Random-access
Random-access stored program
Architecture
Microarchitecture
Von Neumann
Harvard
modified
Dataflow
Transport-triggered
Cellular
Endianness
Memory access
NUMA
HUMA
Loadâstore
Register/memory
Cache hierarchy
Memory hierarchy
Virtual memory
Secondary storage
Heterogeneous
Fabric
Multiprocessing
Cognitive
Neuromorphic
Instruction setarchitecturesTypes
Orthogonal instruction set
CISC
RISC
Application-specific
EDGE
TRIPS
VLIW
EPIC
MISC
OISC
NISC
ZISC
VISC architecture
Quantum computing
Comparison
Addressing modes
Instructionsets
Motorola 68000 series
VAX
PDP-11
x86
ARM
Stanford MIPS
MIPS
MIPS-X
Power
POWER
PowerPC
Power ISA
Clipper architecture
SPARC
SuperH
DEC Alpha
ETRAX CRIS
M32R
Unicore
Itanium
OpenRISC
RISC-V
MicroBlaze
LMC
System/3x0
S/360
S/370
S/390
z/Architecture
Tilera ISA
VISC architecture
Epiphany architecture
Others
ExecutionInstruction pipelining
Pipeline stall
Operand forwarding
Classic RISC pipeline
Hazards
Data dependency
Structural
Control
False sharing
Out-of-order
Scoreboarding
Tomasulo algorithm
Reservation station
Re-order buffer
Register renaming
Wide-issue
Speculative
Branch prediction
Memory dependence prediction
ParallelismLevel
Bit
Bit-serial
Word
Instruction
Pipelining
Scalar
Superscalar
Task
Thread
Process
Data
Vector
Memory
Distributed
Multithreading
Temporal
Simultaneous
Hyperthreading
Speculative
Preemptive
Cooperative
Flynn's taxonomy
SISD
SIMD
Array processing (SIMT)
Pipelined processing
Associative processing
SWAR
MISD
MIMD
SPMD
Processorperformance
Transistor count
Instructions per cycle (IPC)
Cycles per instruction (CPI)
Instructions per second (IPS)
Floating-point operations per second (FLOPS)
Transactions per second (TPS)
Synaptic updates per second (SUPS)
Performance per watt (PPW)
Cache performance metrics
Computer performance by orders of magnitude
Types
Central processing unit (CPU)
Graphics processing unit (GPU)
GPGPU
Vector
Barrel
Stream
Tile processor
Coprocessor
PAL
ASIC
FPGA
FPOA
CPLD
Multi-chip module (MCM)
System in a package (SiP)
Package on a package (PoP)
By application
Embedded system
Microprocessor
Microcontroller
Mobile
Notebook
Ultra-low-voltage
ASIP
Soft microprocessor
Systemson chip
System on a chip (SoC)
Multiprocessor (MPSoC)
Programmable (PSoC)
Network on a chip (NoC)
Hardwareaccelerators
Coprocessor
AI accelerator
Graphics processing unit (GPU)
Image processor
Vision processing unit (VPU)
Physics processing unit (PPU)
Digital signal processor (DSP)
Tensor Processing Unit (TPU)
Secure cryptoprocessor
Network processor
Baseband processor

Word size
1-bit
4-bit
8-bit
12-bit
15-bit
16-bit
24-bit
32-bit
48-bit
64-bit
128-bit
256-bit
512-bit
bit slicing
others
variable
Core count
Single-core
Multi-core
Manycore
Heterogeneous architecture
Components
Core
Cache
CPU cache
Scratchpad memory
Data cache
Instruction cache
replacement policies
coherence
Bus
Clock rate
Clock signal
FIFO
Functionalunits
Arithmetic logic unit (ALU)
Address generation unit (AGU)
Floating-point unit (FPU)
Memory management unit (MMU)
Loadâstore unit
Translation lookaside buffer (TLB)
Branch predictor
Branch target predictor
Integrated memory controller (IMC)
Memory management unit
Instruction decoder
Logic
Combinational
Sequential
Glue
Logic gate
Quantum
Array
Registers
Processor register
Status register
Stack register
Register file
Memory buffer
Memory address register
Program counter
Control unit
Hardwired control unit
Instruction unit
Data buffer
Write buffer
Microcode ROM
Horizontal microcode
Counter
Datapath
Multiplexer
Demultiplexer
Adder
Multiplier
CPU
Binary decoder
Address decoder
Sum-addressed decoder
Barrel shifter
Circuitry
Integrated circuit
3D
Mixed-signal
Power management
Boolean
Digital
Analog
Quantum
Switch

Powermanagement
PMU
APM
ACPI
Dynamic frequency scaling
Dynamic voltage scaling
Clock gating
Performance per watt (PPW)
Related
History of general-purpose CPUs
Microprocessor chronology
Processor design
Digital electronics
Hardware security module
Semiconductor device fabrication
Tickâtock model
Pin grid array
Chip carrier

vteIntel technologyPlatforms
Centrino
Centrino 2
Viiv
MID
Tablet
CULV
Ultrabook
Skulltrail
NUC
Galileo
Edison
Curie
Discontinued
Common Building Block
MultiProcessor Specification
Intel Communication Streaming Architecture
Intel Inboard 386
Intel Play
MMC-1
MMC-2
Current
Advanced Programmable Interrupt Controller
CNVi
Intel Turbo Boost
vPro
Intel Secure Key
Intel Management Engine
Active Management Technology
AMT versions
High-bandwidth Digital Content Protection
High Definition Audio
Hub Architecture
Rapid Storage Technology
Enhanced SpeedStep
Serial Digital Video Out
Host Embedded Controller Interface
Hyper-threading
Omni-Path
Platform Environment Control Interface
QuickPath Interconnect
Platform Controller Hub
System Management Bus
Thunderbolt
Ultra Path Interconnect
Upcoming
Silicon Photonics Link

vteParallel computingGeneral
Distributed computing
Parallel computing
Massively parallel
Cloud computing
High-performance computing
Multiprocessing
Manycore processor
GPGPU
Computer network
Systolic array
Levels
Bit
Instruction
Thread
Task
Data
Memory
Loop
Pipeline
Multithreading
Temporal
Simultaneous (SMT)
Speculative (SpMT)
Preemptive
Cooperative
Clustered multi-thread (CMT)
Hardware scout
Theory
PRAM model
PEM model
Analysis of parallel algorithms
Amdahl's law
Gustafson's law
Cost efficiency
KarpâFlatt metric
Slowdown
Speedup
Elements
Process
Thread
Fiber
Instruction window
Array data structure
Coordination
Multiprocessing
Memory coherency
Cache coherency
Cache invalidation
Barrier
Synchronization
Application checkpointing
Programming
Stream processing
Dataflow programming
Models
Implicit parallelism
Explicit parallelism
Concurrency
Non-blocking algorithm
Hardware
Flynn's taxonomy
SISD
SIMD
Array processing (SIMT)
Pipelined processing
Associative processing
MISD
MIMD
Dataflow architecture
Pipelined processor
Superscalar processor
Vector processor
Multiprocessor
symmetric
asymmetric
Memory
shared
distributed
distributed shared
UMA
NUMA
COMA
Massively parallel computer
Computer cluster
Grid computer
Hardware acceleration
APIs
Ateji PX
Boost
Chapel
HPX
Charm++
Cilk
Coarray Fortran
CUDA
Dryad
C++ AMP
Global Arrays
GPUOpen
MPI
OpenMP
OpenCL
OpenHMPP
OpenACC
Parallel Extensions
PVM
POSIX Threads
RaftLib
ROCm
UPC
TBB
ZPL
Problems
Automatic parallelization
Deadlock
Deterministic algorithm
Embarrassingly parallel
Parallel slowdown
Race condition
Software lockout
Scalability
Starvation

Â Category: Parallel computing





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Hyper-threading&oldid=1051570319"
		Categories: Threads (computing)X86 architectureHidden categories: CS1 errors: missing titleCS1 errors: bare URLCS1 maint: numeric names: authors listCS1 maint: unfit URLArticles with short descriptionShort description is different from WikidataUse dmy dates from August 2020
	
