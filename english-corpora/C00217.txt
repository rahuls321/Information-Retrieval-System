
Title:
AlphaGo
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Artificial intelligence that plays Go



  AlphaGo logo
AlphaGo is a computer program that plays the board game Go.[1] It was developed by DeepMind Technologies[2] a subsidiary of Google (now Alphabet Inc.). Subsequent versions of AlphaGo became increasingly powerful, including a version that competed under the name Master.[3] After retiring from competitive play, AlphaGo Master was succeeded by an even more powerful version known as AlphaGo Zero, which was completely self-taught without learning from human games. AlphaGo Zero was then generalized into a program known as AlphaZero, which played additional games, including chess and shogi.  AlphaZero has in turn been succeeded by a program known as MuZero which learns without being taught the rules.
AlphaGo and its successors use a Monte Carlo tree search algorithm to find its moves based on knowledge previously acquired by machine learning, specifically by an artificial neural network (a deep learning method) by extensive training, both from human and computer play.[4] A neural network is trained to identify the best moves and the winning percentages of these moves. This neural network improves the strength of the tree search, resulting in stronger move selection in the next iteration.
In October 2015, in a match against Fan Hui, the original AlphaGo became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19Ã19 board.[5][6] In March 2016, it beat Lee Sedol in a five-game match, the first time a computer Go program has beaten a 9-dan professional without handicap.[7] Although it lost to Lee Sedol in the fourth game, Lee resigned in the final game, giving a final score of 4 games to 1 in favour of AlphaGo. In recognition of the victory, AlphaGo was awarded an honorary 9-dan by the Korea Baduk Association.[8] The lead up and the challenge match with Lee Sedol were documented in a documentary film also titled AlphaGo,[9] directed by Greg Kohs. The win by AlphaGo was chosen by Science as one of the Breakthrough of the Year runners-up on 22 December 2016.[10]
At the 2017 Future of Go Summit, the Master version of AlphaGo beat Ke Jie, the number one ranked player in the world at the time, in a three-game match, after which AlphaGo was awarded professional 9-dan by the Chinese Weiqi Association.[11]
After the match between AlphaGo and Ke Jie, DeepMind retired AlphaGo, while continuing AI research in other areas.[12] The self-taught AlphaGo Zero achieved a 100â0 victory against the early competitive version of AlphaGo, and its successor AlphaZero is currently perceived as the world's top player in Go as well as possibly in chess.[13][14]

Contents

1 History

1.1 Match against Fan Hui
1.2 Match against Lee Sedol
1.3 Sixty online games
1.4 Future of Go Summit
1.5 AlphaGo Zero and AlphaZero
1.6 Teaching tool


2 Versions
3 Algorithm
4 Style of play
5 Responses to 2016 victory

5.1 AI community
5.2 Go community


6 Similar systems
7 Example game
8 Impacts on Go
9 See also
10 References
11 External links



History[edit]
Go is considered much more difficult for computers to win than other games such as chess, because its much larger branching factor makes it prohibitively difficult to use traditional AI methods such as alphaâbeta pruning, tree traversal and heuristic search.[5][15]
Almost two decades after IBM's computer Deep Blue beat world chess champion Garry Kasparov in the 1997 match, the strongest Go programs using artificial intelligence techniques only reached about amateur 5-dan level,[4] and still could not beat a professional Go player without a handicap.[5][6][16] In 2012, the software program Zen, running on a four PC cluster, beat Masaki Takemiya (9p) twice at five- and four-stone handicaps.[17] In 2013, Crazy Stone beat Yoshio Ishida (9p) at a four-stone handicap.[18]
According to DeepMind's David Silver, the AlphaGo research project was formed around 2014 to test how well a neural network using deep learning can compete at Go.[19] AlphaGo represents a significant improvement over previous Go programs. In 500 games against other available Go programs, including Crazy Stone and Zen, AlphaGo running on a single computer won all but one.[20] In a similar matchup, AlphaGo running on multiple computers won all 500 games played against other Go programs, and 77% of games played against AlphaGo running on a single computer. The distributed version in October 2015 was using 1,202 CPUs and 176 GPUs.[4]

Match against Fan Hui[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: AlphaGo versus Fan Hui
In October 2015, the distributed version of AlphaGo defeated the European Go champion Fan Hui,[21] a 2-dan (out of 9 dan possible) professional, five to zero.[6][22] This was the first time a computer Go program had beaten a professional human player on a full-sized board without handicap.[23] The announcement of the news was delayed until 27 January 2016 to coincide with the publication of a paper in the journal Nature[4] describing the algorithms used.[6]

Match against Lee Sedol[edit]
Main article: AlphaGo versus Lee Sedol
AlphaGo played South Korean professional Go player Lee Sedol, ranked 9-dan, one of the best players at Go,[16][needs update] with five games taking place at the Four Seasons Hotel in Seoul, South Korea on 9, 10, 12, 13, and 15 March 2016,[24][25] which were video-streamed live.[26]  Out of five games, AlphaGo won four games and Lee won the fourth game which made him recorded as the only human player who beat AlphaGo in all of its 74 official games.[27] AlphaGo ran on Google's cloud computing with its servers located in the United States.[28] The match used Chinese rules with a 7.5-point komi, and each side had two hours of thinking time plus three 60-second byoyomi periods.[29] The version of AlphaGo playing against Lee used a similar amount of computing power as was used in the Fan Hui match.[30] The Economist reported that it used 1,920 CPUs and 280 GPUs.[31] At the time of play, Lee Sedol had the second-highest number of Go international championship victories in the world after South Korean player Lee Changho who kept the world championship title for 16 years.[32] Since there is no single official method of ranking in international Go, the rankings may vary among the sources. While he was ranked top sometimes, some sources ranked Lee Sedol as the fourth-best player in the world at the time.[33][34] AlphaGo was not specifically trained to face Lee nor was designed to compete with any specific human players.
The first three games were won by AlphaGo following resignations by Lee.[35][36] However, Lee beat AlphaGo in the fourth game, winning by resignation at move 180. AlphaGo then continued to achieve a fourth win, winning the fifth game by resignation.[37]
The prize was US$1 million. Since AlphaGo won four out of five and thus the series, the prize will be donated to charities, including UNICEF.[38] Lee Sedol received $150,000 for participating in all five games and an additional $20,000 for his win in Game 4.[29]
In June 2016, at a presentation held at a university in the Netherlands, Aja Huang, one of the Deep Mind team, revealed that they had patched the logical weakness that occurred during the 4th game of the match between AlphaGo and Lee, and that after move 78 (which was dubbed the "divine move" by many professionals), it would play as intended and maintain Black's advantage. Before move 78, AlphaGo was leading throughout the game, but Lee's move caused the program's computing powers to be diverted and confused.[39] Huang explained that AlphaGo's policy network of finding the most accurate move order and continuation did not precisely guide AlphaGo to make the correct continuation after move 78, since its value network did not determine Lee's 78th move as being the most likely, and therefore when the move was made AlphaGo could not make the right adjustment to the logical continuation.[40]

Sixty online games[edit]
Main article: Master (software)
On 29 December 2016, a new account on the Tygem server named "Magister" (shown as 'Magist' at the server's Chinese version) from South Korea began to play games with professional players. It changed its account name to "Master" on 30 December, then moved to the FoxGo server on 1 January 2017. On 4 January, DeepMind confirmed that the "Magister" and the "Master" were both played by an updated version of AlphaGo, called AlphaGo Master.[41][42] As of 5 January 2017, AlphaGo Master's online record was 60 wins and 0 losses,[43] including three victories over Go's top-ranked player, Ke Jie,[44] who had been quietly briefed in advance that Master was a version of AlphaGo.[43] After losing to Master, Gu Li offered a bounty of 100,000 yuan (US$14,400) to the first human player who could defeat Master.[42] Master played at the pace of 10 games per day. Many quickly suspected it to be an AI player due to little or no resting between games. Its adversaries included many world champions such as Ke Jie, Park Jeong-hwan, Yuta Iyama, Tuo Jiaxi, Mi Yuting, Shi Yue, Chen Yaoye, Li Qincheng, Gu Li, Chang Hao, Tang Weixing, Fan Tingyu, Zhou Ruiyang, Jiang Weijie, Chou Chun-hsun, Kim Ji-seok, Kang Dong-yun, Park Yeong-hun, and Won Seong-jin; national champions or world championship runners-up such as Lian Xiao, Tan Xiao, Meng Tailing, Dang Yifei, Huang Yunsong, Yang Dingxin, Gu Zihao, Shin Jinseo, Cho Han-seung, and An Sungjoon. All 60 games except one were fast-paced games with three 20 or 30 seconds byo-yomi. Master offered to extend the byo-yomi to one minute when playing with Nie Weiping in consideration of his age. After winning its 59th game Master revealed itself in the chatroom to be controlled by Dr. Aja Huang of the DeepMind team,[45] then changed its nationality to the United Kingdom. After these games were completed, the co-founder of Google DeepMind, Demis Hassabis, said in a tweet, "we're looking forward to playing some official, full-length games later [2017] in collaboration with Go organizations and experts".[41][42]
Go experts were impressed by the program's performance and its nonhuman play style; Ke Jie stated that "After humanity spent thousands of years improving our tactics, computers tell us that humans are completely wrong... I would go as far as to say not a single human has touched the edge of the truth of Go."[43]

Future of Go Summit[edit]
Main article: Future of Go Summit
Further information: AlphaGo versus Ke Jie
In the Future of Go Summit held in Wuzhen in May 2017, AlphaGo Master played three games with Ke Jie, the world No.1 ranked player, as well as two games with several top Chinese professionals, one pair Go game and one against a collaborating team of five human players.[46]
Google DeepMind offered 1.5 million dollar winner prizes for the three-game match between Ke Jie and Master while the losing side took 300,000 dollars.[47][48] Master won all three games against Ke Jie,[49][50] after which AlphaGo was awarded professional 9-dan by the Chinese Weiqi Association.[11]
After winning its three-game match against Ke Jie, the top-rated world Go player, AlphaGo retired. DeepMind also disbanded the team that worked on the game to focus on AI research in other areas.[12] After the Summit, Deepmind published 50 full length AlphaGo vs AlphaGo matches, as a gift to the Go community.[51]

AlphaGo Zero and AlphaZero[edit]
Main articles: AlphaGo Zero and AlphaZero
AlphaGo's team published an article in the journal Nature on 19 October 2017, introducing AlphaGo Zero, a version without human data and stronger than any previous human-champion-defeating version.[52] By playing games against itself, AlphaGo Zero surpassed the strength of AlphaGo Lee in three days by winning 100 games to 0, reached the level of AlphaGo Master in 21 days, and exceeded all the old versions in 40 days.[53]
In a paper released on arXiv on 5 December 2017, DeepMind claimed that it generalized AlphaGo Zero's approach into a single AlphaZero algorithm, which achieved within 24 hours a superhuman level of play in the games of chess, shogi, and Go by defeating world-champion programs, Stockfish, Elmo, and 3-day version of AlphaGo Zero in each case.[54]

Teaching tool[edit]
On 11 December 2017, DeepMind released AlphaGo teaching tool on its website[55] to analyze winning rates of different Go openings as calculated by AlphaGo Master.[56] The teaching tool collects 6,000 Go openings from 230,000 human games each analyzed with 10,000,000 simulations by AlphaGo Master. Many of the openings include human move suggestions.[56]

Versions[edit]
An early version of AlphaGo was tested on hardware with various numbers of CPUs and GPUs, running in asynchronous or distributed mode. Two seconds of thinking time was given to each move. The resulting Elo ratings are listed below.[4] In the matches with more time per move higher ratings are achieved.


Configuration and performance


Configuration
Searchthreads
No. of CPU
No. of GPU
Elo rating


Single[4] p.Â 10â11
40
48
1
2,181


Single
40
48
2
2,738


Single
40
48
4
2,850


Single
40
48
8
2,890


Distributed
12
428
64
2,937


Distributed
24
764
112
3,079


Distributed
40
1,202
176
3,140


Distributed
64
1,920
280
3,168

In May 2016, Google unveiled its own proprietary hardware "tensor processing units", which it stated had already been deployed in multiple internal projects at Google, including the AlphaGo match against Lee Sedol.[57][58]
In the Future of Go Summit in May 2017, DeepMind disclosed that the version of AlphaGo used in this Summit was AlphaGo Master,[59][60] and revealed that it had measured the strength of different versions of the software. AlphaGo Lee, the version used against Lee, could give AlphaGo Fan, the version used in AlphaGo vs. Fan Hui, three stones, and AlphaGo Master was even three stones stronger.[61]


Configuration and strength[62]


Versions
Hardware
Elo rating
Date
Results


AlphaGo Fan
176 GPUs,[53] distributed
3,144[52]
Oct 2015
5:0 against Fan Hui


AlphaGo Lee
48 TPUs,[53] distributed
3,739[52]
Mar 2016
4:1 against Lee Sedol


AlphaGo Master
4 TPUs,[53] single machine
4,858[52]
May 2017
60:0 against professional players;Future of Go Summit


AlphaGo Zero (40 block)
4 TPUs,[53] single machine
5,185[52]
Oct 2017
100:0 against AlphaGo Lee
89:11 against AlphaGo Master



AlphaZero (20 block)
4 TPUs, single machine
5,018
[63]


Dec 2017
60:40 against AlphaGo Zero (20 block)

Algorithm[edit]
As of 2016, AlphaGo's algorithm uses a combination of machine learning and tree search techniques, combined with extensive training, both from human and computer play. It uses Monte Carlo tree search, guided by a "value network" and a "policy network," both implemented using deep neural network technology.[5][4] A limited amount of game-specific feature detection pre-processing (for example, to highlight whether a move matches a nakade pattern) is applied to the input before it is sent to the neural networks.[4] The networks are convolutional neural networks with 12 layers, trained by reinforcement learning.[64]
The system's neural networks were initially bootstrapped from human gameplay expertise. AlphaGo was initially trained to mimic human play by attempting to match the moves of expert players from recorded historical games, using a database of around 30 million moves.[21] Once it had reached a certain degree of proficiency, it was trained further by being set to play large numbers of games against other instances of itself, using reinforcement learning to improve its play.[5] To avoid "disrespectfully" wasting its opponent's time, the program is specifically programmed to resign if its assessment of win probability falls beneath a certain threshold; for the match against Lee, the resignation threshold was set to 20%.[65]

Style of play[edit]
Toby Manning, the match referee for AlphaGo vs. Fan Hui, has described the program's style as "conservative".[66] AlphaGo's playing style strongly favours greater probability of winning by fewer points over lesser probability of winning by more points.[19] Its strategy of maximising its probability of winning is distinct from what human players tend to do which is to maximise territorial gains, and explains some of its odd-looking moves.[67] It makes a lot of opening moves that have never or seldom been made by humans. It likes to use shoulder hits, especially if the opponent is over concentrated.[citation needed]

Responses to 2016 victory[edit]
AI community[edit]
AlphaGo's March 2016 victory was a major milestone in artificial intelligence research.[68] Go had previously been regarded as a hard problem in machine learning that was expected to be out of reach for the technology of the time.[68][69][70] Most experts thought a Go program as powerful as AlphaGo was at least five years away;[71] some experts thought that it would take at least another decade before computers would beat Go champions.[4][72][73] Most observers at the beginning of the 2016 matches expected Lee to beat AlphaGo.[68]
With games such as checkers (that has been "solved" by the Chinook draughts player team), chess, and now Go won by computers, victories at popular board games can no longer serve as major milestones for artificial intelligence in the way that they used to. Deep Blue's Murray Campbell called AlphaGo's victory "the end of an era... board games are more or less done and it's time to move on."[68]
When compared with Deep Blue or Watson, AlphaGo's underlying algorithms are potentially more general-purpose and may be evidence that the scientific community is making progress towards artificial general intelligence.[19][74] Some commentators believe AlphaGo's victory makes for a good opportunity for society to start preparing for the possible future impact of machines with general purpose intelligence. As noted by entrepreneur Guy Suter, AlphaGo only knows how to play Go and doesn't possess general-purpose intelligence; "[It] couldn't just wake up one morning and decide it wants to learn how to use firearms."[68] AI researcher Stuart Russell said that AI systems such as AlphaGo have progressed quicker and become more powerful than expected, and we must therefore develop methods to ensure they "remain under human control".[75] Some scholars,  such as Stephen Hawking, warned (in May 2015 before the matches) that some future self-improving AI could gain actual general intelligence, leading to an unexpected AI takeover; other scholars disagree: AI expert Jean-Gabriel Ganascia believes that "Things like 'common sense'... may never be reproducible",[76] and says "I don't see why we would speak about fears. On the contrary, this raises hopes in many domains such as health and space exploration."[75] Computer scientist Richard Sutton said "I don't think people should be scared... but I do think people should be paying attention."[77]
In China, AlphaGo was a "Sputnik moment" which helped convince the Chinese government to prioritize and dramatically increase funding for artificial intelligence.[78]
In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky medal for Outstanding Achievements in AI. "AlphaGo is a wonderful achievement, and a perfect example of what the Minsky Medal was initiated to recognise", said Professor Michael Wooldridge, Chair of the IJCAI Awards Committee.  "What particularly impressed IJCAI was that AlphaGo achieves what it does through a brilliant combination of classic AI techniques as well as the state-of-the-art machine learning techniques that DeepMind is so closely associated with. It's a breathtaking demonstration of contemporary AI, and we are delighted to be able to recognise it with this award."[79]

Go community[edit]
Go is a popular game in China, Japan and Korea, and the 2016 matches were watched by perhaps a hundred million people worldwide.[68][80] Many top Go players characterized AlphaGo's unorthodox plays as seemingly-questionable moves that initially befuddled onlookers, but made sense in hindsight:[72] "All but the very best Go players craft their style by imitating top players. AlphaGo seems to have totally original moves it creates itself."[68] AlphaGo appeared to have unexpectedly become much stronger, even when compared with its October 2015 match[81] where a computer had beaten a Go professional for the first time ever without the advantage of a handicap.[82] The day after Lee's first defeat, Jeong Ahram, the lead Go correspondent for one of South Korea's biggest daily newspapers, said "Last night was very gloomy... Many people drank alcohol."[83] The Korea Baduk Association, the organization that oversees Go professionals in South Korea, awarded AlphaGo an honorary 9-dan title for exhibiting creative skills and pushing forward the game's progress.[84]
China's Ke Jie, an 18-year-old generally recognized as the world's best Go player at the time,[33][85] initially claimed that he would be able to beat AlphaGo, but declined to play against it for fear that it would "copy my style".[85] As the matches progressed, Ke Jie went back and forth, stating that "it is highly likely that I (could) lose" after analysing the first three matches,[86] but regaining confidence after AlphaGo displayed flaws in the fourth match.[87]
Toby Manning, the referee of AlphaGo's match against Fan Hui, and Hajin Lee, secretary general of the International Go Federation, both reason that in the future, Go players will get help from computers to learn what they have done wrong in games and improve their skills.[82]
After game two, Lee said he felt "speechless": "From the very beginning of the match, I could never manage an upper hand for one single move. It was AlphaGo's total victory."[88] Lee apologized for his losses, stating after game three that "I misjudged the capabilities of AlphaGo and felt powerless."[68] He emphasized that the defeat was "Lee Se-dol's defeat" and "not a defeat of mankind".[27][76] Lee said his eventual loss to a machine was "inevitable" but stated that "robots will never understand the beauty of the game the same way that we humans do."[76] Lee called his game four victory a "priceless win that I (would) not exchange for anything."[27]

Similar systems[edit]
Facebook has also been working on its own Go-playing system darkforest, also based on combining machine learning and Monte Carlo tree search.[66][89] Although a strong player against other computer Go programs, as of early 2016, it had not yet defeated a professional human player.[90] Darkforest has lost to CrazyStone and Zen and is estimated to be of similar strength to CrazyStone and Zen.[91]
DeepZenGo, a system developed with support from video-sharing website Dwango and the University of Tokyo, lost 2â1 in November 2016 to Go master Cho Chikun, who holds the record for the largest number of Go title wins in Japan.[92][93]
A 2018 paper in Nature cited AlphaGo's approach as the basis for a new means of computing potential pharmaceutical drug molecules.[94][95]

Example game[edit]
AlphaGo Master (white) v. Tang Weixing (31 December 2016), AlphaGo won by resignation. White 36 was widely praised.















































































































































































































































































































































































































































































































































































































































































































































































First 99 moves















































































































































































































































































































































































































































































































































































































































































































































































Moves 100â186 (149 at 131, 150 at 130)

Impacts on Go[edit]
The AlphaGo documentary film[9][96] raised hopes that Lee Sedol and Fan Hui would have benefitted from their experience of playing AlphaGo, but as of May 2018 their ratings were little changed; Lee Sedol was ranked 11th in the world, and Fan Hui 545th.[97] On 19 November 2019, Lee announced his retirement from professional play, arguing that he could never be the top overall player of Go due to the increasing dominance of AI. Lee referred to them as being "an entity that cannot be defeated".[98]

See also[edit]
.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}
Chinook (draughts player), draughts playing program
Glossary of artificial intelligence
Go and mathematics
Leela (software)
TD-Gammon, backgammon neural network
Pluribus (poker bot)
AlphaZero
AlphaFold

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol". BBC News. 12 March 2016. Retrieved 17 March 2016.

^ "DeepMind AlphaGO". DeepMind Artificial Intelligence AlphaGo.

^ "AlphaGo | DeepMind". DeepMind.

^ a b c d e f g h i Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassabis, Demis (28 January 2016). "Mastering the game of Go with deep neural networks and tree search". Nature. 529 (7587): 484â489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSNÂ 0028-0836. PMIDÂ 26819042. S2CIDÂ 515925.

^ a b c d e "Research Blog: AlphaGo: Mastering the ancient game of Go with Machine Learning". Google Research Blog. 27 January 2016.

^ a b c d "Google achieves AI 'breakthrough' by beating Go champion". BBC News. 27 January 2016.

^ "Match 1 â Google DeepMind Challenge Match: Lee Sedol vs AlphaGo". 8 March 2016.

^ "Google's AlphaGo gets 'divine' Go ranking". The Straits Times. straitstimes.com. 15 March 2016. Retrieved 9 December 2017.

^ a b "AlphaGo Movie". AlphaGo Movie.

^ "From AI to protein folding: Our Breakthrough runners-up". Science. 22 December 2016. Retrieved 29 December 2016.

^ a b "ä¸­å½å´æ£åä¼æäºAlphaGoèä¸ä¹æ®µ å¹¶é¢åè¯ä¹¦" (in Chinese). Sohu.com. 27 May 2017. Retrieved 9 December 2017.

^ a b Metz, Cade (27 May 2017). "After Win in China, AlphaGo's Designers Explore New AI". Wired.

^ "AlphaZero Crushes Stockfish In New 1,000-Game Match". 17 April 2019.

^ "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play". 7 December 2018.

^ Schraudolph, Nicol N.; Terrence, Peter Dayan; Sejnowski, J., Temporal Difference Learning of Position Evaluation in the Game of Go (PDF)

^ a b "Computer scores big win against humans in ancient game of Go". CNN. 28 January 2016. Retrieved 28 January 2016.

^ "Zen computer Go program beats Takemiya Masaki with just 4 stones!". Go Game Guru. Archived from the original on 1 February 2016. Retrieved 28 January 2016.

^ "ãã¢ãå­æ®µã®åãå¤©æãããå²ç¢æ£å£«ãã³ã³ãã¥ã¼ã¿ã¼ã«æãã åã®å¬å¼æ¦". MSN Sankei News. Archived from the original on 24 March 2013. Retrieved 27 March 2013.

^ a b c John Riberio (14 March 2016). "AlphaGo's unusual moves prove its AI prowess, experts say". PC World. Retrieved 18 March 2016.

^ "Google AlphaGo AI clean sweeps European Go champion". ZDNet. 28 January 2016. Retrieved 28 January 2016.

^ a b Metz, Cade (27 January 2016). "In Major AI Breakthrough, Google System Secretly Beats Top Player at the Ancient Game of Go". WIRED. Retrieved 1 February 2016.

^ "Special Computer Go insert covering the AlphaGo v Fan Hui match" (PDF). British Go Journal. 2017. Retrieved 1 February 2016.

^ "PremiÃ¨re dÃ©faite d'un professionnel du go contre une intelligence artificielle". Le Monde (in French). 27 January 2016.

^ "Google's AI AlphaGo to take on world No 1 Lee Sedol in live broadcast". The Guardian. 5 February 2016. Retrieved 15 February 2016.

^ "Google DeepMind is going to take on the world's best Go player in a luxury 5-star hotel in South Korea". Business Insider. 22 February 2016. Retrieved 23 February 2016.

^ Novet, Jordan (4 February 2016). "YouTube will livestream Google's AI playing Go superstar Lee Sedol in March". VentureBeat. Retrieved 7 February 2016.

^ a b c Yoon Sung-won (14 March 2016). "Lee Se-dol shows AlphaGo beatable". The Korea Times. Retrieved 15 March 2016.

^ "æä¸ä¹­ï¼å³ä½¿Alpha Goå¾å°åçº§ä¹ä¸æ ·è½èµ¢". JoongAng Ilbo (in Chinese). 23 February 2016. Retrieved 24 February 2016.

^ a b "ì´ì¸ë vs ìíê³ , 'êµ¬ê¸ ë¥ë§ì¸ë ì±ë¦°ì§ ë§¤ì¹' ê¸°ìíê²¬ ì´ë ¤" (in Korean). Korea Baduk Association. 22 February 2016. Archived from the original on 3 March 2016. Retrieved 22 February 2016.

^ Demis Hassabis [@demishassabis] (11 March 2016). "We are using roughly same amount of compute power as in Fan Hui match: distributing search over further machines has diminishing returns" (Tweet). Retrieved 14 March 2016 â via Twitter.

^ "Showdown". The Economist. Retrieved 19 November 2016.

^ Steven Borowiec (9 March 2016). "Google's AI machine v world champion of 'Go': everything you need to know". The Guardian. Retrieved 15 March 2016.

^ a b RÃ©mi Coulom. "Rating List of 2016-01-01". Archived from the original on 18 March 2016. Retrieved 18 March 2016.

^ "Korean Go master proves human intuition still powerful in Go". The Korean Herald/ANN. 14 March 2016. Archived from the original on 12 April 2016. Retrieved 15 March 2016.

^ "Google's AI beats world Go champion in first of five matches â BBC News". BBC Online. Retrieved 9 March 2016.

^ "Google AI wins second Go game against world champion â BBC News". BBC Online. Retrieved 10 March 2016.

^ "Google DeepMind AI wins final Go match for 4â1 series win". Engadget. Retrieved 15 March 2016.

^ "Human champion certain he'll beat AI at ancient Chinese game". Associated Press. 22 February 2016. Retrieved 22 February 2016.

^ "In Two Moves, AlphaGo and Lee Sedol Redefined the Future". WIRED. Retrieved 12 November 2017.

^ "é»å£«æ°ï¼AlphaGoæä¸ç³äººæºå¤§æç¬¬åå±é®é¢å·²è§£å³date=8 July 2016" (in Chinese). Retrieved 8 July 2016.

^ a b Demis Hassabis (4 January 2017). "Demis Hassabis on Twitter: "Excited to share an update on #AlphaGo!"". Demis Hassabis's Twitter account. Retrieved 4 January 2017.

^ a b c Elizabeth Gibney (4 January 2017). "Google reveals secret test of AI bot to beat top Go players". Nature. 541 (7636): 142. Bibcode:2017Natur.541..142G. doi:10.1038/nature.2017.21253. PMIDÂ 28079098.

^ a b c "Humans Mourn Loss After Google Is Unmasked as China's Go Master". Wall Street Journal. 5 January 2017. Retrieved 6 January 2017.

^ "The world's best Go player says he still has "one last move" to defeat Google's AlphaGo AI". Quartz. 4 January 2017. Retrieved 6 January 2017.

^ "æ¨ªæ«ä¸­æ¥é©æ£ææ©è·59èçMasteråè¯ï¼ææ¯é¿å°æ³ç" (in Chinese). æ¾æ¹æ°é». 4 January 2017. Retrieved 11 December 2017.

^ "Exploring the mysteries of Go with AlphaGo and China's top players". 10 April 2017.

^ "World No.1 Go player Ke Jie takes on upgraded AlphaGo in May". 10 April 2017.

^ "Ke Jie vs. AlphaGo: 8 things you must know". 27 May 2017.

^ Metz, Cade (23 May 2017). "Revamped AlphaGo Wins First Game Against Chinese Go Grandmaster". Wired.

^ Metz, Cade (25 May 2017). "Google's AlphaGo Continues Dominance With Second Win in China". Wired.

^ "Full length games for Go players to enjoy". Deepmind. Retrieved 28 May 2017.

^ a b c d e Silver, David; Schrittwieser, Julian; Simonyan, Karen; Antonoglou, Ioannis; Huang, Aja; Guez, Arthur; Hubert, Thomas; Baker, Lucas; Lai, Matthew; Bolton, Adrian; Chen, Yutian; Lillicrap, Timothy; Fan, Hui; Sifre, Laurent; Driessche, George van den; Graepel, Thore; Hassabis, Demis (19 October 2017). "Mastering the game of Go without human knowledge" (PDF). Nature. 550 (7676): 354â359. Bibcode:2017Natur.550..354S. doi:10.1038/nature24270. ISSNÂ 0028-0836. PMIDÂ 29052630. S2CIDÂ 205261034.

^ a b c d e "AlphaGo Zero: Learning from scratch". DeepMind official website. 18 October 2017. Retrieved 19 October 2017.

^ Silver, David; Hubert, Thomas; Schrittwieser, Julian; Antonoglou, Ioannis; Lai, Matthew; Guez, Arthur; Lanctot, Marc; Sifre, Laurent; Kumaran, Dharshan; Graepel, Thore; Lillicrap, Timothy; Simonyan, Karen; Hassabis, Demis (5 December 2017). "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm". arXiv:1712.01815 [cs.AI].

^ "AlphaGo teaching tool". DeepMind.

^ a b "AlphaGoæå­¦å·¥å·ä¸çº¿ æ¨éº¾ï¼ä½¿ç¨Masterçæ¬" (in Chinese). Sina.com.cn. 11 December 2017. Retrieved 11 December 2017.

^ McMillan, Robert (18 May 2016). "Google Isn't Playing Games With New Chip". The Wall Street Journal. Retrieved 26 June 2016.

^ Jouppi, Norm (18 May 2016). "Google supercharges machine learning tasks with TPU custom chip". Google Cloud Platform Blog. Retrieved 26 June 2016.

^ "AlphaGoå®æ¹è§£è¯»è®©ä¸å­ å¯¹äººç±»é«ææ²¡è¿ç§ä¼å¿" (in Chinese). Sina. 25 May 2017. Retrieved 2 June 2017.

^ "åçalphagoå®åå¯¹æ¯ masterè½è®©æä¸ç³ç3å­" (in Chinese). Sina. 24 May 2017. Retrieved 2 June 2017.

^ "New version of AlphaGo self-trained and much more efficient". American Go Association. 24 May 2017. Retrieved 1 June 2017.

^ "ãæ¯æ´æè´¥è§£å¯ãAlphaGo Masterææ°æ¶æåç®æ³ï¼è°·æ­äºä¸TPUæè§£" (in Chinese). Sohu. 24 May 2017. Retrieved 1 June 2017.

^ Silver, David; Hubert, Thomas; Schrittwieser, Julian; Antonoglou, Ioannis; Lai, Matthew; Guez, Arthur; Lanctot, Marc; Sifre, Laurent; Kumaran, Dharshan; Graepel, Thore; Lillicrap, Timothy; Simonyan, Karen; Hassabis, Demis (7 December 2018). "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play". Science. 362 (6419): 1140â1144. Bibcode:2018Sci...362.1140S. doi:10.1126/science.aar6404. PMIDÂ 30523106. S2CIDÂ 54457125 â via science.org (Atypon).

^ Silver, David; Schrittwieser, Julian; Simonyan, Karen; Antonoglou, Ioannis; Huang, Aja; Guez, Arthur; Hubert, Thomas; Baker, Lucas; Lai, Matthew; Bolton, Adrian; Chen, Yutian; Lillicrap, Timothy; Fan, Hui; Sifre, Laurent; Driessche, George van den; Graepel, Thore; Hassabis, Demis (19 October 2017). "Mastering the game of Go without human knowledge" (PDF). Nature. 550 (7676): 354â359. Bibcode:2017Natur.550..354S. doi:10.1038/nature24270. ISSNÂ 0028-0836. PMIDÂ 29052630. S2CIDÂ 205261034. AlphaGo Lee... 12 convolutional layers

^ Cade Metz (13 March 2016). "Go Grandmaster Lee Sedol Grabs Consolation Win Against Google's AI". Wired News. Retrieved 29 March 2016.

^ a b Gibney, Elizabeth (27 January 2016). "Google AI algorithm masters ancient game of Go". Nature. 529 (7587): 445â6. Bibcode:2016Natur.529..445G. doi:10.1038/529445a. PMIDÂ 26819021.

^ Chouard, Tanguy (12 March 2016). "The Go Files: AI computer clinches victory against Go champion". Nature. doi:10.1038/nature.2016.19553. S2CIDÂ 155164502.

^ a b c d e f g h Steven Borowiec; Tracey Lien (12 March 2016). "AlphaGo beats human Go champ in milestone for artificial intelligence". Los Angeles Times. Retrieved 13 March 2016.

^ Connor, Steve (27 January 2016). "A computer has beaten a professional at the world's most complex board game". The Independent. Retrieved 28 January 2016.

^ "Google's AI beats human champion at Go". CBC News. 27 January 2016. Retrieved 28 January 2016.

^ Dave Gershgorn (12 March 2016). "GOOGLE'S ALPHAGO BEATS WORLD CHAMPION IN THIRD MATCH TO WIN ENTIRE SERIES". Popular Science. Retrieved 13 March 2016.

^ a b "Google DeepMind computer AlphaGo sweeps human champ in Go matches". CBC News. Associated Press. 12 March 2016. Retrieved 13 March 2016.

^ Sofia Yan (12 March 2016). "A Google computer victorious over the world's 'Go' champion". CNN Money. Retrieved 13 March 2016.

^ "AlphaGo: Google's artificial intelligence to take on world champion of ancient Chinese board game". Australian Broadcasting Corporation. 8 March 2016. Retrieved 13 March 2016.

^ a b MariÃ«tte Le Roux (12 March 2016). "Rise of the Machines: Keep an eye on AI, experts warn". Phys.org. Retrieved 13 March 2016.

^ a b c MariÃ«tte Le Roux; Pascale Mollard (8 March 2016). "Game over? New AI challenge to human smarts (Update)". phys.org. Retrieved 13 March 2016.

^ Tanya Lewis (11 March 2016). "An AI expert says Google's Go-playing program is missing 1 key feature of human intelligence". Business Insider. Retrieved 13 March 2016.

^ Mozur, Paul (20 July 2017). "Beijing Wants A.I. to Be Made in China by 2030". The New York Times. Retrieved 11 April 2018.

^ "Marvin Minsky Medal for Outstanding Achievements in AI". International Joint Conference on Artificial Intelligence. 19 October 2017. Retrieved 21 October 2017.

^ CHOE SANG-HUN (16 March 2016). "Google's Computer Program Beats Lee Se-dol in Go Tournament". The New York Times. Retrieved 18 March 2016. More than 100 million people watched the AlphaGo-Lee matches, Mr. Hassabis said.

^ John Ribeiro (12 March 2016). "Google's AlphaGo AI program strong but not perfect, says defeated South Korean Go player". PC World. Retrieved 13 March 2016.

^ a b Gibney, Elizabeth (2016). "Go players react to computer defeat". Nature. doi:10.1038/nature.2016.19255. S2CIDÂ 146868978.

^ Zastrow, Mark (15 March 2016). "How victory for Google's Go AI is stoking fear in South Korea". New Scientist. Retrieved 18 March 2016.

^ JEE HEUN KAHNG; SE YOUNG LEE (15 March 2016). "Google artificial intelligence program beats S. Korean Go pro with 4â1 score". Reuters. Retrieved 18 March 2016.

^ a b Neil Connor (11 March 2016). "Google AlphaGo 'can't beat me' says China Go grandmaster". The Telegraph (UK). Retrieved 13 March 2016.

^ "Chinese Go master Ke Jie says he could lose to AlphaGoÂ : The DONG-A ILBO". Retrieved 17 March 2016.

^ "...if today's performance was its true capability, then it doesn't deserve to play against me". M.hankooki.com. 14 March 2016. Retrieved 5 June 2018.

^ CHOE SANG-HUN (15 March 2016). "In Seoul, Go Games Spark Interest (and Concern) About Artificial Intelligence". The New York Times. Retrieved 18 March 2016.

^ Tian, Yuandong; Zhu, Yan (2015). "Better Computer Go Player with Neural Network and Long-term Prediction". arXiv:1511.06410v1 [cs.LG].

^ HAL 90210 (28 January 2016). "No Go: Facebook fails to spoil Google's big AI day". The Guardian. ISSNÂ 0261-3077. Retrieved 1 February 2016.

^ "Strachey Lecture â Dr Demis Hassabis". The New Livestream. Retrieved 17 March 2016.

^ "Go master Cho wins best-of-three series against Japan-made AI". The Japan Times Online. 24 November 2016. Retrieved 27 November 2016.

^ "Humans strike back: Korean Go master bests AI in board game bout". CNET. Retrieved 27 November 2016.

^ "Go and make some drugs The Engineer". www.theengineer.co.uk. 3 April 2018. Retrieved 3 April 2018.

^ Segler, Martwin H.S.; Preuss, Mike; Waller, Mark P. (29 March 2018). "Planning chemical syntheses with deep neural networks and symbolic AI". Nature. 555: 604â610.

^ "AlphaGo (2017)". Rotten Tomatoes. Retrieved 5 June 2018.

^ "Go Ratings". Go Ratings. Retrieved 5 June 2018.

^ Vincent, James (27 November 2019). "Former Go champion beaten by DeepMind retires after declaring AI invincible". The Verge. Retrieved 28 November 2019.


External links[edit]
 Media related to AlphaGo at Wikimedia Commons
 Quotations related to AlphaGo at Wikiquote
Official website
AlphaGo wiki at Sensei's Library, including links to AlphaGo games
AlphaGo page, with archive and games
Estimated 2017 rating of Alpha Go
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteDifferentiable computingGeneral
Differentiable programming
Neural Turing machine
Differentiable neural computer
Automatic differentiation
Neuromorphic engineering
Cable theory
Pattern recognition
Computational learning theory
Tensor calculus
Concepts
Gradient descent
SGD
Clustering
Regression
Overfitting
Adversary
Attention
Convolution
Loss functions
Backpropagation
Normalization
Activation
Softmax
Sigmoid
Rectifier
Regularization
Datasets
Augmentation
Programming languages
Python
Julia
Application
Machine learning
Artificial neural network
Deep learning
Scientific computing
Artificial Intelligence
Hardware
IPU
TPU
VPU
Memristor
SpiNNaker
Software library
TensorFlow
PyTorch
Keras
Theano
ImplementationAudio-visual
AlexNet
WaveNet
Human image synthesis
HWR
OCR
Speech synthesis
Speech recognition
Facial recognition
AlphaFold
DALL-E
Verbal
Word2vec
Transformer
BERT
NMT
Project Debater
Watson
GPT-2
GPT-3
Decisional
AlphaGo
AlphaZero
Q-learning
SARSA
OpenAI Five
Self-driving car
MuZero
Action selection
Robot control
People
Alex Graves
Ian Goodfellow
Yoshua Bengio
Geoffrey Hinton
Yann LeCun
Andrew Ng
Demis Hassabis
David Silver
Fei-Fei Li
Organizations
DeepMind
OpenAI
MIT CSAIL
Mila
Google Brain
FAIR

 Portals
Computer programming
Technology
 Category
Artificial neural networks
Machine learning

vteGoOverview
Handicaps
Komi
Rules
Equipment
Bowls
Goban
Katsura
Kaya
Stones
Clamshell
Slate
Yunzi
Terms
Aji
Atari
Board positions
Dame
Divine move
Double hane
Eyes
Gote, sente and tenuki
Hane
Hayago
Jigo
Joseki
Kakari
Keima
Kiai
Kikashi
Ko
Komi
Korigatachi
Kosumi
Ladder
Liberty
Miai
Monkey jump
Moyo
Myoushu
Nakade
Nerai
Myoushu
Peep
Pincer
Probe
Sabaki
Seki
Sente
Shape
Shoulder hit
Tesuji
Thickness
Yose
Strategy and tactics
Capturing race
Fuseki
Chinese
Kobayashi
Shinfuseki
Shusaku
JÅseki
Nadare
Taisha
Ko fight
Ladder
Life and death
Mirror Go
Opening theory
Proverbs
Shape
Empty triangle
Ponnuki
Tenuki
Tsumego
History
Classic of Arts
Dunhuang Go Manual
Emperor Yao
Four Go houses
Four arts
Hoensha
9 Pin Zhi
Oskar Korschelt
Oshirogo
Players
European players
Female players
Nihon Ki-in Hall of Fame
Professional handicaps
Competition
Go professional
Ranks and ratings
Dan
KyÅ«
Honorary titles
Jubango
Title holders
Tournaments
Games and matches
AlphaGo vs. Fan Hui
AlphaGo vs. Ke Jie
AlphaGo vs. Lee Sedol
Atomic bomb game
Blood-vomiting game
Ear-reddening game
The Game of the Century
Kamakura jubango
Lee's broken ladder game
Art and media
AlphaGo
The Divine Move
The Girl Who Played Go
The Go Master
The Go Player
Go World
Hikaru no Go
Igo HatsuyÅron
Long Ode to Watching Weiqi
The Master of Go
Ranka
Sensei's Library
Shibumi
The Surrounding Game
The Weiqi Devil
Computers
Computer Go UEC Cup
Engines
AlphaGo
AlphaGo Master
AlphaGo Zero
AlphaZero
Crazy Stone
Darkforest
Fine Art
GNU Go
KataGo
Leela
Leela Zero
Zen
Future of Go Summit
Monte Carlo tree search
Smart Game Format
Servers
KGS Go Server
Pandanet
Tygem
Organizations
American Go Association
Australian Go Association
British Go Association
China
China Qiyuan
Chinese Weiqi Association
Hong Kong Go Association
European Go Federation
French Federation of Go
International Go Federation
Irish Go Association
Japan
All Japan Student Go Federation
Kansai Ki-in
Nihon Ki-in
Korea
Korea Baduk Association
Myongji University
Mind Sports Organisation
New Zealand Go Society
Singapore Weiqi Association
Taiwan Chi Yuan Culture Foundation
Other
Benson's algorithm
Game record (kifu)
Games played with Go equipment
Go and mathematics
Variants
Batoo
Capture Go
Sygo

Â Go portal
Category





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=AlphaGo&oldid=1067772956"
		Categories: AlphaGo2015 softwareArtificial intelligence applicationsGo enginesGoogleApplied machine learningHidden categories: CS1 Chinese-language sources (zh)CS1 French-language sources (fr)CS1 Korean-language sources (ko)Articles with short descriptionShort description is different from WikidataUse Oxford spelling from September 2016Use dmy dates from May 2017Wikipedia articles in need of updating from April 2016All Wikipedia articles in need of updatingAll articles with unsourced statementsArticles with unsourced statements from July 2017Commons category link from WikidataOfficial website different in Wikidata and Wikipedia
	
