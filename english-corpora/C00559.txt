
Title:
Type theory
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Concept in mathematical logic
In mathematics, logic, and computer science, a type theory is a formal system in which every "term" has a "type".  A "type" in type theory has a role similar to a "type" in a programming language: it dictates the operations that can be performed on a term and, for variables, the possible values it might be replaced with.  
Some type theories serve as alternatives to set theory as a foundation of mathematics. Two influential type theories that were proposed as foundations are Alonzo Church's typed Î»-calculus and Per Martin-LÃ¶f's intuitionistic type theory.  Most computerized proof-writing systems use a type theory for their foundation.  A common one is Thierry Coquand's Calculus of Inductive Constructions.
Type theory is closely related to, and in some cases overlaps with, type systems, which are a programming language feature used to reduce bugs and facilitate certain compiler optimizations.  Because type theory and type systems can overlap, some experts use the phrase "type system" to refer to a specific formal system and the phrase "type theory" to refer to the academic study of them.  

Contents

1 History
2 Introduction to Type Theory

2.1 Basics

2.1.1 Terms and Types
2.1.2 Computation


2.2 Functions

2.2.1 Lambda Terms
2.2.2 Dependent Typing
2.2.3 Universes


2.3 Common "by Rule" Types and Terms

2.3.1 Empty Type
2.3.2 Unit Type
2.3.3 Boolean Type
2.3.4 Product Type
2.3.5 Sum Type
2.3.6 Natural Numbers
2.3.7 Identity Type
2.3.8 Inductive Types




3 Differences from Set Theory
4 Technical Details

4.1 Terms
4.2 Judgements
4.3 Rules
4.4 Properties of Type Theories
4.5 Axioms
4.6 Decision Problems

4.6.1 Type Inhabitation
4.6.2 Type Inference


4.7 Research Areas


5 Interpretations of Type Theory

5.1 Types are Propositions; Terms are Proofs
5.2 Curry-Howard Correspondence
5.3 Intuitionistic Logic
5.4 Constructive Mathematics
5.5 Category theory


6 List of Type Theories

6.1 Major
6.2 Minor
6.3 Active Research


7 Applications

7.1 Mathematical foundations
7.2 Proof assistants
7.3 Programming languages
7.4 Linguistics
7.5 Social sciences


8 See also
9 External links

9.1 Introductory Material
9.2 Advanced Material


10 Further reading
11 References



History[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: History of type theory
Type theory was created to avoid a paradox in a mathematical foundation based on naive set theory and formal logic.  Russell's paradox, which was discovered by Bertrand Russell, existed because a set could be defined using "all possible sets", which included itself.  Between 1902 and 1908, Bertrand Russell proposed various "theories of type" to fix the problem.   By 1908 Russell arrived at a "ramified" theory of types together with an "axiom of reducibility" both of which featured prominently in Whitehead and Russell's Principia Mathematica published between 1910 and 1913.  This system avoided Russell's paradox by creating a hierarchy of types and then assigning each concrete mathematical (and possibly other) entity to a type.  Entities of a given type are built exclusively from entities of those types that are lower in their hierarchy, thus preventing an entity from being defined using itself.  
Types were not always used in logic.  There were other techniques to avoid Russell's paradox.[1] Types did gain a hold when used with one particular logic, Alonzo Church's Lambda calculus.
The most famous early example is Alonzo Church's simply typed lambda calculus. Church's theory of types[2] helped the formal system avoid the KleeneâRosser paradox that afflicted the original untyped lambda calculus. Church demonstrated that it could serve as a foundation of mathematics and it was referred to as a higher-order logic.
The phrase "type theory" now generally refers to a typed system based around lambda calculus.  One influential system is Per Martin-LÃ¶f's intuitionistic type theory, which was proposed as a foundation for constructive mathematics. Another is Thierry Coquand's calculus of constructions, which is used as the foundation by Coq, Lean, and other "proof assistants" (computerized proof writing programs).  Type theories are an area of active research, as demonstrated by homotopy type theory.

Introduction to Type Theory[edit]
There are many type theories, so describing them all is difficult.  This section covers features of many major type theories.  It is an introduction for those unfamiliar with type theory.  This section is not trying to be a complete categorization of type theories, nor an exhaustive description of them.  

Basics[edit]
Terms and Types[edit]
In type theory, every term has a type.  A term and its type are often written together as "termÂ : type".   A common type to include in a type theory is the Natural numbers, often written as "
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
" or "nat".  Another is Boolean logic values.  So, some very simple terms with their types are:

0Â : nat
42Â : nat
trueÂ : bool
Terms can be built out of other terms using function calls.  In type theory, a function call is called "function application".  Function application takes a term of a given type and results in a term of another given type.  Function application is written "function argument argument ...", instead of the conventional "function(argument,argument, ...)".  For natural numbers, it is possible to define a function called "add" that take two natural numbers.  Thus, some more terms with their types are:

add 0 0Â : nat
add 2 3Â : nat
add 1 (add 1 (add 1 0))Â : nat
In the last term, parentheses were added to indicate the order of operations.  Technically, most type theories require the parentheses to be present for every operation, but, in practice, they are not written and authors assume readers can use precedence and associativity to know where they are.  For similar ease, it is a common notation to write "
  
    
      
        x
        +
        y
      
    
    {\displaystyle x+y}
  
" instead of "add 
  
    
      
        x
      
    
    {\displaystyle x}
  
 
  
    
      
        y
      
    
    {\displaystyle y}
  
".  So, the above terms might be rewritten as:

0 + 0Â : nat
2 + 3Â : nat
1 + (1 + (1 + 0))Â : nat
Terms may also contain variables.  Variables always have a type.  So, assuming "x" and "y" are variables of type "nat", the following are also valid terms:

xÂ : nat
x + 2Â : nat
x + (x + y)Â : nat
There are more types than "nat" and "bool".  We have already seen the term "add", which is not a "nat", but a function that, when applied to two "nat"s, computes to a "nat".  The type of "add" will be covered later.  First, we need to describe "computes to".

Computation[edit]
Type theory has a built-in notation of computation.  The following terms are all different:

1 + 4Â : nat
3 + 2Â : nat
0 + 5Â : nat
but they all compute to the term "5Â : nat".  In type theory, we use the words "reduction" and "reduce" to refer to computation.  So, we say "0 + 5Â : nat" reduces to "5Â : nat".  It can be written "0 + 5Â : nat 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 5Â : nat".  The computation is mechanical, accomplished by rewriting the term's syntax.  
Terms that contain variables can be reduced too.  So the term "x + (1 + 4)Â : nat" reduces to "x + 5Â : nat".  (We can reduce any sub-term within a term, thanks to the Church-Rosser theorem.)
A term without any variables that cannot be reduced further is a "canonical term".  All the terms above reduce to "5Â : nat", which is a canonical term.  The canonical terms of the natural numbers are:

0Â : nat
1Â : nat
2Â : nat
etc.
Obviously, terms that compute to the same term are equal.  So, assuming "xÂ : nat", the terms "x + (1 + 4)Â : nat" and "x + (4 + 1)Â : nat" are equal because they both reduce to "x + 5Â : nat".  When two terms are equal, they can be substituted for each other.  Equality is a complex topic in type theory and there are many kinds of equality.  This kind of equality, where two terms compute to the same term, is called "judgemental equality".

Functions[edit]
In type theory, functions are terms.   Functions can either be lambda terms or defined "by rule".  

Lambda Terms[edit]
A lambda term looks like "(Î» variablenameÂ : type1 . term)" and has type "type1 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 type2".   The type "type1 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 type2" indicates that the lambda term is a function takes a parameter of type "type1" and computes to a term of type "type2".  The term inside the lambda term must be a value of "type2", assuming the variable has type "type1".  
An example of a lambda term is this function which doubles its argument:

(Î» xÂ : nat . (add x x))Â : nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 nat
The variable name is "x" and the variable has type "nat".  The term "(add x x) has type "nat", assuming "xÂ : nat".  Thus, the lambda term has type "nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 nat", which means if it is given a "nat" as an argument, it will compute to a "nat".  Reduction (a.k.a. computation) is defined for lambda terms.  When the function is applied (a.k.a. called), the argument is substituted for the parameter.
Earlier, we saw that function application is written by putting the parameter after the function term.  So, if we want to call the above function with the parameter "5" of type "nat", we write:

(Î» xÂ : nat . (add x x)) 5Â : nat
The lambda term was type "nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 nat", which meant that given a "nat" as an argument, it will produce a term of type "nat".  Since we have given it the argument "5", the above term has type "nat".  Reduction works by substituting the argument "5" for the parameter "x" in the term "(add x x)", so the term computes to:

(add 5 5)Â : nat
which obviously computes to

10Â : nat
A lambda term is often called an "anonymous function" because it has no name.  Often, to make things easier to read, a name is given to a lambda term.  This is merely a notation and has no mathematical meaning.  Some authors call it "notational equality".  A name might be given to the function above using the notation:

doubleÂ : nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 nat Â ::= (Î» xÂ : nat . (add x x))
This is the same function as above, just a different way to write it.  So the term

double 5Â : nat
still computes to

10Â : nat
Dependent Typing[edit]
Dependent typing is when the type returned by a function depends on the value of its argument.  For example, when a type theory has a rule that defines the type "bool", it also defines the function "if".  The function "if" takes 3 arguments and "if true b c" computes to "b" and "if false b c" computes to "c".  But what is the type of "if a b c"?
If "b" and "c" have the same type, it is obvious: "if a b c" has the same type as "b" and "c".  Thus, assuming "aÂ : bool",

if a 2 4Â : nat
if a false trueÂ : bool
But if "b" and "c" have different types, then the type of "if a b c" depends on the value of "a".  We use the symbol "Î " to indicate a function that takes an argument and returns a type.  Assuming we have some types "B" and C" and "aÂ : bool", "bÂ : B" and "cÂ : C", then 

if a b cÂ : (Î  aÂ : bool . B 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 C 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 if a B C)
That is, the type of the "if" term is either the type of the second or third argument, depending on the value of the first argument.  In actuality, "if a B C" isn't defined using "if", but that gets into details too complicated for this introduction.
Because the type can contain computation, dependent typing is amazingly powerful.  When mathematicians say "there exists a number 
  
    
      
        x
      
    
    {\displaystyle x}
  
 such that 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is prime" or "there exists a number 
  
    
      
        x
      
    
    {\displaystyle x}
  
 such that property 
  
    
      
        P
        (
        x
        )
      
    
    {\displaystyle P(x)}
  
 holds", it can be expressed as a dependent type.  That is, the property is proven for the specific "
  
    
      
        x
      
    
    {\displaystyle x}
  
" and that is visible in the type of the result.  
There are many details to dependent typing.  They are too long and complicated for this introduction.  See the article on dependent typing and the lambda cube for more information.

Universes[edit]
Î -terms return a type.  So what is the type of their return value?  Well, there must be a type that contains types.  A type that contains other types is called a "universe".  It is often written with the symbol 
  
    
      
        U
      
    
    {\displaystyle U}
  
.  Sometimes there is a hierarchy of universes, with "
  
    
      
        
          U
          
            0
          
        
      
    
    {\displaystyle U_{0}}
  
Â : 
  
    
      
        
          U
          
            1
          
        
      
    
    {\displaystyle U_{1}}
  
", "
  
    
      
        
          U
          
            1
          
        
      
    
    {\displaystyle U_{1}}
  
Â : 
  
    
      
        
          U
          
            2
          
        
      
    
    {\displaystyle U_{2}}
  
", etc..
Universes are complicated.  If a universe contains itself, it can lead to paradoxes like Girard's Paradox.  The details of universes are too long and complicated for this introduction. 

Common "by Rule" Types and Terms[edit]
Type theories are defined by their rules of inference.  There are rules for a "functional core", described above, and rules that create types and terms.  Below is a non-exhaustive list of common types and their associated terms.
The list ends with "inductive types", which is a powerful technique that is able to construct all the other ones in the list.  The mathematical foundations used by the proof assistants "Coq" and "Lean" are based on the "Calculus for Inductive Constructions" which is the "Calculus of Constructions" (its "functional core") with inductive types.  

Empty Type[edit]
The empty type has no terms.  The type is usually written "
  
    
      
        â¥
      
    
    {\displaystyle \bot }
  
" or "
  
    
      
        
          0
        
      
    
    {\displaystyle \mathbb {0} }
  
".
It is used to show that something is uncomputable.  If for a type "A", you can create a function of type "A 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
", you know that "A" has no terms.  An example for the type "A" might be "there exists a number 
  
    
      
        x
      
    
    {\displaystyle x}
  
 such that both 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is even and 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is odd".  (See "Product Type" below for how the example "A" is constructed.)  When a type has no terms, we say it is "uninhabited".  

Unit Type[edit]
The unit type has exactly 1 canonical term.  The type is written "
  
    
      
        â¤
      
    
    {\displaystyle \top }
  
" or "
  
    
      
        
          1
        
      
    
    {\displaystyle \mathbb {1} }
  
" and the single canonical term is written "*".
The unit type is used to show that something exists or is computable.  If for a type "A", you can create a function of type "
  
    
      
        â¤
        â
      
    
    {\displaystyle \top \to }
  
 A", you know that "A" has one or more terms.  When a type has at least 1 term, we say it is "inhabited".

Boolean Type[edit]
The Boolean type has exactly 2 canonical terms.  The type is usually written "bool" or "
  
    
      
        
          B
        
      
    
    {\displaystyle \mathbb {B} }
  
" or "
  
    
      
        
          2
        
      
    
    {\displaystyle \mathbb {2} }
  
".  The canonical terms are usually "true" and "false".
The Boolean type is defined with an eliminator function "if" such that:

if true b c 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 b
if false b c 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 c
Product Type[edit]
The product type has terms that are ordered pairs.  For types "A" and "B", the product type is written "A 
  
    
      
        Ã
      
    
    {\displaystyle \times }
  
 B".  Canonical terms are created by the constructor function "pair".  The terms are "pair a b", where "a" is a term of type "A" and "b" is a term of type "B".  The product type is defined with eliminator functions "first" and "second" such that:

first (pair a b) 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 a
second (pair a b) 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 b
Besides ordered pairs, this type is used for the logical operator "and", because it holds an "A" and a "B".  It is also used for intersection, because it holds one of both types.
If a type theory has dependent typing, it has dependent pairs.  In a dependent pair, the second type depends on the value of the first term.  Thus, the type is written "
  
    
      
        Î£
      
    
    {\displaystyle \Sigma }
  
 a:A . B(a)" where "B" has type "A 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 U".  It is useful when showing existence of an "a" with property "B(a)".

Sum Type[edit]
The sum type is a "tagged union".  That is, for types "A" and "B", the type "A + B" holds either a term of type "A" or a term of type "B" and it knows which one it holds.  The type comes with the constructors "injectionLeft" and "injectionRight". The call "injectionLeft a" takes "aÂ : A" and returns a canonical term of type "A + B".  Similarly, injectionRight b" takes "bÂ : B" and returns a canonical term of type "A + B".  The type is defined with an eliminator function "match" such that for a type "C" and functions "fÂ : A 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 C" and "gÂ : B 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 C":

match (injectionLeft a) C f g 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 (f a)
match (injectionRight b) C f g 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 (g b)
The sum type is used for logical or and for union.

Natural Numbers[edit]
The natural numbers are usually implemented in the style of Peano Arithmetic.  There is a canonical term, "0Â : nat" for zero.  Canonical values larger than zero use the constructor function "SÂ : nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 nat".  Thus, "S 0" is one.  "S (S 0)" is two.  "S (S (S 0)))" is three.  Etc.  The decimal numbers are just notationally equal to those terms.

1Â : natÂ ::= S 0
2Â : natÂ ::= S (S 0)
3Â : natÂ ::= S (S (S 0))
...
The natural numbers defined with an eliminator function "R" that uses recursion to define a function for all nats.  It takes a function "PÂ : nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 U" which is the type of the function to define.  It also takes a term "PZÂ : P 0" which is the value at zero and a function "PSÂ : P n 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 P (S n)" which says how to transform the value at "n" into the value at "n + 1".  Thus, its computation rules are:

R P PZ PS 0 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 PZ
R P PZ PS (S 
  
    
      
        n
      
    
    {\displaystyle n}
  
) 
  
    
      
        â 
      
    
    {\displaystyle \twoheadrightarrow }
  
 PS (R P PZ PS 
  
    
      
        n
      
    
    {\displaystyle n}
  
)
The function "add", that was used earlier, can be defined using "R".

addÂ : nat
  
    
      
        â
      
    
    {\displaystyle \to }
  
nat
  
    
      
        â
      
    
    {\displaystyle \to }
  
natÂ ::= R (Î» n:nat . nat
  
    
      
        â
      
    
    {\displaystyle \to }
  
nat) (Î» n:nat . n) (Î» g:nat
  
    
      
        â
      
    
    {\displaystyle \to }
  
nat . (Î» m:nat . S (g m)))


Identity Type[edit]
The identity type is the third concept of equality in type theory.  The first is "notational equality", which is for definitions like "2Â : natÂ ::= (S (S 0))" that have no mathematical meaning but are useful to readers.  The second is "judgemental equality", which is when two terms compute to the same term, like "x + (1 + 4)" and "x + (4 + 1)", which both compute to "x + 5".  But type theory needs another form of equality, known as the "identity type" or "propositional equality".
The reason it needs the identity type is because some equal terms do not compute to the same term.  Assuming "xÂ : nat", the terms "x + 1" and "1 + x" do not compute to the same term.  Recall that "+" is a notation for the function "add", which is a notation for the function "R".  We cannot compute on "R" until the value for "x" is specified and, until it is specified, two different calls to "R" will not compute to the same term.
An identity type requires two terms "a" and "b" of the same type and is written "a = b".  So, for "x + 1" and "1 + x", the type would be "x+1 = 1+x".  Canonical terms are created with the constructor "reflexivity".  The call "reflexivity a" takes a term "a" and returns a canonical term of the type "a = a".  
Computation with the identity type is done with the eliminator function "J".  The function "J" lets a term dependent on "a", "b", and a term of type "a = b" to be rewritten so that "b" is replaced by "a".  While "J" is one directional, only able to substitute "b" with "a", it can be proven that the identity type is reflexive, symmetric and transitive.  
If the canonical terms are always "a=a" and "x+1" does not compute to the same term as "1+x", how do we create a term of "x+1 = 1+x"?   We use the "R" function.  (See "Natural Numbers" above.)  The "R" function's argument "P" is defined to be "(Î» x:nat . x+1 = 1+x)".  The other arguments act like the parts of an induction proof, where "PZÂ : P 0" becomes the base case "0+1 = 1+0" and "PSÂ : P n 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 P (S n)" becomes the inductive case.  Essentially, this says that when "x+1 = 1+x" has "x" replaced with a canonical value, the expression will be the same as "reflexivity (x+1)".  This application of the function "R" has type "xÂ : nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 x+1 = 1+x".  We can use it and the function "J" to substituted "1+x" for "x+1" in any term.  In this way, the identity type is able to capture equalities that are not possible with judgemental equality.  
To be clear, it is possible to create the type "0 = 1", but there will not be a way to create terms of that type.  Without a term of type "0 = 1", it will not be possible to use the function "J" to substitute "0" for "1" in another term.  
The complexities of equality in type theory make it an active research area, see homotopy type theory.

Inductive Types[edit]
Inductive types is a way to create a large variety of types.  In fact, all the types described above and more can be defined using the rules of inductive types.  Once the type's constructors are specified, the eliminator functions and computation is determined by structural recursion.
There are similar, more powerful ways to create types.  These include induction-recursion and induction-induction.  There is also a way to create similar types using only lambda terms, called Scott encoding.
(NOTE: Type theories do not usually include coinductive types.  They represent an infinite data type and most type theories limit themselves to functions that can be proven to halt.)

Differences from Set Theory[edit]
The traditional foundation for mathematics has been set theory paired with a logic.  The most common one cited is ZermeloâFraenkel set theory, known as "ZF" or, with the Axiom of choice, "ZFC".  Type theories differ from this foundation in a number of ways.

Set theory has both rules and axioms, while type theories only have rules.  Set theories are built on top of logic.  Thus, ZFC is defined by both the rules of first-order logic and its own axioms.  (An axiom is a logical statement accepted as true without a logical derivation.)  Type theories, in general, do not have axioms and are defined by their rules of inference.
Set theory and logic have the law of excluded middle.  That is, every theorem is true or false.  When a type theory defines the concepts of "and" and "or" as types, it leads to intuitionistic logic, which does not have the law of excluded middle.  However, the law can be proven for some types.
In set theory, an element is not restricted to one set.  The element can appear in subsets and unions with other sets.  In type theory, terms (generally) belong to only one type.  Where a subset would be used, type theory can use a predicate function or use a dependently-typed product type, where each element 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is paired with a proof that the subset's property holds for 
  
    
      
        x
      
    
    {\displaystyle x}
  
.  Where a union would be used, type theory uses the sum type, which contains new canonical terms.
Type theory has a built-in notion of computation.  Thus, "1+1" and "2" are different terms in type theory, but they compute to the same value.  Moreover, functions are defined computationally as lambda terms.  In set theory, "1+1=2" means that "1+1" is just another way to refer the value "2".  Type theory's computation does require a complicated concept of equality.
Set theory usually encodes numbers as sets.  (0 is the empty set, 1 is a set containing the empty set, etc.  See Set-theoretic definition of natural numbers.) Type theory can encode numbers as functions using Church encoding or more naturally as inductive types.  The constructors "0" and "S" created by the inductive type closely resemble Peano's axioms.
Set theory has set-builder notation.  It can create any set that can be defined.  This allows it to create Uncountable sets.  Type theories are syntactic, which limits them to a countably infinite terms.  Additionally, most type theories require computation to always halt and limit themselves to recursively generable terms.  As a result, most type theories do not use the Real numbers but the Computable numbers.
In set theory, the Axiom of Choice is an axiom and is controversial, particularly when applied to uncountable sets.  In type theory, the equivalent statement is a theorem (type) and is provable (inhabited by a term).
In type theory, proofs are mathematical objects.  The type "x+1 = 1+x" cannot be used unless there is a term of the type.  That term represents a proof that "x+1 = 1+x".  Thus, type theory opens up proofs to be studied as mathematical objects.
Proponents of type theory will also point out its connection to constructive mathematics through the BHK interpretation, its connected to logic by the CurryâHoward isomorphism, and its connections to Category theory.

Technical Details[edit]
A type theory is a mathematical logic.  It is a collection of rules of inference that result in judgements.  Most logics have judgements meaning "The term 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is true." or "The term 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is a well-formed formula."[3].  A type theory has additional judgements that define types and relate terms to types.

Terms[edit]
A term in logic is recursively defined as a constant symbol, variable, or a function application, where a term is applied to another term.  Some constant symbols will be "0" of the natural numbers, "true" of the Booleans, and functions like "S" and "if".  Thus some terms are "0", "(S 0)", "(S (S x))", and "if true 0 (S 0)".

Judgements[edit]
Most type theories have 4 judgements:

"
  
    
      
        T
      
    
    {\displaystyle T}
  
 is a type."
"
  
    
      
        t
      
    
    {\displaystyle t}
  
 is a term of type 
  
    
      
        T
      
    
    {\displaystyle T}
  
."
"Type 
  
    
      
        
          T
          
            1
          
        
      
    
    {\displaystyle T_{1}}
  
 is equal to type 
  
    
      
        
          T
          
            2
          
        
      
    
    {\displaystyle T_{2}}
  
."
"Terms 
  
    
      
        
          t
          
            1
          
        
      
    
    {\displaystyle t_{1}}
  
 and 
  
    
      
        
          t
          
            2
          
        
      
    
    {\displaystyle t_{2}}
  
 are both of type 
  
    
      
        T
      
    
    {\displaystyle T}
  
 and are equal."
The judgements can be made under an assumption.  Thus, we might say, "assuming 
  
    
      
        x
      
    
    {\displaystyle x}
  
 is a term of type "bool" and 
  
    
      
        y
      
    
    {\displaystyle y}
  
 is a term of type "nat" , (if x y y) is a term of type "nat"".  The mathematical notation for assumptions is a comma-separate list of "termÂ : type" that precede the turnstile symbol '
  
    
      
        â¢
      
    
    {\displaystyle \vdash }
  
'.  Thus, the example statement is formally written:

x:bool, y:nat 
  
    
      
        â¢
      
    
    {\displaystyle \vdash }
  
 (if x y y)Â : nat
If there are no assumptions, there will be nothing to the left of the turnstile.


  
    
      
        â¢
      
    
    {\displaystyle \vdash }
  
 SÂ : nat 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 nat
The list of assumptions is called the "context".  It is very common to see the symbol '
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
' used to represent some or all of the assumptions.  Thus, the formal notation for the 4 different judgements is usually:



Formal notation for judgements
Description



  
    
      
        Î
        â¢
        T
      
    
    {\displaystyle \Gamma \vdash T}
  
 Type

  
    
      
        T
      
    
    {\displaystyle T}
  
 is a type (under assumptions 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
).



  
    
      
        Î
        â¢
        t
        :
        T
      
    
    {\displaystyle \Gamma \vdash t:T}
  


  
    
      
        t
      
    
    {\displaystyle t}
  
 is a term of type 
  
    
      
        T
      
    
    {\displaystyle T}
  
 (under assumptions 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
).



  
    
      
        Î
        â¢
        
          T
          
            1
          
        
        =
        
          T
          
            2
          
        
      
    
    {\displaystyle \Gamma \vdash T_{1}=T_{2}}
  

Type 
  
    
      
        
          T
          
            1
          
        
      
    
    {\displaystyle T_{1}}
  
 is equal to type 
  
    
      
        
          T
          
            2
          
        
      
    
    {\displaystyle T_{2}}
  
 (under assumptions 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
).



  
    
      
        Î
        â¢
        
          t
          
            1
          
        
        =
        
          t
          
            2
          
        
        :
        T
      
    
    {\displaystyle \Gamma \vdash t_{1}=t_{2}:T}
  

Terms 
  
    
      
        
          t
          
            1
          
        
      
    
    {\displaystyle t_{1}}
  
 and 
  
    
      
        
          t
          
            2
          
        
      
    
    {\displaystyle t_{2}}
  
 are both of type 
  
    
      
        T
      
    
    {\displaystyle T}
  
 and are equal (under assumptions 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
).

(NOTE: The judgement of equality of terms is where the phrase "judgemental equality" comes from. )
The judgements enforce that every term has a type.  The type will restrict which rules can be applied to a term.

Rules[edit]
A type theory's rules say what judgements can be made, based on the existence of other judgements.  The rules are expressed using a horizontal line, with the required input judgements above the line and the resulting judgement below the line.  The rule for creating a lambda term is:

  
    
      
        
          
            
              
                Î
                ,
                a
                :
                A
                â¢
                b
                :
                B
              
            
            
              
                Î
                â¢
                (
                Î»
                a
                :
                A
                .
                b
                )
                :
                A
                â
                B
              
            
          
        
      
    
    {\displaystyle {\begin{array}{c}\Gamma ,a:A\vdash b:B\\\hline \Gamma \vdash (\lambda a:A.b):A\to B\\\end{array}}}
  

The judgements required to create the lambda term go above the line.  In this case, only one judgement is required.  It is that there is some term "b" of some type "B", assuming there is some term "a" of some type "A" and some other assumptions "
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
".  (Note: "
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
" "a", "A", "b", and "B" are all metavariables in the rule.)  The resulting judgement goes below the line.  This rule's resulting judgement states that the new lambda term has type "A 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 B" under the other assumptions 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
.  
The rules are syntactic and work by rewriting.  Thus, the metavariables like "
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
", "a", "A", etc. may actually consist of complex terms that contain many function applications, not just single symbols.  
To generate a particular judgement in type theory, there must be a rule to generate it.  Then, there must be rules to generate all of that rule's required inputs.  And then rules for all the inputs for those rules.  The applied rules form a proof tree.  This is usually drawn Gentzen-style,[4] where the target judgement (root) is at the bottom and rules that do not require any inputs (leaves) at the top.  (See Natural_deduction#Proofs_and_type_theory.) An example of a rule that does not require any inputs is one that states there is a term "0" of type "nat":

  
    
      
        
          
            
              
                
                  â¢
                  0
                  :
                  n
                  a
                  t
                
              
            
          
        
      
    
    {\displaystyle {\begin{array}{c}\hline \vdash 0:nat\\\end{array}}}
  

A type theory usually has a number of rules, including ones to:

create a context
add an assumption to the context ("weakening")
rearrange the assumptions
use an assumption to create a variable
define reflexivity, symmetry and transitivity for judgemental equality
define substitution for application of lambda terms
all the interactions of equality, substitution, etc.
define universes
Also, for each "by rule" type, there are 4 different kinds of rules

"type formation" rules say how to create the type
"term introduction" rules define the canonical terms and constructor functions, like "pair" and "S".
"term elimination" rules define the other functions like "first", "second", and "R".
"computation" rules specify how computation is performed with the type-specific functions.
Examples of rules:

Rules to Martin-LÃ¶f's Intuitionistic Type Theory
Appendix A.2 of Homotopy Type Theory book
Properties of Type Theories[edit]
Terms usually belong to a single type.  However, there are set theories that define "subtyping".
Computation takes place by repeated application of rules.  Many type theories are strongly normalizing, which means that any order of applying the rules will always end in the same result.  However, some are not.  In a normalizing type theory, the one-directional computation rules are called "reduction rules" and applying the rules "reduces" the term.  If a rule is not one-directional, it is called a "conversion rule".
Some combinations of types are equivalent to other combinations of types.  When functions are considered "exponentiation", the combinations of types can be written similar to algebraic identities.[5]  Thus, 
  
    
      
        
          
            0
          
        
        +
        A
        â
        A
      
    
    {\displaystyle {\mathbb {0} }+A\cong A}
  
, 
  
    
      
        
          
            1
          
        
        Ã
        A
        â
        A
      
    
    {\displaystyle {\mathbb {1} }\times A\cong A}
  
, 
  
    
      
        
          
            1
          
        
        +
        
          
            1
          
        
        â
        
          
            2
          
        
      
    
    {\displaystyle {\mathbb {1} }+{\mathbb {1} }\cong {\mathbb {2} }}
  
, 
  
    
      
        
          A
          
            B
            +
            C
          
        
        â
        
          A
          
            B
          
        
        Ã
        
          A
          
            C
          
        
      
    
    {\displaystyle A^{B+C}\cong A^{B}\times A^{C}}
  
, 
  
    
      
        
          A
          
            B
            Ã
            C
          
        
        â
        (
        
          A
          
            B
          
        
        
          )
          
            C
          
        
      
    
    {\displaystyle A^{B\times C}\cong (A^{B})^{C}}
  
.

Axioms[edit]
Most type theories do not have axioms.  This is because a type theory is defined by its rules of inference.  (See "Rules" above).  This is a source of confusion for people familiar with Set Theory, where a theory is defined by both the rules of inference for a logic (such as first-order logic) and axioms about sets.  
Sometimes, a type theory will add a few axioms.  An axiom is a judgement that is accepted without a derivation using the rules of inference.  They are often added to ensure properties that cannot be added cleanly through the rules.  
Axioms can cause problems if they introduce terms without a way to compute on those terms.  That is, axioms can interfere with the normalizing property of the type theory.[6]  
Some commonly encountered axioms are:

"Axiom K" ensures "uniqueness of identity proofs".  That is, that every term of an identity type is equal to reflexivity.[7]
"Univalence Axiom" holds that equivalence of types is equality of types.  The research into this property led to cubical type theory, where the property holds without needing an axiom.[8]
"Law of Excluded Middle" is often added to satisfy users who want classical logic, instead of intuitionistic logic.
The Axiom of Choice does not need to be added to type theory, because in most type theories it can be derived from the rules of inference.  This is because of the constructive nature of type theory, where proving that a value exists requires a method to compute the value.  The Axiom of Choice is less powerful in type theory than most set theories, because type theory's functions must be computable and, being syntax-driven, the number of terms in a type must be countable.  (See Axiom_of_choice#In_constructive_mathematics.) 

Decision Problems[edit]
A type theory is naturally associated with the decision problem of type inhabitation.[9]

Type Inhabitation[edit]
Main article: Type inhabitation
The decision problem of type inhabitation (abbreviated by 
  
    
      
        â
        e
        .
        Î
        â¢
        e
        :
        Ï
        ?
      
    
    {\displaystyle \exists e.\Gamma \vdash e:\tau ?}
  
) is: 

Given a type environment 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
 and a type 
  
    
      
        Ï
      
    
    {\displaystyle \tau }
  
, decide whether there exists a term 
  
    
      
        e
      
    
    {\displaystyle e}
  
 that can be assigned the type 
  
    
      
        Ï
      
    
    {\displaystyle \tau }
  
 in the type environment 
  
    
      
        Î
      
    
    {\displaystyle \Gamma }
  
.
Girard's paradox shows that type inhabitation is strongly related to the consistency of a type system with CurryâHoward correspondence. To be sound, such a system must have uninhabited types.
The opposition of terms and types can also be views as one of implementation and specification. By program synthesis (the computational counterpart of) type inhabitation (see below) can be used to construct (all or parts of) programs from specification given in form of type information.[10]

Type Inference[edit]
Main article: Type inference
Many programs that work with type theory (e.g., interactive theorem provers) also do type inferencing.  It lets them select the rules that the user intends, with fewer actions by the user.

Research Areas[edit]
Homotopy type theory differs from intuitionistic type theory mostly by its handling of the equality type.  Recently, there have been proposed "Cubical Type Theory", which is a homotopy type theory with normalization.

Interpretations of Type Theory[edit]
Type theory has connections to other areas of mathematics.  Proponents of type theory as a foundation often mention these connections as justification for its use.

Types are Propositions; Terms are Proofs[edit]
When used as a foundation, certain types are interpreted as propositions (statements that can be proven) and a term of the type is a proof of that proposition.  Thus, the type "Î  x:nat . x+1=1+x" represents that, for any "x" of type "nat", "x+1" and "1+x" are equal.  And a term of that type represents its proof.  

Curry-Howard Correspondence[edit]
The CurryâHoward correspondence is the observed similarity between logics and programming languages.  The implication in logic, "A 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 B" resembles a function from type "A" to type "B".  For a variety of logics, the rules are a similar to expression in a programming language's types.  The similarity goes farther, as applications of the rules resemble programs in the programming languages.  Thus, the correspondence is often summarized as "proofs as programs".
The logic operators "for all" and "exists" led Per Martin-LÃ¶f to invented dependent type theory.

Intuitionistic Logic[edit]
When some types are interpreted as propositions, there is a set of common types that can be used to connect them to make a logic out of types.  However, that logic is not classical logic but intuitionistic logic.  That is, it does not have the law of excluded middle nor double negation.
There is a natural relation of types to logical propositions.  If "A" is a type representing a proposition, being able to create a function of type "
  
    
      
        â¤
        â
      
    
    {\displaystyle \top \to }
  
 A" indicates that A has a proof and being able to create the function "A 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
" indicates that A does not have a proof.  That is, inhabitable types are proven and uninhabitable types are disproven.  
WARNING: This interpretation can lead to a lot of confusion.  A type theory may have terms "true" and "false" of type "bool", which act like a Boolean logic, and at the same time have types 
  
    
      
        â¤
      
    
    {\displaystyle \top }
  
 and 
  
    
      
        â¥
      
    
    {\displaystyle \bot }
  
 to represent "true" (provable) and "false" (disproven), as part of a intuitionistic logic for proposition.
Under this intuitionistic interpretation, there are common types that act as the logical operators:



Logic Name
Logic Notation
Type Notation
Type Name


True

  
    
      
        â¤
      
    
    {\displaystyle \top }
  


  
    
      
        â¤
      
    
    {\displaystyle \top }
  

Unit Type


False

  
    
      
        â¥
      
    
    {\displaystyle \bot }
  


  
    
      
        â¥
      
    
    {\displaystyle \bot }
  

Empty Type


Not

  
    
      
        Â¬
        A
      
    
    {\displaystyle \neg A}
  


  
    
      
        A
        â
        â¥
      
    
    {\displaystyle A\to \bot }
  

Function to Empty Type


Implication

  
    
      
        A
        â
        B
      
    
    {\displaystyle A\to B}
  


  
    
      
        A
        â
        B
      
    
    {\displaystyle A\to B}
  

Function


And

  
    
      
        A
        â§
        B
      
    
    {\displaystyle A\land B}
  


  
    
      
        A
        Ã
        B
      
    
    {\displaystyle A\times B}
  

Product Type


Or

  
    
      
        A
        â¨
        B
      
    
    {\displaystyle A\lor B}
  


  
    
      
        A
        +
        B
      
    
    {\displaystyle A+B}
  

Sum Type


For All

  
    
      
        â
        a
        â
        A
        ,
        P
        (
        a
        )
      
    
    {\displaystyle \forall a\in A,P(a)}
  

Î  aÂ : A . P(a)
Dependent Function


Exists

  
    
      
        â
        a
        â
        A
        ,
        P
        (
        a
        )
      
    
    {\displaystyle \exists a\in A,P(a)}
  

Î£ aÂ : A . P(a)
Dependent Product Type

But under this interpretation, there is no law of excluded middle.  That is, there is no term of type Î  A . A + (A 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
).
Likewise, there is no double negation.  There is no term of type Î  A . ((A 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
) 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
) 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 A.  (Note: Intuitionistic logic does allow 
  
    
      
        Â¬
        Â¬
        Â¬
        A
        â
        Â¬
        A
      
    
    {\displaystyle \lnot \lnot \lnot A\to \lnot A}
  
 and there is a term of type (((A 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
) 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
) 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
) 
  
    
      
        â
      
    
    {\displaystyle \to }
  
 (A 
  
    
      
        â
        â¥
      
    
    {\displaystyle \to \bot }
  
).)
Thus, the logic-of-types is an intuitionistic logic.  Type theory is often cited as an implementation of the BrouwerâHeytingâKolmogorov interpretation. 
It is possible to include the law of excluded middle and double negation into a type theory, by rule or assumption.  However, terms may not compute down to canonical terms and it will interfere with the ability to determine if two terms are judgementally equal to each other.

Constructive Mathematics[edit]
Per Martin-LÃ¶f proposed his Intuitionistic Type Theory as a foundation for constructive mathematics.  Constructive mathematics requires when proving "There exists an 
  
    
      
        x
      
    
    {\displaystyle x}
  
 with property P(
  
    
      
        x
      
    
    {\displaystyle x}
  
)", there must be a particular 
  
    
      
        x
      
    
    {\displaystyle x}
  
 and a proof that it has property "P".    In type theory, existence is accomplished using the dependent product type and, its proof, requires a term of that type.  For the term 
  
    
      
        t
      
    
    {\displaystyle t}
  
, "first 
  
    
      
        t
      
    
    {\displaystyle t}
  
" will produce the 
  
    
      
        x
      
    
    {\displaystyle x}
  
 and "second 
  
    
      
        t
      
    
    {\displaystyle t}
  
" will produce the proof of P(
  
    
      
        x
      
    
    {\displaystyle x}
  
).
An example of a non-constructive proof is a "proof by contradiction".  The first step is assuming that 
  
    
      
        x
      
    
    {\displaystyle x}
  
 does not exist and refuting it by contradiction.  The conclusion from that step is "it is not the case that 
  
    
      
        x
      
    
    {\displaystyle x}
  
 does not exist".  The last step is, by double negation, concluding that 
  
    
      
        x
      
    
    {\displaystyle x}
  
 exists.  To be clear, constructive mathematics still allows "refute by contradiction".  It can prove that "it is not the case that 
  
    
      
        x
      
    
    {\displaystyle x}
  
 does not exist".  But constructive mathematics does not allow the last step of removing the double negation to conclude that 
  
    
      
        x
      
    
    {\displaystyle x}
  
 exists.[11]
Constructive mathematics has often used intutionistic logic, as evidenced by the BrouwerâHeytingâKolmogorov interpretation. 
Most of the type theories proposed as foundations are constructive.  This includes most of the ones used by proof assistants.
It is possible to add non-constructive features to a type theory, by rule or assumption.  These include operators on continuations such as call with current continuation. However, these operators tend to break desirable properties such as canonicity and parametricity.  

Category theory[edit]
Although the initial motivation for category theory was far removed from foundationalism, the two fields turned out to have deep connections. As John Lane Bell writes: "In fact categories can themselves be viewed as type theories of a certain kind; this fact alone indicates that type theory is much more closely related to category theory than it is to set theory." In brief, a category can be viewed as a type theory by regarding its objects as types (or sorts), i.e. "Roughly speaking, a category may be thought of as a type theory shorn of its syntax." A number of significant results follow in this way:[12]

cartesian closed categories correspond to the typed Î»-calculus (Lambek, 1970);
C-monoids (categories with products and exponentials and one non-terminal object) correspond to the untyped Î»-calculus (observed independently by Lambek and Dana Scott around 1980);
locally cartesian closed categories correspond to Martin-LÃ¶f type theories (Seely, 1984).
The interplay, known as categorical logic, has been a subject of active research since then; see the monograph of Jacobs (1999) for instance.
Homotopy type theory attempts to combine type theory and category theory.  It focuses on equalities, especially equalities between types.

List of Type Theories[edit]
Major[edit]
Simply typed lambda calculus which is a higher-order logic
intuitionistic type theory
system F
LF is often used to define other type theories
calculus of constructions and its derivatives
Minor[edit]
Automath
ST type theory
UTT (Luo's Unified Theory of dependent Types)
some forms of combinatory logic
others defined in the lambda cube (also known as pure type systems)
others under the name typed lambda calculus
Active Research[edit]
Homotopy type theory explores equality of types
Cubical Type Theory is an implementation of homotopy type theory
Applications[edit]
Mathematical foundations[edit]
This section needs expansion. You can help by adding to it.  (May 2008)
The first computer proof assistant, called Automath, used type theory to encode mathematics on a computer. Martin-LÃ¶f specifically developed intuitionistic type theory to encode all mathematics to serve as a new foundation for mathematics. There is ongoing research into mathematical foundations using homotopy type theory.
Mathematicians working in category theory already had difficulty working with the widely accepted foundation of ZermeloâFraenkel set theory. This led to proposals such as Lawvere's Elementary Theory of the Category of Sets (ETCS).[13] Homotopy type theory continues in this line using type theory. Researchers are exploring connections between dependent types (especially the identity type) and algebraic topology (specifically homotopy).

Proof assistants[edit]
Main article: Proof assistant
Much of the current research into type theory is driven by proof checkers, interactive proof assistants, and automated theorem provers. Most of these systems use a type theory as the mathematical foundation for encoding proofs, which is not surprising, given the close connection between type theory and programming languages:

LF is used by Twelf, often to define other type theories;
many type theories which fall under higher-order logic are used by the HOL family of provers and PVS;
computational type theory is used by NuPRL;
calculus of constructions and its derivatives are used by Coq, Matita, and Lean;
UTT (Luo's Unified Theory of dependent Types) is used by Agda which is both a programming language and proof assistant
Many type theories are supported by LEGO and Isabelle. Isabelle also supports foundations besides type theories, such as ZFC. Mizar is an example of a proof system that only supports set theory.

Programming languages[edit]
Main article: Type system
There is extensive overlap and interaction between the fields of type theory and type systems. Type systems are a programming language feature designed to identify bugs. Any static program analysis, such as the type checking algorithms in the semantic analysis phase of compiler, has a connection to type theory.
A prime example is Agda, a programming language which uses UTT (Luo's Unified Theory of dependent Types) for its type system. The programming language ML was developed for manipulating type theories (see LCF) and its own type system was heavily influenced by them.

Linguistics[edit]
Type theory is also widely used in formal theories of semantics of natural languages, especially Montague grammar and its descendants. In particular, categorial grammars and pregroup grammars extensively use type constructors to define the types (noun, verb, etc.) of words.
The most common construction takes the basic types 
  
    
      
        e
      
    
    {\displaystyle e}
  
 and 
  
    
      
        t
      
    
    {\displaystyle t}
  
 for individuals and truth-values, respectively, and defines the set of types recursively as follows:

if 
  
    
      
        a
      
    
    {\displaystyle a}
  
 and 
  
    
      
        b
      
    
    {\displaystyle b}
  
 are types, then so is 
  
    
      
        â¨
        a
        ,
        b
        â©
      
    
    {\displaystyle \langle a,b\rangle }
  
;
nothing except the basic types, and what can be constructed from them by means of the previous clause are types.
A complex type 
  
    
      
        â¨
        a
        ,
        b
        â©
      
    
    {\displaystyle \langle a,b\rangle }
  
 is the type of functions from entities of type 
  
    
      
        a
      
    
    {\displaystyle a}
  
 to entities of type 
  
    
      
        b
      
    
    {\displaystyle b}
  
. Thus one has types like 
  
    
      
        â¨
        e
        ,
        t
        â©
      
    
    {\displaystyle \langle e,t\rangle }
  
 which are interpreted as elements of the set of functions from entities to truth-values, i.e. indicator functions of sets of entities. An expression of type 
  
    
      
        â¨
        â¨
        e
        ,
        t
        â©
        ,
        t
        â©
      
    
    {\displaystyle \langle \langle e,t\rangle ,t\rangle }
  
 is a function from sets of entities to truth-values, i.e. a (indicator function of a) set of sets. This latter type is standardly taken to be the type of natural language quantifiers, like  everybody or  nobody (Montague 1973, Barwise and Cooper 1981).

Social sciences[edit]
Gregory Bateson introduced a theory of logical types into the social sciences; his notions of double bind and logical levels are based on Russell's theory of types.

See also[edit]
Type system, which is a programming language feature to find/avoid bugs
Foundations of mathematics
External links[edit]
Introductory Material[edit]
Type Theory at nLab, which has articles on many topics.
Intuitionistic Type Theory article at the Stanford Encyclopedia of Philosophy
Lambda Calculus with Types book by Henk Barendregt
Intuitionistic Type Theory notes by Per Martin-LÃ¶f
Programming in Martin-LÃ¶f âs Type Theory book
Homotopy Type Theory book, which proposed homotopy type theory as a mathematical foundation.
Advanced Material[edit]
.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Robert L. Constable (ed.). "Computational type theory". Scholarpedia.
The TYPES Forum â moderated e-mail forum focusing on type theory in computer science, operating since 1987.
The Nuprl Book: "Introduction to Type Theory."
Types Project lecture notes of summer schools 2005â2008
The 2005 summer school has introductory lectures
Oregon Programming Languages Summer School, many lectures and some notes.
Summer 2013 lectures including Robert Harper's talks on YouTube
Summer 2015 Types, Logic, Semantics, and Verification
Andrej Bauer's blog
Further reading[edit]
.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}
Aarts, C.; Backhouse, R.; Hoogendijk, P.; Voermans, E.; van der Woude, J. (December 1992). "A Relational Theory of Datatypes". Technische Universiteit Eindhoven.
Andrews B., Peter (2002). An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof (2ndÂ ed.). Kluwer. ISBNÂ 978-1-4020-0763-7.
Jacobs, Bart (1999). Categorical Logic and Type Theory. Studies in Logic and the Foundations of Mathematics. Vol.Â 141. Elsevier. ISBNÂ 978-0-444-50170-7. Covers type theory in depth, including polymorphic and dependent type extensions. Gives categorical semantics.
Cardelli, Luca (1996). "Type Systems".  In Tucker, Allen B. (ed.). The Computer Science and Engineering Handbook. CRC Press. pp.Â 2208â36. ISBNÂ 9780849329098.
Collins, Jordan E. (2012). A History of the Theory of Types: Developments After the Second Edition of 'Principia Mathematica'. Lambert Academic Publishing. hdl:11375/12315. ISBNÂ 978-3-8473-2963-3. Provides a historical survey of the developments of the theory of types with a focus on the decline of the theory as a foundation of mathematics over the four decades following the publication of the second edition of 'Principia Mathematica'.
Constable, Robert L. (2012) [2002]. "NaÃ¯ve Computational Type Theory" (PDF).  In Schwichtenberg, H.; Steinbruggen, R. (eds.). Proof and System-Reliability. Nato Science Series II. Vol.Â 62. Springer. pp.Â 213â259. ISBNÂ 9789401004138. Intended as a type theory counterpart of Paul Halmos's (1960) NaÃ¯ve Set Theory
Coquand, Thierry (2018) [2006]. "Type Theory". Stanford Encyclopedia of Philosophy.
Thompson, Simon (1991). Type Theory and Functional Programming. AddisonâWesley. ISBNÂ 0-201-41667-0.
Hindley, J. Roger (2008) [1995]. Basic Simple Type Theory. Cambridge University Press. ISBNÂ 978-0-521-05422-5. A good introduction to simple type theory for computer scientists; the system described is not exactly Church's STT though. Book review
Kamareddine, Fairouz D.; Laan, Twan; Nederpelt, Rob P. (2004). A modern perspective on type theory: from its origins until today. Springer. ISBNÂ 1-4020-2334-0.
FerreirÃ³s, JosÃ©; DomÃ­nguez, JosÃ© FerreirÃ³s (2007). "X. Logic and Type Theory in the Interwar Period". Labyrinth of thought: a history of set theory and its role in modern mathematics (2ndÂ ed.). Springer. ISBNÂ 978-3-7643-8349-7.
Laan, T.D.L. (1997). The evolution of type theory in logic and mathematics (PDF) (PhD). Eindhoven University of Technology. doi:10.6100/IR498552. ISBNÂ 90-386-0531-5.

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ Stanford Encyclopedia of Philosophy (rev. Mon Oct 12, 2020) Russellâs Paradox 3. Early Responses to the Paradox

^ Church, Alonzo (1940). "A formulation of the simple theory of types". The Journal of Symbolic Logic. 5 (2): 56â68. doi:10.2307/2266170. JSTORÂ 2266170.

^ Bauer, Andrej. "What exactly is a judgement?". mathoverflow. Retrieved 29 December 2021.

^ Smith, Peter. "Types of proof system" (PDF). logicmatters.net. Retrieved 29 December 2021.

^ Milewski, Bartosz. "Programming with Math (Exploring Type Theory)". YouTube.

^ "Axioms and Computation". Theorem Proving in Lean. Retrieved 21 January 2022.

^ "Axiom K". nLab.

^ Cohen, Cyril; Coquand, Thierry; Huber, Simon; MÃ¶rtberg, Anders (2016). "Cubical Type Theory: a constructive interpretation of the univalence axiom" (PDF). 42nd  Conference on Very Important Topic. doi:10.4230/LIPIcs.CVIT.2016.23.

^ Henk Barendregt; Wil Dekkers; Richard Statman (20 June 2013). Lambda Calculus with Types. Cambridge University Press. p.Â 66. ISBNÂ 978-0-521-76614-2.

^ 
Heineman, George T.; Bessai, Jan; DÃ¼dder, Boris; Rehof, Jakob (2016). "A long and winding road towards modular synthesis". Leveraging Applications of Formal Methods, Verification and Validation: Foundational Techniques. ISoLA 2016. Lecture Notes in Computer Science. Vol.Â 9952. Springer. pp.Â 303â317. doi:10.1007/978-3-319-47166-2_21.

^ "proof by contradiction". nlab. Retrieved 29 December 2021.

^ Bell, John L. (2012). "Types, Sets and Categories" (PDF).  In Kanamory, Akihiro (ed.). Sets and Extensions in the Twentieth Century. Handbook of the History of Logic. Vol.Â 6. Elsevier. ISBNÂ 978-0-08-093066-4.

^ ETCS in nLab


.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}show.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware
Printed circuit board
Peripheral
Integrated circuit
Very Large Scale Integration
Systems on Chip (SoCs)
Energy consumption (Green computing)
Electronic design automation
Hardware acceleration
Computer systems organization
Computer architecture
Embedded system
Real-time computing
Dependability
Networks
Network architecture
Network protocol
Network components
Network scheduler
Network performance evaluation
Network service
Software organization
Interpreter
Middleware
Virtual machine
Operating system
Software quality
Software notations and tools
Programming paradigm
Programming language
Compiler
Domain-specific language
Modeling language
Software framework
Integrated development environment
Software configuration management
Software library
Software repository
Software development
Control variable
Software development process
Requirements analysis
Software design
Software construction
Software deployment
Software maintenance
Programming team
Open-source model
Theory of computation
Model of computation
Formal language
Automata theory
Computability theory
Computational complexity theory
Logic
Semantics
Algorithms
Algorithm design
Analysis of algorithms
Algorithmic efficiency
Randomized algorithm
Computational geometry
Mathematics of computing
Discrete mathematics
Probability
Statistics
Mathematical software
Information theory
Mathematical analysis
Numerical analysis
Theoretical computer science
Information systems
Database management system
Information storage systems
Enterprise information system
Social information systems
Geographic information system
Decision support system
Process control system
Multimedia information system
Data mining
Digital library
Computing platform
Digital marketing
World Wide Web
Information retrieval
Security
Cryptography
Formal methods
Security services
Intrusion detection system
Hardware security
Network security
Information security
Application security
Humanâcomputer interaction
Interaction design
Social computing
Ubiquitous computing
Visualization
Accessibility
Concurrency
Concurrent computing
Parallel computing
Distributed computing
Multithreading
Multiprocessing
Artificial intelligence
Natural language processing
Knowledge representation and reasoning
Computer vision
Automated planning and scheduling
Search methodology
Control method
Philosophy of artificial intelligence
Distributed artificial intelligence
Machine learning
Supervised learning
Unsupervised learning
Reinforcement learning
Multi-task learning
Cross-validation
Graphics
Animation
Rendering
Image manipulation
Graphics processing unit
Mixed reality
Virtual reality
Image compression
Solid modeling
Applied computing
E-commerce
Enterprise software
Computational mathematics
Computational physics
Computational chemistry
Computational biology
Computational social science
Computational engineering
Computational healthcare
Digital art
Electronic publishing
Cyberwarfare
Electronic voting
Video games
Word processing
Operations research
Educational technology
Document management

 Category
 Outline
WikiProject
 Commons

showvteMathematical logicGeneral
Axiom
First-order logic
Formal proof
Logical consequence
Formal semantics
Foundations of mathematics
Model
Set
Theorem
Theory
Type theory
TheoremsÂ (list)
GÃ¶del's completenessÂ andÂ incompleteness theorems
Tarski's undefinability
BanachâTarski paradox
Cantor'sÂ theorem,Â paradoxÂ andÂ diagonal argument
LindstrÃ¶m's
LÃ¶wenheimâSkolem
Compactness
LogicsTraditional
Classical logic
Proposition
Inference
Logical equivalence
Argument
Validity
Syllogism
Square of opposition
Venn diagram
Propositional
Boolean algebra
Boolean functions
Logical connectives
Propositional calculus
Propositional formula
Truth tables
Many-valued logic
Predicate
First-order
Quantifiers
Predicate
Second-order
Monadic predicate calculus
Set theory
Set
Element
Ordered pair
Ordinal number
Russell's paradox
Power set
Subset
Relation
Function/Map
Domain
Codomain
Image
Extensionality
Forcing
Cardinality
Empty set
Inhabited set
Enumeration
Countable set
Uncountable set
Finite set
Infinite set
Class
SchrÃ¶derâBernstein theorem
Set theories
ZermeloâFraenkel
Axiom of choice
Continuum hypothesis
General
KripkeâPlatek
MorseâKelley
Naive
TarskiâGrothendieck
Von NeumannâBernaysâGÃ¶del
SyntaxÂ &Â Language
Alphabet
Arity
Expression
Ground
Extension
Relation
Formal
Grammar
Language
Proof
System
Theory
Formation rule
Formula
Atomic
Open
Free/bound variable
Logical connective
Â¬
â¨
â§
â
â
=
Predicate
Functional
Variable
Propositional variable
Quantifier
â
â
Sentence
Atomic
Signature
String
Substitution
Symbol
Function
Logical/Constant
Non-logical
Variable
Term
Proof theory
Formal proof
Natural deduction
Logical consequence
Rule of inference
Sequent calculus
Theorem
Systems
Formal
Axiomatic
Deductive
Hilbert
Complete theory
IndependenceÂ (fromÂ ZFC)
Model theory
Interpretation
Model
Equivalence
Finite
Saturated
Substructure
Non-standard model
of arithmetic
Diagram
Elementary
Categorical theory
Model complete theory
Strength
Semantics of logic
Theories of truth
Semantic
Tarski's
Kripke's
T-schema
Transfer principle
Truth predicate
Truth value
Type
Ultraproduct
Validity
Computability theory
ChurchâTuring thesis
Computably enumerable
Computable function
Computable set
Decision problem
Halting problem
Primitive recursive function
Recursion
Recursive set

showvteFormal semantics (natural language)Central concepts
Compositionality
Denotation
Entailment
Extension
Generalized quantifier
Intension
Logical form
Presupposition
Proposition
Reference
Scope
Speech act
Syntaxâsemantics interface
Truth conditions
TopicsAreas
Anaphora
Ambiguity
Binding
Conditionals
Definiteness
Disjunction
Evidentiality
Focus
Indexicality
Lexical semantics
Modality
Negation
Propositional attitudes
Tenseâaspectâmood
Quantification
Vagueness
Phenomena
Antecedent-contained deletion
Cataphora
Coercion
Conservativity
Counterfactuals
Cumulativity
De dicto and de re
De se
Deontic modality
Discourse relations
Donkey anaphora
Epistemic modality
Faultless disagreement
Free choice inferences
Givenness
Crossover effects
Hurford disjunction
Inalienable possession
Intersective modification
Logophoricity
Mirativity
Modal subordination
Negative polarity items
Opaque contexts
Performatives
Privative adjectives
Quantificational variability effect
Responsive predicate
Rising declaratives
Scalar implicature
Sloppy identity
Subsective modification
Subtrigging
Telicity
Temperature paradox
Veridicality
FormalismFormal systems
Alternative semantics
Categorial grammar
Combinatory categorial grammar
Discourse representation theory
Dynamic semantics
Frame semantics
Generative grammar
Glue semantics
Inquisitive semantics
Intensional logic
Lambda calculus
Mereology
Montague grammar
Segmented discourse representation theory
Situation semantics
Supervaluationism
Type theory
TTR
Concepts
Autonomy of syntax
Context set
Continuation
Conversational scoreboard
Existential closure
Function application
Meaning postulate
Monads
Possible world
Quantifier raising
Quantization
Question under discussion
Squiggle operator
Strict conditional
Type shifter
Universal grinder
See also
Cognitive semantics
Computational semantics
Distributional semantics
Formal grammar
Inferentialism
Linguistics wars
Philosophy of language
Pragmatics
Context
Deixis
Semantics of logic





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Type_theory&oldid=1067336629"
		Categories: Type theorySystems of formal logicHierarchyHidden categories: Articles with short descriptionShort description is different from WikidataArticles to be expanded from May 2008All articles to be expandedArticles using small message boxesPages that use a deprecated format of the math tags
	
