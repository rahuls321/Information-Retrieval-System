
Title:
Comparison of programming paradigms
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)

      This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:Â "Comparison of programming paradigms"Â âÂ newsÂ Â· newspapersÂ Â· booksÂ Â· scholarÂ Â· JSTOR  (August 2015) (Learn how and when to remove this template message)
This section possibly contains original research. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed.  (August 2015) (Learn how and when to remove this template message)
    
 (Learn how and when to remove this template message)
.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Programming paradigms
Action
Agent-oriented
Array-oriented
Automata-based
Concurrent computing
Choreographic programming
Relativistic programming
Data-driven
Declarative (contrast: Imperative)
Functional
Functional logic
Purely functional
Logic
Abductive logic
Answer set
Concurrent logic
Functional logic
Inductive logic
Constraint
Constraint logic
Concurrent constraint logic
Dataflow
Flow-based
Reactive
Functional reactive
Ontology
Query language
Differentiable
Dynamic/scripting
Event-driven
Function-level (contrast: Value-level)
Point-free style
Concatenative
Generic
Imperative (contrast: Declarative)
Procedural
Object-oriented
Polymorphic
Intentional
Language-oriented
Domain-specific
Literate
Natural-language programming
Metaprogramming
Automatic
Inductive programming
Reflective
Attribute-oriented
Macro
Template
Non-structured (contrast: Structured)
Array
Nondeterministic
Parallel computing
Process-oriented
Probabilistic
Quantum
Set-theoretic
Stack-based
Structured (contrast: Non-structured)
Block-structured
Structured concurrency
Object-oriented
Actor-based
Class-based
Concurrent
Prototype-based
By separation of concerns:
Aspect-oriented
Role-oriented
Subject-oriented
Recursive
Symbolic
Value-level (contrast: Function-level)
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
This article attempts to set out the various similarities and differences between the various programming paradigms as a summary in both graphical and tabular format with links to the separate discussions concerning these similarities and differences in extant Wikipedia articles.

Contents

1 Main paradigm approaches
2 Differences in terminology
3 Language support
4 Performance comparison

4.1 Managed code
4.2 Pseudocode examples comparing various paradigms

4.2.1 Subroutine, method call overhead
4.2.2 Allocation of dynamic memory for message and object storage
4.2.3 Dynamically dispatched message calls v. direct procedure call overheads


4.3 Serializing objects
4.4 Parallel computing


5 See also
6 References
7 Further reading
8 External links



Main paradigm approaches[edit]
There are two main approaches to programming:

Imperative programmingÂ â focuses on how to execute, defines control flow as statements that change a program state.
Declarative programmingÂ â focuses on what to execute, defines program logic, but not detailed control flow.
The following are widely considered the main programming paradigms, as seen when measuring programming language popularity:

Procedural programming, structured programmingÂ â specifies the steps a program must take to reach a desired state.
Functional programmingÂ â treats programs as evaluating mathematical functions and avoids state and mutable data.
Object-oriented programming (OOP)Â â organizes programs as objects: data structures consisting of datafields and methods together with their interactions.
The following are common types of programming that can be implemented using different paradigms:

Event-driven programmingÂ â program control flow is determined by events, such as sensor inputs or user actions (mouse clicks, key presses) or messages from other programs or threads.
Automata-based programmingÂ â a program, or part, is treated as a model of a finite state machine or any other formal automaton.
Reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change.
The subroutines that implement OOP methods may be ultimately coded in an imperative, functional, or procedural style that may, or may not, directly alter state on behalf of the invoking program. There is some overlap between paradigms, inevitably, but the main features or identifiable differences are summarized in this table:




Paradigm

Description

Main traits

Related paradigm(s)

Critique

Examples


Imperative

Programs as statements that directly change computed state (datafields)

Direct assignments, common data structures, global variables



Edsger W. Dijkstra, Michael A. Jackson

C, C++, Java, Kotlin, PHP, Python, Ruby


Structured

A style of imperative programming with more logical program structure

Structograms, indentation, no or limited use of goto statements

Imperative



C, C++, Java, Kotlin, Pascal, PHP, Python


Procedural

Derived from structured programming, based on the concept of modular programming or the procedure call

Local variables, sequence, selection, iteration, and modularization

Structured, imperative



C, C++, Lisp, PHP, Python


Functional

Treats computation as the evaluation of mathematical functions avoiding state and mutable data

Lambda calculus, compositionality, formula, recursion, referential transparency, no side effects

Declarative



C++,[1] C#,[2][circular reference] Clojure, CoffeeScript,[3] Elixir, Erlang, F#, Haskell, Java (since version 8), Kotlin, Lisp, Python, R,[4] Ruby, Scala, SequenceL, Standard ML, JavaScript, Elm


Event-driven including time-driven

Control flow is determined mainly by events, such as mouse clicks or interrupts including timer

Main loop, event handlers, asynchronous processes

Procedural, dataflow



JavaScript, ActionScript, Visual Basic, Elm


Object-oriented

Treats datafields as objects manipulated through predefined methods only

Objects, methods, message passing, information hiding, data abstraction, encapsulation, polymorphism, inheritance, serialization-marshalling

Procedural

Wikipedia, others[5][6][7]

Common Lisp, C++, C#, Eiffel, Java, Kotlin, PHP, Python, Ruby, Scala, JavaScript[8][9]


Declarative

Defines program logic, but not detailed control flow

Fourth-generation languages, spreadsheets, report program generators





SQL, regular expressions, Prolog, OWL, SPARQL, Datalog, XSLT


Automata-based programming

Treats programs as a model of a finite state machine or any other formal automata

State enumeration, control variable, state changes, isomorphism, state transition table

Imperative, event-driven



Abstract State Machine Language

Differences in terminology[edit]
Despite multiple (types of) programming paradigms existing in parallel (with sometimes apparently conflicting definitions), many of the underlying fundamental components remain more or less the same (constants, variables, datafields, subroutines, calls etc.) and must somehow thus inevitably be incorporated into each separate paradigm with equally similar attributes or functions. The table above is not intended as a guide to precise similarities, but more of an index of where to look for more information, based on the different naming of these entities, within each paradigm. Further complicating matters are non-standardized implementations of each paradigm, in many programming languages, especially languages supporting multiple paradigms, each with its own jargon.

Language support[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Syntactic sugar
Syntactic sugar is the sweetening of program functionality by introducing language features that facilitate a given usage, even if the end result could be achieved without them. One example of syntactic sugar may arguably be the classes used in object-oriented programming languages. The imperative language C can support object-oriented programming via its facilities of function pointers, type casting, and structures. However, languages such as C++ aim to make object-oriented programming more convenient by introducing syntax specific to this coding style. Moreover, the specialized syntax works to emphasize the object-oriented approach. Similarly, functions and looping syntax in C (and other procedural and structured programming languages) could be considered syntactic sugar. Assembly language can support procedural or structured programming via its facilities for modifying register values and branching execution depending on program state. However, languages such as C introduced syntax specific to these coding styles to make procedural and structured programming more convenient. Features of the language C# (C Sharp), such as properties and interfaces, similarly enable no new functions, but are designed to make good programming practices more prominent and natural.
Some programmers feel that these features are unimportant or even frivolous. For example, Alan Perlis once quipped, in a reference to bracket-delimited languages, that "syntactic sugar causes cancer of the semicolon" (see Epigrams on Programming).
An extension of this is the syntactic saccharin, or gratuitous syntax that does not make programming easier.[10]

Performance comparison[edit]
In total instruction path length only, a program coded in an imperative style, using no subroutines, would have the lowest count. However, the binary size of such a program may be larger than the same program coded using subroutines (as in functional and procedural programming) and would reference more non-local physical instructions that may increase cache misses and instruction fetch overhead in modern processors.
The paradigms that use subroutines extensively (including functional, procedural, and object-oriented) and do not also use significant inline expansion (inlining, via compiler optimizations) will, consequently, use a larger fraction of total resources on the subroutine linkages. Object-oriented programs that do not deliberately alter program state directly, instead using mutator methods (or setters) to encapsulate these state changes, will, as a direct consequence, have more overhead. This is because message passing is essentially a subroutine call, but with three added overheads: dynamic memory allocation, parameter copying, and dynamic dispatch. Obtaining memory from the heap and copying parameters for message passing may involve significant resources that far exceed those needed for the state change. Accessors (or getters) that merely return the values of private member variables also depend on similar message passing subroutines, instead of using a more direct assignment (or comparison), adding to total path length.

Managed code[edit]
For programs executing in a managed code environment, such as the .NET Framework, many issues affect performance that are significantly affected by the programming language paradigm and various language features used.[11]

Pseudocode examples comparing various paradigms[edit]
A pseudocode comparison of imperative, procedural, and object oriented approaches used to calculate the area of a circle (ÏrÂ²), assuming no subroutine inlining, no macro preprocessors, register arithmetic, and weighting each instruction 'step' as only 1 instruction â as a crude measure of instruction path length â is presented below. The instruction step that is conceptually performing the state change is highlighted in bold typeface in each case. The arithmetic operations used to compute the area of the circle are the same in all three paradigms, with the difference being that the procedural and object-oriented paradigms wrap those operations in a subroutine call that makes the computation general and reusable. The same effect could be achieved in a purely imperative program using a macro preprocessor at only the cost of increased program size (only at each macro invocation site) without a corresponding pro rata runtime cost (proportional to n invocations â that may be situated within an inner loop for instance). Conversely, subroutine inlining by a compiler could reduce procedural programs to something similar in size to the purely imperative code. However, for object-oriented programs, even with inlining, messages still must be built (from copies of the arguments) for processing by the object-oriented methods. The overhead of calls, virtual or otherwise, is not dominated by the control flow alteration â but by the surrounding calling convention costs, like prologue and epilogue code, stack setup and argument passing[12] (see here[13] for more realistic instruction path length, stack and other costs associated with calls on an x86 platform). See also here[14] for a slide presentation by Eric S. Roberts ("The Allocation of Memory to Variables", chapter 7)[15] â illustrating the use of stack and heap memory use when summing three rational numbers in the Java object-oriented language.



Imperative

Procedural

Object-oriented



 load r;                      1
 r2 = r * r;                  2
 result = r2 * "3.142";       3
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.... storage .............
result variable
constant "3.142"



area proc(r2,res):
   push stack                                 5
   load r2;                                   6
   r3 = r2 * r2;                              7
   res = r3 * "3.142";                        8
   pop stack                                  9
   return;                                   10
...............................................
main proc:
   load r;                                    1
   call area(r,result);
    +load p = address of parameter list;      2
    +load v = address of subroutine 'area';   3
    +goto v with return;                      4
.
.
.
.
.... storage .............
result variable
constant "3.142"
parameter list variable
function pointer (==>area)
stack storage



circle.area method(r2):
   push stack                                 7
   load r2;                                   8
   r3 = r2 * r2;                              9
   res = r3 * "3.142";                       10
   pop stack                                 11
   return(res);                           12,13
...............................................
main proc:
   load r;                                    1
   result = circle.area(r);
      +allocate heap storage;                 2[See 1]
      +copy r to message;                     3
      +load p = address of message;           4
      +load v = addr. of method 'circle.area' 5
      +goto v with return;                    6
.
.
.... storage .............
result variable (assumed pre-allocated)
immutable variable "3.142" (final)
(heap) message variable for circle method call
vtable(==>area)
stack storage



^ See section: Allocation of dynamic memory for message and object storage


The advantages of procedural abstraction and object-oriented-style polymorphism are poorly illustrated by a small example like the one above. This example is designed mainly to illustrate some intrinsic performance differences, not abstraction or code re-use.

Subroutine, method call overhead[edit]
The presence of a (called) subroutine in a program contributes nothing extra to the functionality of the program regardless of paradigm, but may contribute greatly to the structuring and generality of the program, making it much easier to write, modify, and extend.[16] The extent to which different paradigms use subroutines (and their consequent memory requirements) influences the overall performance of the complete algorithm, although as Guy Steele pointed out in a 1977 paper, a well-designed programming language implementation can have very low overheads for procedural abstraction (but laments, in most implementations, that they seldom achieve this in practice - being "rather thoughtless or careless in this regard"). In the same paper, Steele also makes a considered case for automata-based programming (using procedure calls with tail recursion) and concludes that "we should have a healthy respect for procedure calls" (because they are powerful) but suggested "use them sparingly"[16]
In the frequency of subroutine calls:

For procedural programming, the granularity of the code is largely determined by the number of discrete procedures or modules.
For functional programming, frequent calls to library subroutines are common,[citation needed] but may be often inlined by the optimizing compiler
For object-oriented programming, the number of method calls invoked is also partly determined by the granularity of the data structures and may thus include many read-only accesses to low level objects that are encapsulated, and thus accessible in no other, more direct, way. Since increased granularity is a prerequisite for greater code reuse, the tendency is toward fine-grained data structures, and a corresponding increase in the number of discrete objects (and their methods) and, consequently, subroutine calls. The creation of god objects is actively discouraged. Constructors also add to the count as they are also subroutine calls (unless they are inlined). Performance problems caused by excessive granularity may not become apparent until scalability becomes an issue.
For other paradigms, where a mix of the above paradigms may be employed, subroutine use is less predictable.
Allocation of dynamic memory for message and object storage[edit]
Uniquely, the object-oriented paradigm involves dynamic memory allocation from heap storage for both object creation and message passing. A 1994 benchmark - "Memory Allocation Costs in Large C and C++ Programs" conducted by Digital Equipment Corporation on a variety of software, using an instruction-level profiling tool, measured how many instructions were required per dynamic storage allocation. The results showed that the lowest absolute number of instructions executed averaged around 50 but others reached as high as 611.[17] See also "Heap:Pleasures and pains" by Murali R. Krishnan[18] that states "Heap implementations tend to stay general for all platforms, and hence have heavy overhead". The 1996 IBM paper "Scalability of Dynamic Storage Allocation Algorithms" by Arun Iyengar of IBM [19] demonstrates various dynamic storage algorithms and their respective instruction counts. Even the recommended MFLF I algorithm (H.S. Stone, RC 9674) shows instruction counts in a range between 200 and 400. The above pseudocode example does not include a realistic estimate of this memory allocation pathlength or the memory prefix overheads involved and the subsequent associated garbage collection overheads. Suggesting strongly that heap allocation is a nontrivial task, one open-source software microallocator, by game developer John W. Ratcliff, consists of nearly 1,000 lines of code.[20]

Dynamically dispatched message calls v. direct procedure call overheads[edit]
In their Abstract "Optimization of Object-Oriented Programs Using Static Class Hierarchy Analysis",[21] Jeffrey Dean, David Grove, and Craig Chambers of the Department of Computer Science and Engineering, at the University of Washington, claim that "Heavy use of inheritance and dynamically-bound messages is likely to make code more extensible and reusable, but it also imposes a significant performance overhead, relative to an equivalent but non-extensible program written in a non-object-oriented manner. In some domains, such as structured graphics packages, the performance cost of the extra flexibility provided by using a heavily object-oriented style is acceptable. However, in other domains, such as basic data structure libraries, numerical computing packages, rendering libraries, and trace-driven simulation frameworks, the cost of message passing can be too great, forcing the programmer to avoid object-oriented programming in the âhot spotsâ of their application."

Serializing objects[edit]
Main article: Serialization
Serialization imposes large overheads when passing objects from one system to another, especially when the transfer is in human-readable formats such as Extensible Markup Language (XML) and JavaScript Object Notation (JSON). This contrasts with compact binary formats for non-object-oriented data. Both encoding and decoding of the object's data value and its attributes are involved in the serializing process, which also includes awareness of complex issues such as inheriting, encapsulating, and data hiding.

Parallel computing[edit]
Main article: Parallel computing
Carnegie-Mellon University Professor Robert Harper in March 2011 wrote: "This semester Dan Licata and I are co-teaching a new course on functional programming for first-year prospective CS majors... Object-oriented programming is eliminated entirely from the introductory curriculum, because it is both anti-modular and anti-parallel by its very nature, and hence unsuitable for a modern CS curriculum. A proposed new course on object-oriented design methodology will be offered at the sophomore level for those students who wish to study this topic."[22]

See also[edit]
Comparison of programming languages
Comparison of programming languages (basic instructions)
Granularity#Computing
Message passing
Subroutine
References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"Archived copy" (PDF). Archived from the original (PDF) on 2017-02-02. Retrieved 2015-12-18.{{cite web}}:  CS1 maint: archived copy as title (link)

^ "Functional programming C#". August 2020. Retrieved 2015-08-14.

^ Ruiz, Cedric (May 2014). "Functional CoffeeScript for the impatient". Blog de Cedric Ruiz. Cedric Ruiz. Retrieved 2015-08-09.

^ "Functional programming Â· Advanced R".

^ Shelly, Asaf (2008-08-22). "Flaws of Object-oriented Modeling". Intel Software Network. Retrieved 2010-07-04.

^ Yegge, Steve (2006-03-30). "Execution in the Kingdom of Nouns". steve-yegge.blogspot.com. Retrieved 2010-07-03.

^ "Data-Oriented Design (Or Why You Might be Shooting Yourself in the Foot with OOP) â Games from within".

^ Crockford, Douglas. "JavaScript: The World's Most Misunderstood Programming Language". crockford.com.

^ Crockford, Douglas. "Private Members in JavaScript". crockford.com.

^ "The Jargon File v4.4.7: "syntactic sugar"".

^ Gray, Jan (June 2003). "Writing Faster Managed Code: Know What Things Cost". MSDN. Microsoft.

^ "The True Cost of Calls". wordpress.com. 2008-12-30.

^ "X86 Disassembly/Functions and Stack Frames - Wikibooks, open books for an open world".

^ Roberts, Eric S. (2008). "Art and Science of Java; Chapter 7: Objects and Memory". Stanford University. Archived from the original on 2011-06-06. Retrieved 2010-05-17.

^ Roberts, Eric S. (2008). Art and Science of Java. Addison-Wesley. ISBNÂ 978-0-321-48612-7. Archived from the original on 2011-06-06. Retrieved 2010-05-17.

^ Jump up to: a b Guy Lewis Steele, Jr. "Debunking the 'Expensive Procedure Call' Myth, or, Procedure Call Implementations Considered Harmful, or, Lambda: The Ultimate GOTO". MIT AI Lab. AI Lab Memo AIM-443. October 1977. [1] Archived 2009-12-29 at the Wayback Machine[2][3]

^ Detlefs, David; Dosser, Al; Zorn, Benjamin (June 1994). "Memory Allocation Costs in Large C and C++ Programs; Page 532". Software: Practice and Experience. 24 (6): 527â542. CiteSeerXÂ 10.1.1.30.3073. doi:10.1002/spe.4380240602. S2CIDÂ 14214110.

^ Krishnan, Murali R. (February 1999). "Heap: Pleasures and pains". microsoft.com.

^ "Scalability of Dynamic Storage Allocation Algorithms". 1996. CiteSeerXÂ 10.1.1.3.3759. {{cite journal}}: Cite journal requires |journal= (help)

^ "MicroAllocator.h". Google Code. Retrieved 2012-01-29.

^ Dean, Jeffrey; Grove, David; Chambers, Craig (1995). "Optimization of Object-Oriented Programs Using Static Class Hierarchy Analysis". Object-Oriented Programming. Lecture Notes in Computer Science. Vol.Â 952. University of Washington. pp.Â 77â101. CiteSeerXÂ 10.1.1.117.2420. doi:10.1007/3-540-49538-X_5. ISBNÂ 978-3-540-60160-9.

^ Teaching FP to Freshmen, from Harper's blog about teaching introductory computer science.[4]


Further reading[edit]
"A Memory Allocator" by Doug Lea
"Dynamic Memory Allocation and Linked Data Structures" by (Scottish Qualifications Authority)
"Inside A Storage Allocator" by Dr. Newcomer Ph.D
External links[edit]
Comparing Programming Paradigms by Dr Rachel Harrison and Mr Lins Samaraweera
Comparing Programming Paradigms: an Evaluation of Functional and Object-Oriented Programs by Harrison, R., Samaraweera, L. G., Dobie, M. R. and Lewis, P. H. (1996) pp.Â 247â254. ISSN 0268-6961
"The principal programming paradigms" By Peter Van Roy
"Concepts, Techniques, and Models of Computer Programming" (2004) by Peter Van Roy & Seif Haridi, ISBNÂ 0-262-22069-5
The True Cost of Calls- from "Harder, Better, Faster, Stronger" blog by computer scientist Steven Pigeon




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Comparison_of_programming_paradigms&oldid=1064705073"
		Categories: Programming paradigmsHidden categories: CS1 maint: archived copy as titleWebarchive template wayback linksCS1 errors: missing periodicalArticles needing additional references from August 2015All articles needing additional referencesArticles that may contain original research from August 2015All articles that may contain original researchArticles with multiple maintenance issuesAll articles lacking reliable referencesArticles lacking reliable references from October 2020All articles with unsourced statementsArticles with unsourced statements from March 2010Articles with example pseudocode
	
