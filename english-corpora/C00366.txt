
Title:
Memory management
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Computer memory management methodology
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}"Memory allocation" redirects here. For memory allocation in the brain, see Neuronal memory allocation.
This article is about memory management in an address space. For management of physical memory, see Memory management (operating systems).
This article includes a list of general references, but it remains largely unverified because it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations.  (April 2014) (Learn how and when to remove this template message)
.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Operating systems
Common features
Process management
Interrupts
Memory management
File system
Device drivers
Networking
Security
I/O
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
Memory management is a form of resource management applied to computer memory. The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed. This is critical to any advanced computer system where more than a single process might be underway at any time.[1]
Several methods have been devised that increase the effectiveness of memory management. Virtual memory systems separate the memory addresses used by a process from actual physical addresses, allowing separation of processes and increasing the size of the virtual address space beyond the available amount of RAM using paging or swapping to secondary storage. The quality of the virtual memory manager can have an extensive effect on overall system performance.
In some operating systems, e.g. OS/360 and successors,[2] memory is managed by the operating system.[note 1] In other operating systems, e.g. Unix-like operating systems, memory is managed at the application level.
Memory management within an address space is generally categorized as either manual memory management or automatic memory management.

Contents

1 Manual memory management

1.1 Efficiency
1.2 Implementations

1.2.1 Fixed-size blocks allocation
1.2.2 Buddy blocks
1.2.3 Slab allocation
1.2.4 Stack allocation




2 Automatic memory management

2.1 Garbage collection


3 Systems with virtual memory
4 Memory management in OS/360 and successors
5 See also
6 Notes
7 References
8 Further reading
9 External links



 Manual memory management[edit]
  An example of external fragmentation
Main article: Manual memory management
The task of fulfilling an allocation request consists of locating a block of unused memory of sufficient size. Memory requests are satisfied by allocating portions from a large pool[note 2] of memory called the heap or free store.[note 3] At any given time, some parts of the heap are in use, while some are "free" (unused) and thus available for future allocations.
Several issues complicate the implementation, such as external fragmentation, which arises when there are many small gaps between allocated memory blocks, which invalidates their use for an allocation request. The allocator's metadata can also inflate the size of (individually) small allocations. This is often managed by chunking. The memory management system must track outstanding allocations to ensure that they do not overlap and that no memory is ever "lost" (i.e. that there are no "memory leaks").

Efficiency[edit]
The specific dynamic memory allocation algorithm implemented can impact performance significantly. A study conducted in 1994 by Digital Equipment Corporation illustrates the overheads involved for a variety of allocators. The lowest average instruction path length required to allocate a single memory slot was 52 (as measured with an instruction level profiler on a variety of software).[1]

Implementations[edit]
Since the precise location of the allocation is not known in advance, the memory is accessed indirectly, usually through a pointer reference. The specific algorithm used to organize the memory area and allocate and deallocate chunks is interlinked with the kernel, and may use any of the following methods:

Fixed-size blocks allocation[edit]
Main article: Memory pool
Fixed-size blocks allocation, also called memory pool allocation, uses a free list of fixed-size blocks of memory (often all of the same size). This works well for simple embedded systems where no large objects need to be allocated, but suffers from fragmentation, especially with long memory addresses. However, due to the significantly reduced overhead this method can substantially improve performance for objects that need frequent allocation / de-allocation and is often used in video games.

Buddy blocks[edit]
Further information: Buddy memory allocation
In this system, memory is allocated into several pools of memory instead of just one, where each pool represents blocks of memory of a certain power of two in size, or blocks of some other convenient size progression. All blocks of a particular size are kept in a sorted linked list or tree and all new blocks that are formed during allocation are added to their respective memory pools for later use. If a smaller size is requested than is available, the smallest available size is selected and split. One of the resulting parts is selected, and the process repeats until the request is complete. When a block is allocated, the allocator will start with the smallest sufficiently large block to avoid needlessly breaking blocks. When a block is freed, it is compared to its buddy. If they are both free, they are combined and placed in the correspondingly larger-sized buddy-block list.

Slab allocation[edit]
Main article: Slab allocation
This memory allocation mechanism preallocates memory chunks suitable to fit objects of a certain type or size.[3] These chunks are called caches and the allocator only has to keep track of a list of free cache slots. Constructing an object will use any one of the free cache slots and destructing an object will add a slot back to the free cache slot list. This technique alleviates memory fragmentation and is efficient as there is no need to search for a suitable portion of memory, as any open slot will suffice.

Stack allocation[edit]
Main article: Stack-based memory allocation
Many Unix-like systems as well as Microsoft Windows implement a function called alloca for dynamically allocating stack memory in a way similar to the heap-based malloc. A compiler typically translates it to inlined instructions manipulating the stack pointer.[4] Although there is no need of manually freeing memory allocated this way as it is automatically freed when the function that called alloca returns, there exists a risk of overflow. And since alloca is an ad hoc expansion seen in many systems but never in POSIX or the C standard, its behavior in case of a stack overflow is undefined.
A safer version of alloca called _malloca, which reports errors, exists on Microsoft Windows. It requires the use of _freea.[5] gnulib provides an equivalent interface, albeit instead of throwing an SEH exception on overflow, it delegates to malloc when an overlarge size is detected.[6] A similar feature can be emulated using manual accounting and size-checking, such as in the uses of alloca_account in glibc.[7]

Automatic memory management[edit]
See also: Automatic variable and Call stack
In many programming language implementations, the runtime environment for the program automatically allocates memory in the call stack for non-static local variables of a subroutine, called automatic variables, when the subroutine is called, and automatically releases that memory when the subroutine is exited. Special declarations may allow local variables to retain values between invocations of the procedure, or may allow local variables to be accessed by other subroutines. The automatic allocation of local variables makes recursion possible, to a depth limited by available memory.

Garbage collection[edit]
Main article: Garbage collection (computer science)
Garbage collection is a strategy for automatically detecting memory allocated to objects that are no longer usable in a program, and returning that allocated memory to a pool of free memory locations. This method is in contrast to "manual" memory management where a programmer explicitly codes memory requests and memory releases in the program. While automatic garbage collection has the advantages of reducing programmer workload and preventing certain kinds of memory allocation bugs, garbage collection does require memory resources of its own, and can compete with the application program for processor time.

Systems with virtual memory[edit]
Main articles: Memory protection and Shared memory (interprocess communication)
Virtual memory is a method of decoupling the memory organization from the physical hardware. The applications operate on memory via virtual addresses. Each attempt by the application to access a particular virtual memory address results in the virtual memory address being translated to an actual physical address.[8]  In this way the addition of virtual memory enables granular control over memory systems and methods of access.
In virtual memory systems the operating system limits how a process can access the memory. This feature, called memory protection, can be used to disallow a process to read or write to memory that is not allocated to it, preventing malicious or malfunctioning code in one program from interfering with the operation of another.
Even though the memory allocated for specific processes is normally isolated, processes sometimes need to be able to share information. Shared memory is one of the fastest techniques for inter-process communication.
Memory is usually classified by access rate into primary storage and secondary storage. Memory management systems, among other operations, also handle the moving of information between these two levels of memory.

Memory management in OS/360 and successors[edit]
IBM System/360 does not support virtual memory.[note 4] Memory isolation of jobs is optionally accomplished using protection keys, assigning storage for each job a different key, 0 for the supervisor or 1â15. Memory management in OS/360 is a supervisor function. Storage is requested using the GETMAIN macro and freed using the FREEMAIN macro, which result in a call to the supervisor (SVC) to perform the operation.
In OS/360 the details vary depending on how the system is generated, e.g., for PCP, MFT, MVT.
In OS/360 MVT, suballocation within a job's region or the shared System Queue Area (SQA) is based on subpools, areas a multiple of 2Â KB in sizeâthe size of an area protected by a protection key. Subpools are numbered 0â255.[9] Within a region subpools are assigned either the job's storage protection or the supervisor's key, key 0. Subpools 0â127 receive the job's key. Initially only subpool zero is created, and all user storage requests are satisfied from subpool 0, unless another is specified in the memory request. Subpools 250â255 are created by memory requests by the supervisor on behalf of the job. Most of these are assigned key 0, although a few get the key of the job. Subpool numbers are also relevant in MFT, although the details are much simpler.[10]  MFT uses fixed partitions redefinable by the operator instead of dynamic regions and PCP has only a single partition.
Each subpool is mapped by a list of control blocks identifying allocated and free memory blocks within the subpool. Memory is allocated by finding a free area of sufficient size, or by allocating additional blocks in the subpool, up to the region size of the job. It is possible to free all or part of an allocated memory area.[11]
The details for OS/VS1 are similar[12]  to those for MFT and for MVT; the details for OS/VS2 are similar to those for MVT, except that the page size is 4 KiB. For both OS/VS1 and OS/VS2 the shared System Queue Area (SQA) is nonpageable.
In MVS the address space includes an additional pageable shared area, the Common Storage Area (CSA), and an additional private area, the System Work area (SWA). Also, the storage keys 0-7 are all reserved for use by privileged code.

See also[edit]
Dynamic array
Garbage collection (computer science)
Out of memory
Region-based memory management
Notes[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ However, the run-time environment for a language processor may subdivide the memory dynically acquired from the operating system, e.g., to implement a stack.

^ In some operating systems, e.g., OS/360, the free storage may be subdivided in various ways, e.g., subpools in OS/360, below the line, above the line and above the bar in z/OS.

^ Not to be confused with the unrelated heap data structure.

^ Except on the Model 67


References[edit]


^ Jump up to: a b .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Detlefs, D.; Dosser, A.; Zorn, B. (June 1994). "Memory allocation costs in large C and C++ programs" (PDF). Software: Practice and Experience. 24 (6): 527â542. CiteSeerXÂ 10.1.1.30.3073. doi:10.1002/spe.4380240602. S2CIDÂ 14214110.

^ "Main Storage Allocation" (PDF). IBM Operating System/360 Concepts and Facilities (PDF). Systems Reference Library (FirstÂ ed.). IBM Corporation. 1965. p.Â 74. Retrieved Apr 3, 2019.

^ Silberschatz, Abraham; Galvin, Peter B. (2004). Operating system concepts. Wiley. ISBNÂ 0-471-69466-5.

^ alloca(3)Â âÂ Linux Programmer's Manual â Library Functions

^ "_malloca". Microsoft CRT Documentation.

^ "gnulib/malloca.h". GitHub. Retrieved 24 November 2019.

^ "glibc/include/alloca.h". Beren Minor's Mirrors. 23 November 2019.

^ Tanenbaum, Andrew S. (1992). Modern Operating Systems. Englewood Cliffs, N.J.: Prentice-Hall. p.Â 90. ISBNÂ 0-13-588187-0.

^ OS360Sup, pp.Â 82-85.

^ OS360Sup, pp.Â 82.

^ IBM Corporation (May 1973). Program Logic: IBM System/360 Operating System MVT Supervisor (PDF). pp.Â 107â137. Retrieved Apr 3, 2019.

^ OSVS1Dig, pp.Â 2.37-2.39, VS1 Storage Subpools. sfn error: no target: CITEREFOSVS1Dig (help)


OS360Sup
OS Release 21 IBM System/360 Operating System Supervisor Services and Macro Instructions (PDF). Systems Reference Library (EighthÂ ed.). IBM. September 1974. GC28-6646-7.
OSVS1Dig
OS/VS1 Programmer's Reference Digest Release 6 (PDF). Systems (SixthÂ ed.). IBM. November 1975. GC24-5091-5.
Further reading[edit]
Donald Knuth. Fundamental Algorithms, Third Edition. Addison-Wesley, 1997. ISBNÂ 0-201-89683-4. Section 2.5: Dynamic Storage Allocation, pp.Â 435â456.
Simple Memory Allocation AlgorithmsArchived 5 March 2016 at the Wayback Machine (originally published on OSDEV Community)
Wilson, P. R.; Johnstone, M. S.; Neely, M.; Boles, D. (1995). "Dynamic storage allocation: A survey and critical review". Memory Management. Lecture Notes in Computer Science. Vol.Â 986. pp.Â 1â116. CiteSeerXÂ 10.1.1.47.275. doi:10.1007/3-540-60368-9_19. ISBNÂ 978-3-540-60368-9.
Berger, E. D.; Zorn, B. G.; McKinley, K. S. (June 2001). "Composing High-Performance Memory Allocators" (PDF). Proceedings of the ACM SIGPLAN 2001 conference on Programming language design and implementation. PLDI '01. pp.Â 114â124. CiteSeerXÂ 10.1.1.1.2112. doi:10.1145/378795.378821. ISBNÂ 1-58113-414-2. S2CIDÂ 7501376.
Berger, E. D.; Zorn, B. G.; McKinley, K. S. (November 2002). "Reconsidering Custom Memory Allocation" (PDF). Proceedings of the 17th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications. OOPSLA '02. pp.Â 1â12. CiteSeerXÂ 10.1.1.119.5298. doi:10.1145/582419.582421. ISBNÂ 1-58113-471-1. S2CIDÂ 481812.
Wilson, Paul R.; Johnstone, Mark S.; Neely, Michael; Boles, David (September 28â29, 1995), Dynamic Storage Allocation: A Survey and Critical Review (PDF), Austin, Texas: Department of Computer Sciences University of Texas, retrieved 2017-06-03
External links[edit]



Wikibooks has more on the topic of: Memory management

"Generic Memory Manager" C++ library
Sample bit-mapped arena memory allocator in C
TLSF: a constant time allocator for real-time systems
Slides on Dynamic memory allocation
Inside A Storage Allocator
The Memory Management Reference
The Memory Management Reference, Beginner's Guide Allocation
Linux Memory Management
Memory Management For System Programmers
VMem - general malloc/free replacement. Fast thread safe C++ allocator
Dynamic Memory in IEC61508 Systems
Operating System Memory Management

.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}vteMemory management
Memory management as a function of an operating system
Manual memory management
Static memory allocation
C dynamic memory allocation
new and delete (C++)
Virtual memory
Demand paging
Page table
Paging
Virtual memory compression
Memory allocators
dlmalloc
Hoard malloc
jemalloc
mimalloc
ptmalloc
Hardware
Memory management unit (MMU)
Translation lookaside buffer (TLB)
Inputâoutput memory management unit (IOMMU)
Garbage collection
Boehm garbage collector
Concurrent mark sweep collector
Finalizer
Garbage
Garbage-first collector
Mark-compact algorithm
Reference counting
Tracing garbage collection
Strong reference
Weak reference
Memory segmentation
Protected mode
Real mode
Virtual 8086 mode
x86 memory segmentation
Memory safety
Buffer overflow
Buffer over-read
Dangling pointer
Stack overflow
Issues
Fragmentation
Memory leak
Unreachable memory
Other
Automatic variable
International Symposium on Memory Management
Region-based memory management

Authority control General
Integrated Authority File (Germany)
National libraries
United States





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Memory_management&oldid=1069359497"
		Categories: Memory managementComputer architectureHidden categories: Harv and Sfn no-target errorsArticles with short descriptionShort description is different from WikidataArticles lacking in-text citations from April 2014All articles lacking in-text citationsWebarchive template wayback linksArticles with GND identifiersArticles with LCCN identifiers
	
