
Title:
Tree (data structure)
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Abstract data type simulating a hierarchical tree structure and represented as a set of linked nodes
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Not to be confused with trie, a specific type of tree data structure.
Not to be confused with tree (graph theory), a specific type of mathematical object.
A request that this article title be changedÂ to Tree (data type) is under discussion.  Please do not move this article until the discussion is closed.
  A generic, and so non-binary, unsorted, some labels duplicated, arbitrary diagram of a tree. In this diagram, the node labeled 7 has three children, labeled 2, 10 and 6, and one parent, labeled 2. The root node, at the top, has no parent.
In computer science, a tree is a widely used abstract data type that simulates a hierarchical tree structure, with a root value and subtrees of children with a parent node, represented as a set of linked nodes.
A tree data structure can be defined recursively as a collection of nodes, where each node is a data structure consisting of a value and a list of references to nodes. The start of the tree is the "root node" and the reference nodes are the "children". No reference is duplicated and none points to the root.
Alternatively, a tree can be defined abstractly as a whole (globally) as an ordered tree, with a value assigned to each node. Both these perspectives are useful: while a tree can be analyzed mathematically as a whole, when actually represented as a data structure it is usually represented and worked with separately by node (rather than as a set of nodes and an adjacency list of edges between nodes, as one may represent a digraph, for instance). For example, looking at a tree as a whole, one can talk about "the parent node" of a given node, but in general, as a data structure, a given node only contains the list of its children but does not contain a reference to its parent (if any).

Contents

1 Common uses
2 Terminology
3 Preliminary definition
4 Drawing trees
5 Common operations

5.1 Traversal and search methods


6 Representations
7 Generalizations

7.1 Digraphs


8 Data type versus data structure

8.1 Recursive
8.2 Type theory
8.3 Mathematical terminology


9 Mathematical definition

9.1 Unordered tree

9.1.1 Sibling sets
9.1.2 Using set inclusion
9.1.3 Well-founded trees
9.1.4 Using recursive pairs
9.1.5 Using arrows
9.1.6 Using paths in a digraph
9.1.7 Using paths in a multidigraph
9.1.8 Using names

9.1.8.1 Pathnames




9.2 Ordered tree

9.2.1 Definition using horizontal order
9.2.2 Determinacy table
9.2.3 XPath axes
9.2.4 Traversal maps
9.2.5 Generating structure
9.2.6 Definition using binary trees
9.2.7 Per-level ordering
9.2.8 Encoding by sequences
9.2.9 Nested list


9.3 Nested data

9.3.1 Total ordering
9.3.2 Nomenclature




10 See also

10.1 Other trees


11 Notes
12 References
13 Further reading
14 External links



Common uses[edit]
Representing hierarchical data such as:
File systems used to store data on hard drives so that files can easily be found by name
Exploded-view drawing used to identify the sub components of components used to construct larger components
Subroutine calls used to identify which subroutines in a program call other subroutines non recursively
Evolution which species evolved from which prior species (not restricted to biology, e.g. Linux evolution timeline)
Abstract syntax trees for computer languages
Parse trees for human languages
Document Object Models of XML and HTML documents
JSON and YAML documents being processed
Search trees store data in a way that makes an efficient search algorithm possible via tree traversal
A binary search tree is a type of binary tree
Representing sorted lists of data
As a workflow for compositing digital images for visual effects[citation needed]
Storing Barnes-Hut trees used to simulate galaxies
Terminology[edit]
A node is a structure which may contain a value or condition, or represent a separate data structure (which could be a tree of its own). Each node in a tree has zero or more child nodes, which are below it in the tree (by convention, trees are drawn growing downwards). A node that has a child is called the child's parent node (or superior). A node has at most one parent, but possibly many ancestor nodes, such as the parent's parent.  Child nodes with the same parent are sibling nodes.
An internal node (also known as an inner node, inode for short, or branch node) is any node of a tree that has child nodes. Similarly, an external node (also known as an outer node, leaf node, or terminal node) is any node that does not have child nodes.
The topmost node in a tree is called the root node. Depending on the definition, a tree may be required to have a root node (in which case all trees are non-empty), or may be allowed to be empty, in which case it does not necessarily have a root node. Being the topmost node, the root node will not have a parent. It is the node at which algorithms on the tree begin, since as a data structure, one can only pass from parents to children. Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i.e., they first access the children of the root, but only access the value of the root last). All other nodes can be reached from it by following edges or links. (In the formal definition, each such path is also unique.) In diagrams, the root node is conventionally drawn at the top. In some trees, such as heaps, the root node has special properties. Every node in a tree can be seen as the root node of the subtree rooted at that node.
The height of a node is the length of the longest downward path to a leaf from that node. The height of the root is the height of the tree. The depth of a node is the length of the path to its root (i.e., its root path). This is commonly needed in the manipulation of the various self-balancing trees, AVL Trees in particular. The root node has depth zero, leaf nodes have height zero, and a tree with only a single node (hence both a root and leaf) has depth and height zero. Conventionally, an empty tree (tree with no nodes, if such are allowed) has height â1.
A subtree of a tree T is a tree consisting of a node in T and all of its descendants in T.[a][1] Nodes thus correspond to subtrees (each node corresponds to the subtree of itself and all its descendants) â the subtree corresponding to the root node is the entire tree, and each node is the root node of the subtree it determines; the subtree corresponding to any other node is called a proper subtree (by analogy to a proper subset).
Other terms used with trees:


Neighbor Parent or child.
Ancestor A node reachable by repeated proceeding from child to parent.
Descendant A node reachable by repeated proceeding from parent to child. Also known as subchild.
Degree For a given node, its number of children. A leaf has necessarily degree zero.
Degree of tree The degree of a tree is the maximum degree of a node in the tree.
Distance The number of edges along the shortest path between two nodes.
Level The level of a node is the number of edges along the
unique path between it and the root node.[2]
Width The number of nodes in a level.
Breadth The number of leaves.
Forest A set of n â¥ 0 disjoint trees.
Ordered tree A rooted tree in which an ordering is specified for the children of each vertex.
Size of a tree Number of nodes in the tree.

Preliminary definition[edit]
.mw-parser-output .tmulti .thumbinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}Not a tree: two non-connected parts, AâB and CâDâE. There is more than one root.Not a tree: undirected cycle 1-2-4-3. 4 has more than one parent (inbound edge).Not a tree: cycle BâCâEâDâB. B has more than one parent (inbound edge).Not a tree: cycle AâA. A is the root but it also has a parent.Each linear list is trivially a tree
A tree is a nonlinear data structure, compared to arrays, linked lists, stacks and queues which are linear data structures. A tree can be empty with no nodes or a tree is a structure consisting of one node called the root and zero or one or more subtrees.

Drawing trees[edit]
Trees are often drawn in the plane. Ordered trees can be represented essentially uniquely in the plane, and are hence called plane trees, as follows: if one fixes a conventional order (say, counterclockwise), and arranges the child nodes in that order (first incoming parent edge, then first child edge, etc.), this yields an embedding of the tree in the plane, unique up to ambient isotopy. Conversely, such an embedding determines an ordering of the child nodes.
If one places the root at the top (parents above children, as in a family tree) and places all nodes that are a given distance from the root (in terms of number of edges: the "level" of a tree) on a given horizontal line, one obtains a standard drawing of the tree. Given a binary tree, the first child is on the left (the "left node"), and the second child is on the right (the "right node").

Common operations[edit]
.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Graph and treesearch algorithms
Î±âÎ²
A*
B*
Backtracking
Beam
BellmanâFord
Best-first
Bidirectional
BorÅ¯vka
Branch & bound
BFS
British Museum
D*
DFS
Dijkstra
Edmonds
FloydâWarshall
Fringe search
Hill climbing
IDA*
Iterative deepening
Johnson
Jump point
Kruskal
Lexicographic BFS
LPA*
Prim
SMA*

Listings
Graph algorithms
Search algorithms
List of graph algorithms

Related topics
Dynamic programming
Graph traversal
Tree traversal
Search games
Graph coloring
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
Enumerating all the items
Enumerating a section of a tree
Searching for an item
Adding a new item at a certain position on the tree
Deleting an item
Pruning: Removing a whole section of a tree
Grafting: Adding a whole section to a tree
Finding the root for any node
Finding the lowest common ancestor of two nodes
Traversal and search methods[edit]
Main article: Tree traversal
Stepping through the items of a tree, by means of the connections between parents and children, is called walking the tree, and the action is a walk of the tree. Often, an operation might be performed when a pointer arrives at a particular node. A walk in which each parent node is traversed before its children is called a pre-order walk; a walk in which the children are traversed before their respective parents are traversed is called a post-order walk; a walk in which a node's left subtree, then the node itself, and finally its right subtree are traversed is called an in-order traversal. (This last scenario, referring to exactly two subtrees, a left subtree and a right subtree, assumes specifically a binary tree.) A level-order walk effectively performs a breadth-first search over the entirety of a tree; nodes are traversed level by level, where the root node is visited first, followed by its direct child nodes and their siblings, followed by its grandchild nodes and their siblings, etc., until all nodes in the tree have been traversed.

Representations[edit]
There are many different ways to represent trees; common representations represent the nodes as dynamically allocated records with pointers to their children, their parents, or both, or as items in an array, with relationships between them determined by their positions in the array (e.g., binary heap).
Indeed, a binary tree can be implemented as a list of lists (a list where the values are lists): the head of a list (the value of the first term) is the left child (subtree), while the tail (the list of second and subsequent terms) is the right child (subtree). This can be modified to allow values as well, as in Lisp S-expressions, where the head (value of first term) is the value of the node, the head of the tail (value of second term) is the left child, and the tail of the tail (list of third and subsequent terms) is the right child.
In general a node in a tree will not have pointers to its parents, but this information can be included (expanding the data structure to also include a pointer to the parent) or stored separately. Alternatively, upward links can be included in the child node data, as in a threaded binary tree.

Generalizations[edit]
Digraphs[edit]
If edges (to child nodes) are thought of as references, then a tree is a special case of a digraph, and the tree data structure can be generalized to represent directed graphs by removing the constraints that a node may have at most one parent, and that no cycles are allowed. Edges are still abstractly considered as pairs of nodes, however, the terms parent and child are usually replaced by different terminology (for example, source and target). Different implementation strategies exist: a digraph can be represented by the same local data structure as a tree (node with value and list of children), assuming that "list of children" is a list of references, or globally by such structures as adjacency lists.
In graph theory, a tree is a connected acyclic graph; unless stated otherwise, in graph theory trees and graphs are assumed undirected. There is no one-to-one correspondence between such trees and trees as data structure. We can take an arbitrary undirected tree, arbitrarily pick one of its vertices as the root, make all its edges directed by making them point away from the root node â producing an arborescence â and assign an order to all the nodes. The result corresponds to a tree data structure. Picking a different root or different ordering produces a different one.
Given a node in a tree, its children define an ordered forest (the union of subtrees given by all the children, or equivalently taking the subtree given by the node itself and erasing the root). Just as subtrees are natural for recursion (as in a depth-first search), forests are natural for corecursion (as in a breadth-first search).
Via mutual recursion, a forest can be defined as a list of trees (represented by root nodes), where a node (of a tree) consists of a value and a forest (its children):

f: [n[1], ..., n[k]]
n: v f

Data type versus data structure[edit]
There is a distinction between a tree as an abstract data type and as a concrete data structure, analogous to the distinction between a list and a linked list.
As a data type, a tree has a value and children, and the children are themselves trees; the value and children of the tree are interpreted as the value of the root node and the subtrees of the children of the root node. To allow finite trees, one must either allow the list of children to be empty (in which case trees can be required to be non-empty, an "empty tree" instead being represented by a forest of zero trees), or allow trees to be empty, in which case the list of children can be of fixed size (branching factor, especially 2 or "binary"), if desired.
As a data structure, a linked tree is a group of nodes, where each node has a value and a list of references to other nodes (its children).  There is also the requirement that no two "downward" references point to the same node. In practice, nodes in a tree commonly include other data as well, such as next/previous references, references to their parent nodes, or nearly anything.
Owing to the use of references to trees in the linked tree data structure, trees are often discussed implicitly assuming that they are being represented by references to the root node, as this is often how they are actually implemented. For example, rather than an empty tree, one may have a null reference: a tree is always non-empty, but a reference to a tree may be null.

Recursive[edit]
Recursively, as a data type a tree is defined as a value (of some data type, possibly empty), together with a list of trees (possibly an empty list), the subtrees of its children; symbolically:

t: v [t[1], ..., t[k]]
(A tree t consists of a value v and a list of other trees.)
More elegantly, via mutual recursion, of which a tree is one of the most basic examples, a tree can be defined in terms of forest (a list of trees), where a tree consists of a value and a forest (the subtrees of its children):

f: [t[1], ..., t[k]]
t: v f
Note that this definition is in terms of values, and is appropriate in functional languages (it assumes referential transparency); different trees have no connections, as they are simply lists of values.
As a data structure, a tree is defined as a node (the root), which itself consists of a value (of some data type, possibly empty), together with a list of references to other nodes (list possibly empty, references possibly null); symbolically:

n: v [&n[1], ..., &n[k]]
(A node n consists of a value v and a list of references to other nodes.)
This data structure defines a directed graph,[b] and for it to be a tree one must add a condition on its global structure (its topology), namely that at most one reference can point to any given node (a node has at most a single parent), and no node in the tree point to the root. In fact, every node (other than the root) must have exactly one parent, and the root must have no parents.
Indeed, given a list of nodes, and for each node a list of references to its children, one cannot tell if this structure is a tree or not without analyzing its global structure and that it is in fact topologically a tree, as defined below.

Type theory[edit]
As an abstract data type, the abstract tree type T with values of some type E is defined, using the abstract forest type F (list of trees), by the functions:

value: T â E
children: T â F
nil: () â F
node: E Ã F â T
with the axioms:

value(node(e, f)) = e
children(node(e, f)) = f
In terms of type theory, a tree is an inductive type defined by the constructors nil (empty forest) and node (tree with root node with given value and children).

Mathematical terminology[edit]
Viewed as a whole, a tree data structure is an ordered tree, generally with values attached to each node. Concretely, it is (if required to be non-empty):

A rooted tree with the "away from root" direction (a more narrow term is an "arborescence"), meaning:
A directed graph,
whose underlying undirected graph is a tree (any two vertices are connected by exactly one simple path),
with a distinguished root (one vertex is designated as the root),
which determines the direction on the edges (arrows point away from the root; given an edge, the node that the edge points from is called the parent and the node that the edge points to is called the child),
together with:

an ordering on the child nodes of a given node, and
a value (of some data type) at each node.
Often trees have a fixed (more properly, bounded) branching factor (outdegree), particularly always having two child nodes (possibly empty, hence at most two non-empty child nodes), hence a "binary tree".
Allowing empty trees makes some definitions simpler, some more complicated: a rooted tree must be non-empty, hence if empty trees are allowed the above definition instead becomes "an empty tree or a rooted tree such that ...". On the other hand, empty trees simplify defining fixed branching factor: with empty trees allowed, a binary tree is a tree such that every node has exactly two children, each of which is a tree (possibly empty). The complete sets of operations on the tree must include fork operation.

Mathematical definition[edit]
Unordered tree[edit]
Mathematically, an unordered tree[3] (or "algebraic tree")[4] can be defined as an algebraic structure (X, parent) where X is the non-empty carrier set of nodes and parent is a function on X which assigns each node x its "parent" node, parent(x). The structure is subject to the condition that every non-empty subalgebra must have the same fixed point. That is, there must be a unique "root" node r, such that parent(r) = r and for every node x, some iterative application parent(parent(â¯parent(x)â¯)) equals r.
There are several equivalent definitions.
As the closest alternative, one can define unordered trees as partial algebras (X, parent) which are obtained from the total algebras described above by letting parent(r) be undefined. That is, the root r is the only node on which the parent function is not defined and for every node x, the root is reachable from x in the directed graph (X, parent). This definition is in fact coincident with that of an anti-arborescence. The TAoCP book uses the term oriented tree.[5]


.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}An unordered tree is a structure (X, âº) where X is a set of nodes and âº is a child-to-parent relation between nodes such that:(1)X is non-empty.(2)X is weakly connected in âº.(3)âº is functional.(4)âº satisfies ACC: there is no infinite sequence  x1 âº x2 âº x3 âº â¯.
The box on the right describes the partial algebra (X, parent) as a relational structure (X, âº). If (1) is replaced by

X contains exactly one âº-maximal node. 
then condition (2) becomes redundant.
Using this definition, dedicated terminology can be provided for generalizations of unordered trees that correspond to distinguished subsets of the listed conditions: 

(1,2,3) â directed pseudotree,
(3) â directed pseudoforest,
(3,4) â unordered forest (whose components are unordered trees),
(4) â directed acyclic graph, assumed that X is finite,
(1',4) â acyclic accessible pointed graph (then condition (2) holds implicitly).
Another equivalent definition of an unordered tree is that of a set-theoretic tree that is singly-rooted and whose height is at most Ï (a "finite-ish" tree).[6] That is, the algebraic structures (X, parent) are equivalent to partial orders (X, â¤) that have a top element r and whose every principal upset (aka principal filter) is a finite chain. 
To be precise, we should speak about an inverse set-theoretic tree since the set-theoretic definition usually employs opposite ordering.
The correspondence between (X, parent) and (X, â¤) is established via reflexive transitive closure / reduction, with the reduction resulting in the "partial" version without the root cycle.
The definition of trees in descriptive set theory (DST) utilizes the 
representation of partial orders (X, â¥) as prefix orders between finite sequences. In turns out that up to isomorphism, there is a one-to-one correspondence between the (inverse of) DST trees and the tree structures defined so far.
We can refer to the four equivalent characterizations as to tree as an algebra, tree as a partial algebra, tree as a partial order, and tree as a prefix order. There is also a fifth equivalent definition â that of a graph-theoretic rooted tree which is just a connected acyclic 
rooted graph.


The expression of trees as (partial) algebras (also called functional graphs) (X, parent) follows directly the implementation of tree structures using parent pointers. Typically, the partial version is used in which the root node has no parent defined. However, in some implementations or models even the parent(r) = r circularity is established. Notable examples: 

The Linux VFS where "The root dentry has a d_parent that points to itself".[7]
The concept of an instantiation tree[8][9][10]
from object-oriented programming. In this case, the root node is the top metaclass â the only class that is a direct instance of itself.
Note that the above definition admits infinite trees. This allows for the description of infinite structures supported by some implementations via lazy evaluation. A notable example is the infinite regress of eigenclasses from the Ruby object model.[11] In this model, the tree established via superclass links between non-terminal objects is infinite and has an infinite branch (a single infinite branch of "helix" objects â see the diagram).

Sibling sets[edit]
In every unordered tree (X, parent) there is a distinguished partition of the set X of nodes into sibling sets. Two non-root nodes x, y belong to the same sibling set if parent(x) = parent(y). The root node r forms the singleton sibling set {r}.[c] A tree is said to be locally finite or finitely branching if each of its sibling sets is finite.
Each pair of distinct siblings is incomparable in â¤. This is why the word unordered is used in the definition. Such a terminology might become misleading when all sibling sets are singletons, i.e. when the set X of all nodes is totally ordered (and thus well-ordered) by â¤ In such a case we might speak about a singly-branching tree instead.

Using set inclusion[edit]
As with every partially ordered set, tree structures (X, â¤) can be represented by inclusion order â by set systems in which â¤ is coincident with â, the induced inclusion order. Consider a structure (U, â±) such that U is a non-empty set, and â± is a set of subsets of U such that the following are satisfied (by Nested Set Collection definition):

â â â±. (That is, (U, â±) is a hypergraph.)
U â â±.
For every X, Y from â±, X â© Y â {â, X, Y}. (That is, â± is a laminar family.)[12]
For every X from â±, there are only finitely many Y from â± such that X â Y.
Then the structure (â±, â) is an unordered tree whose root equals U. Conversely, if (U, â¤) is an unordered tree, and â± is the set {âx | x â U} of all principal ideals of (U, â¤) then the set system (U, â±) satisfies the above properties.

  Tree as a laminar system of sets (Copied from Nested set model)
The set-system view of tree structures provides the default semantic model â in the majority of most popular cases, tree data structures represent containment hierarchy. This also offers a justification for order direction with the root at the top: The root node is a greater container than any other node. Notable examples:

Directory structure of a file system. A directory contains its sub-directories.
DOM tree. The document parts correspondent to DOM nodes are in subpart relation according to the tree order.
Single inheritance in object-oriented programming. An instance of a class is also an instance of a superclass.
Hierarchical taxonomy such as the Dewey Decimal Classification with sections of increasing specificity.
BSP trees, quadtrees, octrees, R-trees and other tree data structures used for recursive space partitioning.
Well-founded trees[edit]
An unordered tree (X, â¤) is well-founded if the strict partial order < is a well-founded relation. In particular, every finite tree is well-founded. 
Assuming the axiom of dependent choice a tree is well-founded if and only if it has no infinite branch.
Well-founded trees can be defined recursively â by forming trees from a disjoint union of smaller trees. For the precise definition, suppose that X is a set of nodes. Using the reflexivity of partial orders, we can identify any tree (Y, â¤) on a subset of X with its partial order (â¤) â a subset of X Ã X. The set â of all relations R that form a well-founded tree (Y, R) on a subset Y of X is defined in stages âi, so that â = â{âi | i is ordinal}. For each ordinal number i, let R belong to the i-th stage âi if and only if R is equal to

ââ± âª ((dom(ââ±) âª {x}) Ã {x})
where â± is a subset of â{âk | k < i} such that elements of â± are pairwise disjoint, and x is a node that does not belong to dom(ââ±). (We use dom(S) to denote the domain of a relation S.) Observe that the lowest stage â0 consists of single-node trees {(x,x)} since only empty â± is possible. In each stage, (possibly) new trees R are built by taking a forest ââ± with components â± from lower stages and attaching a new root x atop of ââ±.
In contrast to the tree height which is at most Ï, the rank of well-founded trees is unlimited,[13] see the properties of "unfolding".

Using recursive pairs[edit]
In computing, a common way to define well-founded trees is via recursive ordered pairs
(F, x): a tree is a forest F together with a "fresh" node x.[14]  A forest F in turn is a possibly empty set of trees with pairwise disjoint sets of nodes. For the precise definition, proceed similarly as in the construction of names used in the set-theoretic technique of forcing. Let X be a set of nodes. In the superstructure over X, define sets T, â± of trees and forests, respectively, and a map  nodesÂ : T â â(X) assigning each tree t its underlying set of nodes so that:




(trees over X)



t â T

â

t is a pair (F, x) from â± Ã X such that for all s â F, x â nodes(s),


(forests over X)



F â â±

â

F is a subset of T such that for every s,t â F, s â  t, nodes(s) â© nodes(t) = â,


(nodes of trees)



y â nodes(t)

â

t = (F, x) â T and either y = x or y â nodes(s) for some s â F.

Circularities in the above conditions can be eliminated by stratifying each of T, â± and nodes into stages like in the previous subsection. Subsequently, define a "subtree" relation â¤ on T as the reflexive transitive closure of the "immediate subtree" relation âº defined between trees by



 s âº t

â

 s â Ï1(t)

where Ï1(t) is the projection of t onto the first coordinate; i.e., it is the forest F such that t = (F, x) for some x â X. It can be observed that (T, â¤) is a multitree: for every t â T, the principal ideal ât ordered by â¤ is a well-founded tree as a partial order. Moreover, for every tree  t â T, its "nodes"-order structure  (nodes(t), â¤t) is given by  x â¤t y if and only if there are forests F, G â â± such that both (F, x) and (G, y) are subtrees of t and (F, x) â¤ (G, y).

Using arrows[edit]
Another formalization as well as generalization of unordered trees can be obtained by reifying parent-child pairs of nodes. Each such ordered pair can be regarded as an abstract entity â an "arrow". This results in a multidigraph (X, A, s, t) where X is the set of nodes, A is the set of arrows, and s and t are functions from A to X assigning each arrow its source and target, respectively. The structure is subject to the following conditions:

(1) (A, s â tâ1) is an unordered tree, as a total algebra.
(2) The t map is a bijection between arrows and nodes.
In (1), the composition symbol â is to be interpreted left-to-right. The condition says that inverse consecutivity of arrows[d] is a total child-to-parent map. Let this parent map between arrows be denoted p, i.e. p = s â tâ1. Then we also have s = p â t, thus a multidigraph satisfying (1,2) can also be axiomatized as (X, A, p, t), with the parent map p instead of s as a definitory constituent. Observe that the root arrow is necessarily a loop, i.e. its source and target coincide.






Arrow tree: the hard-link structure of VFS

An important generalization of the above structure is established by allowing the target map t to be many-to-one. This means that (2) is weakened to

(2') The t map is surjective â each node is the target of some arrow.
Note that condition (1) asserts that only leaf arrows are allowed to have the same target. That is, the restriction of t to the range of p is still injective.
Multidigraphs satisfying (1,2') can be called "arrow trees" â their tree characteristics is imposed on arrows rather than nodes. These structures can be regarded as the most essential abstraction of the Linux VFS because they reflect the hard-link structure of filesystems. Nodes are called inodes, arrows are dentries (or hard links). The parent and target maps p and t are respectively represented by d_parent and d_inode fields in the dentry data structure.[15] Each inode is assigned a fixed file type, of which the directory type plays a special role of "designed parents":

(a) only directory inodes can appear as hard-link source, and
(b) a directory inode cannot appear as the target of more than one hard-link.
Using dashed style for the first half of the root loop indicates that, similarly to the parent map, there is a partial version for the source map s in which the source of the root arrow is undefined. This variant is employed for further generalization, see #Using paths in a multidigraph.

Using paths in a digraph[edit]





Unfolding of set membership â.
For every set x, the relational structures (x âª {x}, â) and (TC({x}), â) are both apgs.[apg 1]






(5, â) folded




(5, â) unfolded



5 = 4 âª {4} = TC({4}) = {0,1,2,3,4} is a
von Neumann ordinal number.



Unordered trees naturally arise by "unfolding" of accessible pointed graphs.[16]
Let â = (X, R, r) be a pointed relational structure, i.e. such that X is the set of nodes, R is a relation between nodes (a subset of X Ã X), and r is a distinguished "root" node. Assume further that â is accessible, which means that X equals the preimage of {r} under the reflexive transitive closure of R, and call such a structure an accessible pointed graph or apg for short.[apg 2] Then one can derive another apg â' = (X', R', r') â the unfolding of â â as follows:

X' is the set of reversed paths to r, i.e. the set of non-empty finite sequences p of nodes (elements of X) such that (a) consecutive members of p are inversely R-related, and (b) the first member of p is the root r,
R' is a relation between paths from X' such that paths p and q are R'-related if and only if p = q â [x] for some node x (i.e. q is a maximal proper prefix of p, the "popped" p), and
r' is the one-element sequence [r].
Apparently, the structure (X', R') is an unordered tree in the "partial-algebra" version: R' is a partial map that relates each non-root element of X' to its parent by path popping. The root element is obviously  r'. Moreover, the following properties are satisfied:

â is isomorphic to its unfolding â' if and only if â is a tree.[apg 3] (In particular, unfolding is idempotent, up to isomorphism.)
Unfolding preserves well-foundedness: If R is well-founded then so is R'.
Unfolding preserves rank: If R is well-founded then the ranks of R and R' coincide.
Notes:

.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ 
Acyclic relations like the set membership â only allow at most one possible root r to form an apg. The root is then given implicitly and can be left out of the signature.

^ 
To establish a concordancy between R and the parent map, the presented definition uses reversed accessibility: r is reachable from any node.
This approach is also used in nLab â see membership graphs.
In the original definition by P. Aczel, every node is reachable from r (thus, instead of "preimage", the word "image" applies).

^ 
We have implicitly introduced a definition of unordered trees as apgs: call an apg â = (X, R, r) a tree if the reduct (X, R) is an unordered tree as a partial algebra. This can be translated as: Every node is accessible by exactly one path.


Using paths in a multidigraph[edit]
As shown on the example of hard-link structure of file systems, many data structures in computing allow multiple links between nodes. Therefore,  in order to properly exhibit the appearance of unordered trees among data structures it is necessary to generalize accessible pointed graphs to multidigraph setting. To simplify the terminology, we make use of the term quiver which is an established synonym for "multidigraph".




Accessible pointed quiver (apq): generalization of apg to multidigraphs.




Let an accessible pointed quiver or apq for short be defined as a structure

â³ = (X, A, s, t)
where
X is a set of nodes,
A is a set of arrows,
s is a partial function from A to X (the source map), and
t is a total function from A to X (the target map).
Thus, â³ is a "partial multidigraph".
The structure is subject to the following conditions:

There is exactly one "root" arrow, ar, whose source s(ar) is undefined.
Every node x â X is reachable via a finite sequence of consecutive arrows starting with the root arrow ar.
â³ is said to be a tree if the target map t is a bijection between arrows and nodes.
The unfolding of â³ is formed by the sequences mentioned in (2) â which are the accessibility paths (cf. Path algebra). As an apq, the unfolding can be written as 
â³' = (X', A', s', t')
where 
X' is the set of accessibility paths,
A' coincides with X',
s' coincides with path popping, and
t' is the identity on X'.
Like with apgs, unfolding is idempotent and always results in a tree.
The underlying apg is obtained as the structure
(X, R, t(ar))
where
R = {(t(a),s(a)) | a â A \ {ar}}.
The diagram above shows an example of an apq with 1 + 14 arrows. In JavaScript, Python or Ruby, the structure can be created by the following (exactly the same) code:

r = {}; 
r[1] = {}; r[2] = r[1]; r[3] = {}; r[4] = {}; 
r[1][5]    = {};   r[1][14]    = r[1][5];
r[3][7]    = {};   r[3][8]     = r[3][7];  r[3][13] = {};
r[4][9]    = r[4]; r[4][10]    = r[4];     r[4][11] = {};
r[3][7][6] = r[3]; r[3][7][12] = r[1][5];

Using names[edit]
Unordered trees and their generalizations form the essence of naming systems.
There are two prominent examples of naming systems: file systems and (nested) associative arrays. The multidigraph-based structures from previous subsections provided anonymous abstractions for both cases. To obtain naming capabilities, arrows are to be equipped with names as identifiers.
A name must be locally unique â within each sibling set of arrows[e] there can be at most one arrow labelled by a given name.




source

name

target


s(a)

Ï(a)

t(a)

This can be formalized as a structure

 â° = (X, Î£, A, s, Ï, t)
where 
X is a set of nodes, 
Î£ is a set of names, 
A is a set of arrows, 
s is a partial function from A to X, 
Ï is a partial function from A to Î£, and
t is a total function from A to X.
For an arrow a, constituents of the triple (s(a), Ï(a), t(a)) are respectively a's source, name and target.
The structure is subject to the following conditions:

The reduct (X, A, s, t) is an accessible pointed quiver (apq) as defined previously.
The name function Ï is undefined just for the source-less root arrow.
The name function Ï is injective in the restriction to every sibling set of arrows, i.e. for every non-root arrows a, b, if s(a) = s(b) and Ï(a) = Ï(b) then a = b.

A nested dictionary is a structure 
 â° = (X, V, Î£, ð, r)
where X is a set of nodes, V is a set of (primitive) values,  Î£ is a set of names, ð is a subset of X Ã Î£ Ã (X âª V) â the source-name-target relation, and r â X is the root node. The following is required:(1)ð is a partial function on X Ã Î£.(2)(X, âº, r) is an accessible pointed graph where âº is the induced target-source relation.[f]
Such a structure can be called a named apq or a nested dictionary without distinction of containers. 
The box on the right provides an alternative definition in which the distinction of container nodes is accomplished. A shift in terminology can be observed: The term "node" is used as a synonym for "container", whereas "non-containers" form a distinct sort V of (primitive) values. Moreover, arrows are "un-reified" to the set 

ð = {(s(a), Ï(a), t(a)) | a â A \ {ar}}
of source-name-target triples. They can be viewed as a relational database table depicted above. Underlines in source and name indicate primary key (condition (1)).
The structure can be rephrased as a deterministic labelled transition system: X is a set of "states", Î£ is a set of "labels", ð is a set of "labelled transitions", the root node r is an "initial state", and the accessibility condition (2) means that every state is reachable from the initial state.
More specifically, observe a connection between nested dictionaries and Mealy machines. Starting with the definition of Mealy machines, the class of nested dictionaries is obtained by the following modifications:
(a) drop the finiteness requirement(s), 
(b) require every state be reachable, 
(c) allow the transition and output functions to be partial,
(d) require that the transition and output functions have disjoint domains.





Nested dictionary

The diagram on the right shows a nested dictionary â° that has the same underlying multidigraph as the example in the previous subsection. The structure can be created by the code below. Like before, exactly the same code applies for JavaScript, Python and Ruby.
First, a substructure, â°0, is created by a single assignment of a literal {...} to r. This structure, depicted by full lines, is an "arrow tree" (therefore, it is a spanning tree). The literal in turn appears to be a JSON serialization of â°0.
Subsequently, the remaining arrows are created by assignments of already existing nodes. Arrows that cause cycles are displayed in blue.

r = {"a":{"a":5,"b":5},"c":{"a":{"w":5},"c":{}},"d":{"w":1.3}}

r["b"]           = r["a"]; r["c"]["b"] = r["c"]["a"]
r["c"]["a"]["p"] = r["c"]; r["d"]["e"] = r["d"]["self"] = r["d"]

In the Linux VFS, the name function Ï is represented by the d_name field in the dentry data structure.[15] The â°0 structure above demonstrates a correspondence between JSON-representable structures and hard-link structures of file systems. In both cases, there is a fixed set of built-in types of "nodes" of which one type is a container type, except that in JSON, there are in fact two such types â Object and Array. If the latter one is ignored (as well as the distinction between individual primitive data types) then the provided abstractions of file-systems and JSON data are the same â both are arrow trees equipped with naming Ï and a distinction of container nodes.
See #Nested data for the formal description of tree structures ("JSON-trees") with distinction and bipartition of container nodes.

Pathnames[edit]
The naming function Ï of a nested dictionary â° naturally extends from arrows to arrow paths. Each sequence p = [a1, ..., an]  of consecutive arrows is implicitly assigned a pathname (cf. Pathname) â the sequence Ï(p) = [Ï(a1), ..., Ï(an)]  of arrow names.[g]
Local uniqueness carries over to arrow paths: different sibling paths have different pathnames. In particular, the root-originating arrow paths are in one-to-one correspondence with their pathnames. This correspondence provides a "symbolic" representation of the unfolding of â° via pathnames â the nodes in â° are globally identified via a tree of pathnames.

Ordered tree[edit]
The structures introduced in the previous subsection form just the core "hierarchical"  part of tree data structures that appear in computing. In most cases, there is also an additional "horizontal" ordering between siblings. In search trees the order is commonly established by the "key" or value associated with each sibling, but in many trees that is not the case. For example, XML documents, lists within JSON files, and many other structures have order that does not depend on the values in the nodes, but is itself data â sorting the paragraphs of a novel alphabetically would change its meaning.
The correspondent expansion of the previously described tree structures (X, â¤) can be defined by endowing each sibling set with a linear order as follows.[17][18]
An alternative definition according to Kuboyama[3] is presented in the next subsection.
An ordered tree is a structure (X, â¤V, â¤S) where  X is a non-empty set of nodes and â¤V and â¤S are relations on X called vertical (or also hierarchical[3]) order and sibling order, respectively. The structure is subject to the following conditions:

(X, â¤V) is a partial order that is an unordered tree as defined in the previous subsection.
(X, â¤S)  is a partial order.
Distinct nodes are comparable in <S if and only if they are siblings:
(<S) âª (>S) = ((âºV) â (â»V)) â idX.
Every node has only finitely many preceding siblings, i.e. every principal ideal of (X, â¤S) is finite.  (This condition can be omitted in the case of finite trees.)
Conditions (2) and (3) say that (X, â¤S) is a component-wise linear order, each component being a sibling set. Condition (4) asserts that if a sibling set S is infinite then (S, â¤S) is isomorphic to (
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
, â¤), the usual ordering of natural numbers.
Given this, there are three (another) distinguished partial orders which are uniquely given by the following prescriptions:



(<H)

 = 

(â¤V) â (<S) â (â¥V)

(the horizontal order),


(<Lâ)

 = 

(>V) âª (<H)

(the "discordant" linear order),


(<L+)

 = 

(<V) âª (<H)

(the "concordant" linear order).

This amounts to a "V-S-H-LÂ±" system of five partial orders â¤V, â¤S, â¤H, â¤L+, â¤Lâ on the same set X of nodes, in which, except for the pair { â¤S, â¤H }, any two relations uniquely determine the other three, see the determinacy table.
Notes about notational conventions:

The relation composition symbol â used in this subsection is to be interpreted left-to-right (as 
  
    
      
        
          â
          
            l
          
        
      
    
    {\displaystyle \circ _{l}}
  
).
Symbols < and â¤ express the strict and non-strict versions of a partial order.
Symbols > and â¥ express the converse relations.
The âº symbol is used for the covering relation of â¤ which is the immediate version of a partial order.
This yields six versions âº, <, â¤, â», >, â¥ for a single partial order relation. Except for âº and â», each version uniquely determines the others. Passing from âº to <requires that < be transitively reducible. This is always satisfied for all of <V, <S and <H but might not hold for <L+ or <Lâ if X is infinite.


The partial orders â¤V and â¤Hare complementary:

(<V) â (>V) â (<H) â (>H) = X Ã X â idX.
As a consequence, the "concordant" linear order <L+ is a linear extension of <V. Similarly, <Lâ is a linear extension of >V.
The covering relations âºLâ and âºL+ correspond to pre-order traversal and post-order traversal, respectively. If x âºLâ y then, according to whether y has a previous sibling or not, the x node is either the "rightmost" non-strict descendant of the previous sibling of y or, in the latter case, x is the first child of y. Pairs 
  
    
      
        (
        x
        ,
        y
        )
      
    
    {\displaystyle (x,y)}
  
 of the latter case form the relation  (âºLâ) â (<H) which is a partial map that assigns each non-leaf node its first child node. Similarly, (â»L+) â (>H) assigns each non-leaf node with finitely many children its last child node.

Definition using horizontal order[edit]
The Kuboyama's definition of "rooted ordered trees"[3] makes use of the horizontal order â¤H as a definitory relation.[h] (See also Suppes.[19])
Using the notation and terminology introduced so far, the definition can be expressed as follows.
An ordered tree is a structure (X, â¤V, â¤H) such that conditions (1â5) are satisfied:

(X, â¤V) is a partial order that is an unordered tree.  (The vertical order.)
(X, â¤H) is a partial order. (The horizontal order.)
The partial orders â¤V and â¤H are complementary: (<V) â (>V) â (<H) â (>H) = X Ã X â idX.
(That is, pairs of nodes that are incomparable in (<V) are comparable in (<H) and vice versa.)
The partial orders â¤V and â¤H are "consistent": (<H) = (â¤V) â (<H) â (â¥V).
(That is, for every nodes x, y such that x <H y, all descendants of x must precede all the descendants of y.)
Every node has only finitely many preceding siblings. (That is, for every infinite sibling set S, (S, â¤H) has the order type of the natural numbers.)  (Like before, this condition can be omitted in the case of finite trees.)
The sibling order (â¤S) is obtained by (<S) = (<H) â© ((âºV) â (â»V)), i.e. two distinct nodes are in sibling order if and only if they are in horizontal order and are siblings.

Determinacy table[edit]
The following table shows the determinacy of the "V-S-H-LÂ±" system. Relational expressions in the table's body are equal to one of <V, <S, <H, <Lâ, or <L+ according to the column. It follows that except for the pair { â¤S, â¤H }, an ordered tree (X, ...) is uniquely determined by any two of the five relations.





<V

<S

<H

<Lâ

<L+


V,S





(â¤V) â (<S) â (â¥V)






V,H



(<H) â© ((âºV)â(â»V))



(>V) âª (<H)

(<V) âª (<H)


V,Lâ



(<Lâ) â© ((âºV)â(â»V))

(<Lâ) â (>V)






V,L+



(<L+) â© ((âºV)â(â»V))

(<L+) â (<V)






H,Lâ

(>Lâ) â (<H)










H,L+

(<L+) â (<H)










Lâ,L+

(>Lâ) â© (<L+)



(<Lâ) â© (<L+)






S,Lâ

x âºV y â y = infLâ(Y) where Y is the image of {x} under (â¥S)â(â»Lâ)


S,L+

x âºV y â y = supL+(Y) where Y is the image of {x} under (â¤S)â(âºL+)

In the last two rows, infLâ(Y) denotes the infimum of Y in (X, â¤Lâ), and supL+(Y) denotes the supremum of Y in (X, â¤L+). In both rows, (â¤S) resp. (â¥S) can be equivalently replaced by the sibling equivalence (â¤S)â(â¥S). In particular, the partition into sibling sets together with either of â¤Lâ or â¤L+ is also sufficient to determine the ordered tree. The first prescription for âºV can be read as: the parent of a non-root node x equals the infimum of the set of all immediate predecessors of siblings of x, where the words "infimum" and "predecessors" are meant with regard to â¤Lâ. Similarly with the second prescription, just use "supremum", "successors" and â¤L+.
The relations â¤S and â¤H obviously cannot form a definitory pair. For the simplest example, consider an ordered tree with exactly two nodes â then one cannot tell which of them is the root.

XPath axes[edit]



XPath axis

Relation


ancestor

<V


ancestor-or-self

â¤V


child

â»V


descendant

>V


descendant-or-self

â¥V


following

<H


following-sibling

<S


parent

âºV


preceding

>H


preceding-sibling

>S


self

idX


The table on the right shows a correspondence of introduced relations to XPath axes, which are used in structured document systems to access nodes that bear particular ordering relationships to a starting "context" node. For a context node[20] x, its axis named by the specifier in the left column is the set of nodes that equals the
image of {x} under the correspondent relation. As of XPath 2.0, the nodes are "returned" in document order, which is the "discordant" linear order â¤Lâ. A "concordance" would be achieved, if the vertical order â¤V was defined oppositely, with the bottom-up direction outwards the root like in set theory in accordance to natural trees.[i]

Traversal maps[edit]
Below is the list of partial maps that are typically used for ordered tree traversal.[21] Each map is a distinguished functional subrelation of  â¤Lâ or of its opposite.

âºV ... the parent-node partial map,
â»S ... the previous-sibling partial map,
âºS ... the next-sibling partial map,
(âºLâ) â (<H) ... the first-child partial map,
(â»L+) â (>H) ... the last-child partial map,
â»Lâ ... the previous-node partial map,
âºLâ ... the next-node partial map.
Generating structure[edit]
The traversal maps constitute a partial unary algebra[22] (X, parent, previousSibling, ..., nextNode) that forms a basis for representing trees as linked data structures. At least conceptually, there are parent links, sibling adjacency links, and first / last child links. This also applies to unordered trees in general, which can be observed on the dentry data structure in the Linux VFS.[23]
Similarly to the "V-S-H-LÂ±" system of partial orders, there are pairs of traversal maps that uniquely determine the whole ordered tree structure. Naturally, one such generating structure is (X, âºV, âºS) which can be transcribed as (X, parent, nextSibling) â the structure of parent and next-sibling links. Another important generating structure is (X, firstChild, nextSibling) known as left-child right-sibling binary tree. This partial algebra establishes a one-to-one correspondence between binary trees and ordered trees.


Definition using binary trees[edit]
The correspondence to binary trees provides a concise definition of ordered trees as partial algebras.
An ordered tree is a structure 
  
    
      
        (
        X
        ,
        l
        c
        ,
        r
        s
        )
      
    
    {\displaystyle (X,lc,rs)}
  
 where X is a non-empty set of nodes, and lc, rs are partial maps on X called left-child and  right-sibling, respectively. The structure is subject to the following conditions:

The partial maps lc and rs are disjoint, i.e. (lc) â© (rs) = â .
The inverse of (lc) âª (rs) is a partial map p such that the partial algebra (X, p) is an unordered tree.
The partial order structure (X, â¤V, â¤S) is obtained as follows:



(âºS)

 = 

(rs),


(â»V)

 = 

(lc) â (â¤S).

Per-level ordering[edit]
  Dashed line indicates the <Bâ ordering)
As a possible expansion of the "V-S-H-LÂ±" system, another distinguished relations between nodes can be defined, based on the tree's level structure. First, let us denote by â¼E the equivalence relation defined by x â¼E y if and only if x and y have the same number of ancestors. This yields a partition of the set of nodes into levels L0, L1, ... (, Ln) â a coarsement of the partition into sibling sets. Then define relations <E, <Bâ and <B+ by


  
    
      
        
          
            
              
                
                  (
                  
                    <
                    
                      
                        E
                      
                    
                  
                  )
                
              
              
                
                =
                
                  (
                  
                    <
                    
                      
                        H
                      
                    
                  
                  )
                
                â©
                
                  (
                  
                    â¼
                    
                      
                        E
                      
                    
                  
                  )
                
              
              
                
                  ((per) level order),
                
              
            
            
              
                
                  (
                  
                    <
                    
                      
                        
                          B
                        
                        
                          â
                        
                      
                    
                  
                  )
                
              
              
                
                =
                
                  (
                  
                    <
                    
                      
                        E
                      
                    
                  
                  )
                
                âª
                
                  (
                  
                    
                      (
                      
                        â¼
                        
                          
                            E
                          
                        
                      
                      )
                    
                    â
                    
                      (
                      
                        >
                        
                          
                            V
                          
                        
                      
                      )
                    
                  
                  )
                
              
              
                
                  (breadth-first order, BFS ordering),
                
              
            
            
              
                
                  (
                  
                    <
                    
                      
                        
                          B
                        
                        
                          +
                        
                      
                    
                  
                  )
                
              
              
                
                =
                
                  (
                  
                    <
                    
                      
                        E
                      
                    
                  
                  )
                
                âª
                
                  (
                  
                    
                      (
                      
                        
                          <
                        
                        
                          
                            V
                          
                        
                      
                      )
                    
                    â
                    
                      (
                      
                        â¼
                        
                          
                            E
                          
                        
                      
                      )
                    
                  
                  )
                
              
              
                
                  (breadth-first post-order).
                
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\left(<_{\mathrm {E} }\right)&=\left(<_{\mathrm {H} }\right)\cap \left(\sim _{\mathrm {E} }\right)&{\text{((per) level order),}}\\\left(<_{\mathrm {B} ^{-}}\right)&=\left(<_{\mathrm {E} }\right)\cup \left(\left(\sim _{\mathrm {E} }\right)\circ \left(>_{\mathrm {V} }\right)\right)&{\text{(breadth-first order, BFS ordering),}}\\\left(<_{\mathrm {B} ^{+}}\right)&=\left(<_{\mathrm {E} }\right)\cup \left(\left({<}_{\mathrm {V} }\right)\circ \left(\sim _{\mathrm {E} }\right)\right)&{\text{(breadth-first post-order).}}\end{aligned}}}
  

It can be observed that <E is a strict partial order and <Bâ and <B+ are strict total orders. Moreover, there is a similarity between the "V-S-LÂ±" and  "V-E-BÂ±" systems: <E is component-wise linear and orthogonal to <V, <Bâ is linear extension of <E and of >V, and <B+ is a linear extension of <E and of <V.

Encoding by sequences[edit]
Ordered trees can be naturally encoded by finite sequences of natural numbers.[24][j] Denote 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
â the set of all finite sequences of natural numbers. A non-empty subset W of 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
â is called a tree domain[25]
[26]
if for all u, v from 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
â and all i, j from 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
 the following holds (â is the concatenation operator):



If u â v â  W Â  then Â  u â  W.
Â Â (W is prefix-closed.)

If u â [i] â  W and j < i Â  then Â  u â [j] â W.
Â Â  (W is left-sibling-closed.)

The induced structure on W gives rise to an ordered tree: take the prefix order for â¥V and the lexicographical order for â¤Lâ.[k]
Conversely, for an ordered tree T = (X, â¤V, â¤Lâ) assign each node x the sequence w(x) of sibling indices, i.e. the root is assigned the empty sequence and for every non-root node x, let w(x) = w(parent(x)) â [i] where i is the number of preceding siblings of x. Put W = {w(x) | x â X} . Then W is a tree domain with its induced structure isomorphic to T.

Nested list[edit]



Nested list
r = [[5,5],[[5],[]],[[1.3]]]
r[3] = r[0] 
r[1][2] = r[1][0]
r[1][0][1] = r[1] 
r[2][2] = r[2][1] = r[2]


Ordering of siblings can be naturally applied to multidigraph generalizations that have been introduced for unordered trees. Moveover, sibling indices can be viewed as special names. A tree domain is just a tree of pathnames. As a result, one obtains a nested list as a counterpart to a nested dictionary.
The example shown on the right provides a nested-list version of the nested dictionary presented before.
Like before, there is an initial structure (an arrow tree, depicted by full lines) that is created by a single assignment of a literal [...] to r. The structure is subsequently modified by assignments that introduce additional links.
The code is applicable to JavaScript and Ruby. In Python, the modifying assignments are disallowed because of the use of sibling indices that are not present in the initial structure.[l]

Nested data[edit]
The notions of a nested dictionary and a nested list (which are generalizations of unordered / ordered trees, respectively) can be combined into the unifying concept of nested data. Such structures are most popular in connection with the JSON data format. These structures are multidigraphs with a distinguished set of container nodes, each container being either a dictionary or a list. In the text below, the sets of dictionaries and lists are respectively denoted XO and XA. This is according to the JSON terminology in which the corresponding two types of containers are called Object and Array.
The complementary set of non-container nodes represents "primitive values". JSON-specific formalizations[27]
[28]
provide further refinement according to the supported data types.
Nested data can be formalized as a structure
 â³Â = (X, Î£, A, XO, XA, s, t, Ï, Î¹) where 
X is a set of nodes, 
Î£ is a set of names, 
A is a set of arrows, 
XO and
XA are distinguished subsets of X,
s is a partial function from A to X (the source map), 
t is a total function from A to X (the target map),
Ï is a partial function from A to Î£ assigning an arrow its name, and 
Î¹ is a partial function from A to the set 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  
 of natural numbers assigning an arrow its sibling index.
Let  â³ be called a nested data tree if the following conditions are satisfied:



There is exactly one "root" arrow, ar, whose source s(ar) is undefined.


Every node is reachable via a path of arrows starting with the root arrow ar.


Every node from XOÂ âªÂ XA is the target of
exactly one arrow.


Every node that is the source of an arrow is from XOÂ âªÂ XA.


The sets XO and XA are disjoint.


The arrow-naming function Ï satisfies the following, for every arrows a, b.


Ï(a) is defined 
Â  if and only if Â 
s(a)Â âÂ XO.

If Ï(a) and Ï(b) are both defined and equal
Â  then Â 
either
aÂ =Â b or
s(a)Â â Â s(b).


The arrow-indexing function Î¹ satisfies the following, for every arrows a, b.


Î¹(a) is defined 
Â  if and only if Â 
s(a) â XA.

If Î¹(a) and Î¹(b) are both defined and equal
Â  then Â 
either
aÂ =Â b or
s(a)Â â Â s(b).

If Î¹(a) is defined and non-zero then 
Î¹(a) = Î¹(aâ²) + 1 for some arrow aâ²
such that s(a) = s(aâ²).


Note in particular that (1) and (2) define accessible pointed quivers (X, A, s, t).
Conditions (1â4) provide axiomatization of arrow trees with distinction of containers XOÂ âªÂ XA. By (3) there are unique links to containers and by (4) non-containers must be leaf nodes (cf. conditions (b) and (a) for hard-links in file systems).
An important consequence of (1â4) is the condition of acyclicity:



There are no circular paths of consecutive arrows.

This condition provides a weak alternative to (3).

Total ordering[edit]
Although dictionaries have the semantics of unordered collections, in programming environments they are often equipped with some intrinsic ordering.
Such ordering is supported in all of Python, Ruby and JavaScript.[m]
Thus, it is worthwhile to also consider ordered nested data trees, a refinement of nested data trees in which all sibling sets are ordered.
(Condition (7a) is altered to let Î¹(a) be defined for every non-root arrow a.)

Nomenclature[edit]
By considering just particular subsets of the above conditions and/or particular constituents of  â³ we obtain a nomenclature of tree data structures. Accessible pointed quivers (X,A,s,t) form the "lowest common denominator" â conditions (1) and (2) are always required.
Conditions (4â7) are imposed appropriately to whether 
XO, XA, Ï or Î¹ are defined.
The "tree" attribution is established by condition (3).





Require

Define

Distinguish


Uniqueness (3)

Acyclicity (3â²)

Naming Ï

Ordering Î¹

XO

XA


Semantic

Total


Accessible pointed quiver










Unordered tree










Ordered tree










Arrow tree with distinction of containers












XO âª XA



Nested dictionary


Perl:
hash


Python:
dictionary


Ruby:
hash


JavaScript:
object


General










Acyclic










Tree










Ordered










Nested list


Perl:
array


Python:
list


Ruby, JavaScript:
array


General










Acyclic










Tree










Nested data
General










Acyclic










Tree










Ordered









See also[edit]
Tree structure
Tree (graph theory)
Tree (set theory)
Cardinal tree and Ordinal tree
Hierarchy (mathematics)
Dialog tree
Single inheritance
Generative grammar
Genetic programming
Hierarchical clustering
Binary space partition tree
Recursion
Fenwick tree
Other trees[edit]
Trie
DayâStoutâWarren algorithm
Enfilade
Left child-right sibling binary tree
Hierarchical temporal memory
Integral Tree [29]
Notes[edit]


^ This is different from the formal definition of subtree used in graph theory, which is a subgraph that forms a tree â it need not include all descendants. For example, the root node by itself is a subtree in the graph theory sense, but not in the data structure sense (unless there are no descendants).

^ Properly, a rooted, ordered directed graph.

^  Alternatively, a "partial" version can be employed by excluding 
  
    
      
        
          r
        
      
    
    {\displaystyle {r}}
  
.

^  Arrows a and b are said to be consecutive, respectively, if t(a) = s(b).

^ 
I.e. arrows that have the same source node.

^ 
âº = {(y, x) | (x,Î±,y) â ð for some Î±}.

^ 
Here we assume that the root arrow ar is not in p.

^  
Unfortunately, the author uses the term sibling order for the horizontal order relation. This is non-standard, if not a misnomer.

^ 
This would also establish a concordance of the two possible directions of inequality symbols with the categorization of XPath axes into forward axes and reverse axes.

^  In general, any alphabet equipped with ordering that is isomorphic to that of natural numbers can be used. 

^  This statement is valid regardless of condition (ii). 

^ 
This can be solved by e.g. r = [[5,5],[[5,0],[],0],[[1.3],0,0],0].

^ 
As of Python 3.7, Ruby 1.9 and ECMAScript 2020 (tc39.es/proposal-for-in-order).


References[edit]


^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Weisstein, Eric W. "Subtree". MathWorld.

^ Susanna S. Epp (Aug 2010). Discrete Mathematics with Applications. Pacific Grove, CA: Brooks/Cole Publishing Co. p.Â 694. ISBNÂ 978-0-495-39132-6.

^ a b c d 
Tetsuji Kuboyama (2007). "Matching and learning in trees" (PDF). Doctoral Thesis, University of Tokyo.

^ "The Linux VFS Model: Naming structure".

^ 
Donald Knuth. The Art of Computer Programming, Volume 1: Fundamental Algorithms, Third Edition. Addison-Wesley, 1997. Section 2.3.4.2: Oriented trees.

^ 
Unger, Spencer (2012). "Trees in Set Theory" (PDF). {{cite journal}}: Cite journal requires |journal= (help)

^ Bruce Fields. "Notes on the Linux kernel".

^ Pierre Cointe (1987). "Metaclasses are First Class: the ObjVlisp Model". Proceeding OOPSLA '87 Conference Proceedings on Object-oriented Programming Systems, Languages and Applications. North-Holland.

^ 
Wolfgang Klas, Michael Schrefl (1995). Metaclasses and Their Application: Data Model Tailoring and Database Integration. Springer. ISBNÂ 9783540600633.

^ 
"What Is a Metaclass?".

^ 
"The Ruby Object Model: Data structure in detail".

^ B. Korte, and J. Vygen (2012). Combinatorial optimization. Springer, Heidelberg.

^ 
Dasgupta, Abhiit (2014). Set theory: with an introduction to real point sets. New York: BirkhÃ¤user.

^ 
Makinson, David (2012). Sets, logic and maths for computing. Springer Science & Business Media. ISBNÂ 9781447124993.

^ a b 
Bovet, Daniel; Cesati, Marco (2005). Understanding the Linux Kernel. O'Reilly. ISBNÂ 9780596554910.

^ Aczel, Peter (1988), Non-well-founded sets., CSLI Lecture Notes, vol.Â 14, Stanford, CA: Stanford University, Center for the Study of Language and Information, ISBNÂ 0-937073-22-9, MRÂ 0940014

^ 
Jan Hidders; Philippe Michiels; Roel Vercammen (2005). "Optimizing sorting and duplicate elimination in XQuery path expressions" (PDF). {{cite journal}}: Cite journal requires |journal= (help)

^ 
Frithjof Dau; Mark Sifer (2007). "A formalism for navigating and editing XML document structure" (PDF). International Workshop on Databases in Networked Information Systems. Springer, Berlin, Heidelberg.

^ 
Suppes, Patrick (1973). "Semantics of context-free fragments of natural languages". Approaches to Natural Language. Springer, Dordrecht: 370â394. CiteSeerXÂ 10.1.1.398.2289. doi:10.1007/978-94-010-2506-5_21. ISBNÂ 978-90-277-0233-3.

^ 
"XML Path Language (XPath) 3.1". World Wide Web Consortium. 21 March 2017.

^ 
"Document Object Model Traversal". W3C. 2000.

^ "Unary Algebras".

^ J.T. MÃ¼hlberg, G. LÃ¼ttgen (2009). "Verifying compiled file system code". Formal Methods: Foundations and Applications: 12th Brazilian Symposium on Formal Methods. Springer, Berlin, Heidelberg. CiteSeerXÂ 10.1.1.156.7781. {{cite journal}}: Cite journal requires |journal= (help)

^ 
L. Afanasiev; P. Blackburn; I. Dimitriou; B. Gaiffe; E. Goris; M. Marx; M. de Rijke (2005). "PDL for ordered trees" (PDF). Journal of Applied Non-Classical Logics. 15 (2): 115â135. doi:10.3166/jancl.15.115-135. S2CIDÂ 1979330.

^ 
Michaelis, Jens (2001). "Transforming linear context-free rewriting systems into minimalist grammars". International Conference on Logical Aspects of Computational Linguistics. Springer, Berlin, Heidelberg. pp.Â 228â244.

^ 
Morawietz, Frank (2008). Two-Step Approaches to Natural Language Formalism. Walter de Gruyter. ISBNÂ 9783110197259.

^ 
Bourhis, P.; Reutter, J.L.; VrgoÄ, D. (2020). "JSON: Data model and query languages". Information Systems. Vol.Â 89.

^ 
Botoeva, E.; Calvanese, D.; Cogrel, B.; Xiao, G. (2018). "Expressivity and complexity of MongoDB queries". 21st International Conference on Database Theory (ICDT 2018). Schloss Dagstuhl-Leibniz-Zentrum fÃ¼r Informatik.

^ Miltiadou, Milto; Campbell, Neill D. F.; Cosker, Darren; Grant, Michael G. (January 2021). "A Comparative Study about Data Structures Used for Efficient Management of Voxelised Full-Waveform Airborne LiDAR Data during 3D Polygonal Model Creation". Remote Sensing. 13 (4): 559. Bibcode:2021RemS...13..559M. doi:10.3390/rs13040559.


.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}

Further reading[edit]
Donald Knuth. The Art of Computer Programming: Fundamental Algorithms, Third Edition. Addison-Wesley, 1997. ISBNÂ 0-201-89683-4 . Section 2.3: Trees, pp.Â 308â423.
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms, Second Edition. MIT Press and McGraw-Hill, 2001. ISBNÂ 0-262-03293-7 . Section 10.4: Representing rooted trees, pp.Â 214â217. Chapters 12â14 (Binary Search Trees, Red-Black Trees, Augmenting Data Structures), pp.Â 253â320.
External links[edit]



Wikimedia Commons has media related to Tree structures.

Data Trees as a Means of Presenting Complex Data Analysis by Sally Knipe on August 8, 2013
Description from the Dictionary of Algorithms and Data Structures
CRAN - Package data.tree implementation of a tree data structure in the R programming language
WormWeb.org: Interactive Visualization of the C. elegans Cell Tree â Visualize the entire cell lineage tree of the nematode C. elegans (javascript)
Binary Trees by L. Allison
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}vteTree data structuresSearch trees(dynamic sets/associative arrays)
2â3
2â3â4
AA
(a,b)
AVL
B
B+
B*
Bx
(Optimal)Â Binary search
Dancing
HTree
Interval
Order statistic
(Left-leaning)Â Redâblack
Scapegoat
Splay
T
Treap
UB
Weight-balanced
Heaps
Binary
Binomial
Brodal
Fibonacci
Leftist
Pairing
Skew
van Emde Boas
Weak
Tries
Ctrie
C-trie (compressed ADT)
Hash
Radix
Suffix
Ternary search
X-fast
Y-fast
Spatial data partitioning trees
Ball
BK
BSP
Cartesian
Hilbert R
k-d (implicit k-d)
M
Metric
MVP
Octree
Priority R
Quad
R
R+
R*
Segment
VP
X
Other trees
Cover
Exponential
Fenwick
Finger
Fractal tree index
Fusion
Hash calendar
iDistance
K-ary
Left-child right-sibling
Link/cut
Log-structured merge
Merkle
PQ
Range
SPQR
Top

vteWell-known data structuresTypes
Collection
Container
Abstract
Associative array
Multimap
Retrieval Data Structure
List
Stack
Queue
Double-ended queue
Priority queue
Double-ended priority queue
Set
Multiset
Disjoint-set
Arrays
Bit array
Circular buffer
Dynamic array
Hash table
Hashed array tree
Sparse matrix
Linked
Association list
Linked list
Skip list
Unrolled linked list
XOR linked list
Trees
B-tree
Binary search tree
AA tree
AVL tree
Redâblack tree
Self-balancing tree
Splay tree
Heap
Binary heap
Binomial heap
Fibonacci heap
R-tree
R* tree
R+ tree
Hilbert R-tree
Trie
Hash tree
Graphs
Binary decision diagram
Directed acyclic graph
Directed acyclic word graph

List of data structures





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Tree_(data_structure)&oldid=1068168614"
		Categories: Data typesTrees (data structures)Knowledge representationAbstract data typesHidden categories: CS1 errors: missing periodicalCS1: long volume valueArticles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from July 2018Commons category link is on Wikidata
	
