
Title:
Component (graph theory)
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		Maximal subgraph in which all vertices are vertices can reach each other
  A graph with three components.
In graph theory, a component of an undirected graph is a connected subgraph that is not part of any larger connected subgraph. The components of any graph partition its vertices into disjoint sets, and are the induced subgraphs of those sets. A graph that is itself connected has exactly one component, consisting of the whole graph. Components are also sometimes called connected components.
The number of components in a given graph is an important graph invariant that is closely related to invariants of matroids, topological spaces, and matrices. In random graphs, a frequently occurring phenomenon is the incidence of a giant component, one component that is significantly larger than the others, and of a percolation threshold, an edge probability above which a giant component exists and below which it does not.
The components of a graph can be constructed in linear time, and a special case of the problem, connected-component labeling, is a basic technique in image analysis. Dynamic connectivity algorithms maintain components as edges are inserted or deleted in a graph, in low time per change. In computational complexity theory, connected components have been used to study algorithms with limited space complexity, and sublinear time algorithms can accurately estimate the number of components.

Contents

1 Definitions and examples
2 Number of components
3 Algorithms
4 In random graphs
5 References
6 External links



Definitions and examples[edit]
  A cluster graph with seven components
A component of a given undirected graph may be defined as a connected subgraph that is not part of any larger connected subgraph. Every vertex 
  
    
      
        v
      
    
    {\displaystyle v}
  
 of a graph belongs to one of the graph's components, which may be found as the induced subgraph of the set of vertices reachable from 
  
    
      
        v
      
    
    {\displaystyle v}
  
.[1] Every graph is the disjoint union of its components.[2] For instance, the graph shown in the first illustration has three components. Additional examples of this general rule include the following special cases:

In an empty graph, each vertex forms a component with one vertex and zero edges.[3] More generally a component of this type is formed for every isolated vertex in any graph.[4]
In a connected graph, there is exactly one component, the whole graph.[4]
In a forest, every component is a tree.[5]
In a cluster graph, every component is a maximal clique. These graphs may be produced as the transitive closures of arbitrary undirected graphs, for which finding the transitive closure is an equivalent formulation of identifying the connected components.[6]
Another way to define components involves the equivalence classes of an equivalence relation that is defined on the vertices of the graph.
In an undirected graph, a vertex 
  
    
      
        v
      
    
    {\displaystyle v}
  
 is reachable from a vertex 
  
    
      
        u
      
    
    {\displaystyle u}
  
 if there is a path from 
  
    
      
        u
      
    
    {\displaystyle u}
  
 to 
  
    
      
        v
      
    
    {\displaystyle v}
  
, or equivalently a walk (a path allowing repeated vertices and edges).
Reachability is an equivalence relation, since:

It is reflexive: There is a trivial path of length zero from any vertex to itself.
It is symmetric: If there is a path from 
  
    
      
        u
      
    
    {\displaystyle u}
  
 to 
  
    
      
        v
      
    
    {\displaystyle v}
  
, the same edges in the reverse order form a path from 
  
    
      
        v
      
    
    {\displaystyle v}
  
 to 
  
    
      
        u
      
    
    {\displaystyle u}
  
.
It is transitive: If there is a path from 
  
    
      
        u
      
    
    {\displaystyle u}
  
 to 
  
    
      
        v
      
    
    {\displaystyle v}
  
 and a path from 
  
    
      
        v
      
    
    {\displaystyle v}
  
 to 
  
    
      
        w
      
    
    {\displaystyle w}
  
, the two paths may be concatenated together to form a walk from 
  
    
      
        u
      
    
    {\displaystyle u}
  
 to 
  
    
      
        w
      
    
    {\displaystyle w}
  
.
The equivalence classes of this relation partition the vertices of the graph into disjoint sets, subsets of vertices that are all reachable from each other, with no additional reachable pairs outside of any of these subsets. Each vertex belongs to exactly one equivalence class. The components are then the induced subgraphs formed by each of these equivalence classes.[7] Alternatively, some sources define components as sets of vertices, the equivalence classes of vertices, rather than as the subgraphs they induce.[8]
Similar definitions involving equivalence classes have been used to defined components for more advanced forms of graph connectivity, including the strongly connected components of directed graphs[9] and the biconnected components of undirected graphs.[10]

Number of components[edit]
The number of components of a given graph can be used to count the number of edges in its spanning forests: in a graph with 
  
    
      
        n
      
    
    {\displaystyle n}
  
 vertices and 
  
    
      
        c
      
    
    {\displaystyle c}
  
 components, every spanning forest will have exactly 
  
    
      
        n
        â
        c
      
    
    {\displaystyle n-c}
  
 edges. This number 
  
    
      
        n
        â
        c
      
    
    {\displaystyle n-c}
  
 is the matroid-theoretic rank of the graph, and  the rank of its graphic matroid. The rank of the dual cographic matroid equals the circuit rank of the graph, the minimum number of edges that must be removed from the graph to break all its cycles. In a graph with 
  
    
      
        m
      
    
    {\displaystyle m}
  
 edges, 
  
    
      
        n
      
    
    {\displaystyle n}
  
 vertices and 
  
    
      
        c
      
    
    {\displaystyle c}
  
 components, the circuit rank is 
  
    
      
        m
        â
        n
        +
        c
      
    
    {\displaystyle m-n+c}
  
.[11]
A graph can be interpreted as a topological space in multiple ways, for instance by placing its vertices as points in general position in three-dimensional Euclidean space and representing its edges as line segments between those points.[12] The components of a graph can be generalized through these interpretations as the number of topological connected components of the corresponding space. Just as the number of connected components is an important topological invariant, the zeroth Betti number of a space, the number of components of a graph is an important graph invariant, and in topological graph theory it can be interpreted as the zeroth Betti number of the graph.[3]
The same number arises in other ways in graph theory as well. In algebraic graph theory it equals the multiplicity of 0 as an eigenvalue of the Laplacian matrix of the graph.[13] It is also the index of the first nonzero coefficient of the chromatic polynomial of a graph, and the chromatic polynomial of the whole graph can be obtained as the product of the polynomials of its components.[14] Numbers of components play a key role in the Tutte theorem characterizing graphs that have perfect matchings[15] and the associated TutteâBerge formula for the size of a maximum matching,[16] and in the definition of graph toughness.[17]

Algorithms[edit]
It is straightforward to compute the components of a graph in linear time (in terms of the numbers of the vertices and edges of the graph) using either breadth-first search or depth-first search. In either case, a search that begins at some particular vertex 
  
    
      
        v
      
    
    {\displaystyle v}
  
 will find the entire component containing 
  
    
      
        v
      
    
    {\displaystyle v}
  
 (and no more) before returning. To find all the components of a graph, loop through its vertices, starting a new breadth first or depth first search whenever the loop reaches a vertex that has not already been included in a previously found component.  Hopcroft & Tarjan (1973) describe essentially this algorithm, and state that at that point it was already "well known".[18]
Connected-component labeling, a basic technique in computer image analysis, involves the construction of a graph from the image and component analysis on the graph.
The vertices are the subset of the pixels of the image, chosen as being of interest or as likely to be part of objects depicted in the image. Edges connect adjacent pixels, with adjacency defined either orthogonally according to the Von Neumann neighborhood, or both orthogonally and diagonally according to the Moore neighborhood. Identifying the connected components of this graph and labeling them as objects allows them to be subjected to additional processing, to find more structure in those parts of the image or identify what kind of object is depicted.  Researchers in this area have developed several component-finding algorithms specialized for this type of graph, allowing it to be processed in pixel order rather than in the more scattered order that would be generated by breadth-first or depth-first searching.[19]
There are also efficient algorithms to dynamically track the components of a graph as vertices and edges are added, by using a disjoint-set data structure to keep track of the partition of the vertices into equivalence classes, replacing any two classes by their union when an edge connecting them is added. These algorithms take amortized time 
  
    
      
        O
        (
        Î±
        (
        n
        )
        )
      
    
    {\displaystyle O(\alpha (n))}
  
 per operation, where adding vertices and edges and determining the component in which a vertex falls are both operations, and 
  
    
      
        O
        (
        Î±
        (
        n
        )
        )
      
    
    {\displaystyle O(\alpha (n))}
  
  is a very slowly growing inverse of the very quickly growing Ackermann function.[20] One application of this sort of incremental connectivity algorithm is in Kruskal's algorithm for minimum spanning trees, which adds edges to a graph in sorted order by length and includes an edge in the minimum spanning tree only when it connects two different components of the previously-added subgraph.[21] When both edge insertions and edge deletions are allowed, dynamic connectivity algorithms can still maintain the same information, in amortized time 
  
    
      
        O
        (
        
          log
          
            2
          
        
        â¡
        n
        
          /
        
        log
        â¡
        log
        â¡
        n
        )
      
    
    {\displaystyle O(\log ^{2}n/\log \log n)}
  
 per change and time 
  
    
      
        O
        (
        log
        â¡
        n
        
          /
        
        log
        â¡
        log
        â¡
        n
        )
      
    
    {\displaystyle O(\log n/\log \log n)}
  
 per connectivity query,[22] or in near-logarithmic randomized expected time.[23]
Components of graphs have been used in computational complexity theory to study the power of Turing machines that have a working memory limited to a logarithmic number of bits, with the much larger input accessible only through read access rather than being modifiable. The problems that can be solved by machines limited in this way define the complexity class L. It was unclear for many years whether connected components could be found in this model, when formalized as a decision problem of testing whether two vertices belong to the same component, and in 1982 a related complexity class, SL, was defined to include this connectivity problem and any other problem equivalent to it under logarithmic-space reductions.[24] Finally, in 2008, it was proven that this connectivity problem can be solved in logarithmic space, and therefore that SL = L.[25]
In a graph represented as an adjacency list, with random access to its vertices, it is possible to estimate the number of connected components, with constant probability of obtaining additive (absolute) error at most 
  
    
      
        Îµ
        n
      
    
    {\displaystyle \varepsilon n}
  
, in sublinear time 
  
    
      
        O
        (
        
          Îµ
          
            â
            2
          
        
        log
        â¡
        
          Îµ
          
            â
            1
          
        
        )
      
    
    {\displaystyle O(\varepsilon ^{-2}\log \varepsilon ^{-1})}
  
.[26]

In random graphs[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Giant component
In random graphs the sizes of components are given by a random variable, which, in turn, depends on the specific model of how random graphs are chosen. 
In the 
  
    
      
        G
        (
        n
        ,
        p
        )
      
    
    {\displaystyle G(n,p)}
  
 version of the ErdÅsâRÃ©nyiâGilbert model, a graph on 
  
    
      
        n
      
    
    {\displaystyle n}
  
 vertices is generated by choosing randomly and independently for each pair of vertices whether to include an edge connecting that pair, with probability 
  
    
      
        p
      
    
    {\displaystyle p}
  
 of including an edge and probability 
  
    
      
        1
        â
        p
      
    
    {\displaystyle 1-p}
  
 of leaving those two vertices without an edge connecting them.[27] The connectivity of this model depends on 
  
    
      
        p
      
    
    {\displaystyle p}
  
, and there are three different ranges of 
  
    
      
        p
      
    
    {\displaystyle p}
  
 with very different behavior from each other. In the analysis below, all outcomes occur with high probability, meaning that the probability of the outcome is arbitrarily close to one for sufficiently large values of 
  
    
      
        n
      
    
    {\displaystyle n}
  
. The analysis depends on a parameter 
  
    
      
        Îµ
      
    
    {\displaystyle \varepsilon }
  
, a positive constant which can be chosen to be arbitrarily close to zero but should not depend on the choice of 
  
    
      
        n
      
    
    {\displaystyle n}
  
.

Subcritical 
  
    
      
        p
        <
        (
        1
        â
        Îµ
        )
        
          /
        
        n
      
    
    {\displaystyle p<(1-\varepsilon )/n}
  

In this range of 
  
    
      
        p
      
    
    {\displaystyle p}
  
, all components are simple and very small. The largest component has size 
  
    
      
        
          |
        
        
          C
          
            1
          
        
        
          |
        
        =
        O
        (
        log
        â¡
        n
        )
      
    
    {\displaystyle |C_{1}|=O(\log n)}
  
. The graph is a pseudoforest. Most of its components are trees: the number of vertices in components that have cycles grows more slowly than any unbounded function of 
  
    
      
        n
      
    
    {\displaystyle n}
  
. Every tree of fixed size occurs linearly many times.[28]
Critical 
  
    
      
        p
        =
        1
        
          /
        
        n
      
    
    {\displaystyle p=1/n}
  

There is a single giant component with 
  
    
      
        
          |
        
        
          C
          
            1
          
        
        
          |
        
        =
        O
        (
        
          n
          
            2
            
              /
            
            3
          
        
        )
      
    
    {\displaystyle |C_{1}|=O(n^{2/3})}
  
; the remaining components are small, with size 
  
    
      
        O
        (
        log
        â¡
        n
        )
      
    
    {\displaystyle O(\log n)}
  
.[29]
Supercritical 
  
    
      
        p
        >
        (
        1
        +
        Îµ
        )
        
          /
        
        n
      
    
    {\displaystyle p>(1+\varepsilon )/n}
  

The size of the giant component becomes linear, and for large values of 
  
    
      
        p
      
    
    {\displaystyle p}
  
 approaches the whole graph: 
  
    
      
        
          |
        
        
          C
          
            1
          
        
        
          |
        
        â
        y
        n
      
    
    {\displaystyle |C_{1}|\approx yn}
  
 where 
  
    
      
        y
        =
        y
        (
        n
        p
        )
      
    
    {\displaystyle y=y(np)}
  
 is the positive solution to the equation 
  
    
      
        
          e
          
            â
            p
            n
            y
          
        
        =
        1
        â
        y
      
    
    {\displaystyle e^{-pny}=1-y}
  
. Again, all remaining components are small.[30]
In the same model of random graphs, there will exist multiple connected components with high probability for values of 
  
    
      
        p
      
    
    {\displaystyle p}
  
 below a significantly higher threshold, 
  
    
      
        p
        <
        (
        1
        â
        Îµ
        )
        (
        log
        â¡
        n
        )
        
          /
        
        n
      
    
    {\displaystyle p<(1-\varepsilon )(\log n)/n}
  
, and a single connected component for values above the threshold, 
  
    
      
        p
        >
        (
        1
        +
        Îµ
        )
        (
        log
        â¡
        n
        )
        
          /
        
        n
      
    
    {\displaystyle p>(1+\varepsilon )(\log n)/n}
  
. This phenomenon is closely related to the coupon collector's problem: in order to be connected, a random graph needs enough edges for each vertex to be incident to at least one edge. More precisely, if random edges are added one by one to a graph, then with high probability the first edge whose addition connects the whole graph touches the last isolated vertex.[31]
For different models including the random subgraphs of grid graphs, the connected components are described by percolation theory. A key question in this theory is the existence of a percolation threshold, a critical probability above which a giant component (or infinite component) exists and below which it does not.[32]

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Clark, John; Holton, Derek Allan (1995), A First Look at Graph Theory, Allied Publishers, p.Â 28, ISBNÂ 9788170234630

^ Joyner, David; Nguyen, Minh Van; Phillips, David (May 10, 2013), "1.6.1 Union, intersection, and join", Algorithmic Graph Theory and Sage (0.8-r1991Â ed.), Google, pp.Â 34â35

^ Jump up to: a b Tutte, W. T. (1984), Graph Theory, Encyclopedia of Mathematics and its Applications, vol.Â 21, Reading, Massachusetts: Addison-Wesley, p.Â 15, ISBNÂ 0-201-13520-5, MRÂ 0746795

^ Jump up to: a b Thulasiraman, K.; Swamy, M. N. S. (2011), Graphs: Theory and Algorithms, John Wiley & Sons, p.Â 9, ISBNÂ 978-1-118-03025-7

^ BollobÃ¡s, BÃ©la (1998), Modern Graph Theory, Graduate Texts in Mathematics, vol.Â 184, New York: Springer-Verlag, p.Â 6, doi:10.1007/978-1-4612-0619-4, ISBNÂ 0-387-98488-7, MRÂ 1633290

^ McColl, W. F.; Noshita, K. (1986), "On the number of edges in the transitive closure of a graph", Discrete Applied Mathematics, 15 (1): 67â73, doi:10.1016/0166-218X(86)90020-X, MRÂ 0856101

^ Foldes, Stephan (2011), Fundamental Structures of Algebra and Discrete Mathematics, John Wiley & Sons, p.Â 199, ISBNÂ 978-1-118-03143-8

^ Siek, Jeremy; Lee, Lie-Quan; Lumsdaine, Andrew (2001), "7.1 Connected components: Definitions", The Boost Graph Library: User Guide and Reference Manual, Addison-Wesley, pp.Â 97â98

^ Lewis, Harry; Zax, Rachel (2019), Essential Discrete Mathematics for Computer Science, Princeton University Press, p.Â 145, ISBNÂ 978-0-691-19061-7

^ Kozen, Dexter C. (1992), "4.1 Biconnected components", The Design and Analysis of Algorithms, Texts and Monographs in Computer Science, New York: Springer-Verlag, pp.Â 20â22, doi:10.1007/978-1-4612-4400-4, ISBNÂ 0-387-97687-6, MRÂ 1139767

^ Wilson, R. J. (1973), "An introduction to matroid theory", The American Mathematical Monthly, 80: 500â525, doi:10.1080/00029890.1973.11993318, JSTORÂ 2319608, MRÂ 0371694

^ Wood, David R. (2014), "Three-dimensional graph drawing",  in Kao, Ming-Yang (ed.), Encyclopedia of Algorithms (PDF), Springer, pp.Â 1â7, doi:10.1007/978-3-642-27848-8_656-1

^ CioabÄ, Sebastian M. (2011), "Some applications of eigenvalues of graphs",  in Dehmer, Matthias (ed.), Structural Analysis of Complex Networks, New York: BirkhÃ¤user/Springer, pp.Â 357â379, doi:10.1007/978-0-8176-4789-6_14, MRÂ 2777924; see proof of Lemma 5, p. 361

^ Read, Ronald C. (1968), "An introduction to chromatic polynomials", Journal of Combinatorial Theory, 4: 52â71, doi:10.1016/S0021-9800(68)80087-0, MRÂ 0224505; see Theorem 2, p. 59, and corollary, p. 65

^ Tutte, W. T. (1947), "The factorization of linear graphs", The Journal of the London Mathematical Society, 22: 107â111, doi:10.1112/jlms/s1-22.2.107, MRÂ 0023048

^ Berge, Claude (1958), "Sur le couplage maximum d'un graphe", Comptes Rendus Hebdomadaires des SÃ©ances de l'AcadÃ©mie des Sciences, 247: 258â259, MRÂ 0100850

^ ChvÃ¡tal, VÃ¡clav (1973), "Tough graphs and Hamiltonian circuits", Discrete Mathematics, 5 (3): 215â228, doi:10.1016/0012-365X(73)90138-6, MRÂ 0316301

^ Hopcroft, John; Tarjan, Robert (June 1973), "Algorithm 447: efficient algorithms for graph manipulation", Communications of the ACM, 16 (6): 372â378, doi:10.1145/362248.362272

^ Dillencourt, Michael B.; Samet, Hanan; Tamminen, Markku (1992), "A general approach to connected-component labeling for arbitrary image representations", Journal of the ACM, 39 (2): 253â280, doi:10.1145/128749.128750, MRÂ 1160258

^ Bengelloun, Safwan Abdelmajid (December 1982), Aspects of Incremental Computing (PhD thesis), Yale University, p.Â 12, ProQuestÂ 303248045

^ Skiena, Steven (2008), "6.1.2 Kruskal's Algorithm", The Algorithm Design Manual, Springer, pp.Â 196â198, doi:10.1007/978-1-84800-070-4, ISBNÂ 978-1-84800-069-8

^ Wulff-Nilsen, Christian (2013), "Faster deterministic fully-dynamic graph connectivity",  in Khanna, Sanjeev (ed.), Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2013, New Orleans, Louisiana, USA, January 6-8, 2013, pp.Â 1757â1769, arXiv:1209.5608, doi:10.1137/1.9781611973105.126

^ Huang, Shang-En; Huang, Dawei; Kopelowitz, Tsvi; Pettie, Seth (2017), "Fully dynamic connectivity in 
  
    
      
        O
        
          
            (
          
        
        log
        â¡
        n
        (
        log
        â¡
        log
        â¡
        n
        
          )
          
            2
          
        
        
          
            )
          
        
      
    
    {\displaystyle O{\bigl (}\log n(\log \log n)^{2}{\bigr )}}
  
 amortized expected time",  in Klein, Philip N. (ed.), Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2017, Barcelona, Spain, Hotel Porta Fira, January 16-19, pp.Â 510â520, arXiv:1609.05867, doi:10.1137/1.9781611974782.32

^ Lewis, Harry R.; Papadimitriou, Christos H. (1982), "Symmetric space-bounded computation", Theoretical Computer Science, 19 (2): 161â187, doi:10.1016/0304-3975(82)90058-5, MRÂ 0666539

^ Reingold, Omer (2008), "Undirected connectivity in log-space", Journal of the ACM, 55 (4): A17:1âA17:24, doi:10.1145/1391289.1391291, MRÂ 2445014

^ Berenbrink, Petra; Krayenhoff, Bruce; Mallmann-Trenn, Frederik (2014), "Estimating the number of connected components in sublinear time", Information Processing Letters, 114 (11): 639â642, doi:10.1016/j.ipl.2014.05.008, MRÂ 3230913

^ Frieze, Alan; KaroÅski, MichaÅ (2016), "1.1 Models and relationships", Introduction to Random Graphs, Cambridge University Press, Cambridge, pp.Â 3â9, doi:10.1017/CBO9781316339831, ISBNÂ 978-1-107-11850-8, MRÂ 3675279

^ Frieze & KaroÅski (2016), 2.1 Sub-critical phase, pp. 20â33; see especially Theorem 2.8, p. 26, Theorem 2.9, p. 28, and Lemma 2.11, p. 29

^ Frieze & KaroÅski (2016), 2.3 Phase transition, pp. 39â45

^ Frieze & KaroÅski (2016), 2.2 Super-critical phase, pp. 33; see especially Theorem 2.14, p. 33â39

^ Frieze & KaroÅski (2016), 4.1 Connectivity, pp. 64â68

^ Cohen, Reuven; Havlin, Shlomo (2010), "10.1 Percolation on complex networks: Introduction", Complex Networks: Structure, Robustness and Function, Cambridge University Press, pp.Â 97â98, ISBNÂ 978-1-139-48927-0


External links[edit]
MATLAB code to find components in undirected graphs, MATLAB File Exchange.
Connected components, Steven Skiena, The Stony Brook Algorithm Repository




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Component_(graph_theory)&oldid=1066146866"
		Categories: Graph connectivityGraph theory objectsHidden categories: Articles with short descriptionShort description is different from Wikidata
	
