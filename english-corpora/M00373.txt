In mathematics, the tensor algebra of a vector space V, denoted T(V) or T•(V), is the algebra of tensors on V (of any rank) with multiplication being the tensor product. It is the free algebra on V, in the sense of being left adjoint to the forgetful functor from algebras to vector spaces: it is the "most general" algebra containing V, in the sense of the corresponding universal property (see below).The tensor algebra is important because many other algebras arise as quotient algebras of T(V).  These include the exterior algebra, the symmetric algebra, Clifford algebras, the Weyl algebra and universal enveloping algebras.The tensor algebra also has two coalgebra structures; one simple one, which does not make it a bialgebra, but does lead to the concept of a cofree coalgebra, and a more complicated one, which yields a bialgebra, and can be extended by giving an antipode to create a Hopf algebra structure.Note: In this article, all algebras are assumed to be unital and associative. The unit is explicitly required to define the coproduct. Construction Let V be a vector space over a field K. For any nonnegative integer k, we define the kth tensor power of V to be the tensor product of V with itself k times:                              T                      k                          V        =                  V                      ⊗            k                          =        V        ⊗        V        ⊗        ⋯        ⊗        V        .              {\displaystyle T^{k}V=V^{\otimes k}=V\otimes V\otimes \cdots \otimes V.}  That is, TkV consists of all tensors on V of order k. By convention T0V is the ground field K (as a one-dimensional vector space over itself).We then construct T(V) as the direct sum of TkV for k = 0,1,2,…                    T        (        V        )        =                  ⨁                      k            =            0                                ∞                                    T                      k                          V        =        K        ⊕        V        ⊕        (        V        ⊗        V        )        ⊕        (        V        ⊗        V        ⊗        V        )        ⊕        ⋯        .              {\displaystyle T(V)=\bigoplus _{k=0}^{\infty }T^{k}V=K\oplus V\oplus (V\otimes V)\oplus (V\otimes V\otimes V)\oplus \cdots .}  The multiplication in T(V) is determined by the canonical isomorphism                              T                      k                          V        ⊗                  T                      ℓ                          V        →                  T                      k            +            ℓ                          V              {\displaystyle T^{k}V\otimes T^{\ell }V\to T^{k+\ell }V}  given by the tensor product, which is then extended by linearity to all of T(V). This multiplication rule implies that the tensor algebra T(V) is naturally a graded algebra with TkV serving as the grade-k subspace. This grading can be extended to a Z grading by appending subspaces                               T                      k                          V        =        {        0        }              {\displaystyle T^{k}V=\{0\}}   for negative integers k.The construction generalizes in a straightforward manner to the tensor algebra of any module M over a commutative ring. If R is a non-commutative ring, one can still perform the construction for any R-R bimodule M. (It does not work for ordinary R-modules because the iterated tensor products cannot be formed.) Adjunction and universal property The tensor algebra T(V) is also called the free algebra on the vector space V, and is functorial; this means that the map                     V        ↦        T        (        V        )              {\displaystyle V\mapsto T(V)}   extends to linear maps for forming a functor from the category of K-vector spaces to the category of associative algebra. Similarly with other free constructions, the functor T is left adjoint to the forgetful functor  that sends each associative K-algebra to its underlying vector space.Explicitly, the tensor algebra satisfies the following universal property, which formally expresses the statement that it is the most general algebra containing V:Any linear map                     f        :        V        →        A              {\displaystyle f:V\to A}   from V to an associative algebra A over K can be uniquely extended to an algebra homomorphism from T(V) to A as indicated by the following commutative diagram:Here i is the canonical inclusion of V into T(V). As for other universal properties, the tensor algebra T(V) can be definied as the unique algebra satisfying this property (specifically, it is unique up to a unique isomorphism), but this definition requires to prove that an object satisfying this property exists.The above universal property implies that  T is a functor from  the category of vector spaces over K, to the category of K-algebras. This means that any linear map between K-vector spaces U and W extends uniquely to a K-algebra homomorphism from T(U) to T(W). Non-commutative polynomials If V has finite dimension n, another way of looking at the tensor algebra is as the "algebra of polynomials over K in n non-commuting variables". If we take basis vectors for V, those become non-commuting variables (or indeterminates) in T(V), subject to no constraints beyond associativity, the distributive law and K-linearity.Note that the algebra of polynomials on V is not                     T        (        V        )              {\displaystyle T(V)}  , but rather                     T        (                  V                      ∗                          )              {\displaystyle T(V^{*})}  : a (homogeneous) linear function on V is an element of                               V                      ∗                          ,              {\displaystyle V^{*},}   for example coordinates                               x                      1                          ,        …        ,                  x                      n                                {\displaystyle x^{1},\dots ,x^{n}}   on a vector space are covectors, as they take in a vector and give out a scalar (the given coordinate of the vector). Quotients Because of the generality of the tensor algebra, many other algebras of interest can be constructed by starting with the tensor algebra and then imposing certain relations on the generators, i.e. by constructing certain quotient algebras of T(V).  Examples of this are the exterior algebra, the symmetric algebra, Clifford algebras, the Weyl algebra and universal enveloping algebras. Coalgebra The tensor algebra has two different coalgebra structures. One is compatible with the tensor product, and thus can be extended to a bialgebra, and can be further be extended with an antipode to a Hopf algebra structure. The other structure, although simpler, cannot be extended to a bialgebra. The first structure is developed immediately below; the second structure is given in the section on the cofree coalgebra, further down.The development provided below can be equally well applied to the exterior algebra, using the wedge symbol                     ∧              {\displaystyle \wedge }   in place of the tensor symbol                     ⊗              {\displaystyle \otimes }  ; a sign must also be kept track of, when permuting elements of the exterior algebra. This correspondence also lasts through the definition of the bialgebra, and on to the definition of a Hopf algebra. That is, the exterior algebra can also be given a Hopf algebra structure.Similarly, the symmetric algebra can also be given the structure of a Hopf algebra, in exactly the same fashion, by replacing everywhere the tensor product                     ⊗              {\displaystyle \otimes }   by the symmetrized tensor product                               ⊗                                    S              y              m                                            {\displaystyle \otimes _{\mathrm {Sym} }}  , i.e. that product where                     v                  ⊗                                    S              y              m                                      w        =        w                  ⊗                                    S              y              m                                      v        .              {\displaystyle v\otimes _{\mathrm {Sym} }w=w\otimes _{\mathrm {Sym} }v.}  In each case, this is possible because the alternating product                     ∧              {\displaystyle \wedge }   and the symmetric product                               ⊗                                    S              y              m                                            {\displaystyle \otimes _{\mathrm {Sym} }}   obey the required consistency conditions for the definition of a bialgebra and Hopf algebra; this can be explicitly checked in the manner below. Whenever one has a product obeying these consistency conditions, the construction goes thorough; insofar as such a product gave rise to a quotient space, the quotient space inherits the Hopf algebra structure.In the language of category theory, one says that there is a functor T from the category of K-vector spaces to the category of K-associate algebras. But there is also a functor Λ taking vector spaces to the category of exterior algebras, and a functor Sym taking vector spaces to symmetric algebras. There is a natural map from T to each of these. Verifying that quotienting preserves the Hopf algebra structure is the same as verifying that the maps are indeed natural.= Coproduct =The coalgebra is obtained by defining a coproduct or diagonal operator                    Δ        :        T        V        →        T        V        ⊠        T        V              {\displaystyle \Delta :TV\to TV\boxtimes TV}  Here,                     T        V              {\displaystyle TV}   is used as a short-hand for                     T        (        V        )              {\displaystyle T(V)}   to avoid an explosion of parentheses. The                     ⊠              {\displaystyle \boxtimes }   symbol is used to denote the "external" tensor product, needed for the definition of a coalgebra.  It is being used to distinguish it from the "internal" tensor product                     ⊗              {\displaystyle \otimes }  , which is already being used to denote multiplication in the tensor algebra (see the section Multiplication, below, for further clarification on this issue). In order to avoid confusion between these two symbols, most texts will replace                     ⊗              {\displaystyle \otimes }   by a plain dot, or even drop it altogether, with the understanding that it is implied from context. This then allows the                     ⊗              {\displaystyle \otimes }   symbol to be used in place of the                     ⊠              {\displaystyle \boxtimes }   symbol. This is not done below, and the two symbols are used independently and explicitly, so as to show the proper location of each.  The result is a bit more verbose, but should be easier to comprehend.The definition of the operator                     Δ              {\displaystyle \Delta }   is most easily built up in stages, first by defining it for elements                     v        ∈        V        ⊂        T        V              {\displaystyle v\in V\subset TV}   and then by homomorphically extending it to the whole algebra.  A suitable choice for the coproduct is then                    Δ        :        v        ↦        v        ⊠        1        +        1        ⊠        v              {\displaystyle \Delta :v\mapsto v\boxtimes 1+1\boxtimes v}  and                    Δ        :        1        ↦        1        ⊠        1              {\displaystyle \Delta :1\mapsto 1\boxtimes 1}  where                     1        ∈        K        =                  T                      0                          V        ⊂        T        V              {\displaystyle 1\in K=T^{0}V\subset TV}   is the unit of the field                     K              {\displaystyle K}  . By linearity, one obviously has                    Δ        (        k        )        =        k        (        1        ⊠        1        )        =        k        ⊠        1        =        1        ⊠        k              {\displaystyle \Delta (k)=k(1\boxtimes 1)=k\boxtimes 1=1\boxtimes k}  for all                     k        ∈        K        .              {\displaystyle k\in K.}   It is straightforward to verify that this definition satisfies the axioms of a coalgebra: that is, that                    (                              i            d                                T            V                          ⊠        Δ        )        ∘        Δ        =        (        Δ        ⊠                              i            d                                T            V                          )        ∘        Δ              {\displaystyle (\mathrm {id} _{TV}\boxtimes \Delta )\circ \Delta =(\Delta \boxtimes \mathrm {id} _{TV})\circ \Delta }  where                                           i            d                                T            V                          :        x        ↦        x              {\displaystyle \mathrm {id} _{TV}:x\mapsto x}   is the identity map on                     T        V              {\displaystyle TV}  .  Indeed, one gets                    (        (                              i            d                                T            V                          ⊠        Δ        )        ∘        Δ        )        (        v        )        =        v        ⊠        1        ⊠        1        +        1        ⊠        v        ⊠        1        +        1        ⊠        1        ⊠        v              {\displaystyle ((\mathrm {id} _{TV}\boxtimes \Delta )\circ \Delta )(v)=v\boxtimes 1\boxtimes 1+1\boxtimes v\boxtimes 1+1\boxtimes 1\boxtimes v}  and likewise for the other side. At this point, one could invoke a lemma, and say that                     Δ              {\displaystyle \Delta }   extends trivially, by linearity, to all of                     T        V              {\displaystyle TV}  , because                     T        V              {\displaystyle TV}   is a free object and                     V              {\displaystyle V}   is a generator of the free algebra, and                     Δ              {\displaystyle \Delta }   is a homomorphism. However, it is insightful to provide explicit expressions. So, for                     v        ⊗        w        ∈                  T                      2                          V              {\displaystyle v\otimes w\in T^{2}V}  , one has (by definition) the homomorphism                    Δ        :        v        ⊗        w        ↦        Δ        (        v        )        ⊗        Δ        (        w        )              {\displaystyle \Delta :v\otimes w\mapsto \Delta (v)\otimes \Delta (w)}  Expanding, one has                                                                        Δ                (                v                ⊗                w                )                                                            =                (                v                ⊠                1                +                1                ⊠                v                )                ⊗                (                w                ⊠                1                +                1                ⊠                w                )                                                                                                  =                (                v                ⊗                w                )                ⊠                1                +                v                ⊠                w                +                w                ⊠                v                +                1                ⊠                (                v                ⊗                w                )                                                          {\displaystyle {\begin{aligned}\Delta (v\otimes w)&=(v\boxtimes 1+1\boxtimes v)\otimes (w\boxtimes 1+1\boxtimes w)\\&=(v\otimes w)\boxtimes 1+v\boxtimes w+w\boxtimes v+1\boxtimes (v\otimes w)\end{aligned}}}  In the above expansion, there is no need to ever write                     1        ⊗        v              {\displaystyle 1\otimes v}   as this is just plain-old scalar multiplication in the algebra; that is, one trivially has that                     1        ⊗        v        =        1        ⋅        v        =        v        .              {\displaystyle 1\otimes v=1\cdot v=v.}  The extension above preserves the algebra grading. That is,                    Δ        :                  T                      2                          V        →                  ⨁                      k            =            0                                2                                    T                      k                          V        ⊠                  T                      (            2            −            k            )                          V              {\displaystyle \Delta :T^{2}V\to \bigoplus _{k=0}^{2}T^{k}V\boxtimes T^{(2-k)}V}  Continuing in this fashion, one can obtain an explicit expression for the coproduct acting on a homogenous element of order m:                                                                        Δ                (                                  v                                      1                                                  ⊗                ⋯                ⊗                                  v                                      m                                                  )                                                            =                Δ                (                                  v                                      1                                                  )                ⊗                ⋯                ⊗                Δ                (                                  v                                      m                                                  )                                                                                                  =                                  ∑                                      p                    =                    0                                                        m                                                                    (                                                            v                                              0                                                              ⊗                    ⋯                    ⊗                                          v                                              p                                                                              )                                                ω                                                  (                                                            v                                              p                        +                        1                                                              ⊗                    ⋯                    ⊗                                          v                                              m                                                                              )                                                                                                                  =                                  ∑                                      p                    =                    0                                                        m                                                                                    ∑                                      σ                    ∈                                          S                      h                                        (                    p                    ,                    m                    −                    p                    +                    1                    )                                                                                    (                                                            v                                              σ                        (                        0                        )                                                              ⊗                    ⋯                    ⊗                                          v                                              σ                        (                        p                        )                                                                              )                                ⊠                                  (                                                            v                                              σ                        (                        p                        +                        1                        )                                                              ⊗                    ⋯                    ⊗                                          v                                              σ                        (                        m                        )                                                                              )                                                                          {\displaystyle {\begin{aligned}\Delta (v_{1}\otimes \cdots \otimes v_{m})&=\Delta (v_{1})\otimes \cdots \otimes \Delta (v_{m})\\&=\sum _{p=0}^{m}\left(v_{0}\otimes \cdots \otimes v_{p}\right)\;\omega \;\left(v_{p+1}\otimes \cdots \otimes v_{m}\right)\\&=\sum _{p=0}^{m}\;\sum _{\sigma \in \mathrm {Sh} (p,m-p+1)}\;\left(v_{\sigma (0)}\otimes \dots \otimes v_{\sigma (p)}\right)\boxtimes \left(v_{\sigma (p+1)}\otimes \dots \otimes v_{\sigma (m)}\right)\end{aligned}}}  where the                     ω              {\displaystyle \omega }   symbol, which should appear as ш, the sha, denotes the shuffle product. This is expressed in the second summation, which is taken over all (p + 1, m − p)-shuffles.  The above is written with a notational trick, to keep track of the field element 1: the trick is to write                               v                      0                          =        1              {\displaystyle v_{0}=1}  , and this is shuffled into various locations during the expansion of the sum over shuffles.  The shuffle follows directly from the first axiom of a co-algebra: the relative order of the elements                               v                      k                                {\displaystyle v_{k}}   is preserved in the riffle shuffle: the riffle shuffle merely splits the ordered sequence into two ordered sequences, one on the left, and one on the right. Any one given shuffle obeys                    σ        (        0        )        <        ⋯        <        σ        (        p        )                                       and                                   σ        (        p        +        1        )        <        ⋯        <        σ        (        m        )              {\displaystyle \sigma (0)<\cdots <\sigma (p)\quad {\mbox{ and }}\quad \sigma (p+1)<\cdots <\sigma (m)}  As before, the algebra grading is preserved:                    Δ        :                  T                      m                          V        →                  ⨁                      k            =            0                                m                                    T                      k                          V        ⊠                  T                      (            m            −            k            )                          V              {\displaystyle \Delta :T^{m}V\to \bigoplus _{k=0}^{m}T^{k}V\boxtimes T^{(m-k)}V}  = Counit =The counit                     ϵ        :        T        V        →        K              {\displaystyle \epsilon :TV\to K}   is given by the projection of the field component out from the algebra. This can be written as                     ϵ        :        v        ↦        0              {\displaystyle \epsilon :v\mapsto 0}   for                     v        ∈        V              {\displaystyle v\in V}   and                     ϵ        :        k        ↦        k              {\displaystyle \epsilon :k\mapsto k}   for                     k        ∈        K        =                  T                      0                          V              {\displaystyle k\in K=T^{0}V}  .  By homomorphism under the tensor product                     ⊗              {\displaystyle \otimes }  , this extends to                     ϵ        :        x        ↦        0              {\displaystyle \epsilon :x\mapsto 0}  for all                     x        ∈                  T                      1                          V        ⊕                  T                      2                          V        ⊕        ⋯              {\displaystyle x\in T^{1}V\oplus T^{2}V\oplus \cdots }  It is a straightforward matter to verify that this counit satisfies the needed axiom for the coalgebra:                    (                  i          d                ⊠        ϵ        )        ∘        Δ        =                  i          d                =        (        ϵ        ⊠                  i          d                )        ∘        Δ        .              {\displaystyle (\mathrm {id} \boxtimes \epsilon )\circ \Delta =\mathrm {id} =(\epsilon \boxtimes \mathrm {id} )\circ \Delta .}  Working this explicitly, one has                                                                        (                (                                  i                  d                                ⊠                ϵ                )                ∘                Δ                )                (                x                )                                                            =                (                                  i                  d                                ⊠                ϵ                )                (                1                ⊠                x                +                x                ⊠                1                )                                                                                                  =                1                ⊠                ϵ                (                x                )                +                x                ⊠                ϵ                (                1                )                                                                                                  =                0                +                x                ⊠                1                                                                                                  ≅                x                                                          {\displaystyle {\begin{aligned}((\mathrm {id} \boxtimes \epsilon )\circ \Delta )(x)&=(\mathrm {id} \boxtimes \epsilon )(1\boxtimes x+x\boxtimes 1)\\&=1\boxtimes \epsilon (x)+x\boxtimes \epsilon (1)\\&=0+x\boxtimes 1\\&\cong x\end{aligned}}}  where, for the last step, one has made use of the isomorphism                     T        V        ⊠        K        ≅        T        V              {\displaystyle TV\boxtimes K\cong TV}  , as is appropriate for the defining axiom of the counit. Bialgebra A bialgebra defines both multiplication, and comultiplication, and requires them to be compatible.= Multiplication =Multiplication is given by an operator                    ∇        :        T        V        ⊠        T        V        →        T        V              {\displaystyle \nabla :TV\boxtimes TV\to TV}  which, in this case, was already given as the "internal" tensor product. That is,                    ∇        :        x        ⊠        y        ↦        x        ⊗        y              {\displaystyle \nabla :x\boxtimes y\mapsto x\otimes y}  That is,                     ∇        (        x        ⊠        y        )        =        x        ⊗        y        .              {\displaystyle \nabla (x\boxtimes y)=x\otimes y.}   The above should make it clear why the                     ⊠              {\displaystyle \boxtimes }   symbol needs to be used: the                     ⊗              {\displaystyle \otimes }   was actually one and the same thing as                     ∇              {\displaystyle \nabla }  ; and notational sloppiness here would lead to utter chaos.  To strengthen this: the tensor product                     ⊗              {\displaystyle \otimes }   of the tensor algebra corresponds to the multiplication                     ∇              {\displaystyle \nabla }   used in the definition of an algebra, whereas the tensor product                     ⊠              {\displaystyle \boxtimes }   is the one required in the definition of comultiplication in a coalgebra.  These two tensor products are not the same thing!= Unit =The unit for the algebra                    η        :        K        →        T        V              {\displaystyle \eta :K\to TV}  is just the embedding, so that                    η        :        k        ↦        k              {\displaystyle \eta :k\mapsto k}  That the unit is compatible with the tensor product                     ⊗              {\displaystyle \otimes }   is "trivial": it is just part of the standard definition of the tensor product of vector spaces.  That is,                     k        ⊗        x        =        k        x              {\displaystyle k\otimes x=kx}   for field element k and any                     x        ∈        T        V        .              {\displaystyle x\in TV.}    More verbosely, the axioms for an associative algebra require the two homomorphisms (or commuting diagrams):                    ∇        ∘        (        η        ⊠                              i            d                                T            V                          )        =        η        ⊗                              i            d                                T            V                          =        η        ⋅                              i            d                                T            V                                {\displaystyle \nabla \circ (\eta \boxtimes \mathrm {id} _{TV})=\eta \otimes \mathrm {id} _{TV}=\eta \cdot \mathrm {id} _{TV}}  on                     K        ⊠        T        V              {\displaystyle K\boxtimes TV}  , and that symmetrically, on                     T        V        ⊠        K              {\displaystyle TV\boxtimes K}  , that                    ∇        ∘        (                              i            d                                T            V                          ⊠        η        )        =                              i            d                                T            V                          ⊗        η        =                              i            d                                T            V                          ⋅        η              {\displaystyle \nabla \circ (\mathrm {id} _{TV}\boxtimes \eta )=\mathrm {id} _{TV}\otimes \eta =\mathrm {id} _{TV}\cdot \eta }  where the right-hand side of these equations should be understood as the scalar product.= Compatibility =The unit and counit, and multiplication and comultiplication, all have to satisfy compatibility conditions. It is straightforward to see that                     ϵ        ∘        η        =                              i            d                                K                          .              {\displaystyle \epsilon \circ \eta =\mathrm {id} _{K}.}  Similarly, the unit is compatible with comultiplication:                    Δ        ∘        η        =        η        ⊠        η        ≅        η              {\displaystyle \Delta \circ \eta =\eta \boxtimes \eta \cong \eta }  The above requires the use of the isomorphism                     K        ⊠        K        ≅        K              {\displaystyle K\boxtimes K\cong K}   in order to work; without this, one loses linearity. Component-wise,                    (        Δ        ∘        η        )        (        k        )        =        Δ        (        k        )        =        k        (        1        ⊠        1        )        ≅        k              {\displaystyle (\Delta \circ \eta )(k)=\Delta (k)=k(1\boxtimes 1)\cong k}  with the right-hand side making use of the isomorphism.Multiplication and the counit are compatible:                    (        ϵ        ∘        ∇        )        (        x        ⊠        y        )        =        ϵ        (        x        ⊗        y        )        =        0              {\displaystyle (\epsilon \circ \nabla )(x\boxtimes y)=\epsilon (x\otimes y)=0}  whenever x or y are not elements of                     K              {\displaystyle K}  , and otherwise, one has scalar multiplication on the field:                               k                      1                          ⊗                  k                      2                          =                  k                      1                                    k                      2                          .              {\displaystyle k_{1}\otimes k_{2}=k_{1}k_{2}.}    The most difficult to verify is the compatibility of multiplication and comultiplication:                    Δ        ∘        ∇        =        (        ∇        ⊠        ∇        )        ∘        (                  i          d                ⊠        τ        ⊠                  i          d                )        ∘        (        Δ        ⊠        Δ        )              {\displaystyle \Delta \circ \nabla =(\nabla \boxtimes \nabla )\circ (\mathrm {id} \boxtimes \tau \boxtimes \mathrm {id} )\circ (\Delta \boxtimes \Delta )}  where                     τ        (        x        ⊠        y        )        =        y        ⊠        x              {\displaystyle \tau (x\boxtimes y)=y\boxtimes x}   exchanges elements. The compatibility condition only needs to be verified on                     V        ⊂        T        V              {\displaystyle V\subset TV}  ; the full compatibility follows as a homomorphic extension to all of                     T        V        .              {\displaystyle TV.}   The verification is verbose but straightforward; it is not given here, except for the final result:                    (        Δ        ∘        ∇        )        (        v        ⊠        w        )        =        Δ        (        v        ⊗        w        )              {\displaystyle (\Delta \circ \nabla )(v\boxtimes w)=\Delta (v\otimes w)}  For                     v        ,        w        ∈        V        ,              {\displaystyle v,w\in V,}   an explicit expression for this was given in the coalgebra section, above. Hopf algebra The Hopf algebra adds an antipode to the bialgebra axioms.  The antipode                     S              {\displaystyle S}   on                     k        ∈        K        =                  T                      0                          V              {\displaystyle k\in K=T^{0}V}   is given by                    S        (        k        )        =        k              {\displaystyle S(k)=k}  This is sometimes called the "anti-identity". The antipode on                     v        ∈        V        =                  T                      1                          V              {\displaystyle v\in V=T^{1}V}   is given by                    S        (        v        )        =        −        v              {\displaystyle S(v)=-v}  and on                     v        ⊗        w        ∈                  T                      2                          V              {\displaystyle v\otimes w\in T^{2}V}   by                    S        (        v        ⊗        w        )        =        S        (        w        )        ⊗        S        (        v        )        =        w        ⊗        v              {\displaystyle S(v\otimes w)=S(w)\otimes S(v)=w\otimes v}  This extends homomorphically to                                                                        S                (                                  v                                      1                                                  ⊗                ⋯                ⊗                                  v                                      m                                                  )                                                            =                S                (                                  v                                      m                                                  )                ⊗                ⋯                ⊗                S                (                                  v                                      1                                                  )                                                                                                  =                (                −                1                                  )                                      m                                                                    v                                      m                                                  ⊗                ⋯                ⊗                                  v                                      1                                                                                            {\displaystyle {\begin{aligned}S(v_{1}\otimes \cdots \otimes v_{m})&=S(v_{m})\otimes \cdots \otimes S(v_{1})\\&=(-1)^{m}v_{m}\otimes \cdots \otimes v_{1}\end{aligned}}}  = Compatibility =Compatibility of the antipode with multiplication and comultiplication requires that                    ∇        ∘        (        S        ⊠                  i          d                )        ∘        Δ        =        η        ∘        ϵ        =        ∇        ∘        (                  i          d                ⊠        S        )        ∘        Δ              {\displaystyle \nabla \circ (S\boxtimes \mathrm {id} )\circ \Delta =\eta \circ \epsilon =\nabla \circ (\mathrm {id} \boxtimes S)\circ \Delta }  This is straightforward to verify componentwise on                     k        ∈        K              {\displaystyle k\in K}  :                                                                        (                ∇                ∘                (                S                ⊠                                  i                  d                                )                ∘                Δ                )                (                k                )                                                            =                (                ∇                ∘                (                S                ⊠                                  i                  d                                )                )                (                1                ⊠                k                )                                                                                                  =                ∇                (                1                ⊠                k                )                                                                                                  =                1                ⊗                k                                                                                                  =                k                                                          {\displaystyle {\begin{aligned}(\nabla \circ (S\boxtimes \mathrm {id} )\circ \Delta )(k)&=(\nabla \circ (S\boxtimes \mathrm {id} ))(1\boxtimes k)\\&=\nabla (1\boxtimes k)\\&=1\otimes k\\&=k\end{aligned}}}  Similarly, on                     v        ∈        V              {\displaystyle v\in V}  :                                                                        (                ∇                ∘                (                S                ⊠                                  i                  d                                )                ∘                Δ                )                (                v                )                                                            =                (                ∇                ∘                (                S                ⊠                                  i                  d                                )                )                (                v                ⊠                1                +                1                ⊠                v                )                                                                                                  =                ∇                (                −                v                ⊠                1                +                1                ⊠                v                )                                                                                                  =                −                v                ⊗                1                +                1                ⊗                v                                                                                                  =                −                v                +                v                                                                                                  =                0                                                          {\displaystyle {\begin{aligned}(\nabla \circ (S\boxtimes \mathrm {id} )\circ \Delta )(v)&=(\nabla \circ (S\boxtimes \mathrm {id} ))(v\boxtimes 1+1\boxtimes v)\\&=\nabla (-v\boxtimes 1+1\boxtimes v)\\&=-v\otimes 1+1\otimes v\\&=-v+v\\&=0\end{aligned}}}  Recall that                    (        η        ∘        ϵ        )        (        k        )        =        η        (        k        )        =        k              {\displaystyle (\eta \circ \epsilon )(k)=\eta (k)=k}  and that                     (        η        ∘        ϵ        )        (        x        )        =        η        (        0        )        =        0              {\displaystyle (\eta \circ \epsilon )(x)=\eta (0)=0}  for any                     x        ∈        T        V              {\displaystyle x\in TV}   that is not in                     K        .              {\displaystyle K.}  One may proceed in a similar manner, by homomorphism, verifying that the antipode inserts the appropriate cancellative signs in the shuffle, starting with the compatibility condition on                               T                      2                          V              {\displaystyle T^{2}V}   and proceeding by induction. Cofree cocomplete coalgebra One may define a different coproduct on the tensor algebra, simpler than the one given above.  It is given by                    Δ        (                  v                      1                          ⊗        ⋯        ⊗                  v                      k                          )        :=                  ∑                      j            =            0                                k                          (                  v                      0                          ⊗        ⋯        ⊗                  v                      j                          )        ⊠        (                  v                      j            +            1                          ⊗        ⋯        ⊗                  v                      k            +            1                          )              {\displaystyle \Delta (v_{1}\otimes \dots \otimes v_{k}):=\sum _{j=0}^{k}(v_{0}\otimes \dots \otimes v_{j})\boxtimes (v_{j+1}\otimes \dots \otimes v_{k+1})}  Here, as before, one uses the notational trick                               v                      0                          =                  v                      k            +            1                          =        1        ∈        K              {\displaystyle v_{0}=v_{k+1}=1\in K}   (recalling that                     v        ⊗        1        =        v              {\displaystyle v\otimes 1=v}   trivially).This coproduct gives rise to a coalgebra. It describes a coalgebra that is dual to the algebra structure on T(V∗), where V∗ denotes the dual vector space of linear maps V → F. In the same way that the tensor algebra is a free algebra, the corresponding coalgebra is termed cocomplete co-free.  With the usual product this is not a bialgebra. It can be turned into a bialgebra with the product                               v                      i                          ⋅                  v                      j                          =        (        i        ,        j        )                  v                      i            +            j                                {\displaystyle v_{i}\cdot v_{j}=(i,j)v_{i+j}}   where (i,j) denotes the binomial coefficient for                                                                         (                                                              i                  +                  j                                i                                            )                                                          {\displaystyle {\tbinom {i+j}{i}}}  . This bialgebra is known as the divided power Hopf algebra.The difference between this, and the other coalgebra is most easily seen in the                               T                      2                          V              {\displaystyle T^{2}V}   term.  Here, one has that                    Δ        (        v        ⊗        w        )        =        1        ⊠        (        v        ⊗        w        )        +        v        ⊠        w        +        (        v        ⊗        w        )        ⊠        1              {\displaystyle \Delta (v\otimes w)=1\boxtimes (v\otimes w)+v\boxtimes w+(v\otimes w)\boxtimes 1}  for                     v        ,        w        ∈        V              {\displaystyle v,w\in V}  , which is clearly missing a shuffled term, as compared to before. See also Braided vector spaceBraided Hopf algebraMonoidal categoryMultilinear algebraStanisław Lem's Love and Tensor AlgebraFock space References Bourbaki, Nicolas (1989). Algebra I. Chapters 1-3. Elements of Mathematics. Springer-Verlag. ISBN 3-540-64243-9. (See Chapter 3 §5)Serge Lang (2002), Algebra, Graduate Texts in Mathematics, vol. 211 (3rd ed.), Springer Verlag, ISBN 978-0-387-95385-4