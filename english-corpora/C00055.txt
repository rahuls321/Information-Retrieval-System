
Title:
Travelling salesman problem
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		NP-hard problem in combinatorial optimization



  Solution of a travelling salesman problem: the black line shows the shortest possible loop that connects every red dot.
The travelling salesman problem (also called the travelling salesperson problem  or TSP) asks the following question: "Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?" It is an NP-hard problem in combinatorial optimization, important in theoretical computer science and operations research.
The travelling purchaser problem and the vehicle routing problem are both generalizations of TSP.
In the theory of computational complexity, the decision version of the TSP (where given a length L, the task is to decide whether the graph has a tour of at most L) belongs to the class of NP-complete problems. Thus, it is possible that the worst-case running time for any algorithm for the TSP increases superpolynomially (but no more than exponentially) with the number of cities.
The problem was first formulated in 1930 and is one of the most intensively studied problems in optimization. It is used as a benchmark for many optimization methods. Even though the problem is computationally difficult, many heuristics and exact algorithms are known, so that some instances with tens of thousands of cities can be solved completely and even problems with millions of cities can be approximated within a small fraction of 1%.[1]
The TSP has several applications even in its purest formulation, such as planning, logistics, and the manufacture of microchips. Slightly modified, it appears as a sub-problem in many areas, such as DNA sequencing. In these applications, the concept city represents, for example, customers, soldering points, or DNA fragments, and the concept distance represents travelling times or cost, or a similarity measure between DNA fragments. The TSP also appears in astronomy, as astronomers observing many sources will want to minimize the time spent moving the telescope between the sources; in such problems, the TSP can be embedded inside an optimal control problem.[2][3] In many applications, additional constraints such as limited resources or time windows may be imposed.

.mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}Contents

1 History
2 Description

2.1 As a graph problem
2.2 Asymmetric and symmetric
2.3 Related problems


3 Integer linear programming formulations

3.1 MillerâTuckerâZemlin formulation
3.2 DantzigâFulkersonâJohnson formulation


4 Computing a solution

4.1 Exact algorithms
4.2 Heuristic and approximation algorithms

4.2.1 Constructive heuristics

4.2.1.1 The Algorithm of Christofides and Serdyukov


4.2.2 Pairwise exchange
4.2.3 k-opt heuristic, or LinâKernighan heuristics
4.2.4 V-opt heuristic
4.2.5 Randomized improvement

4.2.5.1 Ant colony optimization






5 Special cases

5.1 Metric
5.2 Euclidean
5.3 Asymmetric

5.3.1 Conversion to symmetric


5.4 Analyst's problem
5.5 Path length for random sets of points in a square

5.5.1 Upper bound
5.5.2 Lower bound




6 Computational complexity

6.1 Complexity of approximation


7 Human and animal performance
8 Natural computation
9 Benchmarks
10 Popular culture
11 See also
12 Notes
13 References
14 Further reading
15 External links



History[edit]
The origins of the travelling salesman problem are unclear. A handbook for travelling salesmen from 1832 mentions the problem and includes example tours through Germany and Switzerland, but contains no mathematical treatment.[4]

  William Rowan Hamilton
The travelling salesman problem was mathematically formulated in the 19th century by the Irish mathematician W.R. Hamilton and by the British mathematician Thomas Kirkman. Hamilton's icosian game was a recreational puzzle based on finding a Hamiltonian cycle.[5] The general form of the TSP appears to have been first studied by mathematicians during the 1930s in Vienna and at Harvard, notably by Karl Menger, who defines the problem, considers the obvious brute-force algorithm, and observes the non-optimality of the nearest neighbour heuristic:

.mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}
We denote by messenger problem (since in practice this question should be solved by each postman, anyway also by many travelers) the task to find, for finitely many points whose pairwise distances are known, the shortest route connecting the points. Of course, this problem is solvable by finitely many trials. Rules which would push the number of trials below the number of permutations of the given points, are not known. The rule that one first should go from the starting point to the closest point, then to the point closest to this, etc., in general does not yield the shortest route.[6]
It was first considered mathematically in the 1930s by Merrill M. Flood who was looking to solve a school bus routing problem.[7]
Hassler Whitney at Princeton University generated interest in the problem, which he called the "48 states problem".  The earliest publication using the phrase "travelling salesman problem" was the 1949 RAND Corporation report by Julia Robinson, "On the Hamiltonian game (a traveling salesman problem)."[8][9]
In the 1950s and 1960s, the problem became increasingly popular in scientific circles in Europe and the United States after the RAND Corporation in Santa Monica offered prizes for steps in solving the problem.[7] Notable contributions were made by George Dantzig, Delbert Ray Fulkerson and Selmer M. Johnson from the RAND Corporation, who expressed the problem as an integer linear program and developed the cutting plane method for its solution. They wrote what is considered the seminal paper on the subject in which with these new methods they solved an instance with 49 cities to optimality by constructing a tour and proving that no other tour could be shorter. Dantzig, Fulkerson and Johnson, however, speculated that given a near optimal solution we may be able to find optimality or prove optimality by adding a small number of extra inequalities (cuts). They used this idea to solve their initial 49 city problem using a string model. They found they only needed 26 cuts to come to a solution for their 49 city problem. While this paper did not give an algorithmic approach to TSP problems, the ideas that lay within it were indispensable to later creating exact solution methods for the TSP, though it would take 15 years to find an algorithmic approach in creating these cuts.[7] As well as cutting plane methods, Dantzig, Fulkerson and Johnson used branch and bound algorithms perhaps for the first time.[7]
In 1959, Jillian Beardwood, J.H. Halton and John Hammersley published an article entitled "The Shortest Path Through Many Points" in the journal of the Cambridge Philosophical Society.[10]Â The BeardwoodâHaltonâHammersley theorem provides a practical solution to the travelling salesman problem. Â The authors derived an asymptotic formula to determine the length of the shortest route for a salesman who starts at a home or office and visits a fixed number of locations before returning to the start.
In the following decades, the problem was studied by many researchers from mathematics, computer science, chemistry, physics, and other sciences. In the 1960s, however, a new approach was created, that instead of seeking optimal solutions would produce a solution whose length is provably bounded by a multiple of the optimal length, and in doing so would create lower bounds for the problem; these lower bounds would then be used with branch and bound approaches. One method of doing this was to create a minimum spanning tree of the graph and then double all its edges, which produces the bound that the length of an optimal tour is at most twice the weight of a minimum spanning tree.[7]
In 1976, Christofides and Serdyukov independently of each other made a big advance in this direction:[11] the Christofides-Serdyukov algorithm yields a solution that, in the worst case, is at most 1.5 times longer than the optimal solution. As the algorithm was simple and quick, many hoped it would give way to a near optimal solution method.  However, this hope for improvement did not immediately materialize, and Christofides-Serdyukov remained the method with the best worst-case scenario until 2011, when a (very) slightly improved approximation algorithm was developed for the subset of "graphical" TSPs.[12]  In 2020 this tiny improvement was extended to the full (metric) TSP.[13][14]
Richard M. Karp showed in 1972 that the Hamiltonian cycle problem was NP-complete, which implies the NP-hardness of TSP. This supplied a mathematical explanation for the apparent computational difficulty of finding optimal tours.
Great progress was made in the late 1970s and 1980, when GrÃ¶tschel, Padberg, Rinaldi and others managed to exactly solve instances with up to 2,392 cities, using cutting planes and branch and bound.
In the 1990s, Applegate, Bixby, ChvÃ¡tal, and Cook developed the program Concorde that has been used in many recent record solutions. Gerhard Reinelt published the TSPLIB in 1991, a collection of benchmark instances of varying difficulty, which has been used by many research groups for comparing results. In 2006, Cook and others computed an optimal tour through an 85,900-city instance given by a microchip layout problem, currently the largest solved TSPLIB instance. For many other instances with millions of cities, solutions can be found that are guaranteed to be within 2â3% of an optimal tour.[15]

Description[edit]
As a graph problem[edit]
  Symmetric TSP with four cities
TSP can be modelled as an undirected weighted graph, such that cities are the graph's vertices, paths are the graph's edges, and a path's distance is the edge's weight. It is a minimization problem starting and finishing at a specified vertex after having visited each other vertex exactly once. Often, the model is a complete graph (i.e., each pair of vertices is connected by an edge). If no path exists between two cities, adding a sufficiently long edge will complete the graph without affecting the optimal tour.

Asymmetric and symmetric[edit]
In the symmetric TSP, the distance between two cities is the same in each opposite direction, forming an undirected graph. This symmetry halves the number of possible solutions. In the asymmetric TSP, paths may not exist in both directions or the distances might be different, forming a directed graph. Traffic collisions, one-way streets, and airfares for cities with different departure and arrival fees are examples of how this symmetry could break down.

Related problems[edit]
An equivalent formulation in terms of graph theory is: Given a complete weighted graph (where the vertices would represent the cities, the edges would represent the roads, and the weights would be the cost or distance of that road), find a Hamiltonian cycle with the least weight.
The requirement of returning to the starting city does not change the computational complexity of the problem, see Hamiltonian path problem.
Another related problem is the bottleneck travelling salesman problem (bottleneck TSP): Find a Hamiltonian cycle in a weighted graph with the minimal weight of the weightiest edge. For example, avoiding narrow streets with big buses.[16] The problem is of considerable practical importance, apart from evident transportation and logistics areas. A classic example is in printed circuit manufacturing: scheduling of a route of the drill machine to drill holes in a PCB. In robotic machining or drilling applications, the "cities" are parts to machine or holes (of different sizes) to drill, and the "cost of travel" includes time for retooling the robot (single machine job sequencing problem).[17]
The generalized travelling salesman problem, also known as the "travelling politician problem", deals with "states" that have (one or more) "cities" and the salesman has to visit exactly one "city" from each "state". One application is encountered in ordering a solution to the cutting stock problem in order to minimize knife changes. Another is concerned with drilling in semiconductor manufacturing, see e.g., U.S. Patent 7,054,798. Noon and Bean demonstrated that the generalized travelling salesman problem can be transformed into a standard travelling salesman problem with the same number of cities, but a modified distance matrix.
The sequential ordering problem deals with the problem of visiting a set of cities where precedence relations between the cities exist.
A common interview question at Google is how to route data among data processing nodes; routes vary by time to transfer the data, but nodes also differ by their computing power and storage, compounding the problem of where to send data.
The travelling purchaser problem deals with a purchaser who is charged with purchasing a set of products. He can purchase these products in several cities, but at different prices and not all cities offer the same products. The objective is to find a route between a subset of the cities that minimizes total cost (travel cost + purchasing cost) and enables the purchase of all required products.
Integer linear programming formulations[edit]
The TSP can be formulated as an integer linear program.[18][19][20] Several formulations are known. Two notable formulations are the MillerâTuckerâZemlin (MTZ) formulation and the DantzigâFulkersonâJohnson (DFJ) formulation. The DFJ formulation is stronger, though the MTZ formulation is still useful in certain settings.[21][22]

MillerâTuckerâZemlin formulation[edit]
Label the cities with the numbers 
  
    
      
        1
        ,
        â¦
        ,
        n
      
    
    {\displaystyle 1,\ldots ,n}
  
 and define:


  
    
      
        
          x
          
            i
            j
          
        
        =
        
          
            {
            
              
                
                  1
                
                
                  
                    the path goes from cityÂ 
                  
                  i
                  
                    Â to cityÂ 
                  
                  j
                
              
              
                
                  0
                
                
                  
                    otherwise
                  
                
              
            
            
          
        
      
    
    {\displaystyle x_{ij}={\begin{cases}1&{\text{the path goes from city }}i{\text{ to city }}j\\0&{\text{otherwise}}\end{cases}}}
  

For 
  
    
      
        i
        =
        1
        ,
        â¦
        ,
        n
      
    
    {\displaystyle i=1,\ldots ,n}
  
, let 
  
    
      
        
          u
          
            i
          
        
      
    
    {\displaystyle u_{i}}
  
 be a dummy variable, and finally take 
  
    
      
        
          c
          
            i
            j
          
        
        >
        0
      
    
    {\displaystyle c_{ij}>0}
  
 to be the distance from city 
  
    
      
        i
      
    
    {\displaystyle i}
  
 to city 
  
    
      
        j
      
    
    {\displaystyle j}
  
. Then TSP can be written as the following integer linear programming problem:


  
    
      
        
          
            
              
                min
              
              
                
                
                  â
                  
                    i
                    =
                    1
                  
                  
                    n
                  
                
                
                  â
                  
                    j
                    â 
                    i
                    ,
                    j
                    =
                    1
                  
                  
                    n
                  
                
                
                  c
                  
                    i
                    j
                  
                
                
                  x
                  
                    i
                    j
                  
                
                :
              
              
              
            
            
              
              
                
                  x
                  
                    i
                    j
                  
                
                â
                {
                0
                ,
                1
                }
              
              
              
                i
                ,
                j
                =
                1
                ,
                â¦
                ,
                n
                ;
              
            
            
              
              
                
                  u
                  
                    i
                  
                
                â
                
                  Z
                
              
              
              
                i
                =
                2
                ,
                â¦
                ,
                n
                ;
              
            
            
              
              
                
                
                  â
                  
                    i
                    =
                    1
                    ,
                    i
                    â 
                    j
                  
                  
                    n
                  
                
                
                  x
                  
                    i
                    j
                  
                
                =
                1
              
              
              
                j
                =
                1
                ,
                â¦
                ,
                n
                ;
              
            
            
              
              
                
                
                  â
                  
                    j
                    =
                    1
                    ,
                    j
                    â 
                    i
                  
                  
                    n
                  
                
                
                  x
                  
                    i
                    j
                  
                
                =
                1
              
              
              
                i
                =
                1
                ,
                â¦
                ,
                n
                ;
              
            
            
              
              
                
                  u
                  
                    i
                  
                
                â
                
                  u
                  
                    j
                  
                
                +
                n
                
                  x
                  
                    i
                    j
                  
                
                â¤
                n
                â
                1
              
              
              
                2
                â¤
                i
                â 
                j
                â¤
                n
                ;
              
            
            
              
              
                1
                â¤
                
                  u
                  
                    i
                  
                
                â¤
                n
                â
                1
              
              
              
                2
                â¤
                i
                â¤
                n
                .
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\min &\sum _{i=1}^{n}\sum _{j\neq i,j=1}^{n}c_{ij}x_{ij}\colon &&\\&x_{ij}\in \{0,1\}&&i,j=1,\ldots ,n;\\&u_{i}\in \mathbf {Z} &&i=2,\ldots ,n;\\&\sum _{i=1,i\neq j}^{n}x_{ij}=1&&j=1,\ldots ,n;\\&\sum _{j=1,j\neq i}^{n}x_{ij}=1&&i=1,\ldots ,n;\\&u_{i}-u_{j}+nx_{ij}\leq n-1&&2\leq i\neq j\leq n;\\&1\leq u_{i}\leq n-1&&2\leq i\leq n.\end{aligned}}}
  

The first set of equalities requires that each city is arrived at from exactly one other city, and the second set of equalities requires that from each city there is a departure to exactly one other city. The last constraints enforce that there is only a single tour covering all cities, and not two or more disjointed tours that only collectively cover all cities. To prove this, it is shown below (1) that every feasible solution contains only one closed sequence of cities, and (2) that for every single tour covering all cities, there are values for the dummy variables 
  
    
      
        
          u
          
            i
          
        
      
    
    {\displaystyle u_{i}}
  
 that satisfy the constraints.  (The dummy variables indicate tour ordering, such that 
  
    
      
        
          u
          
            i
          
        
        <
        
          u
          
            j
          
        
      
    
    {\displaystyle u_{i}<u_{j}}
  
 implies city 
  
    
      
        i
      
    
    {\displaystyle i}
  
 is visited before city 
  
    
      
        j
      
    
    {\displaystyle j}
  
.  This may be accomplished by incrementing 
  
    
      
        
          u
          
            i
          
        
      
    
    {\displaystyle u_{i}}
  
 each time it is visited.)
To prove that every feasible solution contains only one closed sequence of cities, it suffices to show that every subtour in a feasible solution passes through city 1 (noting that the equalities ensure there can only be one such tour). For if we sum all the inequalities corresponding to 
  
    
      
        
          x
          
            i
            j
          
        
        =
        1
      
    
    {\displaystyle x_{ij}=1}
  
 for any subtour of k steps not passing through city 1, we obtain:


  
    
      
        n
        k
        â¤
        (
        n
        â
        1
        )
        k
        ,
      
    
    {\displaystyle nk\leq (n-1)k,}
  

which is a contradiction.
It now must be shown that for every single tour covering all cities, there are values for the dummy variables 
  
    
      
        
          u
          
            i
          
        
      
    
    {\displaystyle u_{i}}
  
 that satisfy the constraints.
Without loss of generality, define the tour as originating (and ending) at city 1. Choose 
  
    
      
        
          u
          
            i
          
        
        =
        t
      
    
    {\displaystyle u_{i}=t}
  
 if city 
  
    
      
        i
      
    
    {\displaystyle i}
  
 is visited in step 
  
    
      
        t
        (
        i
        ,
        t
        =
        1
        ,
        2
        ,
        â¦
        ,
        n
        )
      
    
    {\displaystyle t(i,t=1,2,\ldots ,n)}
  
. Then


  
    
      
        
          u
          
            i
          
        
        â
        
          u
          
            j
          
        
        â¤
        n
        â
        1
        ,
      
    
    {\displaystyle u_{i}-u_{j}\leq n-1,}
  

since 
  
    
      
        
          u
          
            i
          
        
      
    
    {\displaystyle u_{i}}
  
 can be no greater than 
  
    
      
        n
      
    
    {\displaystyle n}
  
 and 
  
    
      
        
          u
          
            j
          
        
      
    
    {\displaystyle u_{j}}
  
 can be no less than 1; hence the constraints are satisfied whenever 
  
    
      
        
          x
          
            i
            j
          
        
        =
        0.
      
    
    {\displaystyle x_{ij}=0.}
  
 For 
  
    
      
        
          x
          
            i
            j
          
        
        =
        1
      
    
    {\displaystyle x_{ij}=1}
  
, we have:


  
    
      
        
          u
          
            i
          
        
        â
        
          u
          
            j
          
        
        +
        n
        
          x
          
            i
            j
          
        
        =
        (
        t
        )
        â
        (
        t
        +
        1
        )
        +
        n
        =
        n
        â
        1
        ,
      
    
    {\displaystyle u_{i}-u_{j}+nx_{ij}=(t)-(t+1)+n=n-1,}
  

satisfying the constraint.

DantzigâFulkersonâJohnson formulation[edit]
Label the cities with the numbers 1, â¦, n and define:


  
    
      
        
          x
          
            i
            j
          
        
        =
        
          
            {
            
              
                
                  1
                
                
                  
                    the path goes from cityÂ 
                  
                  i
                  
                    Â to cityÂ 
                  
                  j
                
              
              
                
                  0
                
                
                  
                    otherwise
                  
                
              
            
            
          
        
      
    
    {\displaystyle x_{ij}={\begin{cases}1&{\text{the path goes from city }}i{\text{ to city }}j\\0&{\text{otherwise}}\end{cases}}}
  

Take 
  
    
      
        
          c
          
            i
            j
          
        
        >
        0
      
    
    {\displaystyle c_{ij}>0}
  
 to be the distance from city i to city j. Then TSP can be written as the following integer linear programming problem:


  
    
      
        
          
            
              
                min
              
              
                
                
                  â
                  
                    i
                    =
                    1
                  
                  
                    n
                  
                
                
                  â
                  
                    j
                    â 
                    i
                    ,
                    j
                    =
                    1
                  
                  
                    n
                  
                
                
                  c
                  
                    i
                    j
                  
                
                
                  x
                  
                    i
                    j
                  
                
                :
              
              
              
            
            
              
              
                
                
                  â
                  
                    i
                    =
                    1
                    ,
                    i
                    â 
                    j
                  
                  
                    n
                  
                
                
                  x
                  
                    i
                    j
                  
                
                =
                1
              
              
              
                j
                =
                1
                ,
                â¦
                ,
                n
                ;
              
            
            
              
              
                
                
                  â
                  
                    j
                    =
                    1
                    ,
                    j
                    â 
                    i
                  
                  
                    n
                  
                
                
                  x
                  
                    i
                    j
                  
                
                =
                1
              
              
              
                i
                =
                1
                ,
                â¦
                ,
                n
                ;
              
            
            
              
              
                
                
                  â
                  
                    i
                    â
                    Q
                  
                
                
                  
                    â
                    
                      j
                      â 
                      i
                      ,
                      j
                      â
                      Q
                    
                  
                  
                    
                      x
                      
                        i
                        j
                      
                    
                  
                
                â¤
                
                  |
                
                Q
                
                  |
                
                â
                1
              
              
              
                â
                Q
                â
                {
                1
                ,
                â¦
                ,
                n
                }
                ,
                
                  |
                
                Q
                
                  |
                
                â¥
                2
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\min &\sum _{i=1}^{n}\sum _{j\neq i,j=1}^{n}c_{ij}x_{ij}\colon &&\\&\sum _{i=1,i\neq j}^{n}x_{ij}=1&&j=1,\ldots ,n;\\&\sum _{j=1,j\neq i}^{n}x_{ij}=1&&i=1,\ldots ,n;\\&\sum _{i\in Q}{\sum _{j\neq i,j\in Q}{x_{ij}}}\leq |Q|-1&&\forall Q\subsetneq \{1,\ldots ,n\},|Q|\geq 2\\\end{aligned}}}
  

The last constraint of the DFJ formulation ensures no proper subset Q can form a sub-tour, so the solution returned is a single tour and not the union of smaller tours. Because this leads to an exponential number of possible constraints, in practice it is solved with delayed column generation.[23]

Computing a solution[edit]
The traditional lines of attack for the NP-hard problems are the following:

Devising exact algorithms, which work reasonably fast only for small problem sizes.
Devising "suboptimal" or heuristic algorithms, i.e., algorithms that deliver approximated solutions in a reasonable time.
Finding special cases for the problem ("subproblems") for which either better or exact heuristics are possible.
Exact algorithms[edit]
The most direct solution would be to try all permutations (ordered combinations) and see which one is cheapest (using brute-force search). The running time for this approach lies within a polynomial factor of 
  
    
      
        O
        (
        n
        !
        )
      
    
    {\displaystyle O(n!)}
  
, the factorial of the number of cities, so this solution becomes impractical even for only 20 cities.
One of the earliest applications of dynamic programming is the HeldâKarp algorithm that solves the problem in time 
  
    
      
        O
        (
        
          n
          
            2
          
        
        
          2
          
            n
          
        
        )
      
    
    {\displaystyle O(n^{2}2^{n})}
  
.[24] This bound has also been reached by Exclusion-Inclusion in an attempt preceding the dynamic programming approach.

  Solution to a symmetric TSP with 7 cities using brute force search. Note: Number of permutations: (7â1)!/2 = 360
Improving these time bounds seems to be difficult. For example, it has not been determined whether an exact algorithm for TSP that runs in time 
  
    
      
        O
        (
        
          1.9999
          
            n
          
        
        )
      
    
    {\displaystyle O(1.9999^{n})}
  
 exists.[25]
Other approaches include:

Various branch-and-bound algorithms, which can be used to process TSPs containing 40â60 cities.
  Solution of a TSP with 7 cities using a simple Branch and bound algorithm. Note: The number of permutations is much less than Brute force search
Progressive improvement algorithms which use techniques reminiscent of linear programming. Works well for up to 200 cities.
Implementations of branch-and-bound and problem-specific cut generation (branch-and-cut[26]); this is the method of choice for solving large instances. This approach holds the current record, solving an instance with 85,900 cities, see Applegate et al. (2006).
An exact solution for 15,112 German towns from TSPLIB was found in 2001 using the cutting-plane method proposed by George Dantzig, Ray Fulkerson, and Selmer M. Johnson in 1954, based on linear programming. The computations were performed on a network of 110 processors located at Rice University and Princeton University. The total computation time was equivalent to 22.6Â years on a single 500Â MHz Alpha processor. In May 2004, the travelling salesman problem of visiting all 24,978 towns in Sweden was solved: a tour of length approximately 72,500 kilometres was found and it was proven that no shorter tour exists.[27]  In March 2005, the travelling salesman problem of visiting all 33,810 points in a circuit board was solved using Concorde TSP Solver: a tour of length 66,048,945 units was found and it was proven that no shorter tour exists. The computation took approximately 15.7 CPU-years (Cook et al. 2006). In April 2006 an instance with 85,900 points was solved using Concorde TSP Solver, taking over 136 CPU-years, see Applegate et al. (2006).

Heuristic and approximation algorithms[edit]
Various heuristics and approximation algorithms, which quickly yield good solutions, have been devised. These include the Multi-fragment algorithm. Modern methods can find solutions for extremely large problems (millions of cities) within a reasonable time which are with a high probability just 2â3% away from the optimal solution.[15]
Several categories of heuristics are recognized.

Constructive heuristics[edit]
  Nearest Neighbour algorithm for a TSP with 7 cities. The solution changes as the starting point is changed
The nearest neighbour (NN) algorithm (a greedy algorithm) lets the salesman choose the nearest unvisited city as his next move. This algorithm quickly yields an effectively short route. For N cities randomly distributed on a plane, the algorithm on average yields a path 25% longer than the shortest possible path.[28] However, there exist many specially arranged city distributions which make the NN algorithm give the worst route.[29] This is true for both asymmetric and symmetric TSPs.[30] Rosenkrantz et al.[31] showed that the NN algorithm has the approximation factor 
  
    
      
        Î
        (
        log
        â¡
        
          |
        
        V
        
          |
        
        )
      
    
    {\displaystyle \Theta (\log |V|)}
  
 for instances satisfying the triangle inequality. A variation of NN algorithm, called nearest fragment (NF) operator, which connects a group (fragment) of nearest unvisited cities, can find shorter routes with successive iterations.[32] The NF operator can also be applied on an initial solution obtained by NN algorithm for further improvement in an elitist model, where only better solutions are accepted.
The bitonic tour of a set of points is the minimum-perimeter monotone polygon that has the points as its vertices; it can be computed efficiently by dynamic programming.
Another constructive heuristic, Match Twice and Stitch (MTS), performs two sequential matchings, where the second matching is executed after deleting all the edges of the first matching, to yield a set of cycles. The cycles are then stitched to produce the final tour.[33]

The Algorithm of Christofides and Serdyukov[edit]
  Creating a matching
  Using a shortcut heuristic on the graph created by the matching above
The algorithm of Christofides and Serdyukov follows a similar outline but combines the minimum spanning tree with a solution of another problem, minimum-weight perfect matching. This gives a TSP tour which is at most 1.5 times the optimal.  It was one of the first approximation algorithms, and was in part responsible for drawing attention to approximation algorithms as a practical approach to intractable problems. As a matter of fact, the term "algorithm" was not commonly extended to approximation algorithms until later; the Christofides algorithm was initially referred to as the Christofides heuristic.[11]
This algorithm looks at things differently by using a result from graph theory which helps improve on the lower bound of the TSP which originated from doubling the cost of the minimum spanning tree. Given an Eulerian graph we can find an Eulerian tour in 
  
    
      
        O
        (
        n
        )
      
    
    {\displaystyle O(n)}
  
 time.[7] So if we had an Eulerian graph with cities from a TSP as vertices then we can easily see that we could use such a method for finding an Eulerian tour to find a TSP solution. By triangular inequality we know that the TSP tour can be no longer than the Eulerian tour and as such we have a lower bound for the TSP. Such a method is described below.

Find a minimum spanning tree for the problem
Create duplicates for every edge to create an Eulerian graph
Find an Eulerian tour for this graph
Convert to TSP: if a city is visited twice, create a shortcut from the city before this in the tour to the one after this.
To improve the lower bound, a better way of creating an Eulerian graph is needed. By triangular inequality, the best Eulerian graph must have the same cost as the best travelling salesman tour, hence finding optimal Eulerian graphs is at least as hard as TSP. One way of doing this is by minimum weight matching using algorithms of 
  
    
      
        O
        (
        
          n
          
            3
          
        
        )
      
    
    {\displaystyle O(n^{3})}
  
.[7]
Making a graph into an Eulerian graph starts with the minimum spanning tree. Then all the vertices of odd order must be made even. So a matching for the odd degree vertices must be added which increases the order of every odd degree vertex by one.[7] This leaves us with a graph where every vertex is of even order which is thus Eulerian. Adapting the above method gives the algorithm of Christofides and Serdyukov.

Find a minimum spanning tree for the problem
Create a matching for the problem with the set of cities of odd order.
Find an Eulerian tour for this graph
Convert to TSP using shortcuts.
Pairwise exchange[edit]
  An example of a 2-opt iteration
The pairwise exchange or 2-opt technique involves iteratively removing two edges and replacing these with two different edges that reconnect the fragments created by edge removal into a new and shorter tour. Similarly, the 3-opt technique removes 3 edges and reconnects them to form a shorter tour. These are special cases of the k-opt method. The label LinâKernighan is an often heard misnomer for 2-opt. LinâKernighan is actually the more general k-opt method.
For Euclidean instances, 2-opt heuristics give on average solutions that are about 5% better than Christofides' algorithm. If we start with an initial solution made with a greedy algorithm, the average number of moves greatly decreases again and is 
  
    
      
        O
        (
        n
        )
      
    
    {\displaystyle O(n)}
  
. For random starts however, the average number of moves is 
  
    
      
        O
        (
        n
        log
        â¡
        (
        n
        )
        )
      
    
    {\displaystyle O(n\log(n))}
  
. However whilst in order this is a small increase in size, the initial number of moves for small problems is 10 times as big for a random start compared to one made from a greedy heuristic. This is because such 2-opt heuristics exploit 'bad' parts of a solution such as crossings. These types of heuristics are often used within Vehicle routing problem heuristics to reoptimize route solutions.[28]

k-opt heuristic, or LinâKernighan heuristics[edit]
The LinâKernighan heuristic is a special case of the V-opt or variable-opt technique. It involves the following steps:

Given a tour, delete k mutually disjoint edges.
Reassemble the remaining fragments into a tour, leaving no disjoint subtours (that is, don't connect a fragment's endpoints together). This in effect simplifies the TSP under consideration into a much simpler problem.
Each fragment endpoint can be connected to 2kÂ âÂ 2 other possibilities: of 2k total fragment endpoints available, the two endpoints of the fragment under consideration are disallowed. Such a constrained 2k-city TSP can then be solved with brute force methods to find the least-cost recombination of the original fragments.
The most popular of the k-opt methods are 3-opt, as introduced by Shen Lin of Bell Labs in 1965. A special case of 3-opt is where the edges are not disjoint (two of the edges are adjacent to one another). In practice, it is often possible to achieve substantial improvement over 2-opt without the combinatorial cost of the general 3-opt by restricting the 3-changes to this special subset where two of the removed edges are adjacent. This so-called two-and-a-half-opt typically falls roughly midway between 2-opt and 3-opt, both in terms of the quality of tours achieved and the time required to achieve those tours.

V-opt heuristic[edit]
The variable-opt method is related to, and a generalization of the k-opt method. Whereas the k-opt methods remove a fixed number (k) of edges from the original tour, the variable-opt methods do not fix the size of the edge set to remove. Instead, they grow the set as the search process continues. The best-known method in this family is the LinâKernighan method (mentioned above as a misnomer for 2-opt). Shen Lin and Brian Kernighan first published their method in 1972, and it was the most reliable heuristic for solving travelling salesman problems for nearly two decades. More advanced variable-opt methods were developed at Bell Labs in the late 1980s by David Johnson and his research team. These methods (sometimes called LinâKernighanâJohnson) build on the LinâKernighan method, adding ideas from tabu search and evolutionary computing. The basic LinâKernighan technique gives results that are guaranteed to be at least 3-opt. The LinâKernighanâJohnson methods compute a LinâKernighan tour, and then perturb the tour by what has been described as a mutation that removes at least four edges and reconnects the tour in a different way, then V-opting the new tour. The mutation is often enough to move the tour from the local minimum identified by LinâKernighan. V-opt methods are widely considered the most powerful heuristics for the problem, and are able to address special cases, such as the Hamilton Cycle Problem and other non-metric TSPs that other heuristics fail on. For many years LinâKernighanâJohnson had identified optimal solutions for all TSPs where an optimal solution was known and had identified the best-known solutions for all other TSPs on which the method had been tried.

Randomized improvement[edit]
Optimized Markov chain algorithms which use local searching heuristic sub-algorithms can find a route extremely close to the optimal route for 700 to 800 cities.
TSP is a touchstone for many general heuristics devised for combinatorial optimization such as genetic algorithms, simulated annealing, tabu search, ant colony optimization, river formation dynamics (see swarm intelligence) and the cross entropy method.

Ant colony optimization[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Ant colony optimization algorithms
Artificial intelligence researcher Marco Dorigo described in 1993 a method of heuristically generating "good solutions" to the TSP using a simulation of an ant colony called ACS (ant colony system).[34] It models behaviour observed in real ants to find short paths between food sources and their nest, an emergent behaviour resulting from each ant's preference to follow trail pheromones deposited by other ants.
ACS sends out a large number of virtual ant agents to explore many possible routes on the map. Each ant probabilistically chooses the next city to visit based on a heuristic combining the distance to the city and the amount of virtual pheromone deposited on the edge to the city. The ants explore, depositing pheromone on each edge that they cross, until they have all completed a tour. At this point the ant which completed the shortest tour deposits virtual pheromone along its complete tour route (global trail updating). The amount of pheromone deposited is inversely proportional to the tour length: the shorter the tour, the more it deposits.


  Ant colony optimization algorithm for a TSP with 7 cities: Red and thick lines in the pheromone map indicate presence of more pheromone
Special cases[edit]
Metric[edit]
In the metric TSP, also known as delta-TSP or Î-TSP, the intercity distances satisfy the triangle inequality.
A very natural restriction of the TSP is to require that the distances between cities form a metric to satisfy the triangle inequality; that is the direct connection from A to B is never farther than the route via intermediate C:


  
    
      
        
          d
          
            A
            B
          
        
        â¤
        
          d
          
            A
            C
          
        
        +
        
          d
          
            C
            B
          
        
      
    
    {\displaystyle d_{AB}\leq d_{AC}+d_{CB}}
  
.
The edge spans then build a metric on the set of vertices. When the cities are viewed as points in the plane, many natural distance functions are metrics, and so many natural instances of TSP satisfy this constraint.
The following are some examples of metric TSPs for various metrics.

In the Euclidean TSP (see below) the distance between two cities is the Euclidean distance between the corresponding points.
In the rectilinear TSP the distance between two cities is the sum of the absolute values of the differences of their x- and y-coordinates. This metric is often called the Manhattan distance or city-block metric.
In the maximum metric, the distance between two points is the maximum of the absolute values of differences of their x- and y-coordinates.
The last two metrics appear, for example, in routing a machine that drills a given set of holes in a printed circuit board. The Manhattan metric corresponds to a machine that adjusts first one co-ordinate, and then the other, so the time to move to a new point is the sum of both movements. The maximum metric corresponds to a machine that adjusts both co-ordinates simultaneously, so the time to move to a new point is the slower of the two movements.
In its definition, the TSP does not allow cities to be visited twice, but many applications do not need this constraint. In such cases, a symmetric, non-metric instance can be reduced to a metric one. This replaces the original graph with a complete graph in which the inter-city distance 
  
    
      
        
          d
          
            A
            B
          
        
      
    
    {\displaystyle d_{AB}}
  
 is replaced by the shortest path length between A and B in the original graph.

Euclidean[edit]
When the input numbers can be arbitrary real numbers, Euclidean TSP is a particular case of metric TSP, since distances in a plane obey the triangle inequality. When the input numbers must be integers, comparing lengths of tours involves comparing sums of square-roots.
Like the general TSP, Euclidean TSP is NP-hard in either case. With rational coordinates and discretized metric (distances rounded up to an integer), the problem is NP-complete.[35] With rational coordinates and the actual Euclidean metric, Euclidean TSP is known to be in the Counting Hierarchy,[36] a subclass of PSPACE. With arbitrary real coordinates, Euclidean TSP cannot be in such classes, since there are uncountably many possible inputs. However, Euclidean TSP is probably the easiest version for approximation.[37] For example, the minimum spanning tree of the graph associated with an instance of the Euclidean TSP is a Euclidean minimum spanning tree, and so can be computed in expected O (n log n) time for n points (considerably less than the number of edges). This enables the simple 2-approximation algorithm for TSP with triangle inequality above to operate more quickly.
In general, for any c > 0, where d is the number of dimensions in the Euclidean space, there is a polynomial-time algorithm that finds a tour of length at most (1 + 1/c) times the optimal for geometric instances of TSP in


  
    
      
        O
        
          (
          
            n
            (
            log
            â¡
            n
            
              )
              
                (
                O
                (
                c
                
                  
                    d
                  
                
                )
                
                  )
                  
                    d
                    â
                    1
                  
                
              
            
          
          )
        
        ,
      
    
    {\displaystyle O\left(n(\log n)^{(O(c{\sqrt {d}}))^{d-1}}\right),}
  

time; this is called a polynomial-time approximation scheme (PTAS).[38] Sanjeev Arora and Joseph S. B. Mitchell were awarded the GÃ¶del Prize in 2010 for their concurrent discovery of a PTAS for the Euclidean TSP.
In practice, simpler heuristics with weaker guarantees continue to be used.

Asymmetric[edit]
In most cases, the distance between two nodes in the TSP network is the same in both directions. The case where the distance from A to B is not equal to the distance from B to A is called asymmetric TSP. A practical application of an asymmetric TSP is route optimization using street-level routing (which is made asymmetric by one-way streets, slip-roads, motorways, etc.).

Conversion to symmetric[edit]
Solving an asymmetric TSP graph can be somewhat complex. The following is a 3Ã3 matrix containing all possible path weights between the nodes A, B and C. One option is to turn an asymmetric matrix of size N into a symmetric matrix of size 2N.[39]



Asymmetric path weights



A
B
C


A


1
2


B

6

3


C

5
4


To double the size, each of the nodes in the graph is duplicated, creating a second ghost node, linked to the original node with a "ghost" edge of very low (possibly negative) weight, here denoted âw. (Alternatively, the ghost edges have weight 0, and weight w is added to all other edges.) The original 3Ã3 matrix shown above is visible in the bottom left and the transpose of the original in the top-right. Both copies of the matrix have had their diagonals replaced by the low-cost hop paths, represented by âw. In the new graph, no edge directly links original nodes and no edge directly links ghost nodes.



Symmetric path weights



A
B
C
Aâ²
Bâ²
Câ²


A




âw
6
5


B




1
âw
4


C




2
3
âw


Aâ²

âw
1
2





Bâ²

6
âw
3





Câ²

5
4
âw




The weight âw of the "ghost" edges linking the ghost nodes to the corresponding original nodes must be low enough to ensure that all ghost edges must belong to any optimal symmetric TSP solution on the new graph (w=0 is not always low enough). As a consequence, in the optimal symmetric tour, each original node appears next to its ghost node (e.g. a possible path is 
  
    
      
        
          A
          â
          
            A
            â²
          
          â
          C
          â
          
            C
            â²
          
          â
          B
          â
          
            B
            â²
          
          â
          A
        
      
    
    {\displaystyle \mathrm {A\to A'\to C\to C'\to B\to B'\to A} }
  
) and by merging the original and ghost nodes again we get an (optimal) solution of the original asymmetric problem (in our example, 
  
    
      
        
          A
          â
          C
          â
          B
          â
          A
        
      
    
    {\displaystyle \mathrm {A\to C\to B\to A} }
  
).

Analyst's problem[edit]
There is an analogous problem in geometric measure theory which asks the following: under what conditions may a subset E of Euclidean space be contained in a rectifiable curve (that is, when is there a curve with finite length that visits every point in E)? This problem is known as the analyst's travelling salesman problem.

Path length for random sets of points in a square[edit]
Suppose 
  
    
      
        
          X
          
            1
          
        
        ,
        â¦
        ,
        
          X
          
            n
          
        
      
    
    {\displaystyle X_{1},\ldots ,X_{n}}
  
 are 
  
    
      
        n
      
    
    {\displaystyle n}
  
 independent random variables with uniform distribution in the square 
  
    
      
        [
        0
        ,
        1
        
          ]
          
            2
          
        
      
    
    {\displaystyle [0,1]^{2}}
  
, and let 
  
    
      
        
          L
          
            n
          
          
            â
          
        
      
    
    {\displaystyle L_{n}^{\ast }}
  
 be the shortest path length (i.e. TSP solution) for this set of points, according to the usual Euclidean distance. It is known[10] that, almost surely,


  
    
      
        
          
            
              L
              
                n
              
              
                â
              
            
            
              n
            
          
        
        â
        Î²
        
        
          whenÂ 
        
        n
        â
        â
        ,
      
    
    {\displaystyle {\frac {L_{n}^{*}}{\sqrt {n}}}\rightarrow \beta \qquad {\text{when }}n\to \infty ,}
  

where 
  
    
      
        Î²
      
    
    {\displaystyle \beta }
  
 is a positive constant that is not known explicitly. Since 
  
    
      
        
          L
          
            n
          
          
            â
          
        
        â¤
        2
        
          
            n
          
        
        +
        2
      
    
    {\displaystyle L_{n}^{*}\leq 2{\sqrt {n}}+2}
  
 (see below), it follows from bounded convergence theorem that 
  
    
      
        Î²
        =
        
          lim
          
            n
            â
            â
          
        
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
        
          /
        
        
          
            n
          
        
      
    
    {\displaystyle \beta =\lim _{n\to \infty }\mathbb {E} [L_{n}^{*}]/{\sqrt {n}}}
  
, hence lower and upper bounds on 
  
    
      
        Î²
      
    
    {\displaystyle \beta }
  
 follow from bounds on 
  
    
      
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
      
    
    {\displaystyle \mathbb {E} [L_{n}^{*}]}
  
.
The almost sure limit 
  
    
      
        
          
            
              L
              
                n
              
              
                â
              
            
            
              n
            
          
        
        â
        Î²
      
    
    {\displaystyle {\frac {L_{n}^{*}}{\sqrt {n}}}\rightarrow \beta }
  
 as 
  
    
      
        n
        â
        â
      
    
    {\displaystyle n\to \infty }
  
 may not exist 
if the independent locations  
  
    
      
        
          X
          
            1
          
        
        ,
        â¦
        ,
        
          X
          
            n
          
        
      
    
    {\displaystyle X_{1},\ldots ,X_{n}}
  
 are replaced with observations from a stationary ergodic process with uniform marginals.[40]

Upper bound[edit]
One has 
  
    
      
        
          L
          
            â
          
        
        â¤
        2
        
          
            n
          
        
        +
        2
      
    
    {\displaystyle L^{*}\leq 2{\sqrt {n}}+2}
  
, and therefore 
  
    
      
        Î²
        â¤
        2
      
    
    {\displaystyle \beta \leq 2}
  
, by using a naive path which visits monotonically the points inside each of 
  
    
      
        
          
            n
          
        
      
    
    {\displaystyle {\sqrt {n}}}
  
 slices of width 
  
    
      
        1
        
          /
        
        
          
            n
          
        
      
    
    {\displaystyle 1/{\sqrt {n}}}
  
 in the square.
Few[41] proved 
  
    
      
        
          L
          
            n
          
          
            â
          
        
        â¤
        
          
            2
            n
          
        
        +
        1.75
      
    
    {\displaystyle L_{n}^{*}\leq {\sqrt {2n}}+1.75}
  
, hence 
  
    
      
        Î²
        â¤
        
          
            2
          
        
      
    
    {\displaystyle \beta \leq {\sqrt {2}}}
  
, later improved by Karloff (1987): 
  
    
      
        Î²
        â¤
        0.984
        
          
            2
          
        
      
    
    {\displaystyle \beta \leq 0.984{\sqrt {2}}}
  
.
Fietcher[42] showed an upper bound of 
  
    
      
        Î²
        â¤
        0.73
        â¦
      
    
    {\displaystyle \beta \leq 0.73\dots }
  
.
Lower bound[edit]
By observing that 
  
    
      
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
      
    
    {\displaystyle \mathbb {E} [L_{n}^{*}]}
  
 is greater than 
  
    
      
        n
      
    
    {\displaystyle n}
  
 times the distance between 
  
    
      
        
          X
          
            0
          
        
      
    
    {\displaystyle X_{0}}
  
 and the closest point 
  
    
      
        
          X
          
            i
          
        
        â 
        
          X
          
            0
          
        
      
    
    {\displaystyle X_{i}\neq X_{0}}
  
, one gets (after a short computation)

  
    
      
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
        â¥
        
          
            
              1
              2
            
          
        
        
          
            n
          
        
        .
      
    
    {\displaystyle \mathbb {E} [L_{n}^{*}]\geq {\tfrac {1}{2}}{\sqrt {n}}.}
  

A better lower bound is obtained[10] by observing that 
  
    
      
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
      
    
    {\displaystyle \mathbb {E} [L_{n}^{*}]}
  
 is greater than 
  
    
      
        
          
            
              1
              2
            
          
        
        n
      
    
    {\displaystyle {\tfrac {1}{2}}n}
  
 times the sum of the distances between 
  
    
      
        
          X
          
            0
          
        
      
    
    {\displaystyle X_{0}}
  
 and the closest and second closest points 
  
    
      
        
          X
          
            i
          
        
        ,
        
          X
          
            j
          
        
        â 
        
          X
          
            0
          
        
      
    
    {\displaystyle X_{i},X_{j}\neq X_{0}}
  
, which gives

  
    
      
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
        â¥
        
          (
          
            
              
                
                  1
                  4
                
              
            
            +
            
              
                
                  3
                  8
                
              
            
          
          )
        
        
          
            n
          
        
        =
        
          
            
              5
              8
            
          
        
        
          
            n
          
        
        ,
      
    
    {\displaystyle \mathbb {E} [L_{n}^{*}]\geq \left({\tfrac {1}{4}}+{\tfrac {3}{8}}\right){\sqrt {n}}={\tfrac {5}{8}}{\sqrt {n}},}
  

The currently[43] best lower bound is

  
    
      
        
          E
        
        [
        
          L
          
            n
          
          
            â
          
        
        ]
        â¥
        (
        
          
            
              5
              8
            
          
        
        +
        
          
            
              19
              5184
            
          
        
        )
        
          
            n
          
        
        ,
      
    
    {\displaystyle \mathbb {E} [L_{n}^{*}]\geq ({\tfrac {5}{8}}+{\tfrac {19}{5184}}){\sqrt {n}},}
  

Held and Karp[44] gave a polynomial-time algorithm that provides numerical lower bounds for 
  
    
      
        
          L
          
            n
          
          
            â
          
        
      
    
    {\displaystyle L_{n}^{*}}
  
, and thus for 
  
    
      
        Î²
        (
        â
        
          L
          
            n
          
          
            â
          
        
        
          /
        
        
          
            n
          
        
        )
      
    
    {\displaystyle \beta (\simeq L_{n}^{*}/{\sqrt {n}})}
  
 which seem to be good up to more or less 1%.[45] In particular, David S. Johnson[46] obtained a lower bound by computer experiment:

  
    
      
        
          L
          
            n
          
          
            â
          
        
        â³
        0.7080
        
          
            n
          
        
        +
        0.522
        ,
      
    
    {\displaystyle L_{n}^{*}\gtrsim 0.7080{\sqrt {n}}+0.522,}
  

where 0.522 comes from the points near square boundary which have fewer neighbours,
and Christine L. Valenzuela and Antonia J. Jones[47] obtained the following other numerical lower bound:


  
    
      
        
          L
          
            n
          
          
            â
          
        
        â³
        0.7078
        
          
            n
          
        
        +
        0.551
      
    
    {\displaystyle L_{n}^{*}\gtrsim 0.7078{\sqrt {n}}+0.551}
  
.
Computational complexity[edit]
The problem has been shown to be NP-hard (more precisely, it is complete for the complexity class FPNP; see function problem), and the decision problem version ("given the costs and a number x, decide whether there is a round-trip route cheaper than x") is NP-complete. The bottleneck travelling salesman problem is also NP-hard. The problem remains NP-hard even for the case when the cities are in the plane with Euclidean distances, as well as in a number of other restrictive cases. Removing the condition of visiting each city "only once" does not remove the NP-hardness, since in the planar case there is an optimal tour that visits each city only once (otherwise, by the triangle inequality, a shortcut that skips a repeated visit would not increase the tour length).

Complexity of approximation[edit]
In the general case, finding a shortest travelling salesman tour is NPO-complete.[48] If the distance measure is a metric (and thus symmetric), the problem becomes APX-complete[49] and the algorithm of Christofides and Serdyukov approximates it within 1.5.[50][51][11] A 2020 preprint improves this bound to 
  
    
      
        1.5
        â
        
          10
          
            â
            36
          
        
      
    
    {\displaystyle 1.5-10^{-36}}
  
.[52] The best known inapproximability bound is 123/122.[53]
If the distances are restricted to 1 and 2 (but still are a metric) the approximation ratio becomes 8/7.[54] In the asymmetric case with triangle inequality, up until recently only logarithmic performance guarantees were known.[55] In 2018, a constant factor approximation was developed by Svensson, Tarnawski and VÃ©gh.[56]  The best current algorithm, by Traub and Vygen, achieves performance ratio of 
  
    
      
        22
        +
        Îµ
      
    
    {\displaystyle 22+\varepsilon }
  
.[57] The best known inapproximability bound is 75/74.[53]
The corresponding maximization problem of finding the longest travelling salesman tour is approximable within 63/38.[58] If the distance function is symmetric, the longest tour can be approximated within 4/3 by a deterministic algorithm[59] and within 
  
    
      
        
          
            
              1
              25
            
          
        
        (
        33
        +
        Îµ
        )
      
    
    {\displaystyle {\tfrac {1}{25}}(33+\varepsilon )}
  
 by a randomized algorithm.[60]

Human and animal performance[edit]
The TSP, in particular the Euclidean variant of the problem, has attracted the attention of researchers in cognitive psychology. It has been observed that humans are able to produce near-optimal solutions quickly, in a close-to-linear fashion, with performance that ranges from 1% less efficient for graphs with 10-20 nodes, and 11% less efficient for graphs with 120 nodes.[61][62] The apparent ease with which humans accurately generate near-optimal solutions to the problem has led researchers to hypothesize that humans use one or more heuristics, with the two most popular theories arguably being the convex-hull hypothesis and the crossing-avoidance heuristic.[63][64][65] However, additional evidence suggests that human performance is quite varied, and individual differences as well as graph geometry appear to affect performance in the task.[66][67][68] Nevertheless, results suggest that computer performance on the TSP may be improved by understanding and emulating the methods used by humans for these problems,[69] and have also led to new insights into the mechanisms of human thought.[70] The first issue of the Journal of Problem Solving was devoted to the topic of human performance on TSP,[71] and a 2011 review listed dozens of papers on the subject.[70]
A 2011 study in animal cognition titled "Let the Pigeon Drive the Bus," named after the children's book Don't Let the Pigeon Drive the Bus!, examined spatial cognition in pigeons by studying their flight patterns between multiple feeders in a laboratory in relation to the travelling salesman problem. In the first experiment, pigeons were placed in the corner of a lab room and allowed to fly to nearby feeders containing peas. The researchers found that pigeons largely used proximity to determine which feeder they would select next. In the second experiment, the feeders were arranged in such a way that flying to the nearest feeder at every opportunity would be largely inefficient if the pigeons needed to visit every feeder. The results of the second experiment indicate that pigeons, while still favoring proximity-based solutions, "can plan several steps ahead along the route when the differences in travel costs between efficient and less efficient routes based on proximity become larger."[72] These results are consistent with other experiments done with non-primates, which have proven that some non-primates were able to plan complex travel routes. This suggests non-primates may possess a relatively sophisticated spatial cognitive ability.

Natural computation[edit]
When presented with a spatial configuration of food sources, the amoeboid Physarum polycephalum adapts its morphology to create an efficient path between the food sources which can also be viewed as an approximate solution to TSP.[73]

Benchmarks[edit]
For benchmarking of TSP algorithms, TSPLIB[74] is a library of sample instances of the TSP and related problems is maintained, see the TSPLIB external reference. Many of them are lists of actual cities and layouts of actual printed circuits.

Popular culture[edit]
Travelling Salesman, by director Timothy Lanzone, is the story of four mathematicians hired by the U.S. government to solve the most elusive problem in computer-science history: P vs. NP.[75]
See also[edit]
Canadian traveller problem
Exact algorithm
Route inspection problem (also known as "Chinese postman problem")
Set TSP problem
Seven Bridges of KÃ¶nigsberg
Steiner travelling salesman problem
Subway Challenge
Tube Challenge
Vehicle routing problem
Graph exploration
Notes[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ See the TSP world tour problem which has already been solved to within 0.05% of the optimal solution. [1]

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Ross, I. M.; Proulx, R. J.; Karpenko, M. (6 May 2020). "An Optimal Control Theory for the Traveling Salesman Problem and Its Variants". arXiv:2005.03186 [math.OC].

^ Ross, I. M.; Proulx, R. J.; Karpenko, M. (July 2019). "Autonomous UAV Sensor Planning, Scheduling and Maneuvering: An Obstacle Engagement Technique". 2019 American Control Conference (ACC). IEEE: 65â70. doi:10.23919/acc.2019.8814474. ISBNÂ 978-1-5386-7926-5. S2CIDÂ 201811463.

^ "Der Handlungsreisende â wie er sein soll und was er zu tun hat, um AuftrÃ¤ge zu erhalten und eines glÃ¼cklichen Erfolgs in seinen GeschÃ¤ften gewiÃ zu sein â von einem alten Commis-Voyageur" (The travelling salesman â how he must be and what he should do in order to get commissions and be sure of the happy success in his business â by an old commis-voyageur)

^ A discussion of the early work of Hamilton and Kirkman can be found in Graph Theory, 1736â1936 by Biggs, Lloyd, and Wilson (Clarendon Press, 1986).

^ Cited and English translation in Schrijver (2005). Original German: "Wir bezeichnen als Botenproblem (weil diese Frage in der Praxis von jedem Postboten, Ã¼brigens auch von vielen Reisenden zu lÃ¶sen ist) die Aufgabe, fÃ¼r endlich viele Punkte, deren paarweise AbstÃ¤nde bekannt sind, den kÃ¼rzesten die Punkte verbindenden Weg zu finden. Dieses Problem ist natÃ¼rlich stets durch endlich viele Versuche lÃ¶sbar. Regeln, welche die Anzahl der Versuche unter die Anzahl der Permutationen der gegebenen Punkte herunterdrÃ¼cken wÃ¼rden, sind nicht bekannt. Die Regel, man solle vom Ausgangspunkt erst zum nÃ¤chstgelegenen Punkt, dann zu dem diesem nÃ¤chstgelegenen Punkt gehen usw., liefert im allgemeinen nicht den kÃ¼rzesten Weg."

^ Jump up to: a b c d e f g h Lawler, E. L. (1985). The Travelling Salesman Problem: A Guided Tour of Combinatorial Optimization (Repr. with corrections.Â ed.). John Wiley & sons. ISBNÂ 978-0471904137.

^ Robinson, Julia (5 December 1949). "On the Hamiltonian game (a traveling salesman problem)". Project RAND. Santa Monica, CA: The RAND Corporation (RM-303). Retrieved 2 May 2020.

^ A detailed treatment of the connection between Menger and Whitney as well as the growth in the study of TSP can be found in Schrijver (2005).

^ Jump up to: a b c Beardwood, Halton & Hammersley (1959).

^ Jump up to: a b c van Bevern, RenÃ©; Slugina, Viktoriia A. (2020). "A historical note on the 3/2-approximation algorithm for the metric traveling salesman problem". Historia Mathematica. 53: 118â127. arXiv:2004.02437. doi:10.1016/j.hm.2020.04.003. S2CIDÂ 214803097.

^ Klarreich, Erica (30 January 2013). "Computer Scientists Find New Shortcuts for Infamous Traveling Salesman Problem". WIRED. Retrieved 14 June 2015.

^ Klarreich, Erica (8 October 2020). "Computer Scientists Break Traveling Salesperson Record". Quanta Magazine. Retrieved 13 October 2020.

^ Karlin, Anna R.; Klein, Nathan; Gharan, Shayan Oveis (30 August 2020). "A (Slightly) Improved Approximation Algorithm for Metric TSP". arXiv:2007.01409 [cs.DS].

^ Jump up to: a b Rego, CÃ©sar; Gamboa, Dorabela; Glover, Fred; Osterman, Colin (2011), "Traveling salesman problem heuristics: leading methods, implementations and latest advances", European Journal of Operational Research, 211 (3): 427â441, doi:10.1016/j.ejor.2010.09.010, MRÂ 2774420.

^ "How Do You Fix School Bus Routes? Call MIT in Wall street Journal" (PDF).

^ Behzad, Arash; Modarres, Mohammad (2002), "New Efficient Transformation of the Generalized Traveling Salesman Problem into Traveling Salesman Problem", Proceedings of the 15th International Conference of Systems Engineering (Las Vegas)

^ Papadimitriou, C.H.; Steiglitz, K. (1998), Combinatorial optimization: algorithms and complexity, Mineola, NY: Dover, pp.308-309.

^ Tucker, A. W. (1960), "On Directed Graphs and Integer Programs", IBM Mathematical research Project (Princeton University)

^ Dantzig, George B. (1963), Linear Programming and Extensions, Princeton, NJ: PrincetonUP, pp. 545â7, ISBNÂ 0-691-08000-3, sixth printing, 1974.

^ Velednitsky, Mark (2017). "Short combinatorial proof that the DFJ polytope is contained in the MTZ polytope for the Asymmetric Traveling Salesman Problem". Operations Research Letters. 45 (4): 323â324. arXiv:1805.06997. doi:10.1016/j.orl.2017.04.010. S2CIDÂ 6941484.

^ BektaÅ, Tolga; Gouveia, Luis (2014). "Requiem for the MillerâTuckerâZemlin subtour elimination constraints?". European Journal of Operational Research. 236 (3): 820â832. doi:10.1016/j.ejor.2013.07.038.

^ Dantzig, G.; Fulkerson, R.; Johnson, S. (November 1954). "Solution of a Large-Scale Traveling-Salesman Problem". Journal of the Operations Research Society of America. 2 (4): 393â410. doi:10.1287/opre.2.4.393.

^ Bellman (1960), Bellman (1962), Held & Karp (1962)

^ Woeginger (2003).

^ Padberg & Rinaldi (1991).

^ Applegate, David; Bixby, Robert; ChvÃ¡tal, VaÅ¡ek; Cook, William; Helsgaun, Keld (June 2004). "Optimal Tour of Sweden". Retrieved 11 November 2020.

^ Jump up to: a b Johnson, D. S.; McGeoch, L. A. (1997). "The Traveling Salesman Problem: A Case Study in Local Optimization" (PDF).  In Aarts, E. H. L.; Lenstra, J. K. (eds.). Local Search in Combinatorial Optimisation. London: John Wiley and Sons Ltd. pp.Â 215â310.

^ Gutina, Gregory; Yeob, Anders; Zverovich, Alexey (15 March 2002). "Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP". Discrete Applied Mathematics. 117 (1â3): 81â86. doi:10.1016/S0166-218X(01)00195-0.>

^ Zverovitch, Alexei; Zhang, Weixiong; Yeo, Anders; McGeoch, Lyle A.; Gutin, Gregory; Johnson, David S. (2007), "Experimental Analysis of Heuristics for the ATSP", The Traveling Salesman Problem and Its Variations, Combinatorial Optimization, Springer, Boston, MA, pp.Â 445â487, CiteSeerXÂ 10.1.1.24.2386, doi:10.1007/0-306-48213-4_10, ISBNÂ 978-0-387-44459-8

^ Rosenkrantz, D. J.; Stearns, R. E.; Lewis, P. M. (14â16 October 1974). Approximate algorithms for the traveling salesperson problem. 15th Annual Symposium on Switching and Automata Theory (swat 1974). doi:10.1109/SWAT.1974.4.

^ Ray, S. S.; Bandyopadhyay, S.; Pal, S. K. (2007). "Genetic Operators for Combinatorial Optimization in TSP and Microarray Gene Ordering". Applied Intelligence. 26 (3): 183â195. CiteSeerXÂ 10.1.1.151.132. doi:10.1007/s10489-006-0018-y. S2CIDÂ 8130854.

^ Kahng, A. B.; Reda, S. (2004). "Match Twice and Stitch: A New TSP Tour Construction Heuristic". Operations Research Letters. 32 (6): 499â509. doi:10.1016/j.orl.2004.04.001.

^ Dorigo, Marco; Gambardella, Luca Maria (1997). "Ant Colonies for the Traveling Salesman Problem". Biosystems. 43 (2): 73â81. CiteSeerXÂ 10.1.1.54.7734. doi:10.1016/S0303-2647(97)01708-5. PMIDÂ 9231906. S2CIDÂ 8243011.

^ Papadimitriou (1977).

^ Allender et al. (2007).

^ Larson & Odoni (1981).

^ Arora (1998).

^ Jonker, Roy; Volgenant, Ton (1983). "Transforming asymmetric into symmetric traveling salesman problems". Operations Research Letters. 2 (161â163): 1983. doi:10.1016/0167-6377(83)90048-2.

^ Arlotto, Alessandro; Steele, J. Michael (2016), "BeardwoodâHaltonâHammersley theorem for stationary ergodic sequences: a counterexample", The Annals of Applied Probability, 26 (4): 2141â2168, arXiv:1307.0221, doi:10.1214/15-AAP1142, S2CIDÂ 8904077

^ Few, L. (1955). "The shortest path and the shortest road through n points". Mathematika. 2 (2): 141â144. doi:10.1112/s0025579300000784.

^ Fiechter, C.-N. (1994). "A parallel tabu search algorithm for large traveling salesman problems". Disc. Applied Math. 51 (3): 243â267. doi:10.1016/0166-218X(92)00033-I.

^ Steinerberger (2015).

^ Held, M.; Karp, R.M. (1970). "The Traveling Salesman Problem and Minimum Spanning Trees". Operations Research. 18 (6): 1138â1162. doi:10.1287/opre.18.6.1138.

^ Goemans, M.; Bertsimas, D. (1991). "Probabilistic analysis of the Held and Karp lower bound for the Euclidean traveling salesman problem". Mathematics of Operations Research. 16 (1): 72â89. doi:10.1287/moor.16.1.72.

^ "error". about.att.com.

^ Christine L. Valenzuela and Antonia J. Jones Archived 25 October 2007 at the Wayback Machine

^ Orponen, P.; Mannila, H. (1987). On approximation preserving reductions: Complete problems and robust measures' (Report). Department of Computer Science, University of Helsinki. Technical Report C-1987â28.

^ Papadimitriou & Yannakakis (1993).

^ Christofides (1976).

^ Serdyukov, Anatoliy I. (1978), "Ð Ð½ÐµÐºÐ¾ÑÐ¾ÑÑÑ ÑÐºÑÑÑÐµÐ¼Ð°Ð»ÑÐ½ÑÑ Ð¾Ð±ÑÐ¾Ð´Ð°Ñ Ð² Ð³ÑÐ°ÑÐ°Ñ" [On some extremal walks in graphs] (PDF), Upravlyaemye Sistemy (in Russian), 17: 76â79

^ Karlin, Anna R.; Klein, Nathan; Gharan, Shayan Oveis (30 August 2020). "A (Slightly) Improved Approximation Algorithm for Metric TSP". arXiv:2007.01409 [cs].

^ Jump up to: a b Karpinski, Lampis & Schmied (2015).

^ Berman & Karpinski (2006).

^ Kaplan et al. (2004).

^ Svensson, Ola; Tarnawski, Jakub; VÃ©gh, LÃ¡szlÃ³ A. (2018). "A constant-factor approximation algorithm for the asymmetric traveling salesman problem". Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing - STOC 2018. Stoc 2018. Los Angeles, CA, USA: ACM Press: 204â213. doi:10.1145/3188745.3188824. ISBNÂ 978-1-4503-5559-9. S2CIDÂ 12391033.

^ Traub, Vera; Vygen, Jens (8 June 2020). "An improved approximation algorithm for ATSP". Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing. Stoc 2020. Chicago, IL: ACM: 1â13. arXiv:1912.00670. doi:10.1145/3357713.3384233. ISBNÂ 978-1-4503-6979-4. S2CIDÂ 208527125.

^ Kosaraju, Park & Stein (1994).

^ Serdyukov (1984).

^ Hassin & Rubinstein (2000).

^ Macgregor, J. N.; Ormerod, T. (June 1996), "Human performance on the traveling salesman problem", Perception & Psychophysics, 58 (4): 527â539, doi:10.3758/BF03213088, PMIDÂ 8934685.

^ Dry, Matthew; Lee, Michael D.; Vickers, Douglas; Hughes, Peter (2006). "Human Performance on Visually Presented Traveling Salesperson Problems with Varying Numbers of Nodes". The Journal of Problem Solving. 1 (1). CiteSeerXÂ 10.1.1.360.9763. doi:10.7771/1932-6246.1004. ISSNÂ 1932-6246.

^ Rooij, Iris Van; Stege, Ulrike; Schactman, Alissa (1 March 2003). "Convex hull and tour crossings in the Euclidean traveling salesperson problem: Implications for human performance studies". Memory & Cognition. 31 (2): 215â220. CiteSeerXÂ 10.1.1.12.6117. doi:10.3758/bf03194380. ISSNÂ 0090-502X. PMIDÂ 12749463. S2CIDÂ 18989303.

^ MacGregor, James N.; Chu, Yun (2011). "Human Performance on the Traveling Salesman and Related Problems: A Review". The Journal of Problem Solving. 3 (2). doi:10.7771/1932-6246.1090. ISSNÂ 1932-6246.

^ MacGregor, James N.; Chronicle, Edward P.; Ormerod, Thomas C. (1 March 2004). "Convex hull or crossing avoidance? Solution heuristics in the traveling salesperson problem". Memory & Cognition. 32 (2): 260â270. doi:10.3758/bf03196857. ISSNÂ 0090-502X. PMIDÂ 15190718.

^ Vickers, Douglas; Mayo, Therese; Heitmann, Megan; Lee, Michael D; Hughes, Peter (2004). "Intelligence and individual differences in performance on three types of visually presented optimisation problems". Personality and Individual Differences. 36 (5): 1059â1071. doi:10.1016/s0191-8869(03)00200-9.

^ Kyritsis, Markos; Gulliver, Stephen R.; Feredoes, Eva (12 June 2017). "Acknowledging crossing-avoidance heuristic violations when solving the Euclidean travelling salesperson problem". Psychological Research. 82 (5): 997â1009. doi:10.1007/s00426-017-0881-7. ISSNÂ 0340-0727. PMIDÂ 28608230. S2CIDÂ 3959429.

^ Kyritsis, Markos; Blathras, George; Gulliver, Stephen; Varela, Vasiliki-Alexia (11 January 2017). "Sense of direction and conscientiousness as predictors of performance in the Euclidean travelling salesman problem". Heliyon. 3 (11): e00461. doi:10.1016/j.heliyon.2017.e00461. PMCÂ 5727545. PMIDÂ 29264418.

^ Kyritsis, Markos; Gulliver, Stephen R.; Feredoes, Eva; Din, Shahab Ud (December 2018). "Human behaviour in the Euclidean Travelling Salesperson Problem: Computational modelling of heuristics and figural effects". Cognitive Systems Research. 52: 387â399. doi:10.1016/j.cogsys.2018.07.027. S2CIDÂ 53761995.

^ Jump up to: a b MacGregor, James N.; Chu, Yun (2011), "Human performance on the traveling salesman and related problems: A review", Journal of Problem Solving, 3 (2), doi:10.7771/1932-6246.1090.

^ Journal of Problem Solving 1(1), 2006, retrieved 2014-06-06.

^ Gibson, Brett; Wilkinson, Matthew; Kelly, Debbie (1 May 2012). "Let the pigeon drive the bus: pigeons can plan future routes in a room". Animal Cognition. 15 (3): 379â391. doi:10.1007/s10071-011-0463-9. ISSNÂ 1435-9456. PMIDÂ 21965161. S2CIDÂ 14994429.

^ Jones, Jeff; Adamatzky, Andrew (2014), "Computation of the travelling salesman problem by a shrinking blob" (PDF), Natural Computing: 2, 13, arXiv:1303.4969, Bibcode:2013arXiv1303.4969J

^ "TSPLIB". comopt.ifi.uni-heidelberg.de. Retrieved 10 October 2020.

^ Geere, Duncan (26 April 2012). "'Travelling Salesman' movie considers the repercussions if P equals NP". Wired UK. Retrieved 26 April 2012.


References[edit]
.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li{margin-left:0;padding-left:3.2em;text-indent:-3.2em}.mw-parser-output .refbegin-hanging-indents ul,.mw-parser-output .refbegin-hanging-indents ul li{list-style:none}@media(max-width:720px){.mw-parser-output .refbegin-hanging-indents>ul>li{padding-left:1.6em;text-indent:-1.6em}}.mw-parser-output .refbegin-columns{margin-top:0.3em}.mw-parser-output .refbegin-columns ul{margin-top:0}.mw-parser-output .refbegin-columns li{page-break-inside:avoid;break-inside:avoid-column}
Applegate, D. L.; Bixby, R. M.; ChvÃ¡tal, V.; Cook, W. J. (2006), The Traveling Salesman Problem, ISBNÂ 978-0-691-12993-8.
Allender, Eric; BÃ¼rgisser, Peter; Kjeldgaard-Pedersen, Johan; Mitersen, Peter Bro (2007), "On the Complexity of Numerical Analysis" (PDF), SIAM J. Comput., 38 (5): 1987â2006, CiteSeerXÂ 10.1.1.167.5495, doi:10.1137/070697926.
Arora, Sanjeev (1998), "Polynomial time approximation schemes for Euclidean traveling salesman and other geometric problems" (PDF), Journal of the ACM, 45 (5): 753â782, doi:10.1145/290179.290180, MRÂ 1668147, S2CIDÂ 3023351.
Beardwood, J.; Halton, J.H.; Hammersley, J.M. (October 1959), "The Shortest Path Through Many Points", Proceedings of the Cambridge Philosophical Society, 55 (4): 299â327, Bibcode:1959PCPS...55..299B, doi:10.1017/s0305004100034095, ISSNÂ 0305-0041.
Bellman, R. (1960), "Combinatorial Processes and Dynamic Programming",  in Bellman, R.; Hall, M. Jr. (eds.), Combinatorial Analysis, Proceedings of Symposia in Applied Mathematics 10, American Mathematical Society, pp.Â 217â249.
Bellman, R. (1962), "Dynamic Programming Treatment of the Travelling Salesman Problem", J. Assoc. Comput. Mach., 9: 61â63, doi:10.1145/321105.321111, S2CIDÂ 15649582.
Berman, Piotr; Karpinski, Marek (2006), "8/7-approximation algorithm for (1,2)-TSP", Proc. 17th ACM-SIAM Symposium on Discrete Algorithms (SODA '06), pp.Â 641â648, CiteSeerXÂ 10.1.1.430.2224, doi:10.1145/1109557.1109627, ISBNÂ 978-0898716054, S2CIDÂ 9054176, ECCCÂ TR05-069.
Christofides, N. (1976), Worst-case analysis of a new heuristic for the travelling salesman problem, Technical Report 388, Graduate School of Industrial Administration, Carnegie-Mellon University, Pittsburgh.
Hassin, R.; Rubinstein, S. (2000), "Better approximations for max TSP", Information Processing Letters, 75 (4): 181â186, CiteSeerXÂ 10.1.1.35.7209, doi:10.1016/S0020-0190(00)00097-1.
Held, M.; Karp, R. M. (1962), "A Dynamic Programming Approach to Sequencing Problems", Journal of the Society for Industrial and Applied Mathematics, 10 (1): 196â210, doi:10.1137/0110015, hdl:10338.dmlcz/103900.
Kaplan, H.; Lewenstein, L.; Shafrir, N.; Sviridenko, M. (2004), "Approximation Algorithms for Asymmetric TSP by Decomposing Directed Regular Multigraphs", In Proc. 44th IEEE Symp. on Foundations of Comput. Sci, pp.Â 56â65.
Karpinski, M.; Lampis, M.; Schmied, R. (2015), "New Inapproximability bounds for TSP", Journal of Computer and System Sciences, 81 (8): 1665â1677, arXiv:1303.6437, doi:10.1016/j.jcss.2015.06.003
Kosaraju, S. R.; Park, J. K.; Stein, C. (1994), "Long tours and short superstrings'", Proc. 35th Ann. IEEE Symp. on Foundations of Comput. Sci, IEEE Computer Society, pp.Â 166â177.
Larson, Richard C.; Odoni, Amedeo R. (1981), "6.4.7: Applications of Network Models Â§ Routing Problems Â§Â§ Euclidean TSP", Urban Operations Research, Prentice-Hall, ISBNÂ 9780139394478, OCLCÂ 6331426.
Padberg, M.; Rinaldi, G. (1991), "A Branch-and-Cut Algorithm for the Resolution of Large-Scale Symmetric Traveling Salesman Problems", SIAM Review, 33: 60â100, doi:10.1137/1033004, S2CIDÂ 18516138.
Papadimitriou, Christos H. (1977), "The Euclidean traveling salesman problem is NP-complete", Theoretical Computer Science, 4 (3): 237â244, doi:10.1016/0304-3975(77)90012-3, MRÂ 0455550.
Papadimitriou, C. H.; Yannakakis, M. (1993), "The traveling salesman problem with distances one and two", Math. Oper. Res., 18: 1â11, doi:10.1287/moor.18.1.1.
Schrijver, Alexander (2005). "On the history of combinatorial optimization (till 1960)".  In K. Aardal; G.L. Nemhauser; R. Weismantel (eds.). Handbook of Discrete Optimization (PDF). Amsterdam: Elsevier. pp.Â 1â68.
Serdyukov, A. I. (1984), "An algorithm with an estimate for the traveling salesman problem of the maximum'", Upravlyaemye Sistemy, 25: 80â86.
Steinerberger, Stefan (2015), "New Bounds for the Traveling Salesman Constant", Advances in Applied Probability, 47 (1): 27â36, arXiv:1311.6338, Bibcode:2013arXiv1311.6338S, doi:10.1239/aap/1427814579, S2CIDÂ 119293287.
Woeginger, G.J. (2003), "Exact Algorithms for NP-Hard Problems: A Survey", Combinatorial Optimization â Eureka, You Shrink! Lecture notes in computer science, vol. 2570, Springer, pp.Â 185â207.

Further reading[edit]

Adleman, Leonard (1994), "Molecular Computation of Solutions To Combinatorial Problems" (PDF), Science, 266 (5187): 1021â4, Bibcode:1994Sci...266.1021A, CiteSeerXÂ 10.1.1.54.2565, doi:10.1126/science.7973651, PMIDÂ 7973651, archived from the original (PDF) on 6 February 2005
Babin, Gilbert; Deneault, StÃ©phanie; Laportey, Gilbert (2005), "Improvements to the Or-opt Heuristic for the Symmetric Traveling Salesman Problem", The Journal of the Operational Research Society, Cahiers du GERAD, Montreal: Group for Research in Decision Analysis, G-2005-02 (3): 402â407, CiteSeerXÂ 10.1.1.89.9953, JSTORÂ 4622707
Cook, William (2012). In Pursuit of the Traveling Salesman: Mathematics at the Limits of Computation. Princeton University Press. ISBNÂ 9780691152707.
Cook, William; Espinoza, Daniel; Goycoolea, Marcos (2007), "Computing with domino-parity inequalities for the TSP", INFORMS Journal on Computing, 19 (3): 356â365, doi:10.1287/ijoc.1060.0204
Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (31 July 2009). "35.2: The traveling-salesman problem". Introduction to Algorithms (2ndÂ ed.). MIT Press. pp.Â 1027â1033. ISBNÂ 9780262033848.
Dantzig, G. B.; Fulkerson, R.; Johnson, S. M. (1954), "Solution of a large-scale traveling salesman problem", Operations Research, 2 (4): 393â410, doi:10.1287/opre.2.4.393, JSTORÂ 166695, S2CIDÂ 44960960
Garey, Michael R.; Johnson, David S. (1979). "A2.3: ND22â24". Computers and Intractability: A Guide to the Theory of NP-completeness. W. H. Freeman. pp.Â 211â212. ISBNÂ 9780716710448.
Goldberg, D. E. (1989), "Genetic Algorithms in Search, Optimization & Machine Learning", Reading: Addison-Wesley, New York: Addison-Wesley, Bibcode:1989gaso.book.....G, ISBNÂ 978-0-201-15767-3
Gutin, G.; Yeo, A.; Zverovich, A. (15 March 2002). "Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP". Discrete Applied Mathematics. 117 (1â3): 81â86. doi:10.1016/S0166-218X(01)00195-0. ISSNÂ 0166-218X.
Gutin, G.; Punnen, A. P. (18 May 2007). The Traveling Salesman Problem and Its Variations. Springer US. ISBNÂ 9780387444598.
Johnson, D. S.; McGeoch, L. A. (1997), "The Traveling Salesman Problem: A Case Study in Local Optimization",  in Aarts, E. H. L.; Lenstra, J. K. (eds.), Local Search in Combinatorial Optimisation (PDF), John Wiley and Sons Ltd., pp.Â 215â310
Lawler, E. L.; Shmoys, D. B.; Kan, A. H. G. Rinnooy; Lenstra, J. K. (1985). The Traveling Salesman Problem. John Wiley & Sons, Incorporated. ISBNÂ 9780471904137.
MacGregor, J. N.; Ormerod, T. (1996), "Human performance on the traveling salesman problem", Perception & Psychophysics, 58 (4): 527â539, doi:10.3758/BF03213088, PMIDÂ 8934685, S2CIDÂ 38355042
Medvedev, Andrei; Lee, Michael; Butavicius, Marcus; Vickers, Douglas (1 February 2001). "Human performance on visually presented Traveling Salesman problems". Psychological Research. 65 (1): 34â45. doi:10.1007/s004260000031. ISSNÂ 1430-2772. PMIDÂ 11505612. S2CIDÂ 8986203.
Mitchell, J. S. B. (1999), "Guillotine subdivisions approximate polygonal subdivisions: A simple polynomial-time approximation scheme for geometric TSP, k-MST, and related problems", SIAM Journal on Computing, 28 (4): 1298â1309, doi:10.1137/S0097539796309764
Rao, S.; Smith, W. (1998). "Approximating geometrical graphs via 'spanners' and 'banyans'". STOC '98: Proceedings of the thirtieth annual ACM symposium on Theory of computing. pp.Â 540â550. CiteSeerXÂ 10.1.1.51.8676.
Rosenkrantz, Daniel J.; Stearns, Richard E.; Lewis, Philip M., II (1977). "An Analysis of Several Heuristics for the Traveling Salesman Problem". SIAM Journal on Computing. SIAM (Society for Industrial and Applied Mathematics). 6 (5): 563â581. doi:10.1137/0206041. S2CIDÂ 14764079.
Ross, I. M., Proulx, R. J., Karpenko, M. (2020). An optimal control theory for the traveling salesman problem and its variants. arXiv 2005.03186.
Walshaw, Chris (2000), A Multilevel Approach to the Travelling Salesman Problem, CMS Press
Walshaw, Chris (2001), A Multilevel Lin-Kernighan-Helsgaun Algorithm for the Travelling Salesman Problem, CMS Press

External links[edit]



Wikimedia Commons has media related to Traveling salesman problem.

Traveling Salesman Problem at the Wayback Machine (archived 17 December 2013) at University of Waterloo
TSPLIB at the University of Heidelberg
Traveling Salesman Problem by Jon McLoone at the Wolfram Demonstrations Project
TSP visualization tool
.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}hideAuthority control General
Integrated Authority File (Germany)
National libraries
United States





<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Travelling_salesman_problem&oldid=1068951455"
		Categories: Travelling salesman problemNP-complete problemsNP-hard problemsCombinatorial optimizationGraph algorithmsComputational problems in graph theoryHamiltonian paths and cyclesHidden categories: Webarchive template wayback linksCS1 Russian-language sources (ru)Articles with short descriptionShort description is different from WikidataUse Oxford spelling from August 2016Use dmy dates from November 2020CS1: long volume valueCommons category link is on WikidataArticles with GND identifiersArticles with LCCN identifiers
	
