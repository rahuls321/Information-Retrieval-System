
Title:
Biasâvariance tradeoff
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}Part of a series onMachine learningand data mining
showProblems
Classification
Clustering
Regression
Anomaly detection
Data Cleaning
AutoML
Association rules
Reinforcement learning
Structured prediction
Feature engineering
Feature learning
Online learning
Semi-supervised learning
Unsupervised learning
Learning to rank
Grammar induction

showSupervised learning.mw-parser-output .nobold{font-weight:normal}(classificationÂ â¢ regression) 
Decision trees
Ensembles
Bagging
Boosting
Random forest
k-NN
Linear regression
Naive Bayes
Artificial neural networks
Logistic regression
Perceptron
Relevance vector machine (RVM)
Support vector machine (SVM)

showClustering
BIRCH
CURE
Hierarchical
k-means
Expectationâmaximization (EM)
DBSCAN
OPTICS
Mean shift

showDimensionality reduction
Factor analysis
CCA
ICA
LDA
NMF
PCA
PGD
t-SNE

showStructured prediction
Graphical models
Bayes net
Conditional random field
Hidden Markov

showAnomaly detection
k-NN
Local outlier factor

showArtificial neural network
Autoencoder
Cognitive computing
Deep learning
DeepDream
Multilayer perceptron
RNN
LSTM
GRU
ESN
Restricted Boltzmann machine
GAN
SOM
Convolutional neural network
U-Net
Transformer
Vision
Spiking neural network
Memtransistor
Electrochemical RAM (ECRAM)

showReinforcement learning
Q-learning
SARSA
Temporal difference (TD)

hideTheory
Kernel machines
Biasâvariance tradeoff
Computational learning theory
Empirical risk minimization
Occam learning
PAC learning
Statistical learning
VC theory

showMachine-learning venues
NeurIPS
ICML
ML
JMLR
ArXiv:cs.LG

showRelated articles
Glossary of artificial intelligence
List of datasets for machine-learning research
Outline of machine learning
.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vte
Property of a model
.mw-parser-output .tmulti .thumbinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}Function and noisy data.spread=5spread=1spread=0.1A function (red) is approximated using radial basis functions (blue). Several trials are shown in each graph. For each trial, a few noisy data points are provided as a training set (top). For a wide spread (image 2) the bias is high: the RBFs cannot fully approximate the function (especially the central dip), but the variance between different trials is low. As spread decreases (image 3 and 4) the bias decreases: the blue curves more closely approximate the red. However, depending on the noise in different trials the variance between trials increases. In the lowermost image the approximated values for x=0 varies wildly depending on where the data points were located.
  Bias and variance as function of model complexity
In statistics and machine learning, the biasâvariance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters.
The biasâvariance dilemma or biasâvariance problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:[1][2]

The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).
The variance is an error from sensitivity to small fluctuations in the training set. High variance may result from an algorithm modeling the random noise in the training data (overfitting).
The biasâvariance decomposition is a way of analyzing a learning algorithm's expected generalization error with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, resulting from noise in the problem itself.

Contents

1 Motivation
2 Biasâvariance decomposition of mean squared error

2.1 Derivation


3 Approaches

3.1 k-nearest neighbors


4 Applications

4.1 In regression
4.2 In classification
4.3 In reinforcement learning
4.4 In human learning


5 See also
6 References
7 External links



Motivation[edit]

		
			
			
bias low,                                                                                        variance low

			
		
		
			
			
bias high,variance low:

			
		
		
			
			
bias low,variance high:

			
		
		
			
			
bias high,variance high:

			
		

The biasâvariance tradeoff is a central problem in supervised learning. Ideally, one wants to choose a model that both accurately captures the regularities in its training data, but also generalizes well to unseen data. Unfortunately, it is typically impossible to do both simultaneously. High-variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data. In contrast, algorithms with high bias typically produce simpler models that may fail to capture important regularities (i.e. underfit) in the data.
It is an often made fallacy[3][4] to assume that complex models must have high variance; High variance models are 'complex' in some sense, but the reverse needs not be true[clarification needed].
In addition, one has to be careful how to define complexity: In particular, the number of parameters used to describe the model is a poor measure of complexity. This is illustrated by an example adapted from:[5] The model 
  
    
      
        
          f
          
            a
            ,
            b
          
        
        (
        x
        )
        =
        a
        sin
        â¡
        (
        b
        x
        )
      
    
    {\displaystyle f_{a,b}(x)=a\sin(bx)}
  
 has only two parameters (
  
    
      
        a
        ,
        b
      
    
    {\displaystyle a,b}
  
) but it can interpolate any number of points by oscillating with a high enough frequency, resulting in both a high bias and high variance.
Intuitively, bias is reduced by using only local information, whereas variance can only be reduced by averaging over multiple observations, which inherently means using information from a larger region. For an enlightening example, see the section on k-nearest neighbors or the figure on the right.
To balance how much information is used from neighboring observations, a model can be smoothed via explicit regularization, such as shrinkage.

Biasâvariance decomposition of mean squared error[edit]
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Main article: Mean squared error
Suppose that we have a training set consisting of a set of points 
  
    
      
        
          x
          
            1
          
        
        ,
        â¦
        ,
        
          x
          
            n
          
        
      
    
    {\displaystyle x_{1},\dots ,x_{n}}
  
 and real values 
  
    
      
        
          y
          
            i
          
        
      
    
    {\displaystyle y_{i}}
  
 associated with each point 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
  
. We assume that there is a function with noise 
  
    
      
        y
        =
        f
        (
        x
        )
        +
        Îµ
      
    
    {\displaystyle y=f(x)+\varepsilon }
  
, where the noise, 
  
    
      
        Îµ
      
    
    {\displaystyle \varepsilon }
  
, has zero mean and variance 
  
    
      
        
          Ï
          
            2
          
        
      
    
    {\displaystyle \sigma ^{2}}
  
.
We want to find a function 
  
    
      
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
      
    
    {\displaystyle {\hat {f}}(x;D)}
  
, that approximates the true function 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  
 as well as possible, by means of some learning algorithm based on a training dataset (sample) 
  
    
      
        D
        =
        {
        (
        
          x
          
            1
          
        
        ,
        
          y
          
            1
          
        
        )
        â¦
        ,
        (
        
          x
          
            n
          
        
        ,
        
          y
          
            n
          
        
        )
        }
      
    
    {\displaystyle D=\{(x_{1},y_{1})\dots ,(x_{n},y_{n})\}}
  
. We make "as well as possible" precise by measuring the mean squared error between 
  
    
      
        y
      
    
    {\displaystyle y}
  
 and 
  
    
      
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
      
    
    {\displaystyle {\hat {f}}(x;D)}
  
: we want 
  
    
      
        (
        y
        â
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          )
          
            2
          
        
      
    
    {\displaystyle (y-{\hat {f}}(x;D))^{2}}
  
 to be minimal, both for 
  
    
      
        
          x
          
            1
          
        
        ,
        â¦
        ,
        
          x
          
            n
          
        
      
    
    {\displaystyle x_{1},\dots ,x_{n}}
  
 and for points outside of our sample. Of course, we cannot hope to do so perfectly, since the 
  
    
      
        
          y
          
            i
          
        
      
    
    {\displaystyle y_{i}}
  
 contain noise 
  
    
      
        Îµ
      
    
    {\displaystyle \varepsilon }
  
; this means we must be prepared to accept an irreducible error in any function we come up with.
Finding an 
  
    
      
        
          
            
              f
              ^
            
          
        
      
    
    {\displaystyle {\hat {f}}}
  
 that generalizes to points outside of the training set can be done with any of the countless algorithms used for supervised learning. It turns out that whichever function 
  
    
      
        
          
            
              f
              ^
            
          
        
      
    
    {\displaystyle {\hat {f}}}
  
 we select, we can decompose its expected error on an unseen sample 
  
    
      
        x
      
    
    {\displaystyle x}
  
 as follows:[6]:â34â[7]:â223â


  
    
      
        
          E
          
            D
            ,
            Îµ
          
        
        â¡
        
          
            [
          
        
        
          
            (
          
        
        y
        â
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            
              )
            
          
          
            2
          
        
        
          
            ]
          
        
        =
        
          
            (
          
        
        
          Bias
          
            D
          
        
        â¡
        
          
            [
          
        
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            ]
          
        
        
          
            
              )
            
          
          
            2
          
        
        +
        
          Var
          
            D
          
        
        â¡
        
          
            [
          
        
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            ]
          
        
        +
        
          Ï
          
            2
          
        
      
    
    {\displaystyle \operatorname {E} _{D,\varepsilon }{\Big [}{\big (}y-{\hat {f}}(x;D){\big )}^{2}{\Big ]}={\Big (}\operatorname {Bias} _{D}{\big [}{\hat {f}}(x;D){\big ]}{\Big )}^{2}+\operatorname {Var} _{D}{\big [}{\hat {f}}(x;D){\big ]}+\sigma ^{2}}
  

where


  
    
      
        
          Bias
          
            D
          
        
        â¡
        
          
            [
          
        
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            ]
          
        
        =
        
          E
          
            D
          
        
        â¡
        
          
            [
          
        
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            ]
          
        
        â
        f
        (
        x
        )
      
    
    {\displaystyle \operatorname {Bias} _{D}{\big [}{\hat {f}}(x;D){\big ]}=\operatorname {E} _{D}{\big [}{\hat {f}}(x;D){\big ]}-f(x)}
  

and


  
    
      
        
          Var
          
            D
          
        
        â¡
        
          
            [
          
        
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            ]
          
        
        =
        
          E
          
            D
          
        
        â¡
        [
        
          
            (
          
        
        
          E
          
            D
          
        
        â¡
        [
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        ]
        â
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            
              )
            
          
          
            2
          
        
        ]
        .
      
    
    {\displaystyle \operatorname {Var} _{D}{\big [}{\hat {f}}(x;D){\big ]}=\operatorname {E} _{D}[{\big (}\operatorname {E} _{D}[{\hat {f}}(x;D)]-{\hat {f}}(x;D){\big )}^{2}].}
  

The expectation ranges over different choices of the training set 
  
    
      
        D
        =
        {
        (
        
          x
          
            1
          
        
        ,
        
          y
          
            1
          
        
        )
        â¦
        ,
        (
        
          x
          
            n
          
        
        ,
        
          y
          
            n
          
        
        )
        }
      
    
    {\displaystyle D=\{(x_{1},y_{1})\dots ,(x_{n},y_{n})\}}
  
, all sampled from the same joint distribution 
  
    
      
        P
        (
        x
        ,
        y
        )
      
    
    {\displaystyle P(x,y)}
  
. The three terms represent:

the square of the bias of the learning method, which can be thought of as the error caused by the simplifying assumptions built into the method. E.g., when approximating a non-linear function 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  
 using a learning method for linear models, there will be error in the estimates 
  
    
      
        
          
            
              f
              ^
            
          
        
        (
        x
        )
      
    
    {\displaystyle {\hat {f}}(x)}
  
 due to this assumption;
the variance of the learning method, or, intuitively, how much the learning method 
  
    
      
        
          
            
              f
              ^
            
          
        
        (
        x
        )
      
    
    {\displaystyle {\hat {f}}(x)}
  
 will move around its mean;
the irreducible error 
  
    
      
        
          Ï
          
            2
          
        
      
    
    {\displaystyle \sigma ^{2}}
  
.
Since all three terms are non-negative, the irreducible error forms a lower bound on the expected error on unseen samples.[6]:â34â
The more complex the model 
  
    
      
        
          
            
              f
              ^
            
          
        
        (
        x
        )
      
    
    {\displaystyle {\hat {f}}(x)}
  
 is, the more data points it will capture, and the lower the bias will be. However, complexity will make the model "move" more to capture the data points, and hence its variance will be larger.

Derivation[edit]
The derivation of the biasâvariance decomposition for squared error proceeds as follows.[8][9] For notational convenience, we abbreviate 
  
    
      
        f
        =
        f
        (
        x
        )
      
    
    {\displaystyle f=f(x)}
  
, 
  
    
      
        
          
            
              f
              ^
            
          
        
        =
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
      
    
    {\displaystyle {\hat {f}}={\hat {f}}(x;D)}
  
 and we drop the 
  
    
      
        D
      
    
    {\displaystyle D}
  
 subscript on our expectation operators. First, recall that, by definition, for any random variable 
  
    
      
        X
      
    
    {\displaystyle X}
  
, we have


  
    
      
        Var
        â¡
        [
        X
        ]
        =
        E
        â¡
        [
        
          X
          
            2
          
        
        ]
        â
        E
        â¡
        [
        X
        
          ]
          
            2
          
        
        .
      
    
    {\displaystyle \operatorname {Var} [X]=\operatorname {E} [X^{2}]-\operatorname {E} [X]^{2}.}
  

Rearranging, we get:


  
    
      
        E
        â¡
        [
        
          X
          
            2
          
        
        ]
        =
        Var
        â¡
        [
        X
        ]
        +
        E
        â¡
        [
        X
        
          ]
          
            2
          
        
        .
      
    
    {\displaystyle \operatorname {E} [X^{2}]=\operatorname {Var} [X]+\operatorname {E} [X]^{2}.}
  

Since 
  
    
      
        f
      
    
    {\displaystyle f}
  
 is deterministic, i.e. independent of 
  
    
      
        D
      
    
    {\displaystyle D}
  
,


  
    
      
        E
        â¡
        [
        f
        ]
        =
        f
        .
      
    
    {\displaystyle \operatorname {E} [f]=f.}
  

Thus, given 
  
    
      
        y
        =
        f
        +
        Îµ
      
    
    {\displaystyle y=f+\varepsilon }
  
 and 
  
    
      
        E
        â¡
        [
        Îµ
        ]
        =
        0
      
    
    {\displaystyle \operatorname {E} [\varepsilon ]=0}
  
 (because 
  
    
      
        Îµ
      
    
    {\displaystyle \varepsilon }
  
 is noise), implies 
  
    
      
        E
        â¡
        [
        y
        ]
        =
        E
        â¡
        [
        f
        +
        Îµ
        ]
        =
        E
        â¡
        [
        f
        ]
        =
        f
        .
      
    
    {\displaystyle \operatorname {E} [y]=\operatorname {E} [f+\varepsilon ]=\operatorname {E} [f]=f.}
  

Also, since 
  
    
      
        Var
        â¡
        [
        Îµ
        ]
        =
        
          Ï
          
            2
          
        
        ,
      
    
    {\displaystyle \operatorname {Var} [\varepsilon ]=\sigma ^{2},}
  



  
    
      
        Var
        â¡
        [
        y
        ]
        =
        E
        â¡
        [
        (
        y
        â
        E
        â¡
        [
        y
        ]
        
          )
          
            2
          
        
        ]
        =
        E
        â¡
        [
        (
        y
        â
        f
        
          )
          
            2
          
        
        ]
        =
        E
        â¡
        [
        (
        f
        +
        Îµ
        â
        f
        
          )
          
            2
          
        
        ]
        =
        E
        â¡
        [
        
          Îµ
          
            2
          
        
        ]
        =
        Var
        â¡
        [
        Îµ
        ]
        +
        E
        â¡
        [
        Îµ
        
          ]
          
            2
          
        
        =
        
          Ï
          
            2
          
        
        +
        
          0
          
            2
          
        
        =
        
          Ï
          
            2
          
        
        .
      
    
    {\displaystyle \operatorname {Var} [y]=\operatorname {E} [(y-\operatorname {E} [y])^{2}]=\operatorname {E} [(y-f)^{2}]=\operatorname {E} [(f+\varepsilon -f)^{2}]=\operatorname {E} [\varepsilon ^{2}]=\operatorname {Var} [\varepsilon ]+\operatorname {E} [\varepsilon ]^{2}=\sigma ^{2}+0^{2}=\sigma ^{2}.}
  

Thus, since 
  
    
      
        Îµ
      
    
    {\displaystyle \varepsilon }
  
 and 
  
    
      
        
          
            
              f
              ^
            
          
        
      
    
    {\displaystyle {\hat {f}}}
  
 are independent, we can write


  
    
      
        
          
            
              
                E
                â¡
                
                  
                    [
                  
                
                (
                y
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
              
              
                
                =
                E
                â¡
                
                  
                    [
                  
                
                (
                f
                +
                Îµ
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
              
            
            
              
              
                
                =
                E
                â¡
                
                  
                    [
                  
                
                (
                f
                +
                Îµ
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                +
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
              
            
            
              
              
                
                =
                E
                â¡
                
                  
                    [
                  
                
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
                +
                E
                â¡
                [
                
                  Îµ
                  
                    2
                  
                
                ]
                +
                E
                â¡
                
                  
                    [
                  
                
                (
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
                +
                2
                E
                â¡
                
                  
                    [
                  
                
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                )
                Îµ
                
                  
                    ]
                  
                
                +
                2
                E
                â¡
                
                  
                    [
                  
                
                Îµ
                (
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                )
                
                  
                    ]
                  
                
                +
                2
                E
                â¡
                
                  
                    [
                  
                
                (
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                )
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                )
                
                  
                    ]
                  
                
              
            
            
              
              
                
                =
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                
                  )
                  
                    2
                  
                
                +
                E
                â¡
                [
                
                  Îµ
                  
                    2
                  
                
                ]
                +
                E
                â¡
                
                  
                    [
                  
                
                (
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
                +
                2
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                )
                E
                â¡
                [
                Îµ
                ]
                +
                2
                E
                â¡
                [
                Îµ
                ]
                E
                â¡
                
                  
                    [
                  
                
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  
                    ]
                  
                
                +
                2
                E
                â¡
                
                  
                    [
                  
                
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  
                    ]
                  
                
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                )
              
            
            
              
              
                
                =
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                
                  )
                  
                    2
                  
                
                +
                E
                â¡
                [
                
                  Îµ
                  
                    2
                  
                
                ]
                +
                E
                â¡
                
                  
                    [
                  
                
                (
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                â
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  )
                  
                    2
                  
                
                
                  
                    ]
                  
                
              
            
            
              
              
                
                =
                (
                f
                â
                E
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                ]
                
                  )
                  
                    2
                  
                
                +
                Var
                â¡
                [
                Îµ
                ]
                +
                Var
                â¡
                
                  
                    [
                  
                
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  
                    ]
                  
                
              
            
            
              
              
                
                =
                Bias
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  ]
                  
                    2
                  
                
                +
                Var
                â¡
                [
                Îµ
                ]
                +
                Var
                â¡
                
                  
                    [
                  
                
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  
                    ]
                  
                
              
            
            
              
              
                
                =
                Bias
                â¡
                [
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  ]
                  
                    2
                  
                
                +
                
                  Ï
                  
                    2
                  
                
                +
                Var
                â¡
                
                  
                    [
                  
                
                
                  
                    
                      f
                      ^
                    
                  
                
                
                  
                    ]
                  
                
                .
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\operatorname {E} {\big [}(y-{\hat {f}})^{2}{\big ]}&=\operatorname {E} {\big [}(f+\varepsilon -{\hat {f}})^{2}{\big ]}\\[5pt]&=\operatorname {E} {\big [}(f+\varepsilon -{\hat {f}}+\operatorname {E} [{\hat {f}}]-\operatorname {E} [{\hat {f}}])^{2}{\big ]}\\[5pt]&=\operatorname {E} {\big [}(f-\operatorname {E} [{\hat {f}}])^{2}{\big ]}+\operatorname {E} [\varepsilon ^{2}]+\operatorname {E} {\big [}(\operatorname {E} [{\hat {f}}]-{\hat {f}})^{2}{\big ]}+2\operatorname {E} {\big [}(f-\operatorname {E} [{\hat {f}}])\varepsilon {\big ]}+2\operatorname {E} {\big [}\varepsilon (\operatorname {E} [{\hat {f}}]-{\hat {f}}){\big ]}+2\operatorname {E} {\big [}(\operatorname {E} [{\hat {f}}]-{\hat {f}})(f-\operatorname {E} [{\hat {f}}]){\big ]}\\[5pt]&=(f-\operatorname {E} [{\hat {f}}])^{2}+\operatorname {E} [\varepsilon ^{2}]+\operatorname {E} {\big [}(\operatorname {E} [{\hat {f}}]-{\hat {f}})^{2}{\big ]}+2(f-\operatorname {E} [{\hat {f}}])\operatorname {E} [\varepsilon ]+2\operatorname {E} [\varepsilon ]\operatorname {E} {\big [}\operatorname {E} [{\hat {f}}]-{\hat {f}}{\big ]}+2\operatorname {E} {\big [}\operatorname {E} [{\hat {f}}]-{\hat {f}}{\big ]}(f-\operatorname {E} [{\hat {f}}])\\[5pt]&=(f-\operatorname {E} [{\hat {f}}])^{2}+\operatorname {E} [\varepsilon ^{2}]+\operatorname {E} {\big [}(\operatorname {E} [{\hat {f}}]-{\hat {f}})^{2}{\big ]}\\[5pt]&=(f-\operatorname {E} [{\hat {f}}])^{2}+\operatorname {Var} [\varepsilon ]+\operatorname {Var} {\big [}{\hat {f}}{\big ]}\\[5pt]&=\operatorname {Bias} [{\hat {f}}]^{2}+\operatorname {Var} [\varepsilon ]+\operatorname {Var} {\big [}{\hat {f}}{\big ]}\\[5pt]&=\operatorname {Bias} [{\hat {f}}]^{2}+\sigma ^{2}+\operatorname {Var} {\big [}{\hat {f}}{\big ]}.\end{aligned}}}
  

Finally, MSE loss function (or negative log-likelihood) is obtained by taking the expectation value over 
  
    
      
        x
        â¼
        P
      
    
    {\displaystyle x\sim P}
  
:


  
    
      
        
          MSE
        
        =
        
          E
          
            x
          
        
        â¡
        
          
            {
          
        
        
          Bias
          
            D
          
        
        â¡
        [
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          ]
          
            2
          
        
        +
        
          Var
          
            D
          
        
        â¡
        
          
            [
          
        
        
          
            
              f
              ^
            
          
        
        (
        x
        ;
        D
        )
        
          
            ]
          
        
        
          
            }
          
        
        +
        
          Ï
          
            2
          
        
        .
      
    
    {\displaystyle {\text{MSE}}=\operatorname {E} _{x}{\bigg \{}\operatorname {Bias} _{D}[{\hat {f}}(x;D)]^{2}+\operatorname {Var} _{D}{\big [}{\hat {f}}(x;D){\big ]}{\bigg \}}+\sigma ^{2}.}
  

Approaches[edit]
Dimensionality reduction and feature selection can decrease variance by simplifying models. Similarly, a larger training set tends to decrease variance. Adding features (predictors) tends to decrease bias, at the expense of introducing additional variance. Learning algorithms typically have some tunable parameters that control bias and variance; for example,

linear  and Generalized linear models can be regularized to decrease their variance at the cost of increasing their bias.[10]
In artificial neural networks, the variance increases and the bias decreases as the number of hidden units increase,[11] although this classical assumption has been the subject of recent debate.[4] Like in GLMs, regularization is typically applied.
In k-nearest neighbor models, a high value of k leads to high bias and low variance (see below).
In instance-based learning, regularization can be achieved varying the mixture of prototypes and exemplars.[12]
In decision trees, the depth of the tree determines the variance. Decision trees are commonly pruned to control variance.[6]:â307â
One way of resolving the trade-off is to use mixture models and ensemble learning.[13][14] For example, boosting combines many "weak" (high bias) models in an ensemble that has lower bias than the individual models, while bagging combines "strong" learners in a way that reduces their variance.  
Model validation methods such as cross-validation (statistics) can be used to tune models so as to optimize the trade-off. 

k-nearest neighbors[edit]
In the case of k-nearest neighbors regression, when the expectation is taken over the possible labeling of a fixed training set, a closed-form expression exists that relates the biasâvariance decomposition to the parameter k:[7]:â37,â223â


  
    
      
        E
        â¡
        [
        (
        y
        â
        
          
            
              f
              ^
            
          
        
        (
        x
        )
        
          )
          
            2
          
        
        â£
        X
        =
        x
        ]
        =
        
          
            (
            
              f
              (
              x
              )
              â
              
                
                  1
                  k
                
              
              
                â
                
                  i
                  =
                  1
                
                
                  k
                
              
              f
              (
              
                N
                
                  i
                
              
              (
              x
              )
              )
            
            )
          
          
            2
          
        
        +
        
          
            
              Ï
              
                2
              
            
            k
          
        
        +
        
          Ï
          
            2
          
        
      
    
    {\displaystyle \operatorname {E} [(y-{\hat {f}}(x))^{2}\mid X=x]=\left(f(x)-{\frac {1}{k}}\sum _{i=1}^{k}f(N_{i}(x))\right)^{2}+{\frac {\sigma ^{2}}{k}}+\sigma ^{2}}
  

where 
  
    
      
        
          N
          
            1
          
        
        (
        x
        )
        ,
        â¦
        ,
        
          N
          
            k
          
        
        (
        x
        )
      
    
    {\displaystyle N_{1}(x),\dots ,N_{k}(x)}
  
 are the k nearest neighbors of x in the training set. The bias (first term) is a monotone rising function of k, while the variance (second term) drops off as k is increased. In fact, under "reasonable assumptions" the bias of the first-nearest neighbor (1-NN) estimator vanishes entirely as the size of the training set approaches infinity.[11]

Applications[edit]
In regression[edit]
The biasâvariance decomposition forms the conceptual basis for regression regularization methods such as Lasso and ridge regression. Regularization methods introduce bias into the regression solution that can reduce variance considerably relative to the ordinary least squares (OLS) solution.  Although the OLS solution provides non-biased regression estimates, the lower variance solutions produced by regularization techniques provide superior MSE performance.

In classification[edit]
The biasâvariance decomposition was originally formulated for least-squares regression. For the case of classification under the 0-1 loss (misclassification rate), it is possible to find a similar decomposition.[15][16] Alternatively, if the classification problem can be phrased as probabilistic classification, then the expected squared error of the predicted probabilities with respect to the true probabilities can be decomposed as before.[17]

In reinforcement learning[edit]
Even though the biasâvariance decomposition does not directly apply in reinforcement learning, a similar tradeoff can also characterize generalization. When an agent has limited information on its environment, the suboptimality of an RL algorithm can be decomposed into the sum of two terms: a term related to an asymptotic bias and a term due to overfitting. The asymptotic bias is directly related to the learning algorithm (independently of the quantity of data) while the overfitting term comes from the fact that the amount of data is limited.[18]

In human learning[edit]
While widely discussed in the context of machine learning, the biasâvariance dilemma has been examined in the context of human cognition, most notably by Gerd Gigerenzer and co-workers in the context of learned heuristics. They have argued (see references below) that the human brain resolves the dilemma in the case of the typically sparse, poorly-characterised training-sets provided by experience by adopting high-bias/low variance heuristics. This reflects the fact that a zero-bias approach has poor generalisability to new situations, and also unreasonably presumes precise knowledge of the true state of the world. The resulting heuristics are relatively simple, but produce better inferences in a wider variety of situations.[19]
Geman et al.[11] argue that the biasâvariance dilemma implies that abilities such as generic object recognition cannot be learned from scratch, but require a certain degree of "hard wiring"   that is later tuned by experience.  This is because model-free approaches to inference require impractically large training sets if they are to avoid high variance.

See also[edit]
.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}
Accuracy and precision
Bias of an estimator
GaussâMarkov theorem
Hyperparameter optimization
Minimum-variance unbiased estimator
Model selection
Regression model validation
Supervised learning

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}Kohavi, Ron; Wolpert, David H. (1996). "Bias Plus Variance Decomposition for Zero-One Loss Functions". ICML. 96.

^ Luxburg, Ulrike V.; SchÃ¶lkopf, B. (2011). "Statistical learning theory: Models, concepts, and results". Handbook of the History of Logic. 10: Section 2.4.

^ Neal, Brady (2019). "On the Bias-Variance Tradeoff: Textbooks Need an Update". arXiv:1912.08286 [cs.LG].

^ Jump up to: a b Neal, Brady; Mittal, Sarthak; Baratin, Aristide; Tantia, Vinayak; Scicluna, Matthew; Lacoste-Julien, Simon; Mitliagkas, Ioannis (2018). "A Modern Take on the Bias-Variance Tradeoff in Neural Networks". arXiv:1810.08591 [cs.LG].

^ Vapnik, Vladimir (2000). The nature of statistical learning theory. New York: Springer-Verlag. ISBNÂ 978-1-4757-3264-1.

^ Jump up to: a b c James, Gareth; Witten, Daniela; Hastie, Trevor; Tibshirani, Robert (2013). An Introduction to Statistical Learning. Springer.

^ Jump up to: a b Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome H. (2009). The Elements of Statistical Learning. Archived from the original on 2015-01-26. Retrieved 2014-08-20.

^ Vijayakumar, Sethu (2007). "The BiasâVariance Tradeoff" (PDF). University of Edinburgh. Retrieved 19 August 2014.

^ Shakhnarovich, Greg (2011). "Notes on derivation of bias-variance decomposition in linear regression" (PDF). Archived from the original (PDF) on 21 August 2014. Retrieved 20 August 2014.

^ Belsley, David (1991). Conditioning diagnosticsÂ : collinearity and weak data in regression. New York (NY): Wiley. ISBNÂ 978-0471528890.

^ Jump up to: a b c Geman, Stuart; Bienenstock, Ãlie; Doursat, RenÃ© (1992). "Neural networks and the bias/variance dilemma" (PDF). Neural Computation. 4: 1â58. doi:10.1162/neco.1992.4.1.1.

^ Gagliardi, Francesco (May 2011). "Instance-based classifiers applied to medical databases: diagnosis and knowledge extraction". Artificial Intelligence in Medicine. 52 (3): 123â139. doi:10.1016/j.artmed.2011.04.002. PMIDÂ 21621400.

^ Ting, Jo-Anne; Vijaykumar, Sethu; Schaal, Stefan (2011). "Locally Weighted Regression for Control".  In Sammut, Claude; Webb, Geoffrey I. (eds.). Encyclopedia of Machine Learning (PDF). Springer. p.Â 615. Bibcode:2010eoml.book.....S.

^ Fortmann-Roe, Scott (2012). "Understanding the BiasâVariance Tradeoff".

^ Domingos, Pedro (2000). A unified bias-variance decomposition (PDF). ICML.

^ Valentini, Giorgio; Dietterich, Thomas G. (2004). "Biasâvariance analysis of support vector machines for the development of SVM-based ensemble methods" (PDF). Journal of Machine Learning Research. 5: 725â775.

^ Manning, Christopher D.; Raghavan, Prabhakar; SchÃ¼tze, Hinrich (2008). Introduction to Information Retrieval. Cambridge University Press. pp.Â 308â314.

^ Francois-Lavet, Vincent; Rabusseau, Guillaume; Pineau, Joelle; Ernst, Damien; Fonteneau, Raphael (2019). "On Overfitting and Asymptotic Bias in Batch Reinforcement Learning with Partial Observability". Journal of AI Research. 65: 1â30. doi:10.1613/jair.1.11478.

^ Gigerenzer, Gerd; Brighton, Henry (2009). "Homo Heuristicus: Why Biased Minds Make Better Inferences". Topics in Cognitive Science. 1 (1): 107â143. doi:10.1111/j.1756-8765.2008.01006.x. hdl:11858/00-001M-0000-0024-F678-0. PMIDÂ 25164802.


External links[edit]
MLU-Explain: The Bias Variance Tradeoff â An interactive visualization of the bias-variance tradeoff in LOESS Regression and K-Nearest Neighbors.




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Biasâvariance_tradeoff&oldid=1063504188"
		Categories: DilemmasModel selectionMachine learningStatistical classificationHidden categories: Articles with short descriptionShort description is different from WikidataWikipedia articles needing clarification from May 2021
	
