
Title:
Okapi BM25
Text:

		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}Not to be confused with Okapi.
Ranking function used by search engines
In information retrieval, Okapi BM25 (BM is an abbreviation of best matching) is a ranking function used by search engines to estimate the relevance of documents to a given search query. It is based on the probabilistic retrieval framework developed in the 1970s and 1980s by Stephen E. Robertson, Karen SpÃ¤rck Jones, and others.
The name of the actual ranking function is BM25. The fuller name, Okapi BM25, includes the name of the first system to use it, which was the Okapi information retrieval system, implemented at London's City University in the 1980s and 1990s. BM25 and its newer variants, e.g. BM25F (a version of BM25 that can take document structure and anchor text into account), represent state-of-the-art TF-IDF-like retrieval functions used in document retrieval.[citation needed]

Contents

1 The ranking function
2 IDF information theoretic interpretation
3 Modifications
4 References
5 General references
6 External links



The ranking function[edit]
BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document, regardless of their proximity within the document. It is a family of scoring functions with slightly different components and parameters. One of the most prominent instantiations of the function is as follows.
Given a query Q, containing keywords 
  
    
      
        
          q
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          q
          
            n
          
        
      
    
    {\displaystyle q_{1},...,q_{n}}
  
, the BM25 score of a document D is:


  
    
      
        
          score
        
        (
        D
        ,
        Q
        )
        =
        
          â
          
            i
            =
            1
          
          
            n
          
        
        
          IDF
        
        (
        
          q
          
            i
          
        
        )
        â
        
          
            
              f
              (
              
                q
                
                  i
                
              
              ,
              D
              )
              â
              (
              
                k
                
                  1
                
              
              +
              1
              )
            
            
              f
              (
              
                q
                
                  i
                
              
              ,
              D
              )
              +
              
                k
                
                  1
                
              
              â
              
                (
                
                  1
                  â
                  b
                  +
                  b
                  â
                  
                    
                      
                        
                          |
                        
                        D
                        
                          |
                        
                      
                      avgdl
                    
                  
                
                )
              
            
          
        
      
    
    {\displaystyle {\text{score}}(D,Q)=\sum _{i=1}^{n}{\text{IDF}}(q_{i})\cdot {\frac {f(q_{i},D)\cdot (k_{1}+1)}{f(q_{i},D)+k_{1}\cdot \left(1-b+b\cdot {\frac {|D|}{\text{avgdl}}}\right)}}}
  

where 
  
    
      
        f
        (
        
          q
          
            i
          
        
        ,
        D
        )
      
    
    {\displaystyle f(q_{i},D)}
  
 is 
  
    
      
        
          q
          
            i
          
        
      
    
    {\displaystyle q_{i}}
  
's term frequency in the document D, 
  
    
      
        
          |
        
        D
        
          |
        
      
    
    {\displaystyle |D|}
  
 is the length of the document D in words, and avgdl is the average document length in the text collection from which documents are drawn. 
  
    
      
        
          k
          
            1
          
        
      
    
    {\displaystyle k_{1}}
  
 and b are free parameters, usually chosen, in absence of an advanced optimization, as 
  
    
      
        
          k
          
            1
          
        
        â
        [
        1.2
        ,
        2.0
        ]
      
    
    {\displaystyle k_{1}\in [1.2,2.0]}
  
 and 
  
    
      
        b
        =
        0.75
      
    
    {\displaystyle b=0.75}
  
.[1] 
  
    
      
        
          IDF
        
        (
        
          q
          
            i
          
        
        )
      
    
    {\displaystyle {\text{IDF}}(q_{i})}
  
 is the IDF (inverse document frequency) weight of the query term 
  
    
      
        
          q
          
            i
          
        
      
    
    {\displaystyle q_{i}}
  
. It is usually computed as:


  
    
      
        
          IDF
        
        (
        
          q
          
            i
          
        
        )
        =
        ln
        â¡
        
          (
          
            
              
                
                  N
                  â
                  n
                  (
                  
                    q
                    
                      i
                    
                  
                  )
                  +
                  0.5
                
                
                  n
                  (
                  
                    q
                    
                      i
                    
                  
                  )
                  +
                  0.5
                
              
            
            +
            1
          
          )
        
      
    
    {\displaystyle {\text{IDF}}(q_{i})=\ln \left({\frac {N-n(q_{i})+0.5}{n(q_{i})+0.5}}+1\right)}
  

where  N is the total number of documents in the collection, and 
  
    
      
        n
        (
        
          q
          
            i
          
        
        )
      
    
    {\displaystyle n(q_{i})}
  
 is the number of documents containing 
  
    
      
        
          q
          
            i
          
        
      
    
    {\displaystyle q_{i}}
  
.
There are several interpretations for IDF and slight variations on its formula. In the original BM25 derivation, the IDF component is derived from the Binary Independence Model.

IDF information theoretic interpretation[edit]
Here is an interpretation from information theory. Suppose a query term 
  
    
      
        q
      
    
    {\displaystyle q}
  
 appears in 
  
    
      
        n
        (
        q
        )
      
    
    {\displaystyle n(q)}
  
 documents. Then a randomly picked document 
  
    
      
        D
      
    
    {\displaystyle D}
  
 will contain the term with probability 
  
    
      
        
          
            
              n
              (
              q
              )
            
            N
          
        
      
    
    {\displaystyle {\frac {n(q)}{N}}}
  
 (where 
  
    
      
        N
      
    
    {\displaystyle N}
  
 is again the cardinality of the set of documents in the collection). Therefore, the information content of the message "
  
    
      
        D
      
    
    {\displaystyle D}
  
 contains 
  
    
      
        q
      
    
    {\displaystyle q}
  
" is:


  
    
      
        â
        log
        â¡
        
          
            
              n
              (
              q
              )
            
            N
          
        
        =
        log
        â¡
        
          
            N
            
              n
              (
              q
              )
            
          
        
        .
      
    
    {\displaystyle -\log {\frac {n(q)}{N}}=\log {\frac {N}{n(q)}}.}
  

Now suppose we have two query terms 
  
    
      
        
          q
          
            1
          
        
      
    
    {\displaystyle q_{1}}
  
 and 
  
    
      
        
          q
          
            2
          
        
      
    
    {\displaystyle q_{2}}
  
. If the two terms occur in documents entirely independently of each other, then the probability of seeing both 
  
    
      
        
          q
          
            1
          
        
      
    
    {\displaystyle q_{1}}
  
 and 
  
    
      
        
          q
          
            2
          
        
      
    
    {\displaystyle q_{2}}
  
 in a randomly picked document 
  
    
      
        D
      
    
    {\displaystyle D}
  
 is:


  
    
      
        
          
            
              n
              (
              
                q
                
                  1
                
              
              )
            
            N
          
        
        â
        
          
            
              n
              (
              
                q
                
                  2
                
              
              )
            
            N
          
        
        ,
      
    
    {\displaystyle {\frac {n(q_{1})}{N}}\cdot {\frac {n(q_{2})}{N}},}
  

and the information content of such an event is:


  
    
      
        
          â
          
            i
            =
            1
          
          
            2
          
        
        log
        â¡
        
          
            N
            
              n
              (
              
                q
                
                  i
                
              
              )
            
          
        
        .
      
    
    {\displaystyle \sum _{i=1}^{2}\log {\frac {N}{n(q_{i})}}.}
  

With a small variation, this is exactly what is expressed by the IDF component of BM25.

Modifications[edit]
At the extreme values of the coefficient b BM25 turns into ranking functions known as BM11 (for 
  
    
      
        b
        =
        1
      
    
    {\displaystyle b=1}
  
) and BM15 (for 
  
    
      
        b
        =
        0
      
    
    {\displaystyle b=0}
  
).[2]
BM25F[3][4] is a modification of BM25 in which the document is considered to be composed from several fields (such as headlines, main text, anchor text) with possibly different degrees of importance, term relevance saturation and length normalization.
BM25+[5] is an extension of BM25. BM25+ was developed to address one deficiency of the standard BM25 in which the component of term frequency normalization by document length is not properly lower-bounded; as a result of this deficiency, long documents which do match the query term can often be scored unfairly by BM25 as having a similar relevancy to shorter documents that do not contain the query term at all. The scoring formula of BM25+ only has one additional free parameter 
  
    
      
        Î´
      
    
    {\displaystyle \delta }
  
 (a default value is 1.0 in absence of a training data) as compared with BM25:

  
    
      
        
          score
        
        (
        D
        ,
        Q
        )
        =
        
          â
          
            i
            =
            1
          
          
            n
          
        
        
          IDF
        
        (
        
          q
          
            i
          
        
        )
        â
        
          [
          
            
              
                
                  f
                  (
                  
                    q
                    
                      i
                    
                  
                  ,
                  D
                  )
                  â
                  (
                  
                    k
                    
                      1
                    
                  
                  +
                  1
                  )
                
                
                  f
                  (
                  
                    q
                    
                      i
                    
                  
                  ,
                  D
                  )
                  +
                  
                    k
                    
                      1
                    
                  
                  â
                  
                    (
                    
                      1
                      â
                      b
                      +
                      b
                      â
                      
                        
                          
                            
                              |
                            
                            D
                            
                              |
                            
                          
                          avgdl
                        
                      
                    
                    )
                  
                
              
            
            +
            Î´
          
          ]
        
      
    
    {\displaystyle {\text{score}}(D,Q)=\sum _{i=1}^{n}{\text{IDF}}(q_{i})\cdot \left[{\frac {f(q_{i},D)\cdot (k_{1}+1)}{f(q_{i},D)+k_{1}\cdot \left(1-b+b\cdot {\frac {|D|}{\text{avgdl}}}\right)}}+\delta \right]}
  

References[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ Christopher D. Manning, Prabhakar Raghavan, Hinrich SchÃ¼tze. An Introduction to Information Retrieval, Cambridge University Press, 2009, p. 233.

^ .mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}"The BM25 Weighting Scheme".

^ Hugo Zaragoza, Nick Craswell, Michael Taylor, Suchi Saria, and Stephen Robertson. Microsoft Cambridge at TREC-13: Web and HARD tracks. In Proceedings of TREC-2004.

^ Stephen Robertson & Hugo Zaragoza (2009). "The Probabilistic Relevance Framework: BM25 and Beyond". Foundations and Trends in Information Retrieval. 3 (4): 333â389. CiteSeerXÂ 10.1.1.156.5282. doi:10.1561/1500000019.

^ Yuanhua Lv and ChengXiang Zhai. Lower-bounding term frequency normalization. In Proceedings of CIKM'2011, pages 7-16.


General references[edit]
Stephen E. Robertson; Steve Walker; Susan Jones; Micheline Hancock-Beaulieu & Mike Gatford (November 1994). Okapi at TREC-3. Proceedings of the Third Text REtrieval Conference (TREC 1994). Gaithersburg, USA. {{cite conference}}: External link in |conference= (help)
Stephen E. Robertson; Steve Walker & Micheline Hancock-Beaulieu (November 1998). Okapi at TREC-7. Proceedings of the Seventh Text REtrieval Conference. Gaithersburg, USA. {{cite conference}}: External link in |conference= (help)
SpÃ¤rck Jones, K.; Walker, S.; Robertson, S. E. (2000). "A probabilistic model of information retrieval: Development and comparative experiments: Part 1". Information Processing & Management. 36 (6): 779â808. CiteSeerXÂ 10.1.1.134.6108. doi:10.1016/S0306-4573(00)00015-7.
SpÃ¤rck Jones, K.; Walker, S.; Robertson, S. E. (2000). "A probabilistic model of information retrieval: Development and comparative experiments: Part 2". Information Processing & Management. 36 (6): 809â840. doi:10.1016/S0306-4573(00)00016-9.
Stephen Robertson & Hugo Zaragoza (2009). "The Probabilistic Relevance Framework: BM25 and Beyond". Foundations and Trends in Information Retrieval. 3 (4): 333â389. CiteSeerXÂ 10.1.1.156.5282. doi:10.1561/1500000019.
External links[edit]
Robertson, Stephen; Zaragoza, Hugo (2009). The Probabilistic Relevance Framework: BM25 and Beyond (PDF). NOW Publishers, Inc. ISBNÂ 978-1-60198-308-4.




<img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" />
Retrieved from "https://en.wikipedia.org/w/index.php?title=Okapi_BM25&oldid=1008742667"
		Categories: Ranking functionsHidden categories: Articles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from October 2017CS1 errors: external links
	
